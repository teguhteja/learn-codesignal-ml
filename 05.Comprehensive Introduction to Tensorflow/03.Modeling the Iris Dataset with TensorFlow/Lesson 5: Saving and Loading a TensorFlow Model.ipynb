{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Welcome to this next lesson on Saving and Loading a TensorFlow Model. By the end of this lesson, you’ll be able to understand the importance of saving and loading models, how to save a trained TensorFlow model, load it from the saved file format, and validate the loaded model. This will give you a full cycle understanding and hands-on knowledge on how to handle models when training is done. With the provided code examples that train, save, load, and test a model, let's start our lesson!\n",
    "\n",
    "## The Importance of Saving and Loading Models\n",
    "When building machine learning models, it's important to save your models for various reasons. The most obvious one is efficiency - once you trained an intricate model that could take hours or even days to train, you want to keep the learned weights to avoid re-training. So, you’d save the model for reuse later without the need to retrain.\n",
    "\n",
    "Not only that, but the saved model can be shared with others - if you're collaborating with other professionals or even publishing your results, it aids in reproducibility of your results by others. Finally, when deploying a model to production you'll need to load the trained model to make predictions on new data.\n",
    "\n",
    "In the previous lessons, we trained a TensorFlow model. Now, let's save it!\n",
    "\n",
    "Quick Refresh: Loading Data and Training the Model\n",
    "Before we focus on saving our model, let's briefly revisit the key steps we took to load our data and train the model. Here's the code snippet we used to preprocess the Iris dataset:\n",
    "\n",
    "```Python\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "def load_preprocessed_data():\n",
    "    # Load the Iris dataset\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # One-hot encode the targets\n",
    "    encoder = OneHotEncoder(sparse_output=False).fit(y_train.reshape(-1, 1))\n",
    "    y_train_encoded = encoder.transform(y_train.reshape(-1, 1))\n",
    "    y_test_encoded = encoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train_encoded, y_test_encoded\n",
    "```\n",
    "\n",
    "And to train a model with our preprocessed data:\n",
    "\n",
    "```Python\n",
    "import tensorflow as tf\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "\n",
    "# Load preprocessed data\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=150, batch_size=5, validation_data=(X_test, y_test))\n",
    "```\n",
    "\n",
    "In summary:\n",
    "\n",
    "We began by loading the preprocessed data using the load_preprocessed_data() function from our data_preprocessing.py file to get our datasets: X_train, X_test, y_train, and y_test.\n",
    "We constructed a sequential model with TensorFlow's Keras API, with the input shape tailored to our dataset, including several dense layers with ReLU and Softmax activations.\n",
    "The model was then compiled using the Adam optimizer and the categorical crossentropy loss function, with accuracy as a metric.\n",
    "Finally, we trained the model for 150 epochs with a batch size of 5, validating its performance on the test data throughout the training process.\n",
    "With our training steps revisited, let's move on to saving our well-trained model.\n",
    "\n",
    "Saving TensorFlow Model\n",
    "After training your model, you can save the model's architecture, learned weights, and the configuration of the model's optimizer, so you can resume training exactly where you left off.\n",
    "\n",
    "To save a model in TensorFlow, the save() method of the Model class is used. This method accepts one argument: filepath, a string that specifies the path and the filename where the model should be saved.\n",
    "\n",
    "Using the provided solution code as guidance, let's save our model:\n",
    "\n",
    "```Python\n",
    "# Saving the model\n",
    "model.save('iris_model.keras')\n",
    "```\n",
    "By running this code, TensorFlow will write a file named iris_model.keras in the current working directory. This file is saved with the .keras extension, which is a standard format used by TensorFlow for saving complete models. The file contains everything we need to use the model: its architecture, its learned parameters, and the configuration of its optimizer.\n",
    "\n",
    "Loading TensorFlow Model\n",
    "Now that the model is saved, we can load it at any time without needing to train it again or write its architecture manually. To load a model in TensorFlow, we use the load_model() function from tensorflow.keras.models module.\n",
    "\n",
    "This function accepts one argument: filepath, a string specifying the path and the filename of the model file. The function returns the loaded model. Let's load the model using the code from the script:\n",
    "\n",
    "```Python\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Loading the model\n",
    "loaded_model = load_model('iris_model.keras')\n",
    "```\n",
    "And voila! You've just loaded a pretrained model. If you're thinking about using this model to make predictions, you're on the right track. But wait a second! Before using the loaded model for predictions, let's verify it first.\n",
    "\n",
    "## Verifying the Loaded Model\n",
    "To verify whether the loaded model works as expected, we evaluate it using the same test data that we used when training the original model. In TensorFlow, we can use the evaluate() method of the Model class to evaluate a model. This method accepts test data and labels as arguments and returns the loss value and metrics values for the model in test mode.\n",
    "\n",
    "Let's evaluate the loaded model using the test data:\n",
    "\n",
    "```Python\n",
    "# Verify the model by evaluating it on test data\n",
    "loss, accuracy = loaded_model.evaluate(X_test, y_test, verbose=False)\n",
    "print(f'Loaded Model - Test Accuracy: {accuracy}, Test Loss: {loss}')\n",
    "```\n",
    "The output of the above code will be:\n",
    "\n",
    "```sh\n",
    "Loaded Model - Test Accuracy: 0.9111, Test Loss: 0.2468\n",
    "```\n",
    "This indicates that the loaded model performs just as well as the initial model before it was saved, demonstrating successful model saving and loading operations.\n",
    "\n",
    "## Lesson Summary and Practice\n",
    "Congratulations! We traversed the unique topic of saving and loading TensorFlow models. We started by understanding why saving and loading models is important, moved onto the process of saving a trained TensorFlow model, and loaded it back only to validate the loaded model against meaningful criteria.\n",
    "\n",
    "This is pivotal in a real-world context, since saving and loading models allows us to reuse trained models without having to retrain them, enhancing efficiency, reproducibility, and sharing of models. A reminder that practice makes perfect, so get ready to dive into some hands-on activities to solidify the concepts covered in this lesson. Happy learning!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Saving and Loading Basics with TensorFlow\n",
    "\n",
    "In the previous lesson, you learned about saving and loading TensorFlow models. Now, let's put that knowledge into practice.\n",
    "\n",
    "Run the provided code to see how to save a trained model and load it for evaluation. Observe the results and understand the complete lifecycle of model handling.\n",
    "\n",
    "```py\n",
    "import tensorflow as tf\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load preprocessed data\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "model.fit(X_train, y_train, epochs=150, batch_size=5, validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "# Save the model\n",
    "model.save('iris_model.keras')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model('iris_model.keras')\n",
    "\n",
    "# Verify the model by evaluating it on test data\n",
    "loss, accuracy = loaded_model.evaluate(X_test, y_test, verbose=False)\n",
    "print(f'Loaded Model - Test Accuracy: {accuracy}, Test Loss: {loss}')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Saved Model's Name\n",
    "\n",
    "In this task, you will modify the code to save the model with any name you prefer using the .keras extension. Ensure that you load the model using the same name you've selected. Then run the code to confirm that the model is saved and loaded correctly.\n",
    "\n",
    "\n",
    "```py\n",
    "import tensorflow as tf\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load preprocessed data\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "model.fit(X_train, y_train, epochs=150, batch_size=5, validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "# Save the model with any name you want, use the .keras extension\n",
    "model.save('iris_model.keras')\n",
    "\n",
    "# Load the model with the same name you saved\n",
    "loaded_model = load_model('iris_model.keras')\n",
    "\n",
    "# Verify the model by evaluating it on test data\n",
    "loss, accuracy = loaded_model.evaluate(X_test, y_test, verbose=False)\n",
    "print(f'Loaded Model - Test Accuracy: {accuracy}, Test Loss: {loss}')\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Model Saving and Loading\n",
    "\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load preprocessed data\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "model.fit(X_train, y_train, epochs=150, batch_size=5, validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "# Saving the model with the correct filename\n",
    "model.save('iris_model.keras')  # Add .keras extension\n",
    "\n",
    "# Loading the model with the correct filename\n",
    "loaded_model = load_model('iris_model.keras')  # Add .keras extension\n",
    "\n",
    "# Verify the model by evaluating it on test data\n",
    "loss, accuracy = loaded_model.evaluate(X_test, y_test, verbose=False)\n",
    "print(f'Loaded Model - Test Accuracy: {accuracy}, Test Loss: {loss}')\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Save and Load in TensorFlow\n",
    "In the previous task, you practiced running code to save and load a TensorFlow model. Now, let's try implementing these functionalities yourself.\n",
    "\n",
    "Fill in the missing parts to save the trained model and then load it using the save() and load_model() functions from TensorFlow. This will help solidify your understanding of saving and loading models.\n",
    "\n",
    "Fill in the missing parts denoted by TODO comments.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load preprocessed data\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "model.fit(X_train, y_train, epochs=150, batch_size=5, validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "# TODO: Save the model to a file named 'iris_model.keras'\n",
    "model.save('iris_model.keras')  # Save the trained model\n",
    "\n",
    "# TODO: Load the saved model from the file 'iris_model.keras'\n",
    "loaded_model = load_model('iris_model.keras')  # Load the saved model\n",
    "\n",
    "# TODO: Verify the model by evaluating it on test data\n",
    "loss, accuracy = loaded_model.evaluate(X_test, y_test, verbose=False)\n",
    "print(f'Loaded Model - Test Accuracy: {accuracy}, Test Loss: {loss}')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save, Load, and Verify Models\n",
    "Great work on the previous exercises! You've practiced and honed your skills in saving and loading TensorFlow models.\n",
    "\n",
    "In this final practice, you will consolidate your learning by writing the implementation almost from scratch. With a defined model ready, the steps of this task include compiling, training, saving, and then loading a model. Finally, evaluate the loaded model to verify its performance.\n",
    "\n",
    "This practice wraps up everything you've learned and offers a hands-on opportunity to apply these concepts.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load preprocessed data\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# TODO: Compile the model\n",
    "# - Use the 'adam' optimizer\n",
    "# - Set loss to 'categorical_crossentropy'\n",
    "# - Set metrics to ['accuracy']\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# TODO: Train the model\n",
    "# - Train for 150 epochs\n",
    "# - Set batch_size=5 \n",
    "# - Use the test sets as validation data\n",
    "# - Run with verbose=0\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=5, validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "# TODO: Save the model to a file named 'iris_model.keras'\n",
    "model.save('iris_model.keras')\n",
    "\n",
    "# TODO: Load the saved model from the file 'iris_model.keras'\n",
    "loaded_model = load_model('iris_model.keras')\n",
    "\n",
    "# TODO: Verify the loaded model by evaluating it on test data\n",
    "loss, accuracy = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Loaded Model - Test Accuracy: {accuracy}, Test Loss: {loss}')\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
