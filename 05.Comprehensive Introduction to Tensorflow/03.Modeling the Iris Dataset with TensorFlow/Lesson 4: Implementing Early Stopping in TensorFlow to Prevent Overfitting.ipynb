{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Welcome back! In our previous lessons, we preprocessed the Iris dataset and built a multi-class classification model using TensorFlow. Now, we're going to explore the concept of Early Stopping and learn how to implement it in TensorFlow.\n",
    "\n",
    "In machine learning, early stopping is a form of regularization that helps us prevent overfitting by stopping the training process once the model's performance on validation data starts showing signs of degradation. The goal of this lesson is to provide you with a deeper understanding of early stopping and guide you step-by-step on how to include Early Stopping in your model training process using TensorFlow.\n",
    "\n",
    "## Understanding Early Stopping\n",
    "Before we get into the code, it's important to understand what early stopping is and why it is vital.\n",
    "\n",
    "Overfitting occurs when a model performs exceptionally well on the training data but fails to generalize well to unseen data. In other words, it has learned the training data too well, including its noise and outliers aspects. On the contrary, underfitting is when the model does not perform well even on the training data because it has not learned the underlying pattern of the data.\n",
    "\n",
    "Early stopping provides a straightforward solution to overfitting by keeping a tab on the model's performance on the validation data during model training. If it sees the model's performance degrading (indicating overfitting), it stops the training process. This technique prevents the model from learning the training data’s noise and outliers too precisely, which results in a robust model that can generalize well to unseen data.\n",
    "\n",
    "\n",
    "## Recap: Loading Data and Defining the Model\n",
    "Before we dive into implementing early stopping in our model, let's quickly recap the steps we took to preprocess, load our data and define the model in the previous lessons. Here’s the code we used to preprocess the Iris dataset:\n",
    "\n",
    "```Python\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "def load_preprocessed_data():\n",
    "    # Load the Iris dataset\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # One-hot encode the targets\n",
    "    encoder = OneHotEncoder(sparse_output=False).fit(y_train.reshape(-1, 1))\n",
    "    y_train_encoded = encoder.transform(y_train.reshape(-1, 1))\n",
    "    y_test_encoded = encoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train_encoded, y_test_encoded\n",
    "```\n",
    "Following that, we loaded the data and defined a model designed to fit it:\n",
    "\n",
    "```Python\n",
    "import tensorflow as tf\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "\n",
    "# Load preprocessed data\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "```\n",
    "In summary:\n",
    "\n",
    "1. We started by loading the preprocessed data using our custom function load_preprocessed_data() to obtain our training and testing datasets: X_train, X_test, y_train, and y_test.\n",
    "2. We defined a sequential model using TensorFlow's Keras API, with input shapes matching our dataset and various dense layers featuring ReLU and Softmax activations.\n",
    "3. The model was compiled with the Adam optimizer and categorical crossentropy loss function, and we included accuracy as a metric.\n",
    "Now that we are refreshed on the data loading and model definition steps, let's proceed to implementing early stopping in TensorFlow.\n",
    "\n",
    "\n",
    "## Implementing Early Stopping in TensorFlow\n",
    "Let's write some code now. TensorFlow provides a simple way to implement early stopping via the EarlyStopping callback, which is a set of functions to be applied at different stages of training. We can specify the performance measure to monitor (monitor), the number of epochs with no improvement after which training will be stopped (patience), and whether to restore model weights from the epoch with the best value of the monitored quantity (restore_best_weights).\n",
    "\n",
    "Here's how we can use this in our TensorFlow model:\n",
    "\n",
    "```Python\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Initialize early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=150,\n",
    "                    batch_size=5,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=0)\n",
    "```\n",
    "With these few lines of code, we've added an early stopping mechanism to our model. The model will cease training if it doesn't observe an improvement in val_loss for 10 consecutive epochs. Upon stopping, it will restore the best weights observed during training.\n",
    "\n",
    "\n",
    "## Result Interpretation and Debugging\n",
    "After integrating early stopping into our model, we need to know how to interpret the results and debug if necessary. The fit method of a model returns a history object. The history.history attribute is a dictionary recording training/validation loss values and metrics values at successive epochs, which can be used to analyze the training process.\n",
    "\n",
    "Let's print out the final training and validation loss, as well as the epoch in which early stopping was triggered:\n",
    "\n",
    "```Python\n",
    "# Print the final training and validation loss\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "stopped_epoch = early_stopping.stopped_epoch\n",
    "\n",
    "print(f\"Final Training Loss: {final_train_loss:.4f}\")\n",
    "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
    "print(f\"Early stopping occurred at epoch: {stopped_epoch + 1}\")\n",
    "```\n",
    "\n",
    "The output of the above code will be:\n",
    "\n",
    "```s\n",
    "\n",
    "Final Training Loss: 0.0476\n",
    "Final Validation Loss: 0.1256\n",
    "Early stopping occurred at epoch: 100\n",
    "```\n",
    "\n",
    "This output indicates the effectiveness of using early stopping. We can observe that the training was halted at epoch 100, preventing further overfitting and potentially saving computational resources. It also automatically restored the best weights achieved during training, ensuring the model is as effective as possible when making predictions on unseen data.\n",
    "\n",
    "## End of Lesson Summary\n",
    "Great job! Today you expanded your knowledge of TensorFlow and the techniques used in machine learning to optimize model training. You now know how to use early stopping to prevent overfitting, keep your model robust, and save computational resources by stopping the training when it's no longer beneficial. You learned how to add early stopping to the model training process and how to inspect the results to understand its workings.\n",
    "\n",
    "In the given practice exercises, you'll get a chance to cement this newfound knowledge, so let's dive right in! In machine learning, it's important to understand how various techniques work, but even more crucial to understand when and why to use them. Through these exercises, you'll learn to make informed decisions and develop more reliable and robust models. Happy modeling!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stop on Training with TensorFlow\n",
    "\n",
    "Great progress so far! In this task, you will be running code that implements early stopping in TensorFlow to prevent overfitting.\n",
    "\n",
    "The model is trained on the Iris dataset, and the training process will stop if the validation loss does not improve for 10 consecutive epochs, with the best weights restored.\n",
    "\n",
    "Running this code will help you understand how early stopping works in practice. No changes to the code are needed; simply execute it to observe the results.\n",
    "\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load preprocessed data\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Initialize early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=150,\n",
    "                    batch_size=5,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=0)\n",
    "\n",
    "# Print the final training and validation loss\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "stopped_epoch = early_stopping.stopped_epoch\n",
    "\n",
    "print(f\"Final Training Loss: {final_train_loss:.4f}\")\n",
    "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
    "print(f\"Early stopping occurred at epoch: {stopped_epoch + 1}\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify Early Stopping Parameters\n",
    "\n",
    "Great job understanding how early stopping works in TensorFlow. Now, let's apply what you've learned by making some changes.\n",
    "\n",
    "In this task, you will modify the code to change the patience parameter in the early stopping mechanism to 5. Then run the code to see how changing this parameter can affect the number of epochs executed.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load preprocessed data\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Initialize early stopping callback with patience set to 5\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=150,\n",
    "                    batch_size=5,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=0)\n",
    "\n",
    "# Print the final training and validation loss\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "stopped_epoch = early_stopping.stopped_epoch\n",
    "\n",
    "print(f\"Final Training Loss: {final_train_loss:.4f}\")\n",
    "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
    "print(f\"Early stopping occurred at epoch: {stopped_epoch + 1}\")\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix TensorFlow Early Stopping Code\n",
    "\n",
    "You've successfully learned how to implement early stopping to prevent overfitting in TensorFlow. Now, let's put your skills to the test with a debugging task.\n",
    "\n",
    "Below is the code designed to train a model using early stopping by monitoring the validation loss, but something isn't right. A common mistake has been introduced, and your task is to find and correct it.\n",
    "\n",
    "Debugging is a critical skill that will help you understand TensorFlow better.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load preprocessed data\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Initialize early stopping callback monitoring the validation loss\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=150,\n",
    "                    batch_size=5,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=0)\n",
    "\n",
    "# Print the final training and validation loss\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "stopped_epoch = early_stopping.stopped_epoch\n",
    "\n",
    "print(f\"Final Training Loss: {final_train_loss:.4f}\")\n",
    "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
    "print(f\"Early stopping occurred at epoch: {stopped_epoch + 1}\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Early Stopping Callback\n",
    "\n",
    "You've made great progress! Previously, you learned how to implement early stopping to prevent overfitting in TensorFlow. Now, let's practice implementing part of that process.\n",
    "\n",
    "In this exercise, you will complete the code to initialize the early stopping mechanism used in the model training process, following some specific requirements.\n",
    "\n",
    "Fill in the missing parts denoted by TODO comments in the provided starter code.\n",
    "\n",
    "```py\n",
    "import tensorflow as tf\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load preprocessed data\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# TODO: Initialize early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',      # Monitor validation loss\n",
    "    patience=10,             # Number of epochs with no improvement to wait before stopping\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")\n",
    "\n",
    "# TODO: Train the model with early stopping callback\n",
    "history = model.fit(X_train, \n",
    "                    y_train,\n",
    "                    epochs=150,           # Train for a maximum of 150 epochs\n",
    "                    batch_size=5,         # Use a batch size of 5\n",
    "                    validation_data=(X_test, y_test),  # Use the test set for validation\n",
    "                    callbacks=[early_stopping],  # Include early stopping callback\n",
    "                    verbose=0)            # Set verbose to 0 for no output during training\n",
    "\n",
    "# TODO: Print the final training and validation loss\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "\n",
    "print(f\"Final Training Loss: {final_train_loss:.4f}\")\n",
    "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
    "\n",
    "# TODO: Print the epoch at which early stopping occurred\n",
    "stopped_epoch = early_stopping.stopped_epoch\n",
    "print(f\"Early stopping occurred at epoch: {stopped_epoch + 1}\")\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Early Stopping in TensorFlow"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
