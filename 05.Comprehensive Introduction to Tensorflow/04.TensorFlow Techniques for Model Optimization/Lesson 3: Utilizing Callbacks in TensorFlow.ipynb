{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Overview\n",
    "Welcome! Today's agenda is focused on delving deeper into an important aspect of model optimization using TensorFlow - Callbacks. We'll explore what they are, their importance, and showcase the implementation of different types of callbacks in TensorFlow. By the end of this lesson, your understanding of callbacks and how to utilize them in TensorFlow would have notably improved. Let's get started!\n",
    "\n",
    "## Understanding Callbacks\n",
    "Let's first understand what callbacks are. In TensorFlow, a callback is a Python class that you can customize to perform specific actions at different stages of training, like at the beginning or end of a batch or epoch, during testing, and predicting. They are useful for monitoring internal states and statistics of the model while it is being trained, making it easier to manage and optimize the training process. For example, you are already familiar with the EarlyStopping callback from a previous lesson, which stops training when a monitored metric stops improving.\n",
    "\n",
    "The primary use of callbacks is during the model training phase, where they are passed as a list to the .fit() method of the Sequential or Model classes. They allow custom actions to occur at different intervals of training for purposes such as stopping training early under certain conditions, saving model weights to the disk, adjusting the learning rate values, or even custom actions defined by users.\n",
    "\n",
    "Callbacks can be a helpful tool, especially when training larger models, as they provide us with more control over the training process.\n",
    "\n",
    "In this lesson, we will cover three important types of callbacks:\n",
    "\n",
    "1. ModelCheckpoint: This callback allows you to save the model's state at different stages of training, ensuring you don't lose progress and can store the best-performing model.\n",
    "\n",
    "2. LearningRateScheduler: This callback provides a mechanism to adjust the learning rate dynamically based on the epoch, helping the model converge more efficiently.\n",
    "\n",
    "3. Custom Callbacks: You will learn how to create your custom actions to be executed during the training process, offering flexibility for unique requirements.\n",
    "\n",
    "By mastering these callbacks, you will have greater flexibility and control over your model training workflows.\n",
    "\n",
    "## Recap: Loading Data and Defining the Model\n",
    "Before we delve into the use of callbacks, let‚Äôs recap the steps to load our preprocessed data and define our model. We will use a function from a secondary file named data_preprocessing.py to load the preprocessed Iris dataset, which we learned in previous lessons:\n",
    "\n",
    "```Python\n",
    "import tensorflow as tf\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "\n",
    "# Load preprocessed Iris dataset\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "With the data loaded and the model defined and compiled, we are ready to explore the different types of callbacks.\n",
    "\n",
    "## Checkpointing Models\n",
    "The first type of callback we'll explore is ModelCheckpoint. This callback can save the model state at the end of every epoch if desired, or when certain conditions are met (e.g., when the monitored metric improves), creating a checkpoint at various stages of training.\n",
    "\n",
    "Here is an example of how ModelCheckpoint is used:\n",
    "\n",
    "```Python\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath='best_model.keras', save_best_only=True, monitor='val_accuracy')\n",
    "```\n",
    "The filepath parameter can be a string that contains a file path where the model checkpoint would be saved. A new model is saved to this path at the end of each epoch.\n",
    "\n",
    "The save_best_only parameter, if set to True, would make the current model saved be replaced only if the monitor metric has improved, ensuring that only the best model is saved. If set to False, a new model will be saved in every epoch.\n",
    "\n",
    "The monitor is essentially the metric that you want to observe. If save_best_only=True, then the current model is saved only if this metric improves.\n",
    "\n",
    "## Scheduler for Learning Rate\n",
    "The second callback is LearningRateScheduler. This callback adjusts the learning rate according to a schedule that you define. Let's explore this through an example:\n",
    "\n",
    "```Python\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.1\n",
    "                \n",
    "learning_rate_scheduler = LearningRateScheduler(scheduler)\n",
    "```\n",
    "\n",
    "The LearningRateScheduler callback in Keras takes a function scheduler as an argument. This function should have two parameters: the current epoch (integer, indexed from 0) and the current learning rate, and should return the learning rate for the next epoch. LearningRateScheduler automatically passes the epoch number and current learning rate to the scheduler function during training.\n",
    "\n",
    "In the above example, you can see that we are maintaining the learning rate for the first ten epochs. However, for epochs thereafter, the learning rate is reduced by 90%. This is known as learning rate decay and it's a common technique to ensure that the model converges.\n",
    "\n",
    "## Custom Callbacks\n",
    "In addition to built-in callbacks, you can create your own callbacks. This offers a high level of flexibility to create and experiment with new strategies. The custom callback class looks for specific function names that correspond to different stages of the training process, one example being the on_epoch_end. Let's see how to create a custom callback, where we print the accuracy at the end of each epoch:\n",
    "\n",
    "```Python\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class CustomCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"End of epoch {epoch + 1}. Accuracy: {logs['accuracy']:.4f}\")\n",
    "               \n",
    "custom_callback = CustomCallback()\n",
    "```\n",
    "\n",
    "Here, we define a Callback subclass and then define the method on_epoch_end, which gets called at the end of every epoch. The method automatically receives two parameters: epoch, which is the current epoch number, and logs, which is a dictionary that contains the loss value along with all of the metrics we are using.\n",
    "\n",
    "The output of this callback during model training will be:\n",
    "\n",
    "```sh\n",
    "End of epoch 1. Accuracy: 0.5200\n",
    "End of epoch 2. Accuracy: 0.5500\n",
    "End of epoch 3. Accuracy: 0.5400\n",
    "End of epoch 4. Accuracy: 0.5500\n",
    "End of epoch 5. Accuracy: 0.5400\n",
    "```\n",
    "\n",
    "This output demonstrates how the custom callback prints the accuracy at the end of each epoch, providing real-time feedback on the training performance of the model; you could also print other metrics or execute different custom actions.\n",
    "\n",
    "## Using Callbacks in Model\n",
    "Now, we are ready to apply these three callbacks to our model during training. We pass a list of callbacks to our model.fit() function, like so:\n",
    "\n",
    "```Python\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_test, y_test), \n",
    "    epochs=50, \n",
    "    callbacks=[model_checkpoint, learning_rate_scheduler, custom_callback],\n",
    "    verbose=0)\n",
    "```\n",
    "With this approach, all three callbacks will be used during training. They will save the model at the end of each epoch, adjust the learning rate according to the scheduler, and fire on our custom callback's method at the end of each epoch.\n",
    "\n",
    "## Lesson Summary and Next Steps\n",
    "Excellent work! We've covered what callbacks are and how they can be used to customize and control the training process in TensorFlow. We've focused on how to use the ModelCheckpoint to save our model, how to use the LearningRateScheduler to adjust the learning rate, and how to create and use a custom callback to execute custom actions.\n",
    "\n",
    "The ability to calibrate and control TensorFlow training processes using callbacks is a powerful skill. Now you're ready to take on the practice tasks where your understanding of callbacks and their implementations will be fortified. Through these tasks, your TensorFlow skills will be further refined. Keep going and happy learning!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing TensorFlow Callbacks\n",
    "\n",
    "Great progress so far! This task allows you to see how various TensorFlow callbacks such as ModelCheckpoint, LearningRateScheduler, and a custom callback work to improve model training control.\n",
    "\n",
    "Run the code and observe how these callbacks are implemented with the training process. No changes are needed; simply execute it and see the results.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback\n",
    "\n",
    "# Load preprocessed Iris dataset\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define learning rate schedule\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.1\n",
    "\n",
    "# Custom callback to log epoch number\n",
    "class CustomCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch + 1}. Accuracy: {logs['accuracy']:.4f}\")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath='best_model.keras', save_best_only=True, monitor='val_accuracy')\n",
    "learning_rate_scheduler = LearningRateScheduler(scheduler)\n",
    "custom_callback = CustomCallback()\n",
    "\n",
    "# Train the model with the callbacks\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_test, y_test), \n",
    "    epochs=50, \n",
    "    callbacks=[model_checkpoint, learning_rate_scheduler, custom_callback],\n",
    "    verbose=0)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying TensorFlow Callbacks\n",
    "\n",
    "Great progress so far! Let's build upon what you've learned. In this task, you'll make the following modifications on the implemented callbacks.\n",
    "\n",
    "1- Change the scheduler to update the learning rate if the epoch is less than 5.\n",
    "\n",
    "2- Modify the custom callback to print the validation accuracy instead of the training accuracy at the end of each epoch.\n",
    "\n",
    "3- Change the monitor parameter of ModelCheckpoint to 'accuracy' instead of 'val_accuracy'.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback\n",
    "\n",
    "# Load preprocessed Iris dataset\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define learning rate schedule\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.1\n",
    "\n",
    "# Custom callback to log epoch number\n",
    "class CustomCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch + 1}. Accuracy: {logs['accuracy']:.4f}\")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath='best_model.keras', save_best_only=True, monitor='val_accuracy')\n",
    "learning_rate_scheduler = LearningRateScheduler(scheduler)\n",
    "custom_callback = CustomCallback()\n",
    "\n",
    "# Train the model with the callbacks\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_test, y_test), \n",
    "    epochs=50, \n",
    "    callbacks=[model_checkpoint, learning_rate_scheduler, custom_callback],\n",
    "    verbose=0)\n",
    "\n",
    "```\n",
    "## answer\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback\n",
    "\n",
    "# Load preprocessed Iris dataset\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define learning rate schedule\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return lr * 0.1  # Adjust learning rate for the first 5 epochs\n",
    "    else:\n",
    "        return lr\n",
    "\n",
    "# Custom callback to log epoch number\n",
    "class CustomCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch + 1}. Validation Accuracy: {logs['val_accuracy']:.4f}\")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath='best_model.keras', save_best_only=True, monitor='accuracy')\n",
    "learning_rate_scheduler = LearningRateScheduler(scheduler)\n",
    "custom_callback = CustomCallback()\n",
    "\n",
    "# Train the model with the callbacks\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_test, y_test), \n",
    "    epochs=50, \n",
    "    callbacks=[model_checkpoint, learning_rate_scheduler, custom_callback],\n",
    "    verbose=0)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug TensorFlow Callbacks\n",
    "\n",
    "Having mastered the basics, let's strengthen your skills with a debugging challenge.\n",
    "\n",
    "Below is some code showcasing how to implement ModelCheckpoint, LearningRateScheduler, and custom callbacks for a TensorFlow model. However, a few bugs have been introduced to all the three callbacks.\n",
    "\n",
    "Your task is to identify and correct these bugs to ensure that the callbacks function correctly.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback\n",
    "\n",
    "# Load preprocessed Iris dataset\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define learning rate schedule\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.1\n",
    "\n",
    "# Custom callback to log epoch number\n",
    "class CustomCallback(Callback):\n",
    "    def on_epoch(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch + 1}. Accuracy: {logs['accuracy']:.4f}\")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath='', save_best_only=True, monitor='val_accuracy')\n",
    "learning_rate_scheduler = LearningRateScheduler()\n",
    "custom_callback = CustomCallback()\n",
    "\n",
    "# Train the model with the callbacks\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_test, y_test), \n",
    "    epochs=50, \n",
    "    callbacks=[model_checkpoint, learning_rate_scheduler, custom_callback],\n",
    "    verbose=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging TensorFlow Callbacks\n",
    "\n",
    "Let's identify and correct the bugs in the provided code to ensure the callbacks function correctly.\n",
    "\n",
    "### Identified Bugs:\n",
    "\n",
    "1. **Scheduler Function**:\n",
    "   - The `scheduler` function is not updating the learning rate correctly based on the epoch number.\n",
    "   - The function definition in `LearningRateScheduler` is missing.\n",
    "\n",
    "2. **Custom Callback**:\n",
    "   - The `on_epoch` method should be `on_epoch_end` for it to be called at the end of each epoch.\n",
    "   - The custom callback is trying to print `accuracy` from `logs`, but we need to print `val_accuracy`.\n",
    "\n",
    "3. **ModelCheckpoint**:\n",
    "   - The `filepath` parameter in `ModelCheckpoint` is empty, which should be a valid path to save the model.\n",
    "   - The `LearningRateScheduler` callback should pass the scheduler function.\n",
    "\n",
    "### Corrected Code:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback\n",
    "\n",
    "# Load preprocessed Iris dataset\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define learning rate schedule\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return lr * 0.1  # Adjust learning rate for the first 5 epochs\n",
    "    else:\n",
    "        return lr\n",
    "\n",
    "# Custom callback to log epoch number\n",
    "class CustomCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch + 1}. Validation Accuracy: {logs['val_accuracy']:.4f}\")\n",
    "\n",
    "# Corrected ModelCheckpoint with a valid filepath\n",
    "model_checkpoint = ModelCheckpoint(filepath='best_model.keras', save_best_only=True, monitor='val_accuracy')\n",
    "\n",
    "# Corrected LearningRateScheduler with the scheduler function\n",
    "learning_rate_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "# Custom callback corrected\n",
    "custom_callback = CustomCallback()\n",
    "\n",
    "# Train the model with the callbacks\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_test, y_test), \n",
    "    epochs=50, \n",
    "    callbacks=[model_checkpoint, learning_rate_scheduler, custom_callback],\n",
    "    verbose=0)\n",
    "```\n",
    "\n",
    "### Detailed Changes:\n",
    "1. **Learning Rate Scheduler**:\n",
    "   - The `scheduler` function is now correctly adjusting the learning rate for the first 5 epochs.\n",
    "   - The `LearningRateScheduler` callback now correctly references the `scheduler` function.\n",
    "   ```python\n",
    "   def scheduler(epoch, lr):\n",
    "       if epoch < 5:\n",
    "           return lr * 0.1\n",
    "       else:\n",
    "           return lr\n",
    "\n",
    "   learning_rate_scheduler = LearningRateScheduler(scheduler)\n",
    "   ```\n",
    "\n",
    "2. **Custom Callback**:\n",
    "   - The method `on_epoch_end` is used instead of `on_epoch`.\n",
    "   - The callback now prints `val_accuracy` from `logs`.\n",
    "   ```python\n",
    "   class CustomCallback(Callback):\n",
    "       def on_epoch_end(self, epoch, logs=None):\n",
    "           print(f\"Epoch {epoch + 1}. Validation Accuracy: {logs['val_accuracy']:.4f}\")\n",
    "   ```\n",
    "\n",
    "3. **ModelCheckpoint**:\n",
    "   - A valid file path (`'best_model.keras'`) is provided to save the model checkpoints.\n",
    "   ```python\n",
    "   model_checkpoint = ModelCheckpoint(filepath='best_model.keras', save_best_only=True, monitor='val_accuracy')\n",
    "   ```\n",
    "\n",
    "### Kesimpulan\n",
    "Dengan perbaikan ini, semua callback sekarang berfungsi dengan benar, memastikan bahwa pembaruan learning rate dilakukan pada epoch yang sesuai, akurasi validasi dicetak pada akhir setiap epoch, dan model disimpan ke jalur yang benar berdasarkan metrik yang dipantau. Langkah-langkah ini meningkatkan keandalan dan pemantauan proses pelatihan model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completing Callbacks Implementation in TensorFlow\n",
    "\n",
    "Nice work so far! Let's see how well you can implement some of the techniques you've learned.\n",
    "\n",
    "In this exercise, you will complete the missing parts of the code to better understand the details from the implementation and make sure the callbacks work as intended.\n",
    "\n",
    "Fill in the missing part denoted by the TODO comment.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback\n",
    "\n",
    "# Load preprocessed Iris dataset\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define learning rate schedule\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.1\n",
    "\n",
    "# Custom callback to log epoch number\n",
    "class CustomCallback(Callback):\n",
    "    # TODO: Complete the function to use callback at the end of every epoch\n",
    "    def _____________(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch + 1}. Accuracy: {logs['accuracy']:.4f}\")\n",
    "\n",
    "model_checkpoint = # TODO: Define the callback to save model every time val_accuracy increases\n",
    "learning_rate_scheduler = LearningRateScheduler(scheduler)\n",
    "custom_callback = CustomCallback()\n",
    "\n",
    "# Train the model with the callbacks\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_test, y_test), \n",
    "    epochs=50, \n",
    "    callbacks=[model_checkpoint, learning_rate_scheduler, custom_callback],\n",
    "    verbose=0)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completing Callbacks Implementation in TensorFlow\n",
    "\n",
    "Let's fill in the missing parts of the code to ensure the callbacks work as intended.\n",
    "\n",
    "### Implementation:\n",
    "\n",
    "1. **Custom Callback**:\n",
    "   - Use the `on_epoch_end` method to define the behavior at the end of each epoch.\n",
    "\n",
    "2. **ModelCheckpoint**:\n",
    "   - Define the callback to save the model every time the `val_accuracy` increases.\n",
    "\n",
    "Here's the completed code:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback\n",
    "\n",
    "# Load preprocessed Iris dataset\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define learning rate schedule\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.1\n",
    "\n",
    "# Custom callback to log epoch number\n",
    "class CustomCallback(Callback):\n",
    "    # Complete the function to use callback at the end of every epoch\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch + 1}. Accuracy: {logs['accuracy']:.4f}\")\n",
    "\n",
    "# Define the callback to save the model every time val_accuracy increases\n",
    "model_checkpoint = ModelCheckpoint(filepath='best_model.keras', save_best_only=True, monitor='val_accuracy')\n",
    "\n",
    "learning_rate_scheduler = LearningRateScheduler(scheduler)\n",
    "custom_callback = CustomCallback()\n",
    "\n",
    "# Train the model with the callbacks\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_test, y_test), \n",
    "    epochs=50, \n",
    "    callbacks=[model_checkpoint, learning_rate_scheduler, custom_callback],\n",
    "    verbose=0)\n",
    "```\n",
    "\n",
    "### Detailed Explanation:\n",
    "\n",
    "1. **Custom Callback**:\n",
    "   - The `on_epoch_end` method is used to print the training accuracy at the end of each epoch.\n",
    "   ```python\n",
    "   class CustomCallback(Callback):\n",
    "       def on_epoch_end(self, epoch, logs=None):\n",
    "           print(f\"Epoch {epoch + 1}. Accuracy: {logs['accuracy']:.4f}\")\n",
    "   ```\n",
    "\n",
    "2. **ModelCheckpoint**:\n",
    "   - The `ModelCheckpoint` callback is set to save the model every time the validation accuracy (`val_accuracy`) increases.\n",
    "   ```python\n",
    "   model_checkpoint = ModelCheckpoint(filepath='best_model.keras', save_best_only=True, monitor='val_accuracy')\n",
    "   ```\n",
    "\n",
    "### Kesimpulan\n",
    "Dengan melengkapi bagian kode yang hilang, kita memastikan bahwa callback khusus mencetak akurasi pelatihan pada akhir setiap epoch, dan ModelCheckpoint menyimpan model setiap kali akurasi validasi meningkat. Langkah-langkah ini penting untuk memantau dan menyimpan model secara efektif selama pelatihan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write TensorFlow Callbacks From Scratch\n",
    "\n",
    "Great job so far! Building on your understanding of callbacks discussed earlier, this exercise requires you to configure various callbacks including a learning rate scheduler, a custom callback, and a model checkpoint.\n",
    "\n",
    "Finally, train the model using these callbacks to gain hands-on experience.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback\n",
    "\n",
    "# Load preprocessed Iris dataset\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# TODO: Create scheduler function to multiply the learning rate by 0.1 after 10 epoch\n",
    "\n",
    "# TODO: Create custom callback to print epoch number and accuracy\n",
    "# Hint: Use on_epoch_end\n",
    "\n",
    "# TODO: Define ModelCheckpoint callback monitoring val_accuracy saving only the best model\n",
    "\n",
    "# TODO: Define LearningRateScheduler callback\n",
    "\n",
    "# TODO: Define CustomCallback\n",
    "\n",
    "# Train the model with the callbacks\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_test, y_test), \n",
    "    epochs=50, \n",
    "    callbacks= # TODO: Add Callbacks\n",
    "    verbose=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how you can complete the code by implementing the learning rate scheduler, custom callback, and model checkpoint. Each callback serves a different purpose in monitoring or improving the training process. Let's break it down step-by-step:\n",
    "\n",
    "### 1. **Learning Rate Scheduler**\n",
    "   - This callback will adjust the learning rate after every epoch. Specifically, it will reduce the learning rate by multiplying it by 0.1 after the 10th epoch.\n",
    "\n",
    "### 2. **Custom Callback**\n",
    "   - This custom callback will print out the epoch number and accuracy at the end of each epoch.\n",
    "\n",
    "### 3. **Model Checkpoint**\n",
    "   - This callback will save the best model based on validation accuracy.\n",
    "\n",
    "Here's the completed code:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from data_preprocessing import load_preprocessed_data\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback\n",
    "\n",
    "# Load preprocessed Iris dataset\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Learning Rate Scheduler: Reduce learning rate by 0.1 after epoch 10\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch > 10:\n",
    "        return lr * 0.1\n",
    "    else:\n",
    "        return lr\n",
    "\n",
    "# Custom Callback: Print epoch number and accuracy\n",
    "class CustomCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch + 1}, Accuracy: {logs['accuracy']:.4f}\")\n",
    "\n",
    "# Define ModelCheckpoint: Save the best model based on validation accuracy\n",
    "checkpoint_cb = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "\n",
    "# Define LearningRateScheduler callback\n",
    "lr_scheduler_cb = LearningRateScheduler(scheduler)\n",
    "\n",
    "# Define CustomCallback\n",
    "custom_cb = CustomCallback()\n",
    "\n",
    "# Train the model with the callbacks\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_test, y_test), \n",
    "    epochs=50, \n",
    "    callbacks=[checkpoint_cb, lr_scheduler_cb, custom_cb],\n",
    "    verbose=0)\n",
    "\n",
    "```\n",
    "\n",
    "### Summary of the Callbacks:\n",
    "\n",
    "1. **LearningRateScheduler**:\n",
    "   - üõ†Ô∏è **Function**: Adjusts learning rate after 10 epochs.\n",
    "   - üîß **Implementation**: `LearningRateScheduler(scheduler)`\n",
    "\n",
    "2. **CustomCallback**:\n",
    "   - üñ®Ô∏è **Function**: Prints the epoch number and training accuracy at the end of each epoch.\n",
    "   - üîß **Implementation**: `CustomCallback()`\n",
    "\n",
    "3. **ModelCheckpoint**:\n",
    "   - üíæ **Function**: Saves the best model during training based on validation accuracy.\n",
    "   - üîß **Implementation**: `ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_accuracy', mode='max')`\n",
    "\n",
    "### Conclusion\n",
    "By incorporating these callbacks, the training process is better managed: the learning rate is adjusted to prevent overshooting, the best model is saved for future use, and training progress is monitored and displayed. This not only improves the performance but also helps in tracking the training process effectively."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
