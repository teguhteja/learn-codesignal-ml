{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Unit 4 Building an Automated ML Retraining Pipeline with Apache Airflow\n",
                                    "\n",
                                    "# Building an Automated ML Retraining Pipeline with Airflow\n",
                                    "\n",
                                    "Welcome to the fourth lesson of our \"Automating Retraining with Apache Airflow\" course\\! You've made great progress, and now it's time to put everything you've learned into practice. In this lesson, we will focus on building a complete, automated ML retraining pipeline using Airflow and the modular components you've already worked with. This is where your knowledge of task definition and workflow orchestration comes together, enabling you to create a single, scheduled workflow that handles everything from data loading to model saving.\n",
                                    "\n",
                                    "By the end of this lesson, you will be able to connect all the pieces into a robust pipeline that automatically retrains and evaluates your model. Let's get started.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### Recap: Interfaces of Our ML Modules\n",
                                    "\n",
                                    "To build our Airflow pipeline, we'll use the functions from our custom data, model, and evaluation modules. Here is a quick refresher on the key functions we'll be using:\n",
                                    "\n",
                                    "  * **`load_diamonds_data(file_path)`**: Loads the diamonds dataset from a CSV file.\n",
                                    "  * **`preprocess_diamonds_data(df)`**: Preprocesses the data, splits it into training and test sets, and returns the data and preprocessor.\n",
                                    "  * **`train_model(X_train, y_train, model_type, **params)`**: Trains a machine learning model.\n",
                                    "  * **`evaluate_model(model, X_test, y_test)`**: Evaluates the model's performance and returns a dictionary of metrics.\n",
                                    "  * **`save_model(model, preprocessor, model_dir, model_name, metadata)`**: Saves the model, preprocessor, and metadata to disk.\n",
                                    "\n",
                                    "By chaining these functions as Airflow tasks, we can automate the entire retraining process.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### Structuring the Airflow DAG\n",
                                    "\n",
                                    "We'll start by setting up the basic structure of our Airflow DAG. The DAG defines the workflow and the order of task execution. The following Python code shows the necessary imports and configuration, including the DAG's default arguments and constants for file paths.\n",
                                    "\n",
                                    "```python\n",
                                    "from datetime import datetime, timedelta\n",
                                    "import os\n",
                                    "from airflow.decorators import dag, task\n",
                                    "\n",
                                    "# Import our custom ML modules\n",
                                    "from data import load_diamonds_data, preprocess_diamonds_data\n",
                                    "from model import train_model, save_model\n",
                                    "from evaluation import evaluate_model\n",
                                    "\n",
                                    "# Set default arguments for the DAG\n",
                                    "default_args = {\n",
                                    "    'owner': 'airflow',\n",
                                    "    'depends_on_past': False,\n",
                                    "    'email_on_failure': False,\n",
                                    "    'email_on_retry': False,\n",
                                    "    'retries': 1,\n",
                                    "    'retry_delay': timedelta(minutes=5),\n",
                                    "}\n",
                                    "\n",
                                    "# Define paths for data and model storage\n",
                                    "DATA_PATH = \"diamonds.csv\"\n",
                                    "MODEL_DIR = \"./saved_models\"\n",
                                    "os.makedirs(MODEL_DIR, exist_ok=True)  # Ensure the model directory exists\n",
                                    "```\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### Task Chaining and Data Passing\n",
                                    "\n",
                                    "Next, we'll define the pipeline's steps as tasks and chain them together. A key feature of Airflow is its ability to pass data between tasks using **XComs**. By default, Airflow serializes objects using pickle, which is convenient for small-scale pipelines but can pose security and compatibility risks in production. For production environments, it is recommended to use more robust serialization formats or to pass file paths between tasks.\n",
                                    "\n",
                                    "For this lesson, we will use pickle-based XComs for simplicity. Below is the code for the first two tasks: `load_data` and `process_data`.\n",
                                    "\n",
                                    "```python\n",
                                    "@dag(\n",
                                    "    dag_id='mlops_pipeline',\n",
                                    "    description='ML model training pipeline for diamond price prediction',\n",
                                    "    default_args=default_args,\n",
                                    "    schedule='@daily',\n",
                                    "    start_date=datetime(2025, 1, 1),\n",
                                    "    catchup=False,\n",
                                    "    tags=['ml', 'training', 'diamonds'],\n",
                                    ")\n",
                                    "def diamond_training_pipeline():\n",
                                    "    @task(task_id=\"load_data\")\n",
                                    "    def task_load_data():\n",
                                    "        # Load the diamonds dataset from CSV\n",
                                    "        print(f\"Loading diamonds data from {DATA_PATH}\")\n",
                                    "        df = load_diamonds_data(DATA_PATH)\n",
                                    "        print(f\"Dataset loaded with shape: {df.shape}\")\n",
                                    "        return df\n",
                                    "\n",
                                    "    @task(task_id=\"process_data\")\n",
                                    "    def task_process_data(df):\n",
                                    "        # Preprocess the data and split into train/test sets\n",
                                    "        print(\"Preprocessing data\")\n",
                                    "        X_train, X_test, y_train, y_test, preprocessor = preprocess_diamonds_data(df)\n",
                                    "        print(f\"Data preprocessing complete. Training set size: {X_train.shape[0]}\")\n",
                                    "        return {\n",
                                    "            \"X_train\": X_train,\n",
                                    "            \"X_test\": X_test,\n",
                                    "            \"y_train\": y_train,\n",
                                    "            \"y_test\": y_test,\n",
                                    "            \"preprocessor\": preprocessor\n",
                                    "        }\n",
                                    "```\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### Model Training\n",
                                    "\n",
                                    "With the data prepared, the `train_model` task consumes the processed data to train a model. This task returns both the trained model and the data required for the next step.\n",
                                    "\n",
                                    "```python\n",
                                    "    @task(task_id=\"train_model\")\n",
                                    "    def task_train_model(processed_data):\n",
                                    "        # Train a Random Forest model using the training set\n",
                                    "        print(\"Training model\")\n",
                                    "        model = train_model(\n",
                                    "            processed_data[\"X_train\"],\n",
                                    "            processed_data[\"y_train\"],\n",
                                    "            model_type=\"random_forest\",\n",
                                    "            n_estimators=10,\n",
                                    "            max_depth=5,\n",
                                    "            random_state=42\n",
                                    "        )\n",
                                    "        print(\"Model training complete.\")\n",
                                    "        return {\"model\": model, \"processed_data\": processed_data}\n",
                                    "```\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### Model Evaluation\n",
                                    "\n",
                                    "The `evaluate_model` task is essential for assessing the model's performance on the test set. It helps monitor the model's quality and identify potential issues.\n",
                                    "\n",
                                    "```python\n",
                                    "    @task(task_id=\"evaluate_model\")\n",
                                    "    def task_evaluate_model(training_result):\n",
                                    "        # Evaluate the trained model on the test set\n",
                                    "        model = training_result[\"model\"]\n",
                                    "        processed_data = training_result[\"processed_data\"]\n",
                                    "        print(\"Evaluating model\")\n",
                                    "        metrics, _ = evaluate_model(model, processed_data[\"X_test\"], processed_data[\"y_test\"])\n",
                                    "        print(f\"Model evaluation metrics: {metrics}\")\n",
                                    "        return {\n",
                                    "            \"model\": model,\n",
                                    "            \"preprocessor\": processed_data[\"preprocessor\"],\n",
                                    "            \"metrics\": metrics\n",
                                    "        }\n",
                                    "```\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### Model Saving and Versioning\n",
                                    "\n",
                                    "The final step is to save the trained model, preprocessor, and any relevant metadata. This ensures that every retrained model is properly versioned and can be traced.\n",
                                    "\n",
                                    "```python\n",
                                    "    @task(task_id=\"save_model\")\n",
                                    "    def task_save_model(evaluation_result):\n",
                                    "        # Save the trained model, preprocessor, and metadata\n",
                                    "        model = evaluation_result[\"model\"]\n",
                                    "        preprocessor = evaluation_result[\"preprocessor\"]\n",
                                    "        metrics = evaluation_result[\"metrics\"]\n",
                                    "        print(f\"Saving model to {MODEL_DIR}\")\n",
                                    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
                                    "        model_name = f\"diamond_price_model_{timestamp}\"\n",
                                    "        metadata = {\n",
                                    "            \"metrics\": metrics,\n",
                                    "            \"model_type\": \"RandomForestRegressor\",\n",
                                    "            \"timestamp\": timestamp\n",
                                    "        }\n",
                                    "        model_path = save_model(\n",
                                    "            model, \n",
                                    "            preprocessor,\n",
                                    "            MODEL_DIR, \n",
                                    "            model_name, \n",
                                    "            metadata\n",
                                    "        )\n",
                                    "        print(f\"Model saved to {model_path}\")\n",
                                    "        return model_path\n",
                                    "```\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### Building the Complete Workflow\n",
                                    "\n",
                                    "The final step is to link all the tasks together by passing the output of one task as the input to the next. This defines the dependencies and execution order of the entire pipeline.\n",
                                    "\n",
                                    "```python\n",
                                    "    df = task_load_data()\n",
                                    "    processed_data = task_process_data(df)\n",
                                    "    training_result = task_train_model(processed_data)\n",
                                    "    evaluation_result = task_evaluate_model(training_result)\n",
                                    "    final_model_path = task_save_model(evaluation_result)\n",
                                    "    \n",
                                    "diamond_training_pipeline()\n",
                                    "```\n",
                                    "\n",
                                    "This linear and easy-to-follow pipeline makes it simple to add new steps or swap components as needed. You have successfully built a powerful and maintainable ML retraining workflow."
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Unpacking Data for ML Pipelines\n",
                                    "\n",
                                    "You’ve just seen how each part of the ML pipeline fits together in an Airflow DAG and how tasks pass data from one step to the next. Now, let’s focus on the data processing step.\n",
                                    "\n",
                                    "In this exercise, you’ll complete the task_process_data function inside the Airflow DAG. Your job is to call the preprocess_diamonds_data(df) function and unpack its return values into the variables X_train, X_test, y_train, y_test, and preprocessor. Then, make sure these variables are included in the dictionary that the function returns.\n",
                                    "\n",
                                    "This step is important for ensuring the right data is passed to the next tasks in your pipeline. Give it a try!\n",
                                    "\n",
                                    "```python\n",
                                    "\"\"\"\n",
                                    "ML Model Training Pipeline DAG\n",
                                    "\n",
                                    "This module defines an Airflow DAG that orchestrates a complete ML training pipeline\n",
                                    "for the diamonds dataset, using functions from our ML modules.\n",
                                    "\"\"\"\n",
                                    "\n",
                                    "from datetime import datetime, timedelta\n",
                                    "import os\n",
                                    "from airflow.decorators import dag, task\n",
                                    "\n",
                                    "# Import our custom modules\n",
                                    "from data import load_diamonds_data, preprocess_diamonds_data\n",
                                    "from model import train_model, save_model\n",
                                    "from evaluation import evaluate_model\n",
                                    "\n",
                                    "# Define default arguments for the DAG\n",
                                    "default_args = {\n",
                                    "    'owner': 'airflow',\n",
                                    "    'depends_on_past': False,\n",
                                    "    'email_on_failure': False,\n",
                                    "    'email_on_retry': False,\n",
                                    "    'retries': 1,\n",
                                    "    'retry_delay': timedelta(minutes=5),\n",
                                    "}\n",
                                    "\n",
                                    "# Define constants\n",
                                    "DATA_PATH = \"diamonds.csv\"\n",
                                    "MODEL_DIR = \"./saved_models\"\n",
                                    "\n",
                                    "# Create model directory if it doesn't exist\n",
                                    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
                                    "\n",
                                    "@dag(\n",
                                    "    dag_id='mlops_pipeline',\n",
                                    "    description='ML model training pipeline for diamond price prediction',\n",
                                    "    default_args=default_args,\n",
                                    "    schedule_interval='@daily',\n",
                                    "    start_date=datetime(2025, 1, 1),\n",
                                    "    catchup=False,\n",
                                    "    tags=['ml', 'training', 'diamonds'],\n",
                                    ")\n",
                                    "def diamond_training_pipeline():\n",
                                    "    \"\"\"\n",
                                    "    This DAG implements a complete ML training pipeline for diamond price prediction.\n",
                                    "    \n",
                                    "    Tasks:\n",
                                    "    1. Load data: Load the diamonds dataset\n",
                                    "    2. Process data: Preprocess the data for model training\n",
                                    "    3. Train model: Train a random forest model\n",
                                    "    4. Evaluate model: Evaluate the model on test data\n",
                                    "    5. Save model: Save the trained model and preprocessor\n",
                                    "    \"\"\"\n",
                                    "    \n",
                                    "    @task(task_id=\"load_data\")\n",
                                    "    def task_load_data():\n",
                                    "        \"\"\"Load the diamonds dataset.\"\"\"\n",
                                    "        print(f\"Loading diamonds data from {DATA_PATH}\")\n",
                                    "        df = load_diamonds_data(DATA_PATH)\n",
                                    "        print(f\"Dataset loaded with shape: {df.shape}\")\n",
                                    "        return df\n",
                                    "    \n",
                                    "    @task(task_id=\"process_data\")\n",
                                    "    def task_process_data(df):\n",
                                    "        \"\"\"Preprocess the data for model training.\"\"\"\n",
                                    "        print(\"Preprocessing data\")\n",
                                    "        # TODO: Call preprocess_diamonds_data and unpack its return values\n",
                                    "        # into X_train, X_test, y_train, y_test, and preprocessor\n",
                                    "\n",
                                    "        # TODO: return a dict with the unpacked variables\n",
                                    "        \n",
                                    "    \n",
                                    "    @task(task_id=\"train_model\")\n",
                                    "    def task_train_model(processed_data):\n",
                                    "        \"\"\"Train a random forest model.\"\"\"\n",
                                    "        print(\"Training model\")\n",
                                    "        # Train the model\n",
                                    "        model = train_model(\n",
                                    "            processed_data[\"X_train\"],\n",
                                    "            processed_data[\"y_train\"],\n",
                                    "            model_type=\"random_forest\",\n",
                                    "            n_estimators=10,\n",
                                    "            max_depth=5,\n",
                                    "            random_state=42\n",
                                    "        )\n",
                                    "        print(\"Model training complete.\")\n",
                                    "        return {\"model\": model, \"processed_data\": processed_data}\n",
                                    "    \n",
                                    "    @task(task_id=\"evaluate_model\")\n",
                                    "    def task_evaluate_model(training_result):\n",
                                    "        \"\"\"Evaluate the trained model.\"\"\"\n",
                                    "        model = training_result[\"model\"]\n",
                                    "        processed_data = training_result[\"processed_data\"]\n",
                                    "        \n",
                                    "        print(\"Evaluating model\")\n",
                                    "        # Evaluate the model\n",
                                    "        metrics, _ = evaluate_model(model, processed_data[\"X_test\"], processed_data[\"y_test\"])\n",
                                    "        print(f\"Model evaluation metrics: {metrics}\")\n",
                                    "        \n",
                                    "        return {\n",
                                    "            \"model\": model,\n",
                                    "            \"preprocessor\": processed_data[\"preprocessor\"],\n",
                                    "            \"metrics\": metrics\n",
                                    "        }\n",
                                    "    \n",
                                    "    @task(task_id=\"save_model\")\n",
                                    "    def task_save_model(evaluation_result):\n",
                                    "        \"\"\"Save the trained model and preprocessor.\"\"\"\n",
                                    "        model = evaluation_result[\"model\"]\n",
                                    "        preprocessor = evaluation_result[\"preprocessor\"]\n",
                                    "        metrics = evaluation_result[\"metrics\"]\n",
                                    "        \n",
                                    "        print(f\"Saving model to {MODEL_DIR}\")\n",
                                    "        # Create a timestamp for the model name\n",
                                    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
                                    "        model_name = f\"diamond_price_model_{timestamp}\"\n",
                                    "        \n",
                                    "        # Create metadata\n",
                                    "        metadata = {\n",
                                    "            \"metrics\": metrics,\n",
                                    "            \"model_type\": \"RandomForestRegressor\",\n",
                                    "            \"timestamp\": timestamp\n",
                                    "        }\n",
                                    "        \n",
                                    "        # Save the model\n",
                                    "        model_path = save_model(\n",
                                    "            model, \n",
                                    "            preprocessor,\n",
                                    "            MODEL_DIR, \n",
                                    "            model_name, \n",
                                    "            metadata\n",
                                    "        )\n",
                                    "        \n",
                                    "        print(f\"Model saved to {model_path}\")\n",
                                    "        return model_path\n",
                                    "    \n",
                                    "    # Define the task dependencies\n",
                                    "    df = task_load_data()\n",
                                    "    processed_data = task_process_data(df)\n",
                                    "    training_result = task_train_model(processed_data)\n",
                                    "    evaluation_result = task_evaluate_model(training_result)\n",
                                    "    final_model_path = task_save_model(evaluation_result)\n",
                                    "\n",
                                    "# Create the DAG\n",
                                    "diamond_training_pipeline()\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "\"\"\"\n",
                                    "ML Model Training Pipeline DAG\n",
                                    "\n",
                                    "This module defines an Airflow DAG that orchestrates a complete ML training pipeline\n",
                                    "for the diamonds dataset, using functions from our ML modules.\n",
                                    "\"\"\"\n",
                                    "\n",
                                    "from datetime import datetime, timedelta\n",
                                    "import os\n",
                                    "from airflow.decorators import dag, task\n",
                                    "\n",
                                    "# Import our custom modules\n",
                                    "from data import load_diamonds_data, preprocess_diamonds_data\n",
                                    "from model import train_model, save_model\n",
                                    "from evaluation import evaluate_model\n",
                                    "\n",
                                    "# Define default arguments for the DAG\n",
                                    "default_args = {\n",
                                    "    'owner': 'airflow',\n",
                                    "    'depends_on_past': False,\n",
                                    "    'email_on_failure': False,\n",
                                    "    'email_on_retry': False,\n",
                                    "    'retries': 1,\n",
                                    "    'retry_delay': timedelta(minutes=5),\n",
                                    "}\n",
                                    "\n",
                                    "# Define constants\n",
                                    "DATA_PATH = \"diamonds.csv\"\n",
                                    "MODEL_DIR = \"./saved_models\"\n",
                                    "\n",
                                    "# Create model directory if it doesn't exist\n",
                                    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
                                    "\n",
                                    "@dag(\n",
                                    "    dag_id='mlops_pipeline',\n",
                                    "    description='ML model training pipeline for diamond price prediction',\n",
                                    "    default_args=default_args,\n",
                                    "    schedule_interval='@daily',\n",
                                    "    start_date=datetime(2025, 1, 1),\n",
                                    "    catchup=False,\n",
                                    "    tags=['ml', 'training', 'diamonds'],\n",
                                    ")\n",
                                    "def diamond_training_pipeline():\n",
                                    "    \"\"\"\n",
                                    "    This DAG implements a complete ML training pipeline for diamond price prediction.\n",
                                    "    \n",
                                    "    Tasks:\n",
                                    "    1. Load data: Load the diamonds dataset\n",
                                    "    2. Process data: Preprocess the data for model training\n",
                                    "    3. Train model: Train a random forest model\n",
                                    "    4. Evaluate model: Evaluate the model on test data\n",
                                    "    5. Save model: Save the trained model and preprocessor\n",
                                    "    \"\"\"\n",
                                    "    \n",
                                    "    @task(task_id=\"load_data\")\n",
                                    "    def task_load_data():\n",
                                    "        \"\"\"Load the diamonds dataset.\"\"\"\n",
                                    "        print(f\"Loading diamonds data from {DATA_PATH}\")\n",
                                    "        df = load_diamonds_data(DATA_PATH)\n",
                                    "        print(f\"Dataset loaded with shape: {df.shape}\")\n",
                                    "        return df\n",
                                    "    \n",
                                    "    @task(task_id=\"process_data\")\n",
                                    "    def task_process_data(df):\n",
                                    "        \"\"\"Preprocess the data for model training.\"\"\"\n",
                                    "        print(\"Preprocessing data\")\n",
                                    "        # TODO: Call preprocess_diamonds_data and unpack its return values\n",
                                    "        # into X_train, X_test, y_train, y_test, and preprocessor\n",
                                    "        X_train, X_test, y_train, y_test, preprocessor = preprocess_diamonds_data(df)\n",
                                    "\n",
                                    "        # TODO: return a dict with the unpacked variables\n",
                                    "        print(f\"Data preprocessing complete. Training set size: {X_train.shape[0]}\")\n",
                                    "        return {\n",
                                    "            \"X_train\": X_train,\n",
                                    "            \"X_test\": X_test,\n",
                                    "            \"y_train\": y_train,\n",
                                    "            \"y_test\": y_test,\n",
                                    "            \"preprocessor\": preprocessor\n",
                                    "        }\n",
                                    "    \n",
                                    "    @task(task_id=\"train_model\")\n",
                                    "    def task_train_model(processed_data):\n",
                                    "        \"\"\"Train a random forest model.\"\"\"\n",
                                    "        print(\"Training model\")\n",
                                    "        # Train the model\n",
                                    "        model = train_model(\n",
                                    "            processed_data[\"X_train\"],\n",
                                    "            processed_data[\"y_train\"],\n",
                                    "            model_type=\"random_forest\",\n",
                                    "            n_estimators=10,\n",
                                    "            max_depth=5,\n",
                                    "            random_state=42\n",
                                    "        )\n",
                                    "        print(\"Model training complete.\")\n",
                                    "        return {\"model\": model, \"processed_data\": processed_data}\n",
                                    "    \n",
                                    "    @task(task_id=\"evaluate_model\")\n",
                                    "    def task_evaluate_model(training_result):\n",
                                    "        \"\"\"Evaluate the trained model.\"\"\"\n",
                                    "        model = training_result[\"model\"]\n",
                                    "        processed_data = training_result[\"processed_data\"]\n",
                                    "        \n",
                                    "        print(\"Evaluating model\")\n",
                                    "        # Evaluate the model\n",
                                    "        metrics, _ = evaluate_model(model, processed_data[\"X_test\"], processed_data[\"y_test\"])\n",
                                    "        print(f\"Model evaluation metrics: {metrics}\")\n",
                                    "        \n",
                                    "        return {\n",
                                    "            \"model\": model,\n",
                                    "            \"preprocessor\": processed_data[\"preprocessor\"],\n",
                                    "            \"metrics\": metrics\n",
                                    "        }\n",
                                    "    \n",
                                    "    @task(task_id=\"save_model\")\n",
                                    "    def task_save_model(evaluation_result):\n",
                                    "        \"\"\"Save the trained model and preprocessor.\"\"\"\n",
                                    "        model = evaluation_result[\"model\"]\n",
                                    "        preprocessor = evaluation_result[\"preprocessor\"]\n",
                                    "        metrics = evaluation_result[\"metrics\"]\n",
                                    "        \n",
                                    "        print(f\"Saving model to {MODEL_DIR}\")\n",
                                    "        # Create a timestamp for the model name\n",
                                    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
                                    "        model_name = f\"diamond_price_model_{timestamp}\"\n",
                                    "        \n",
                                    "        # Create metadata\n",
                                    "        metadata = {\n",
                                    "            \"metrics\": metrics,\n",
                                    "            \"model_type\": \"RandomForestRegressor\",\n",
                                    "            \"timestamp\": timestamp\n",
                                    "        }\n",
                                    "        \n",
                                    "        # Save the model\n",
                                    "        model_path = save_model(\n",
                                    "            model, \n",
                                    "            preprocessor,\n",
                                    "            MODEL_DIR, \n",
                                    "            model_name, \n",
                                    "            metadata\n",
                                    "        )\n",
                                    "        \n",
                                    "        print(f\"Model saved to {model_path}\")\n",
                                    "        return model_path\n",
                                    "    \n",
                                    "    # Define the task dependencies\n",
                                    "    df = task_load_data()\n",
                                    "    processed_data = task_process_data(df)\n",
                                    "    training_result = task_train_model(processed_data)\n",
                                    "    evaluation_result = task_evaluate_model(training_result)\n",
                                    "    final_model_path = task_save_model(evaluation_result)\n",
                                    "\n",
                                    "# Create the DAG\n",
                                    "diamond_training_pipeline()\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Ensuring Data Flow in Model Training\n",
                                    "\n",
                                    "You’ve just practiced how to pass multiple pieces of data between Airflow tasks in your ML pipeline. Now, let’s ensure that each task provides everything the next step needs.\n",
                                    "\n",
                                    "In this exercise, you’ll work on the model training step. The current code implementing this step features a bug that prevents the pipeline from running correctly. Can you ensure our pipeline runs smoothly from start to finish? Enjoy the challenge!\n",
                                    "\n",
                                    "```python\n",
                                    "\"\"\"\n",
                                    "ML Model Training Pipeline DAG\n",
                                    "\n",
                                    "This module defines an Airflow DAG that orchestrates a complete ML training pipeline\n",
                                    "for the diamonds dataset, using functions from our ML modules.\n",
                                    "\"\"\"\n",
                                    "\n",
                                    "from datetime import datetime, timedelta\n",
                                    "import os\n",
                                    "from airflow.decorators import dag, task\n",
                                    "\n",
                                    "# Import our custom modules\n",
                                    "from data import load_diamonds_data, preprocess_diamonds_data\n",
                                    "from model import train_model, save_model\n",
                                    "from evaluation import evaluate_model\n",
                                    "\n",
                                    "# Define default arguments for the DAG\n",
                                    "default_args = {\n",
                                    "    'owner': 'airflow',\n",
                                    "    'depends_on_past': False,\n",
                                    "    'email_on_failure': False,\n",
                                    "    'email_on_retry': False,\n",
                                    "    'retries': 1,\n",
                                    "    'retry_delay': timedelta(minutes=5),\n",
                                    "}\n",
                                    "\n",
                                    "# Define constants\n",
                                    "DATA_PATH = \"diamonds.csv\"\n",
                                    "MODEL_DIR = \"./saved_models\"\n",
                                    "\n",
                                    "# Create model directory if it doesn't exist\n",
                                    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
                                    "\n",
                                    "@dag(\n",
                                    "    dag_id='mlops_pipeline',\n",
                                    "    description='ML model training pipeline for diamond price prediction',\n",
                                    "    default_args=default_args,\n",
                                    "    schedule_interval='@daily',\n",
                                    "    start_date=datetime(2025, 1, 1),\n",
                                    "    catchup=False,\n",
                                    "    tags=['ml', 'training', 'diamonds'],\n",
                                    ")\n",
                                    "def diamond_training_pipeline():\n",
                                    "    \"\"\"\n",
                                    "    This DAG implements a complete ML training pipeline for diamond price prediction.\n",
                                    "    \n",
                                    "    Tasks:\n",
                                    "    1. Load data: Load the diamonds dataset\n",
                                    "    2. Process data: Preprocess the data for model training\n",
                                    "    3. Train model: Train a random forest model\n",
                                    "    4. Evaluate model: Evaluate the model on test data\n",
                                    "    5. Save model: Save the trained model and preprocessor\n",
                                    "    \"\"\"\n",
                                    "    \n",
                                    "    @task(task_id=\"load_data\")\n",
                                    "    def task_load_data():\n",
                                    "        \"\"\"Load the diamonds dataset.\"\"\"\n",
                                    "        print(f\"Loading diamonds data from {DATA_PATH}\")\n",
                                    "        df = load_diamonds_data(DATA_PATH)\n",
                                    "        print(f\"Dataset loaded with shape: {df.shape}\")\n",
                                    "        return df\n",
                                    "    \n",
                                    "    @task(task_id=\"process_data\")\n",
                                    "    def task_process_data(df):\n",
                                    "        \"\"\"Preprocess the data for model training.\"\"\"\n",
                                    "        print(f\"Preprocessing data\")\n",
                                    "        # Preprocess the data\n",
                                    "        X_train, X_test, y_train, y_test, preprocessor = preprocess_diamonds_data(df)\n",
                                    "        print(f\"Data preprocessing complete. Training set size: {X_train.shape[0]}\")\n",
                                    "        return {\"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \n",
                                    "                \"y_test\": y_test, \"preprocessor\": preprocessor}\n",
                                    "    \n",
                                    "    @task(task_id=\"train_model\")\n",
                                    "    def task_train_model(processed_data):\n",
                                    "        \"\"\"Train a random forest model.\"\"\"\n",
                                    "        print(\"Training model\")\n",
                                    "        # Train the model\n",
                                    "        model = train_model(\n",
                                    "            processed_data[\"X_train\"],\n",
                                    "            processed_data[\"y_train\"],\n",
                                    "            model_type=\"random_forest\",\n",
                                    "            n_estimators=10,\n",
                                    "            max_depth=5,\n",
                                    "            random_state=42\n",
                                    "        )\n",
                                    "        print(\"Model training complete.\")\n",
                                    "        return model\n",
                                    "    \n",
                                    "    @task(task_id=\"evaluate_model\")\n",
                                    "    def task_evaluate_model(training_result):\n",
                                    "        \"\"\"Evaluate the trained model.\"\"\"\n",
                                    "        model = training_result[\"model\"]\n",
                                    "        processed_data = training_result[\"processed_data\"]\n",
                                    "        \n",
                                    "        print(\"Evaluating model\")\n",
                                    "        # Evaluate the model\n",
                                    "        metrics, _ = evaluate_model(model, processed_data[\"X_test\"], processed_data[\"y_test\"])\n",
                                    "        print(f\"Model evaluation metrics: {metrics}\")\n",
                                    "        \n",
                                    "        return {\n",
                                    "            \"model\": model,\n",
                                    "            \"preprocessor\": processed_data[\"preprocessor\"],\n",
                                    "            \"metrics\": metrics\n",
                                    "        }\n",
                                    "    \n",
                                    "    @task(task_id=\"save_model\")\n",
                                    "    def task_save_model(evaluation_result):\n",
                                    "        \"\"\"Save the trained model and preprocessor.\"\"\"\n",
                                    "        model = evaluation_result[\"model\"]\n",
                                    "        preprocessor = evaluation_result[\"preprocessor\"]\n",
                                    "        metrics = evaluation_result[\"metrics\"]\n",
                                    "        \n",
                                    "        print(f\"Saving model to {MODEL_DIR}\")\n",
                                    "        # Create a timestamp for the model name\n",
                                    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
                                    "        model_name = f\"diamond_price_model_{timestamp}\"\n",
                                    "        \n",
                                    "        # Create metadata\n",
                                    "        metadata = {\n",
                                    "            \"metrics\": metrics,\n",
                                    "            \"model_type\": \"RandomForestRegressor\",\n",
                                    "            \"timestamp\": timestamp\n",
                                    "        }\n",
                                    "        \n",
                                    "        # Save the model\n",
                                    "        model_path = save_model(\n",
                                    "            model, \n",
                                    "            preprocessor,\n",
                                    "            MODEL_DIR, \n",
                                    "            model_name, \n",
                                    "            metadata\n",
                                    "        )\n",
                                    "        \n",
                                    "        print(f\"Model saved to {model_path}\")\n",
                                    "        return model_path\n",
                                    "    \n",
                                    "    # Define the task dependencies\n",
                                    "    df = task_load_data()\n",
                                    "    processed_data = task_process_data(df)\n",
                                    "    training_result = task_train_model(processed_data)\n",
                                    "    evaluation_result = task_evaluate_model(training_result)\n",
                                    "    final_model_path = task_save_model(evaluation_result)\n",
                                    "\n",
                                    "# Create the DAG\n",
                                    "diamond_training_pipeline()\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "\"\"\"\n",
                                    "ML Model Training Pipeline DAG\n",
                                    "\n",
                                    "This module defines an Airflow DAG that orchestrates a complete ML training pipeline\n",
                                    "for the diamonds dataset, using functions from our ML modules.\n",
                                    "\"\"\"\n",
                                    "\n",
                                    "from datetime import datetime, timedelta\n",
                                    "import os\n",
                                    "from airflow.decorators import dag, task\n",
                                    "\n",
                                    "# Import our custom modules\n",
                                    "from data import load_diamonds_data, preprocess_diamonds_data\n",
                                    "from model import train_model, save_model\n",
                                    "from evaluation import evaluate_model\n",
                                    "\n",
                                    "# Define default arguments for the DAG\n",
                                    "default_args = {\n",
                                    "    'owner': 'airflow',\n",
                                    "    'depends_on_past': False,\n",
                                    "    'email_on_failure': False,\n",
                                    "    'email_on_retry': False,\n",
                                    "    'retries': 1,\n",
                                    "    'retry_delay': timedelta(minutes=5),\n",
                                    "}\n",
                                    "\n",
                                    "# Define constants\n",
                                    "DATA_PATH = \"diamonds.csv\"\n",
                                    "MODEL_DIR = \"./saved_models\"\n",
                                    "\n",
                                    "# Create model directory if it doesn't exist\n",
                                    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
                                    "\n",
                                    "@dag(\n",
                                    "    dag_id='mlops_pipeline',\n",
                                    "    description='ML model training pipeline for diamond price prediction',\n",
                                    "    default_args=default_args,\n",
                                    "    schedule_interval='@daily',\n",
                                    "    start_date=datetime(2025, 1, 1),\n",
                                    "    catchup=False,\n",
                                    "    tags=['ml', 'training', 'diamonds'],\n",
                                    ")\n",
                                    "def diamond_training_pipeline():\n",
                                    "    \"\"\"\n",
                                    "    This DAG implements a complete ML training pipeline for diamond price prediction.\n",
                                    "    \n",
                                    "    Tasks:\n",
                                    "    1. Load data: Load the diamonds dataset\n",
                                    "    2. Process data: Preprocess the data for model training\n",
                                    "    3. Train model: Train a random forest model\n",
                                    "    4. Evaluate model: Evaluate the model on test data\n",
                                    "    5. Save model: Save the trained model and preprocessor\n",
                                    "    \"\"\"\n",
                                    "    \n",
                                    "    @task(task_id=\"load_data\")\n",
                                    "    def task_load_data():\n",
                                    "        \"\"\"Load the diamonds dataset.\"\"\"\n",
                                    "        print(f\"Loading diamonds data from {DATA_PATH}\")\n",
                                    "        df = load_diamonds_data(DATA_PATH)\n",
                                    "        print(f\"Dataset loaded with shape: {df.shape}\")\n",
                                    "        return df\n",
                                    "    \n",
                                    "    @task(task_id=\"process_data\")\n",
                                    "    def task_process_data(df):\n",
                                    "        \"\"\"Preprocess the data for model training.\"\"\"\n",
                                    "        print(f\"Preprocessing data\")\n",
                                    "        # Preprocess the data\n",
                                    "        X_train, X_test, y_train, y_test, preprocessor = preprocess_diamonds_data(df)\n",
                                    "        print(f\"Data preprocessing complete. Training set size: {X_train.shape[0]}\")\n",
                                    "        return {\"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \n",
                                    "                \"y_test\": y_test, \"preprocessor\": preprocessor}\n",
                                    "    \n",
                                    "    @task(task_id=\"train_model\")\n",
                                    "    def task_train_model(processed_data):\n",
                                    "        \"\"\"Train a random forest model.\"\"\"\n",
                                    "        print(\"Training model\")\n",
                                    "        # Train the model\n",
                                    "        model = train_model(\n",
                                    "            processed_data[\"X_train\"],\n",
                                    "            processed_data[\"y_train\"],\n",
                                    "            model_type=\"random_forest\",\n",
                                    "            n_estimators=10,\n",
                                    "            max_depth=5,\n",
                                    "            random_state=42\n",
                                    "        )\n",
                                    "        print(\"Model training complete.\")\n",
                                    "        return {\"model\": model, \"processed_data\": processed_data}\n",
                                    "    \n",
                                    "    @task(task_id=\"evaluate_model\")\n",
                                    "    def task_evaluate_model(training_result):\n",
                                    "        \"\"\"Evaluate the trained model.\"\"\"\n",
                                    "        model = training_result[\"model\"]\n",
                                    "        processed_data = training_result[\"processed_data\"]\n",
                                    "        \n",
                                    "        print(\"Evaluating model\")\n",
                                    "        # Evaluate the model\n",
                                    "        metrics, _ = evaluate_model(model, processed_data[\"X_test\"], processed_data[\"y_test\"])\n",
                                    "        print(f\"Model evaluation metrics: {metrics}\")\n",
                                    "        \n",
                                    "        return {\n",
                                    "            \"model\": model,\n",
                                    "            \"preprocessor\": processed_data[\"preprocessor\"],\n",
                                    "            \"metrics\": metrics\n",
                                    "        }\n",
                                    "    \n",
                                    "    @task(task_id=\"save_model\")\n",
                                    "    def task_save_model(evaluation_result):\n",
                                    "        \"\"\"Save the trained model and preprocessor.\"\"\"\n",
                                    "        model = evaluation_result[\"model\"]\n",
                                    "        preprocessor = evaluation_result[\"preprocessor\"]\n",
                                    "        metrics = evaluation_result[\"metrics\"]\n",
                                    "        \n",
                                    "        print(f\"Saving model to {MODEL_DIR}\")\n",
                                    "        # Create a timestamp for the model name\n",
                                    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
                                    "        model_name = f\"diamond_price_model_{timestamp}\"\n",
                                    "        \n",
                                    "        # Create metadata\n",
                                    "        metadata = {\n",
                                    "            \"metrics\": metrics,\n",
                                    "            \"model_type\": \"RandomForestRegressor\",\n",
                                    "            \"timestamp\": timestamp\n",
                                    "        }\n",
                                    "        \n",
                                    "        # Save the model\n",
                                    "        model_path = save_model(\n",
                                    "            model, \n",
                                    "            preprocessor,\n",
                                    "            MODEL_DIR, \n",
                                    "            model_name, \n",
                                    "            metadata\n",
                                    "        )\n",
                                    "        \n",
                                    "        print(f\"Model saved to {model_path}\")\n",
                                    "        return model_path\n",
                                    "    \n",
                                    "    # Define the task dependencies\n",
                                    "    df = task_load_data()\n",
                                    "    processed_data = task_process_data(df)\n",
                                    "    training_result = task_train_model(processed_data)\n",
                                    "    evaluation_result = task_evaluate_model(training_result)\n",
                                    "    final_model_path = task_save_model(evaluation_result)\n",
                                    "\n",
                                    "# Create the DAG\n",
                                    "diamond_training_pipeline()\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Adding a Model Quality Gate\n",
                                    "\n",
                                    "You’ve just seen how to evaluate your model’s performance in the pipeline. Now, let’s make your workflow a bit smarter by adding a quality check before saving the model.\n",
                                    "\n",
                                    "Your task is to add a new step to the Airflow DAG that checks if the model’s R2 score is good enough before moving on. This helps ensure you only keep models that meet your standards.\n",
                                    "\n",
                                    "Here’s what you need to do:\n",
                                    "\n",
                                    "Create a new task called check_model_quality in the pipeline.\n",
                                    "In this task, check if the R2 score from the evaluation metrics is above a set threshold (for example, 0.8).\n",
                                    "If the R2 score is missing or too low, raise an exception with a clear message so the pipeline stops.\n",
                                    "If the model passes the check, return the evaluation result so the next step can use it.\n",
                                    "Update the task dependencies so that the model is only saved if it passes the quality check.\n",
                                    "This step will help you build more reliable and trustworthy ML pipelines.\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "\"\"\"\n",
                                    "ML Model Training Pipeline DAG\n",
                                    "\n",
                                    "This module defines an Airflow DAG that orchestrates a complete ML training pipeline\n",
                                    "for the diamonds dataset, using functions from our ML modules.\n",
                                    "\"\"\"\n",
                                    "\n",
                                    "from datetime import datetime, timedelta\n",
                                    "import os\n",
                                    "from airflow.decorators import dag, task\n",
                                    "\n",
                                    "# Import our custom modules\n",
                                    "from data import load_diamonds_data, preprocess_diamonds_data\n",
                                    "from model import train_model, save_model\n",
                                    "from evaluation import evaluate_model\n",
                                    "\n",
                                    "# Define default arguments for the DAG\n",
                                    "default_args = {\n",
                                    "    'owner': 'airflow',\n",
                                    "    'depends_on_past': False,\n",
                                    "    'email_on_failure': False,\n",
                                    "    'email_on_retry': False,\n",
                                    "    'retries': 1,\n",
                                    "    'retry_delay': timedelta(minutes=5),\n",
                                    "}\n",
                                    "\n",
                                    "# Define constants\n",
                                    "DATA_PATH = \"diamonds.csv\"\n",
                                    "MODEL_DIR = \"./saved_models\"\n",
                                    "\n",
                                    "# Create model directory if it doesn't exist\n",
                                    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
                                    "\n",
                                    "@dag(\n",
                                    "    dag_id='mlops_pipeline',\n",
                                    "    description='ML model training pipeline for diamond price prediction',\n",
                                    "    default_args=default_args,\n",
                                    "    schedule_interval='@daily',\n",
                                    "    start_date=datetime(2025, 1, 1),\n",
                                    "    catchup=False,\n",
                                    "    tags=['ml', 'training', 'diamonds'],\n",
                                    ")\n",
                                    "def diamond_training_pipeline():\n",
                                    "    \"\"\"\n",
                                    "    This DAG implements a complete ML training pipeline for diamond price prediction.\n",
                                    "    \n",
                                    "    Tasks:\n",
                                    "    1. Load data: Load the diamonds dataset\n",
                                    "    2. Process data: Preprocess the data for model training\n",
                                    "    3. Train model: Train a random forest model\n",
                                    "    4. Evaluate model: Evaluate the model on test data\n",
                                    "    5. Save model: Save the trained model and preprocessor\n",
                                    "    \"\"\"\n",
                                    "    \n",
                                    "    @task(task_id=\"load_data\")\n",
                                    "    def task_load_data():\n",
                                    "        \"\"\"Load the diamonds dataset.\"\"\"\n",
                                    "        print(f\"Loading diamonds data from {DATA_PATH}\")\n",
                                    "        df = load_diamonds_data(DATA_PATH)\n",
                                    "        print(f\"Dataset loaded with shape: {df.shape}\")\n",
                                    "        return df\n",
                                    "    \n",
                                    "    @task(task_id=\"process_data\")\n",
                                    "    def task_process_data(df):\n",
                                    "        \"\"\"Preprocess the data for model training.\"\"\"\n",
                                    "        print(f\"Preprocessing data\")\n",
                                    "        # Preprocess the data\n",
                                    "        X_train, X_test, y_train, y_test, preprocessor = preprocess_diamonds_data(df)\n",
                                    "        print(f\"Data preprocessing complete. Training set size: {X_train.shape[0]}\")\n",
                                    "        return {\"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \n",
                                    "                \"y_test\": y_test, \"preprocessor\": preprocessor}\n",
                                    "    \n",
                                    "    @task(task_id=\"train_model\")\n",
                                    "    def task_train_model(processed_data):\n",
                                    "        \"\"\"Train a random forest model.\"\"\"\n",
                                    "        print(\"Training model\")\n",
                                    "        # Train the model\n",
                                    "        model = train_model(\n",
                                    "            processed_data[\"X_train\"],\n",
                                    "            processed_data[\"y_train\"],\n",
                                    "            model_type=\"random_forest\",\n",
                                    "            n_estimators=10,\n",
                                    "            max_depth=5,\n",
                                    "            random_state=42\n",
                                    "        )\n",
                                    "        print(\"Model training complete.\")\n",
                                    "        return {\"model\": model, \"processed_data\": processed_data}\n",
                                    "    \n",
                                    "    @task(task_id=\"evaluate_model\")\n",
                                    "    def task_evaluate_model(training_result):\n",
                                    "        \"\"\"Evaluate the trained model.\"\"\"\n",
                                    "        model = training_result[\"model\"]\n",
                                    "        processed_data = training_result[\"processed_data\"]\n",
                                    "        \n",
                                    "        print(\"Evaluating model\")\n",
                                    "        # Evaluate the model\n",
                                    "        metrics, _ = evaluate_model(model, processed_data[\"X_test\"], processed_data[\"y_test\"])\n",
                                    "        print(f\"Model evaluation metrics: {metrics}\")\n",
                                    "        \n",
                                    "        return {\n",
                                    "            \"model\": model,\n",
                                    "            \"preprocessor\": processed_data[\"preprocessor\"],\n",
                                    "            \"metrics\": metrics\n",
                                    "        }\n",
                                    "    \n",
                                    "    # TODO: Define a new task called check_model_quality\n",
                                    "\n",
                                    "    #     # TODO: Set the minimum R2 score required (e.g., 0.8)\n",
                                    "    #     # TODO: Get the R2 score from evaluation_result[\"metrics\"]\n",
                                    "    #     # TODO: If the R2 score is missing or too low, raise an Exception with a helpful message\n",
                                    "    #     # TODO: If the check passes, return evaluation_result\n",
                                    "    \n",
                                    "    @task(task_id=\"save_model\")\n",
                                    "    def task_save_model(evaluation_result):\n",
                                    "        \"\"\"Save the trained model and preprocessor.\"\"\"\n",
                                    "        model = evaluation_result[\"model\"]\n",
                                    "        preprocessor = evaluation_result[\"preprocessor\"]\n",
                                    "        metrics = evaluation_result[\"metrics\"]\n",
                                    "        \n",
                                    "        print(f\"Saving model to {MODEL_DIR}\")\n",
                                    "        # Create a timestamp for the model name\n",
                                    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
                                    "        model_name = f\"diamond_price_model_{timestamp}\"\n",
                                    "        \n",
                                    "        # Create metadata\n",
                                    "        metadata = {\n",
                                    "            \"metrics\": metrics,\n",
                                    "            \"model_type\": \"RandomForestRegressor\",\n",
                                    "            \"timestamp\": timestamp\n",
                                    "        }\n",
                                    "        \n",
                                    "        # Save the model\n",
                                    "        model_path = save_model(\n",
                                    "            model, \n",
                                    "            preprocessor,\n",
                                    "            MODEL_DIR, \n",
                                    "            model_name, \n",
                                    "            metadata\n",
                                    "        )\n",
                                    "        \n",
                                    "        print(f\"Model saved to {model_path}\")\n",
                                    "        return model_path\n",
                                    "    \n",
                                    "    # Define the task dependencies\n",
                                    "    df = task_load_data()\n",
                                    "    processed_data = task_process_data(df)\n",
                                    "    training_result = task_train_model(processed_data)\n",
                                    "    evaluation_result = task_evaluate_model(training_result)\n",
                                    "    # TODO: Insert the check_model_quality task here, so it runs after evaluation_result\n",
                                    "\n",
                                    "    final_model_path = task_save_model(evaluation_result)\n",
                                    "\n",
                                    "# Create the DAG\n",
                                    "diamond_training_pipeline()\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "\"\"\"\n",
                                    "ML Model Training Pipeline DAG\n",
                                    "\n",
                                    "This module defines an Airflow DAG that orchestrates a complete ML training pipeline\n",
                                    "for the diamonds dataset, using functions from our ML modules.\n",
                                    "\"\"\"\n",
                                    "\n",
                                    "from datetime import datetime, timedelta\n",
                                    "import os\n",
                                    "from airflow.decorators import dag, task\n",
                                    "\n",
                                    "# Import our custom modules\n",
                                    "from data import load_diamonds_data, preprocess_diamonds_data\n",
                                    "from model import train_model, save_model\n",
                                    "from evaluation import evaluate_model\n",
                                    "\n",
                                    "# Define default arguments for the DAG\n",
                                    "default_args = {\n",
                                    "    'owner': 'airflow',\n",
                                    "    'depends_on_past': False,\n",
                                    "    'email_on_failure': False,\n",
                                    "    'email_on_retry': False,\n",
                                    "    'retries': 1,\n",
                                    "    'retry_delay': timedelta(minutes=5),\n",
                                    "}\n",
                                    "\n",
                                    "# Define constants\n",
                                    "DATA_PATH = \"diamonds.csv\"\n",
                                    "MODEL_DIR = \"./saved_models\"\n",
                                    "\n",
                                    "# Create model directory if it doesn't exist\n",
                                    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
                                    "\n",
                                    "@dag(\n",
                                    "    dag_id='mlops_pipeline',\n",
                                    "    description='ML model training pipeline for diamond price prediction',\n",
                                    "    default_args=default_args,\n",
                                    "    schedule_interval='@daily',\n",
                                    "    start_date=datetime(2025, 1, 1),\n",
                                    "    catchup=False,\n",
                                    "    tags=['ml', 'training', 'diamonds'],\n",
                                    ")\n",
                                    "def diamond_training_pipeline():\n",
                                    "    \"\"\"\n",
                                    "    This DAG implements a complete ML training pipeline for diamond price prediction.\n",
                                    "    \n",
                                    "    Tasks:\n",
                                    "    1. Load data: Load the diamonds dataset\n",
                                    "    2. Process data: Preprocess the data for model training\n",
                                    "    3. Train model: Train a random forest model\n",
                                    "    4. Evaluate model: Evaluate the model on test data\n",
                                    "    5. Save model: Save the trained model and preprocessor\n",
                                    "    \"\"\"\n",
                                    "    \n",
                                    "    @task(task_id=\"load_data\")\n",
                                    "    def task_load_data():\n",
                                    "        \"\"\"Load the diamonds dataset.\"\"\"\n",
                                    "        print(f\"Loading diamonds data from {DATA_PATH}\")\n",
                                    "        df = load_diamonds_data(DATA_PATH)\n",
                                    "        print(f\"Dataset loaded with shape: {df.shape}\")\n",
                                    "        return df\n",
                                    "    \n",
                                    "    @task(task_id=\"process_data\")\n",
                                    "    def task_process_data(df):\n",
                                    "        \"\"\"Preprocess the data for model training.\"\"\"\n",
                                    "        print(f\"Preprocessing data\")\n",
                                    "        # Preprocess the data\n",
                                    "        X_train, X_test, y_train, y_test, preprocessor = preprocess_diamonds_data(df)\n",
                                    "        print(f\"Data preprocessing complete. Training set size: {X_train.shape[0]}\")\n",
                                    "        return {\"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \n",
                                    "                \"y_test\": y_test, \"preprocessor\": preprocessor}\n",
                                    "    \n",
                                    "    @task(task_id=\"train_model\")\n",
                                    "    def task_train_model(processed_data):\n",
                                    "        \"\"\"Train a random forest model.\"\"\"\n",
                                    "        print(\"Training model\")\n",
                                    "        # Train the model\n",
                                    "        model = train_model(\n",
                                    "            processed_data[\"X_train\"],\n",
                                    "            processed_data[\"y_train\"],\n",
                                    "            model_type=\"random_forest\",\n",
                                    "            n_estimators=10,\n",
                                    "            max_depth=5,\n",
                                    "            random_state=42\n",
                                    "        )\n",
                                    "        print(\"Model training complete.\")\n",
                                    "        return {\"model\": model, \"processed_data\": processed_data}\n",
                                    "    \n",
                                    "    @task(task_id=\"evaluate_model\")\n",
                                    "    def task_evaluate_model(training_result):\n",
                                    "        \"\"\"Evaluate the trained model.\"\"\"\n",
                                    "        model = training_result[\"model\"]\n",
                                    "        processed_data = training_result[\"processed_data\"]\n",
                                    "        \n",
                                    "        print(\"Evaluating model\")\n",
                                    "        # Evaluate the model\n",
                                    "        metrics, _ = evaluate_model(model, processed_data[\"X_test\"], processed_data[\"y_test\"])\n",
                                    "        print(f\"Model evaluation metrics: {metrics}\")\n",
                                    "        \n",
                                    "        return {\n",
                                    "            \"model\": model,\n",
                                    "            \"preprocessor\": processed_data[\"preprocessor\"],\n",
                                    "            \"metrics\": metrics\n",
                                    "        }\n",
                                    "    \n",
                                    "    @task(task_id=\"check_model_quality\")\n",
                                    "    def task_check_model_quality(evaluation_result):\n",
                                    "        \"\"\"Check if the model meets the quality threshold.\"\"\"\n",
                                    "        r2_score = evaluation_result[\"metrics\"].get(\"r2_score\")\n",
                                    "        min_r2_score = 0.8\n",
                                    "        \n",
                                    "        if r2_score is None or r2_score < min_r2_score:\n",
                                    "            raise ValueError(\n",
                                    "                f\"Model quality check failed. R2 score ({r2_score}) is below the threshold ({min_r2_score}).\"\n",
                                    "            )\n",
                                    "        \n",
                                    "        print(f\"Model quality check passed with R2 score: {r2_score}\")\n",
                                    "        return evaluation_result\n",
                                    "    \n",
                                    "    @task(task_id=\"save_model\")\n",
                                    "    def task_save_model(evaluation_result):\n",
                                    "        \"\"\"Save the trained model and preprocessor.\"\"\"\n",
                                    "        model = evaluation_result[\"model\"]\n",
                                    "        preprocessor = evaluation_result[\"preprocessor\"]\n",
                                    "        metrics = evaluation_result[\"metrics\"]\n",
                                    "        \n",
                                    "        print(f\"Saving model to {MODEL_DIR}\")\n",
                                    "        # Create a timestamp for the model name\n",
                                    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
                                    "        model_name = f\"diamond_price_model_{timestamp}\"\n",
                                    "        \n",
                                    "        # Create metadata\n",
                                    "        metadata = {\n",
                                    "            \"metrics\": metrics,\n",
                                    "            \"model_type\": \"RandomForestRegressor\",\n",
                                    "            \"timestamp\": timestamp\n",
                                    "        }\n",
                                    "        \n",
                                    "        # Save the model\n",
                                    "        model_path = save_model(\n",
                                    "            model, \n",
                                    "            preprocessor,\n",
                                    "            MODEL_DIR, \n",
                                    "            model_name, \n",
                                    "            metadata\n",
                                    "        )\n",
                                    "        \n",
                                    "        print(f\"Model saved to {model_path}\")\n",
                                    "        return model_path\n",
                                    "    \n",
                                    "    # Define the task dependencies\n",
                                    "    df = task_load_data()\n",
                                    "    processed_data = task_process_data(df)\n",
                                    "    training_result = task_train_model(processed_data)\n",
                                    "    evaluation_result = task_evaluate_model(training_result)\n",
                                    "    \n",
                                    "    # Insert the new task in the dependency chain\n",
                                    "    quality_check_result = task_check_model_quality(evaluation_result)\n",
                                    "    \n",
                                    "    final_model_path = task_save_model(quality_check_result)\n",
                                    "\n",
                                    "# Create the DAG\n",
                                    "diamond_training_pipeline()\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "id": "4adbd087",
                           "metadata": {},
                           "source": [
                                    "You’ve practiced building and connecting individual steps of an ML pipeline in Airflow, including adding a model quality check to make your workflow more reliable.\n",
                                    "\n",
                                    "Now, it’s time to put everything together by creating a complete Airflow DAG that runs the full retraining process for the diamonds dataset. Your goal is to complete the provided Python script by filling in the missing pieces to define all the tasks and connect them into a working pipeline.\n",
                                    "\n",
                                    "Here’s what you need to do:\n",
                                    "\n",
                                    "Import the necessary Airflow decorators (dag and task).\n",
                                    "Add the @dag decorator to the main pipeline function, specifying appropriate arguments (such as dag_id, description, schedule, etc.).\n",
                                    "For each pipeline step, add the @task decorator and implement the function:\n",
                                    "Load Data: Load the diamonds data from a CSV file using load_diamonds_data and return the DataFrame.\n",
                                    "Process Data: Preprocess the data and split it into training and test sets using preprocess_diamonds_data. Return a dictionary with X_train, X_test, y_train, y_test, and preprocessor.\n",
                                    "Train Model: Train a random forest model using the training data and return a dictionary with the model and the processed data.\n",
                                    "Evaluate Model: Evaluate the model using evaluate_model and return a dictionary with the model, preprocessor, and metrics.\n",
                                    "Check Model Quality: Check if the model’s R2 score meets a minimum threshold (e.g., 0.8). If not, raise an exception. If it passes, return the evaluation result.\n",
                                    "Save Model: Save the model, preprocessor, and metadata (including metrics and a timestamp) using save_model. Return the model path.\n",
                                    "Set up the dependencies so that each task runs in the correct order and passes the right data to the next step.\n",
                                    "At the end, enable the DAG by calling your pipeline function.\n",
                                    "Make sure your pipeline passes all the necessary information between tasks and only saves models that meet your quality standards.\n",
                                    "\n",
                                    "This is your chance to show you can build a full, automated ML retraining workflow from start to finish!\n",
                                    "\n",
                                    "```python\n",
                                    "\"\"\"\n",
                                    "Complete ML Retraining Pipeline DAG\n",
                                    "\n",
                                    "This script will define an Airflow DAG for a full machine learning retraining workflow\n",
                                    "for the diamonds dataset. You will need to fill in the tasks and set up the pipeline.\n",
                                    "\"\"\"\n",
                                    "\n",
                                    "from datetime import datetime, timedelta\n",
                                    "import os\n",
                                    "# TODO: Import the Airflow DAG and task decorators\n",
                                    "\n",
                                    "# Import custom ML modules\n",
                                    "from data import load_diamonds_data, preprocess_diamonds_data\n",
                                    "from model import train_model, save_model\n",
                                    "from evaluation import evaluate_model\n",
                                    "\n",
                                    "# Default DAG arguments\n",
                                    "default_args = {\n",
                                    "    'owner': 'airflow',\n",
                                    "    'depends_on_past': False,\n",
                                    "    'email_on_failure': False,\n",
                                    "    'email_on_retry': False,\n",
                                    "    'retries': 1,\n",
                                    "    'retry_delay': timedelta(minutes=5),\n",
                                    "}\n",
                                    "\n",
                                    "# Constants\n",
                                    "DATA_PATH = \"diamonds.csv\"\n",
                                    "MODEL_DIR = \"./saved_models\"\n",
                                    "\n",
                                    "# Ensure model directory exists\n",
                                    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
                                    "\n",
                                    "# TODO: Add the dag decorator here with appropriate arguments (dag_id, description, schedule, ...)\n",
                                    "# Make sure to use `mlops_pipeline` as `dag_id`.\n",
                                    "def diamond_retraining_pipeline():\n",
                                    "    \"\"\"\n",
                                    "    This DAG should run a full ML retraining workflow:\n",
                                    "    1. Load data\n",
                                    "    2. Preprocess data\n",
                                    "    3. Train model\n",
                                    "    4. Evaluate model\n",
                                    "    5. Check model quality\n",
                                    "    6. Save model and metadata\n",
                                    "    \"\"\"\n",
                                    "\n",
                                    "    # TODO: Add the task decorator here\n",
                                    "    def load_data_task():\n",
                                    "        \"\"\"Load the diamonds dataset from CSV.\"\"\"\n",
                                    "        # TODO: Load the diamonds data using load_diamonds_data and return the DataFrame\n",
                                    "        pass\n",
                                    "\n",
                                    "    # TODO: Add the task decorator here\n",
                                    "    def process_data_task(df):\n",
                                    "        \"\"\"Preprocess the data and split into train/test sets.\"\"\"\n",
                                    "        # TODO: Preprocess the data using preprocess_diamonds_data\n",
                                    "        # TODO: Return a dictionary with X_train, X_test, y_train, y_test, and preprocessor\n",
                                    "        pass\n",
                                    "\n",
                                    "    # TODO: Add the task decorator here\n",
                                    "    def train_model_task(processed_data):\n",
                                    "        \"\"\"Train a random forest model.\"\"\"\n",
                                    "        # TODO: Train the model using train_model\n",
                                    "        # TODO: Return a dictionary with the model and the processed_data\n",
                                    "        pass\n",
                                    "\n",
                                    "    # TODO: Add the task decorator here\n",
                                    "    def evaluate_model_task(training_result):\n",
                                    "        \"\"\"Evaluate the trained model and return metrics.\"\"\"\n",
                                    "        # TODO: Evaluate the model using evaluate_model\n",
                                    "        # TODO: Return a dictionary with the model, preprocessor, and metrics\n",
                                    "        pass\n",
                                    "\n",
                                    "    # TODO: Add the task decorator here\n",
                                    "    def check_model_quality_task(evaluation_result):\n",
                                    "        \"\"\"\n",
                                    "        Check if the model's R2 score meets the minimum threshold.\n",
                                    "        Raise an exception if not.\n",
                                    "        \"\"\"\n",
                                    "        # TODO: Set a minimum R2 score (e.g., 0.8)\n",
                                    "        # TODO: Get the R2 score from evaluation_result[\"metrics\"]\n",
                                    "        # TODO: If the R2 score is missing or too low, raise an Exception\n",
                                    "        # TODO: If the check passes, return evaluation_result\n",
                                    "        pass\n",
                                    "\n",
                                    "    # TODO: Add the task decorator here\n",
                                    "    def save_model_task(evaluation_result):\n",
                                    "        \"\"\"Save the trained model, preprocessor, and metadata.\"\"\"\n",
                                    "        # TODO: Save the model using save_model\n",
                                    "        # TODO: Use a timestamp for the model name and include metrics in metadata\n",
                                    "        # TODO: Return the model path\n",
                                    "        pass\n",
                                    "\n",
                                    "    # TODO: Set up the task dependencies below\n",
                                    "\n",
                                    "\n",
                                    "# TODO: Enable the DAG\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "\"\"\"\n",
                                    "Complete ML Retraining Pipeline DAG\n",
                                    "\n",
                                    "This script will define an Airflow DAG for a full machine learning retraining workflow\n",
                                    "for the diamonds dataset. You will need to fill in the tasks and set up the pipeline.\n",
                                    "\"\"\"\n",
                                    "\n",
                                    "from datetime import datetime, timedelta\n",
                                    "import os\n",
                                    "# TODO: Import the Airflow DAG and task decorators\n",
                                    "from airflow.decorators import dag, task\n",
                                    "\n",
                                    "# Import custom ML modules\n",
                                    "from data import load_diamonds_data, preprocess_diamonds_data\n",
                                    "from model import train_model, save_model\n",
                                    "from evaluation import evaluate_model\n",
                                    "\n",
                                    "# Default DAG arguments\n",
                                    "default_args = {\n",
                                    "    'owner': 'airflow',\n",
                                    "    'depends_on_past': False,\n",
                                    "    'email_on_failure': False,\n",
                                    "    'email_on_retry': False,\n",
                                    "    'retries': 1,\n",
                                    "    'retry_delay': timedelta(minutes=5),\n",
                                    "}\n",
                                    "\n",
                                    "# Constants\n",
                                    "DATA_PATH = \"diamonds.csv\"\n",
                                    "MODEL_DIR = \"./saved_models\"\n",
                                    "\n",
                                    "# Ensure model directory exists\n",
                                    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
                                    "\n",
                                    "# TODO: Add the dag decorator here with appropriate arguments (dag_id, description, schedule, ...)\n",
                                    "# Make sure to use `mlops_pipeline` as `dag_id`.\n",
                                    "@dag(\n",
                                    "    dag_id='mlops_pipeline',\n",
                                    "    description='A complete ML retraining pipeline for diamond price prediction',\n",
                                    "    default_args=default_args,\n",
                                    "    schedule_interval='@daily',\n",
                                    "    start_date=datetime(2025, 1, 1),\n",
                                    "    catchup=False,\n",
                                    "    tags=['ml', 'training'],\n",
                                    ")\n",
                                    "def diamond_retraining_pipeline():\n",
                                    "    \"\"\"\n",
                                    "    This DAG should run a full ML retraining workflow:\n",
                                    "    1. Load data\n",
                                    "    2. Preprocess data\n",
                                    "    3. Train model\n",
                                    "    4. Evaluate model\n",
                                    "    5. Check model quality\n",
                                    "    6. Save model and metadata\n",
                                    "    \"\"\"\n",
                                    "\n",
                                    "    # TODO: Add the task decorator here\n",
                                    "    @task(task_id=\"load_data\")\n",
                                    "    def load_data_task():\n",
                                    "        \"\"\"Load the diamonds dataset from CSV.\"\"\"\n",
                                    "        # TODO: Load the diamonds data using load_diamonds_data and return the DataFrame\n",
                                    "        print(\"Loading diamonds data...\")\n",
                                    "        df = load_diamonds_data(DATA_PATH)\n",
                                    "        print(\"Data loaded successfully.\")\n",
                                    "        return df\n",
                                    "\n",
                                    "    # TODO: Add the task decorator here\n",
                                    "    @task(task_id=\"process_data\")\n",
                                    "    def process_data_task(df):\n",
                                    "        \"\"\"Preprocess the data and split into train/test sets.\"\"\"\n",
                                    "        # TODO: Preprocess the data using preprocess_diamonds_data\n",
                                    "        # TODO: Return a dictionary with X_train, X_test, y_train, y_test, and preprocessor\n",
                                    "        print(\"Preprocessing data...\")\n",
                                    "        X_train, X_test, y_train, y_test, preprocessor = preprocess_diamonds_data(df)\n",
                                    "        print(\"Data preprocessing complete.\")\n",
                                    "        return {\n",
                                    "            \"X_train\": X_train, \n",
                                    "            \"X_test\": X_test, \n",
                                    "            \"y_train\": y_train, \n",
                                    "            \"y_test\": y_test, \n",
                                    "            \"preprocessor\": preprocessor\n",
                                    "        }\n",
                                    "\n",
                                    "    # TODO: Add the task decorator here\n",
                                    "    @task(task_id=\"train_model\")\n",
                                    "    def train_model_task(processed_data):\n",
                                    "        \"\"\"Train a random forest model.\"\"\"\n",
                                    "        # TODO: Train the model using train_model\n",
                                    "        # TODO: Return a dictionary with the model and the processed_data\n",
                                    "        print(\"Training model...\")\n",
                                    "        model = train_model(\n",
                                    "            X_train=processed_data[\"X_train\"],\n",
                                    "            y_train=processed_data[\"y_train\"],\n",
                                    "            model_type=\"random_forest\",\n",
                                    "            n_estimators=10,\n",
                                    "            max_depth=5,\n",
                                    "            random_state=42\n",
                                    "        )\n",
                                    "        print(\"Model training complete.\")\n",
                                    "        return {\"model\": model, \"processed_data\": processed_data}\n",
                                    "\n",
                                    "    # TODO: Add the task decorator here\n",
                                    "    @task(task_id=\"evaluate_model\")\n",
                                    "    def evaluate_model_task(training_result):\n",
                                    "        \"\"\"Evaluate the trained model and return metrics.\"\"\"\n",
                                    "        # TODO: Evaluate the model using evaluate_model\n",
                                    "        # TODO: Return a dictionary with the model, preprocessor, and metrics\n",
                                    "        print(\"Evaluating model...\")\n",
                                    "        model = training_result[\"model\"]\n",
                                    "        processed_data = training_result[\"processed_data\"]\n",
                                    "        metrics, _ = evaluate_model(model, processed_data[\"X_test\"], processed_data[\"y_test\"])\n",
                                    "        print(f\"Model evaluation metrics: {metrics}\")\n",
                                    "        return {\n",
                                    "            \"model\": model,\n",
                                    "            \"preprocessor\": processed_data[\"preprocessor\"],\n",
                                    "            \"metrics\": metrics\n",
                                    "        }\n",
                                    "\n",
                                    "    # TODO: Add the task decorator here\n",
                                    "    @task(task_id=\"check_model_quality\")\n",
                                    "    def check_model_quality_task(evaluation_result):\n",
                                    "        \"\"\"\n",
                                    "        Check if the model's R2 score meets the minimum threshold.\n",
                                    "        Raise an exception if not.\n",
                                    "        \"\"\"\n",
                                    "        # TODO: Set a minimum R2 score (e.g., 0.8)\n",
                                    "        # TODO: Get the R2 score from evaluation_result[\"metrics\"]\n",
                                    "        # TODO: If the R2 score is missing or too low, raise an Exception\n",
                                    "        # TODO: If the check passes, return evaluation_result\n",
                                    "        min_r2_score = 0.8\n",
                                    "        r2_score = evaluation_result[\"metrics\"].get(\"r2_score\")\n",
                                    "        \n",
                                    "        if r2_score is None or r2_score < min_r2_score:\n",
                                    "            raise ValueError(f\"Model quality check failed. R2 score ({r2_score}) is below the threshold ({min_r2_score}).\")\n",
                                    "            \n",
                                    "        print(f\"Model quality check passed with R2 score: {r2_score}\")\n",
                                    "        return evaluation_result\n",
                                    "\n",
                                    "    # TODO: Add the task decorator here\n",
                                    "    @task(task_id=\"save_model\")\n",
                                    "    def save_model_task(evaluation_result):\n",
                                    "        \"\"\"Save the trained model, preprocessor, and metadata.\"\"\"\n",
                                    "        # TODO: Save the model using save_model\n",
                                    "        # TODO: Use a timestamp for the model name and include metrics in metadata\n",
                                    "        # TODO: Return the model path\n",
                                    "        model = evaluation_result[\"model\"]\n",
                                    "        preprocessor = evaluation_result[\"preprocessor\"]\n",
                                    "        metrics = evaluation_result[\"metrics\"]\n",
                                    "        \n",
                                    "        print(f\"Saving model to {MODEL_DIR}\")\n",
                                    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
                                    "        model_name = f\"diamond_price_model_{timestamp}\"\n",
                                    "        metadata = {\n",
                                    "            \"metrics\": metrics,\n",
                                    "            \"model_type\": \"RandomForestRegressor\",\n",
                                    "            \"timestamp\": timestamp\n",
                                    "        }\n",
                                    "        \n",
                                    "        model_path = save_model(\n",
                                    "            model, \n",
                                    "            preprocessor,\n",
                                    "            MODEL_DIR, \n",
                                    "            model_name, \n",
                                    "            metadata\n",
                                    "        )\n",
                                    "        \n",
                                    "        print(f\"Model saved to {model_path}\")\n",
                                    "        return model_path\n",
                                    "\n",
                                    "    # TODO: Set up the task dependencies below\n",
                                    "    df = load_data_task()\n",
                                    "    processed_data = process_data_task(df)\n",
                                    "    training_result = train_model_task(processed_data)\n",
                                    "    evaluation_result = evaluate_model_task(training_result)\n",
                                    "    quality_check_result = check_model_quality_task(evaluation_result)\n",
                                    "    final_model_path = save_model_task(quality_check_result)\n",
                                    "\n",
                                    "\n",
                                    "# TODO: Enable the DAG\n",
                                    "diamond_retraining_pipeline()\n",
                                    "```"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
