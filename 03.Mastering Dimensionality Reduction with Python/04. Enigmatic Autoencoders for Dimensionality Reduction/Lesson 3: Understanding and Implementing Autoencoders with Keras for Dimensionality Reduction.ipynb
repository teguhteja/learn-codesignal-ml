{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Welcome! This lesson explores the world of autoencoders, neural networks designed to learn efficient encodings of the input data. During this interactive session, we'll familiarize you with the autoencoder architecture, focusing on its encoder and decoder components, and how to implement these components using Python with the Keras API. We'll also show how to train and apply an autoencoder for digit image reconstruction with sklearn's digit dataset.\n",
    "\n",
    "## Understanding Autoencoder Architecture and Preprocessing Data\n",
    "Autoencoders are a type of neural network that learns to compress the input data into a lower-dimensional space and then reconstruct the original input from this compressed version. They are widely used for tasks such as dimensionality reduction, denoising, and anomaly detection.\n",
    "\n",
    "Imagine we have a house, and we want to build an exact copy of the house across town. We could go back and forth between the old and new house to get the details of the house, but this process is time-consuming and inefficient. Instead, we could use an autoencoder to create a blueprint of the house that captures all the essential details. We then use this blueprint to build the new house, saving time and effort.\n",
    "\n",
    "The two major components of an autoencoder - the encoder and the decoder - help compress the input data into a latent space and reconstruct the original input from the compressed version. Autoencoders are often employed for tasks such as dimensionality reduction and denoising.\n",
    "\n",
    "Before implementing the components, preprocessing the data is our first step. We'll use sklearn's load_digits() function to download the digits dataset and normalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = load_digits().data\n",
    "scaler = MinMaxScaler()\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The load_digits() function downloads the digits dataset, which contains 8x8 pixel images of handwritten digits. We normalize the data using the MinMaxScaler to ensure all features are within the same range. This step is crucial for training the autoencoder effectively.\n",
    "\n",
    "The encoder will compress the digit images into a lower-dimensional space, while the decoder will attempt to reconstruct the original images from this compressed version. The autoencoder will learn to minimize the reconstruction error, improving its performance over time.\n",
    "\n",
    "## Implementing Encoder and Decoder Components in Python\n",
    "Once the data is ready, we move on to implementing the autoencoder components in Keras. The encoder transforms the input data into a latent-space representation. The decoder then reverts this process, attempting to recreate the original input. Note that in the previous lessons we used the Sequential model for building neural networks. However, for autoencoders, we'll use the following syntax, which allows us to define more complex architectures. With this approach we create an input layer and then stack additional layers on top of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 10:37:43.345475: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-26 10:37:43.345741: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-26 10:37:43.374247: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-26 10:37:43.626779: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-26 10:37:44.797557: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# Create an input layer with 64 neurons to match the number of features in the digit images\n",
    "input_img_layer = Input(shape=(64,))\n",
    "\n",
    "# Create a consecutive layer with 32 neurons and ReLU activation function on the top of the input layer\n",
    "encoded_layer = Dense(32, activation='relu')(input_img_layer)\n",
    "\n",
    "# Create a consecutive layer with 64 neurons and Sigmoid activation function on the top of the encoded layer to reconstruct the original input\n",
    "decoded_layer = Dense(64, activation='sigmoid')(encoded_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Input shape for the encoder layer is 64, which matches the number of features in our digit images. The encoder is followed by the decoder layer, which reconstructs the original 64-feature input from the condensed output of the encoder. Once the encoder and decoder layers are defined, we can create the autoencoder model by tying the input and output layers together. We'll see this in the next section.\n",
    "\n",
    "## Training the Autoencoder\n",
    "Now that we've defined the encoder and decoder components, we can compile and train the autoencoder model. The autoencoder will learn to compress the input data into a lower-dimensional space and then reconstruct the original input from this compressed version. To do that we first need to create the autoencoder model by combining the input and output layers using the Model class. Moving on, we compile the autoencoder and define the loss function and optimizer. The optimizer 'adam' controls the learning rate, while 'binary_crossentropy' functions as our loss metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6969  \n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6600 \n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6268 \n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5915 \n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5552 \n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5181 \n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4858 \n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4618 \n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4441 \n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4318 \n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4226 \n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4164 \n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4100 \n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 0.4063\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4017 \n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3971 \n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.3924\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3897 \n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3832 \n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.3816\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3766 \n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3722 \n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3692 \n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3651 \n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3612 \n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3579 \n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3538\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3500 \n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3462 \n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3446 \n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3404 \n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3385 \n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3354 \n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3325 \n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3304 \n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.3283\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3266 \n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3250 \n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3232 \n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3220 \n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3186 \n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.3170\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3164 \n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3161 \n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3140 \n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - loss: 0.3115\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 0.3101\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3092 \n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3082 \n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3063 \n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.3056\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3045 \n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.3034\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3012 \n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3008 \n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3001 \n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 0.2987\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 0.2986\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2976 \n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 0.2970\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2958 \n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 0.2947\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2941 \n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 0.2931\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2928 \n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 0.2918\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2900 \n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - loss: 0.2906\n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2897 \n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2878 \n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 0.2885\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 0.2864\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2871 \n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2852 \n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 0.2864\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2843 \n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2848 \n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2833 \n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2826 \n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.2820\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2820 \n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.2809\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2813 \n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 0.2806\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2790 \n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.2782\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 0.2776\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - loss: 0.2775\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.2766\n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.2770\n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2765 \n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.2762\n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2748 \n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2748 \n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2740 \n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2749 \n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2735 \n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 0.2727\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.2717\n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2719 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x79afe7b36e40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Autoencoder\n",
    "autoencoder = Model(input_img_layer, decoded_layer)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(data, data, epochs=100, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the autoencoder compiled, we train it using the actual data employing the fit method. This process adjusts the autoencoder weights to reduce the reconstruction error, improving the model's performance over the training period or epochs.\n",
    "\n",
    "## Visualizing the Autoencoder Effectiveness\n",
    "Once the autoencoder is trained, we'll apply it to the test set and visualize its effectiveness in input reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    }
   ],
   "source": [
    "reconstructed_data = autoencoder.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cross-verify the autoencoder's performance by visualizing a set of actual digit images and their reconstructed versions generated by the autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 21 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.title('Original vs Reconstructed')\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(data[i].reshape(8, 8))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    # Display reconstruction as generated by our autoencoder\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(reconstructed_data[i].reshape(8, 8))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our autoencoder is effectively trained, the reconstructed images should reveal digits similarly shaped as in the original images.\n",
    "In the above code, we display the original digit images on the top row and their reconstructed versions on the bottom row. The reconstructed images should closely resemble the original images, indicating that the autoencoder has learned to compress and reconstruct the input data effectively.\n",
    "\n",
    "## Using Encoder for Dimensionality Reduction\n",
    "One of the major applications of an autoencoder is for dimensionality reduction. By extracting the encoding layers, you can transform the input features into a lower-dimensional space, making it easier to visualize and process.\n",
    "\n",
    "Since we've already trained our autoencoder model, the encoder will have learned to compress the input images effectively. We can use this learned knowledge to transform our 64-dimensional images into a 32-dimensional encoded space.\n",
    "\n",
    "To get the encoder, we create a new model using the autoencoder's input and the encoded output as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step\n",
      "Shape of the original data: (1797, 64)\n",
      "Shape of encoded_data: (1797, 32)\n"
     ]
    }
   ],
   "source": [
    "# Encoder Model\n",
    "encoder = Model(input_img_layer, encoded_layer)\n",
    "# Apply the encoder to the data\n",
    "encoded_data = encoder.predict(data)\n",
    "\n",
    "print('Shape of the original data:', data.shape) # Output: (1797, 64)\n",
    "print('Shape of encoded_data:', encoded_data.shape) # Output: (1797, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we first define a new Model that shares the same input layer as the original autoencoder, but only outputs the encoder's output. We then transform our data by calling predict on the encoder model.\n",
    "\n",
    "Now, encoded_data will be a new representation of our original input data but in the latent space as defined by our encoder. This action is similar to how Principal Component Analysis (PCA) compresses original data into a lower-dimensional space. However, unlike PCA, the encoder, as part of the autoencoder, does not necessarily maintain the linearity of features. Encoders can capture complex, non-linear relationships, making them a powerful tool for dimensionality reduction and a stepping stone to more complex tasks in deep learning.\n",
    "\n",
    "This compressed representation can be beneficial for various tasks, like feature reduction, data visualization, or even used for training other machine learning models where the fewer number of features can result in less computation.\n",
    "\n",
    "## Lesson Summary and Practice\n",
    "We've successfully discovered the architecture behind autoencoders, implemented them using Python and Keras API, compiled and trained our model, and visualized the effectiveness of our autoencoder in digit image reconstruction. Brace yourself for the next level of autoencoder adventures. Next up, let's exercise to solidify these concepts! Keep practicing, and happy coding!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Autoencoders with Digit Reconstruction\n",
    "\n",
    "Imagine we need to compress a vast array — quite a challenge — of digit images to save storage space while maintaining the essence of the images. An autoencoder can learn to reduce the dimensionality of our data. Take a look at the given code where an autoencoder is trained to compress and reconstruct digit images. Let's see how this method performs by running the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - loss: 0.7125\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6857 \n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6585 \n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6281 \n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 0.5921\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5534 \n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5145 \n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4830 \n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.4590\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4438 \n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4329 \n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4232 \n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4182 \n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4115 \n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4069 \n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4015 \n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3948 \n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3905 \n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.3849\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3791 \n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3749 \n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3702 \n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3657 \n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3631 \n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3582 \n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3548 \n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3510 \n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 0.3467\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3427 \n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3418 \n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3384 \n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3348 \n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.3329\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3298 \n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3278 \n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3256 \n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3242 \n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3223 \n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3196 \n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.3191\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 0.3151\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - loss: 0.3145\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3133 \n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3114 \n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3099 \n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3085 \n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3068 \n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3057 \n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3042 \n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3038 \n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3018 \n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3013 \n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3012 \n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2994 \n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2978 \n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2970 \n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2958 \n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2952 \n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2935 \n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2935 \n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2930 \n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2924 \n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2913 \n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2896 \n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - loss: 0.2884\n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2880 \n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2864 \n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2869 \n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2860 \n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2861 \n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2850 \n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2851 \n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2841 \n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2839 \n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2822 \n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2818 \n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2821 \n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 0.2810\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2807 \n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2806 \n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2799 \n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2783 \n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2784 \n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2771 \n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2784 \n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2760 \n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2776 \n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2755 \n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2757 \n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2741 \n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2749 \n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2744 \n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2745 \n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2730 \n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2730 \n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2714 \n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2718 \n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 0.2704\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2709 \n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2701 \n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppresses all TensorFlow logs, shows only errors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load digits dataset and normalize data\n",
    "digits_data = load_digits().data\n",
    "scaler = MinMaxScaler()\n",
    "data = scaler.fit_transform(digits_data)\n",
    "\n",
    "# Define the encoder\n",
    "input_img = Input(shape=(64,))\n",
    "encoded = Dense(32, activation='relu')(input_img)\n",
    "\n",
    "# Define the decoder\n",
    "decoded = Dense(64, activation='sigmoid')(encoded)\n",
    "\n",
    "# Define the autoencoder model\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(data, data, epochs=100, batch_size=256, shuffle=True)\n",
    "\n",
    "# Predict using the autoencoder\n",
    "predicted = autoencoder.predict(data)\n",
    "\n",
    "# Visualize the original and reconstructed data\n",
    "n = 10  # Number of digit images to display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original digits\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(data[i].reshape(8, 8))\n",
    "    plt.gray()\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Display reconstructed digits\n",
    "    ax = plt.subplot(2, n, i + n + 1)\n",
    "    plt.imshow(predicted[i].reshape(8, 8))\n",
    "    plt.gray()\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder Decoder Adjustment\n",
    "\n",
    "Terrific progress, Celestial Traveler! It's time to experiment with our autoencoder's decoder component. Adjust the activation function of the last layer from 'relu' to 'sigmoid' and update the encoder layer to have 40 features. Witness the impact of this small change on the reconstructed images. Are you ready to embark on this micro-mission?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6907  \n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6532 \n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6206 \n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5872 \n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5507 \n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.5142\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4810 \n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 0.4554\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4375 \n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4251 \n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4164 \n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4092 \n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4020 \n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.3957\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3913 \n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3847 \n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3796 \n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3737 \n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 0.3698\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3635 \n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3592 \n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3550 \n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3494 \n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 0.3469\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3430 \n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.3394\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3355 \n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3330 \n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 0.3315\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3270 \n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3245 \n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.3236\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3197 \n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3195 \n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3169 \n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3144 \n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 0.3123\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3103 \n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3092 \n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 0.3068\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3063 \n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3046 \n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3026 \n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3019 \n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2999 \n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2998 \n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2987 \n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2962 \n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2956 \n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 0.2938\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2934 \n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2925 \n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.2912\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2905 \n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.2889\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2888 \n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.2875\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2870 \n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.2858\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2848 \n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2845 \n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 0.2840\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2820 \n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2819 \n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2813 \n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2801 \n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2804 \n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2792 \n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 0.2782\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2768 \n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.2774\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2768 \n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.2756\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2760 \n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2749 \n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2740 \n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2743 \n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2735 \n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.2721\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2725 \n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 0.2726\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2714 \n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2706 \n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 0.2702\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2697 \n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2686 \n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2675 \n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 0.2676\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2678 \n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2669 \n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2654 \n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2658 \n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 0.2658\n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2651 \n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 0.2660\n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2646 \n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2639 \n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 0.2632\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2634 \n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2625 \n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppresses all TensorFlow logs, shows only errors\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the data\n",
    "digits = load_digits()\n",
    "data = digits.data\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(data)\n",
    "\n",
    "# Build the encoder\n",
    "input_img = Input(shape=(64,))\n",
    "encoded = Dense(40, activation='relu')(input_img)\n",
    "\n",
    "# Build the decoder\n",
    "decoded = Dense(64, activation='sigmoid')(encoded)\n",
    "\n",
    "# Build the autoencoder\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(normalized_data, normalized_data, epochs=100, batch_size=256, shuffle=True)\n",
    "\n",
    "# Apply the trained autoencoder to the data\n",
    "predicted = autoencoder.predict(normalized_data)\n",
    "\n",
    "# Visualize original vs reconstructed images\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(10):  # Show 10 digits\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, 10, i + 1)\n",
    "    plt.imshow(normalized_data[i].reshape(8, 8))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstructed (decoded) image\n",
    "    ax = plt.subplot(2, 10, i + 1 + 10)\n",
    "    plt.imshow(predicted[i].reshape(8, 8))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder Space Odyssey: Compress and Reconstruct\n",
    "\n",
    "Your knowledge of autoencoder architecture has prepared you for the final frontier! Construct a simple autoencoder for our imaginary 8x8 digit images that can compress and then attempt to reconstruct them. Use the provided code structure to define the encoder and decoder, and train the autoencoder. The data loading and final visualisation part are already provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7063  \n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.6833\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6629 \n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6384 \n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6065 \n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5683 \n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5282 \n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4925 \n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4644 \n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4462 \n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4354 \n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4230 \n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4178 \n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4114 \n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4060 \n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4006 \n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3956 \n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3905 \n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3860 \n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.3823\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3765 \n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3723 \n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3678 \n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3635 \n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3595 \n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3554 \n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3514 \n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3485 \n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3452 \n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3420 \n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3398 \n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3372 \n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3333 \n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3315 \n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3308 \n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3286 \n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - loss: 0.3271\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3252 \n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3229 \n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3214 \n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3200 \n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3191 \n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3177 \n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3157 \n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3140 \n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3137 \n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3099 \n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3104 \n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3087 \n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3089 \n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3066 \n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3070 \n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3050 \n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3042 \n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3024 \n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3032 \n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3013 \n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3000 \n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2982 \n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2969 \n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2968 \n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2946 \n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2935 \n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2935 \n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2922 \n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2917 \n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2903 \n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2896 \n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 0.2889\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2883 \n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2881 \n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2864 \n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2866 \n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2859 \n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2839 \n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2834 \n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2830 \n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 0.2810\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 0.2829\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2820 \n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2812 \n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2810 \n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2789 \n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2790 \n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2779 \n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2781 \n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - loss: 0.2771\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2770 \n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2759 \n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2758 \n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2753 \n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.2748\n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2742 \n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.2746\n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2744 \n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2721 \n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2731 \n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2728 \n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2719 \n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2701 \n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Preprocessing the data\n",
    "data = load_digits().data\n",
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(data)\n",
    "\n",
    "# Create the input layer of the autoencoder\n",
    "input_layer = Input(shape=(64,))\n",
    "\n",
    "# Create the encoded layer with a reduced dimensionality and relu activation\n",
    "encoded = Dense(32, activation='relu')(input_layer)\n",
    "\n",
    "# Create the decoded layer to reconstruct the input\n",
    "decoded = Dense(64, activation='sigmoid')(encoded)\n",
    "\n",
    "# Build the autoencoder model and compile it with an optimizer and binary_crossentropy loss\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the autoencoder model with normalized data\n",
    "autoencoder.fit(data_normalized, data_normalized, epochs=100, batch_size=256, shuffle=True)\n",
    "\n",
    "# Predict the reconstructed data using the trained autoencoder\n",
    "reconstructed_data = autoencoder.predict(data_normalized)\n",
    "\n",
    "# Visualizing the original and reconstructed images\n",
    "n = 10  # Display 10 digits\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(data_normalized[i].reshape(8, 8))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(reconstructed_data[i].reshape(8, 8))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
