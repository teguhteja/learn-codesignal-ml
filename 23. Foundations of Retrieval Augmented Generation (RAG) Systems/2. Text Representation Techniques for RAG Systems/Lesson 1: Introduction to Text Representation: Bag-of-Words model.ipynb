{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Lesson 1: Introduction to Text Representation: Bag-of-Words model\n",
                                    "\n",
                                    "Welcome to the very first lesson of our course **“Text Representation Techniques for RAG Systems”**, part of our **“Foundations of RAG Systems”** path! In the first course of this learning path, you learned the fundamentals of RAG, how to structure a simple RAG workflow, and why combining retrieval with generation is so powerful. Now, we’ll shift our focus to how we can turn raw text into numerical data — a crucial step if we want our RAG systems to retrieve information accurately and feed it into downstream pipelines. In other words, we’ll focus on the **indexing component** of our RAG pipeline.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Learning Objectives\n",
                                    "\n",
                                    "1. Understand why we must transform text into a structured format for RAG workflows.  \n",
                                    "2. Explore the **Bag-of-Words (BOW)** method, a simple yet classic text representation technique.  \n",
                                    "\n",
                                    "By the end, you’ll know:\n",
                                    "- How words get mapped into vectors  \n",
                                    "- Why these representations matter for building robust retrieval systems  \n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Why Text Representation Is Essential\n",
                                    "\n",
                                    "RAG systems revolve around:\n",
                                    "1. Retrieving relevant documents based on a user’s query  \n",
                                    "2. Generating a final answer  \n",
                                    "\n",
                                    "Computers don’t process language like humans—they require **structured, numerical forms** of text to compare documents effectively. Without proper representation:\n",
                                    "\n",
                                    "- We can’t reliably measure similarity between two texts.  \n",
                                    "- Retrieving contextually relevant information becomes very difficult.  \n",
                                    "\n",
                                    "A straightforward solution is the **Bag-of-Words** method. It counts how often each word appears, providing a simple numerical snapshot of a document. While BOW ignores word order and nuances, it’s an excellent entry point for converting messy language into machine-friendly formats.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Understanding the BOW Model\n",
                                    "\n",
                                    "Consider these three sentences:\n",
                                    "\n",
                                    "1. “I love machine learning”  \n",
                                    "2. “Machine learning is fun”  \n",
                                    "3. “I love coding”  \n",
                                    "\n",
                                    "First, gather all unique words into a **vocabulary**:  \n",
                                    "```\n",
                                    "{ I, love, machine, learning, is, fun, coding }\n",
                                    "```\n",
                                    "\n",
                                    "| Word     | I | love | machine | learning | is | fun | coding |\n",
                                    "|----------|:-:|:----:|:-------:|:--------:|:-:|:---:|:------:|\n",
                                    "| **Index**| 0 |  1   |    2    |     3    | 4 |  5  |   6    |\n",
                                    "\n",
                                    "Next, transform each sentence into a numeric **frequency vector**:\n",
                                    "\n",
                                    "| Sentence                   | I | love | machine | learning | is | fun | coding |\n",
                                    "|----------------------------|:-:|:----:|:-------:|:--------:|:-:|:---:|:------:|\n",
                                    "| I love machine learning    | 1 |  1   |    1    |     1    | 0 |  0  |   0    |\n",
                                    "| Machine learning is fun    | 0 |  0   |    1    |     1    | 1 |  1  |   0    |\n",
                                    "| I love coding              | 1 |  1   |    0    |     0    | 0 |  0  |   1    |\n",
                                    "\n",
                                    "Each column corresponds to a word; each entry is its occurrence count.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Building a Basic Vocabulary\n",
                                    "\n",
                                    "In BOW, the first step is constructing a **vocabulary** dictionary:\n",
                                    "\n",
                                    "```python\n",
                                    "def build_vocab(docs):\n",
                                    "    unique_words = set()\n",
                                    "    for doc in docs:\n",
                                    "        for word in doc.lower().split():\n",
                                    "            clean_word = word.strip(\".,!?\")\n",
                                    "            if clean_word:\n",
                                    "                unique_words.add(clean_word)\n",
                                    "    # Sort for consistent ordering\n",
                                    "    return {word: idx for idx, word in enumerate(sorted(unique_words))}\n",
                                    "```\n",
                                    "\n",
                                    "**How it works:**\n",
                                    "1. Iterate through each document.  \n",
                                    "2. Lowercase and split into tokens.  \n",
                                    "3. Strip punctuation, add tokens to a `set` for uniqueness.  \n",
                                    "4. Sort and enumerate to assign each word an index.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Converting Text to Vectors\n",
                                    "\n",
                                    "Once you have a vocabulary, create a numeric BOW vector:\n",
                                    "\n",
                                    "```python\n",
                                    "import numpy as np\n",
                                    "\n",
                                    "def bow_vectorize(text, vocab):\n",
                                    "    vector = np.zeros(len(vocab), dtype=int)\n",
                                    "    for word in text.lower().split():\n",
                                    "        clean_word = word.strip(\".,!?\")\n",
                                    "        if clean_word in vocab:\n",
                                    "            vector[vocab[clean_word]] += 1\n",
                                    "    return vector\n",
                                    "```\n",
                                    "\n",
                                    "1. Initialize a zero vector of length `|vocab|`.  \n",
                                    "2. For each cleaned token, look up its index and increment the count.  \n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Conclusion and Next Steps\n",
                                    "\n",
                                    "In this lesson, you learned:\n",
                                    "- **Why** text must be represented numerically for RAG systems.  \n",
                                    "- **How** the Bag-of-Words model converts words into count-based vectors.  \n",
                                    "\n",
                                    "While BOW has limitations—ignoring word order and context—it’s an essential first step in any NLP workflow.  \n",
                                    "\n",
                                    "**Next Up:**  \n",
                                    "- Explore advanced methods that preserve semantics (e.g., embeddings from language models).  \n",
                                    "- Practice coding your own BOW pipeline with varied text inputs.  \n",
                                    "\n",
                                    "This foundation prepares you for more powerful semantic retrieval techniques and deeper RAG integration. Good luck, and have fun experimenting!  \n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Text Cleaning with Python\n",
                                    "\n",
                                    "You've just learned how to build a vocabulary and convert text into Bag-of-Words vectors. Now, let's put that knowledge into practice with a simple task.\n",
                                    "\n",
                                    "Your objective is to create a function called preprocess_string that processes a single string. Here's what you need to do:\n",
                                    "\n",
                                    "Split the string into words.\n",
                                    "Convert each word to lowercase.\n",
                                    "Remove punctuation from the start and end of each word (bonus points for doing it with a list comprehension!).\n",
                                    "This exercise will help you solidify your understanding of text preprocessing. Dive in and see how well you can clean up a string!\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "def preprocess_string(text):\n",
                                    "    # TODO: Split the text into words\n",
                                    "    # TODO: Convert words to lowercase and remove punctuation\n",
                                    "    # TODO: Return the cleaned tokens\n",
                                    "\n",
                                    "\n",
                                    "print(preprocess_string(\"Hello, World! We are preprocessing strings today.\"))\n",
                                    "\n",
                                    "\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Building a Vocabulary Dictionary\n",
                                    "\n",
                                    "Nice job on processing unique words and their counts! Now, let's take it a step further by creating a vocabulary dictionary.\n",
                                    "\n",
                                    "Your task is to build a function that:\n",
                                    "\n",
                                    "Takes a list of tokens.\n",
                                    "Sorts these words.\n",
                                    "Assigns each word a numeric index to form a vocabulary dictionary.\n",
                                    "This exercise will help you understand how to map words to indices, a key step in text representation. Dive in and see how well you can create a structured vocabulary!\n",
                                    "\n",
                                    "```python\n",
                                    "def preprocess_string(text):\n",
                                    "    words = text.split()\n",
                                    "    cleaned_tokens = [word.lower().strip(\".,!?\") for word in words]\n",
                                    "    return cleaned_tokens\n",
                                    "    \n",
                                    "    \n",
                                    "def build_vocab(tokens):\n",
                                    "    # TODO: Sort the unique tokens and assign each a numeric index\n",
                                    "    pass\n",
                                    "\n",
                                    "\n",
                                    "sentence = \"Hello, World! We are preprocessing strings today.\"\n",
                                    "tokens = preprocess_string(sentence)\n",
                                    "vocab = build_vocab(tokens)\n",
                                    "print(\"Vocabulary:\", vocab)\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "def preprocess_string(text):\n",
                                    "    words = text.split()\n",
                                    "    cleaned_tokens = [word.lower().strip(\".,!?\") for word in words]\n",
                                    "    return cleaned_tokens\n",
                                    "    \n",
                                    "    \n",
                                    "def build_vocab(tokens):\n",
                                    "    \"\"\"\n",
                                    "    Takes a list of tokens, sorts the unique words, \n",
                                    "    and assigns each word a numeric index.\n",
                                    "    \"\"\"\n",
                                    "    unique_tokens = sorted(set(tokens))\n",
                                    "    return {word: idx for idx, word in enumerate(unique_tokens)}\n",
                                    "\n",
                                    "\n",
                                    "# Example usage:\n",
                                    "sentence = \"Hello, World! We are preprocessing strings today.\"\n",
                                    "tokens = preprocess_string(sentence)\n",
                                    "vocab = build_vocab(tokens)\n",
                                    "print(\"Vocabulary:\", vocab)\n",
                                    "# Output:\n",
                                    "# Vocabulary: {'are': 0, 'hello': 1, 'preprocessing': 2, 'strings': 3, 'today': 4, 'we': 5, 'world': 6}\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Transform Text into Numeric Vectors\n",
                                    "\n",
                                    "You've just explored how to build a vocabulary and convert text into Bag-of-Words vectors. Now, let's apply that knowledge in a practical task.\n",
                                    "\n",
                                    "Your objective is to complete the bow_vectorize function. Here's what you need to do:\n",
                                    "\n",
                                    "Create a zero vector with the same length as the vocabulary.\n",
                                    "For each word in the text, clean it and check if it's in the vocabulary.\n",
                                    "Increment the vector slot corresponding to each vocabulary word found.\n",
                                    "This exercise will help you solidify your understanding of transforming text into numeric vectors. Dive in and see how well you can implement this transformation!\n",
                                    "\n",
                                    "```python\n",
                                    "import numpy as np\n",
                                    "\n",
                                    "\n",
                                    "def build_vocab(docs):\n",
                                    "    unique_words = set()\n",
                                    "    for doc in docs:\n",
                                    "        for word in doc.lower().split():\n",
                                    "            clean_word = word.strip(\".,!?\")\n",
                                    "            if clean_word:\n",
                                    "                unique_words.add(clean_word)\n",
                                    "    return {word: idx for idx, word in enumerate(sorted(unique_words))}\n",
                                    "\n",
                                    "\n",
                                    "def bow_vectorize(text, vocab):\n",
                                    "    # TODO: Create a zero vector with the same length as the vocabulary\n",
                                    "    # TODO: Convert the text to lowercase and split it into words\n",
                                    "    # TODO: For each word, clean it by stripping punctuation\n",
                                    "    # TODO: Check if the cleaned word is in the vocabulary\n",
                                    "    # TODO: If the word is in the vocabulary, increment the corresponding index in the vector\n",
                                    "    pass\n",
                                    "\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    example_texts = [\n",
                                    "        \"RAG stands for retrieval augmented generation, and retrieval is a key component of RAG.\",\n",
                                    "        \"Data is crucial for retrieval processes, and without data, retrieval systems cannot function effectively.\"\n",
                                    "    ]\n",
                                    "\n",
                                    "    vocab = build_vocab(example_texts)\n",
                                    "    print(\"Vocabulary: \", vocab.items(), '\\n')\n",
                                    "\n",
                                    "    for txt in example_texts:\n",
                                    "        vec = bow_vectorize(txt, vocab)\n",
                                    "        print(f\"Text: {txt}\\nBOW Vector: {vec}\\n\")\n",
                                    "```\n",
                                    "\n",
                                    "Here’s a filled-in version of your script with `bow_vectorize` implemented. It:\n",
                                    "\n",
                                    "1. Creates a zero vector of length `len(vocab)`.  \n",
                                    "2. Lowercases and splits the input text.  \n",
                                    "3. Strips punctuation from each token.  \n",
                                    "4. Looks up the token in `vocab` and, if present, increments that slot.\n",
                                    "\n",
                                    "```python\n",
                                    "import numpy as np\n",
                                    "\n",
                                    "\n",
                                    "def build_vocab(docs):\n",
                                    "    unique_words = set()\n",
                                    "    for doc in docs:\n",
                                    "        for word in doc.lower().split():\n",
                                    "            clean_word = word.strip(\".,!?\")\n",
                                    "            if clean_word:\n",
                                    "                unique_words.add(clean_word)\n",
                                    "    return {word: idx for idx, word in enumerate(sorted(unique_words))}\n",
                                    "\n",
                                    "\n",
                                    "def bow_vectorize(text, vocab):\n",
                                    "    # 1. Zero vector\n",
                                    "    vec = np.zeros(len(vocab), dtype=int)\n",
                                    "    # 2. Tokenize\n",
                                    "    for word in text.lower().split():\n",
                                    "        # 3. Clean punctuation\n",
                                    "        clean_word = word.strip(\".,!?\")\n",
                                    "        # 4. Increment if in vocab\n",
                                    "        if clean_word in vocab:\n",
                                    "            vec[vocab[clean_word]] += 1\n",
                                    "    return vec\n",
                                    "\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    example_texts = [\n",
                                    "        \"RAG stands for retrieval augmented generation, and retrieval is a key component of RAG.\",\n",
                                    "        \"Data is crucial for retrieval processes, and without data, retrieval systems cannot function effectively.\"\n",
                                    "    ]\n",
                                    "\n",
                                    "    vocab = build_vocab(example_texts)\n",
                                    "    print(\"Vocabulary (word → index):\")\n",
                                    "    for w, i in vocab.items():\n",
                                    "        print(f\"  {w:12} → {i}\")\n",
                                    "    print()\n",
                                    "\n",
                                    "    for txt in example_texts:\n",
                                    "        vec = bow_vectorize(txt, vocab)\n",
                                    "        print(f\"Text:\\n  {txt}\")\n",
                                    "        print(f\"BOW Vector:\\n  {vec}\\n\")\n",
                                    "```\n",
                                    "\n",
                                    "### Sample Output\n",
                                    "\n",
                                    "```\n",
                                    "Vocabulary (word → index):\n",
                                    "  a            → 0\n",
                                    "  and          → 1\n",
                                    "  augmented    → 2\n",
                                    "  component    → 3\n",
                                    "  crucial      → 4\n",
                                    "  data         → 5\n",
                                    "  effectively  → 6\n",
                                    "  for          → 7\n",
                                    "  function     → 8\n",
                                    "  generation   → 9\n",
                                    "  is           → 10\n",
                                    "  key          → 11\n",
                                    "  cannot       → 12\n",
                                    "  of           → 13\n",
                                    "  processes    → 14\n",
                                    "  rag          → 15\n",
                                    "  retrieval    → 16\n",
                                    "  stands       → 17\n",
                                    "  systems      → 18\n",
                                    "  without      → 19\n",
                                    "\n",
                                    "Text:\n",
                                    "  RAG stands for retrieval augmented generation, and retrieval is a key component of RAG.\n",
                                    "BOW Vector:\n",
                                    "  [0 1 1 1 0 0 0 1 0 1 1 1 0 1 0 2 2 1 0 0]\n",
                                    "\n",
                                    "Text:\n",
                                    "  Data is crucial for retrieval processes, and without data, retrieval systems cannot function effectively.\n",
                                    "BOW Vector:\n",
                                    "  [0 1 0 0 1 2 1 0 0 0 1 0 1 0 1 0 1 0 1 1]\n",
                                    "```\n",
                                    "\n",
                                    "You can now see each vector slot corresponds to the count of its vocabulary word in the text."
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Bag-of-Words Vectorization Task\n",
                                    "\n",
                                    "You've just explored how to build a vocabulary and convert text into Bag-of-Words (BOW) vectors. Now, let's apply that knowledge to process multiple texts.\n",
                                    "\n",
                                    "Your task is to:\n",
                                    "\n",
                                    "Generate a single vocabulary dictionary from a list of texts.\n",
                                    "Create a BOW vector for each text using the shared vocabulary.\n",
                                    "Print each resulting BOW vector.\n",
                                    "This exercise will reinforce your understanding of text representation. Jump in and see how effectively you can manage and transform text!\n",
                                    "\n",
                                    "```python\n",
                                    "import numpy as np\n",
                                    "\n",
                                    "\n",
                                    "def build_vocab(docs):\n",
                                    "    # TODO: Create a set of unique words from all documents\n",
                                    "    # 1. Initialize an empty set for unique words\n",
                                    "    # 2. Iterate through each document and its words\n",
                                    "    # 3. Clean words by converting to lowercase and removing punctuation\n",
                                    "    # 4. Add clean words to the set\n",
                                    "    # 5. Return a dictionary mapping words to indices (use enumerate)\n",
                                    "\n",
                                    "\n",
                                    "def bow_vectorize(text, vocab):\n",
                                    "    # TODO: Convert text into a Bag-of-Words vector\n",
                                    "    # 1. Create a zero vector with length equal to vocabulary size\n",
                                    "    # 2. Process each word in the text (lowercase and clean)\n",
                                    "    # 3. If word exists in vocabulary, increment its count in the vector\n",
                                    "    # 4. Return the BOW vector\n",
                                    "\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    example_texts = [\n",
                                    "        \"RAG stands for retrieval augmented generation, and retrieval is a key component of RAG.\",\n",
                                    "        \"Data is crucial for retrieval processes, and without data, retrieval systems cannot function effectively.\"\n",
                                    "    ]\n",
                                    "\n",
                                    "    # TODO: Build a vocabulary from the example texts\n",
                                    "    # 1. Call build_vocab() with example_texts\n",
                                    "    # 2. Print the vocabulary to see word-to-index mapping\n",
                                    "\n",
                                    "    # TODO: Convert each text into its BOW vector representation\n",
                                    "    # 1. Iterate through each text in example_texts\n",
                                    "    # 2. Convert each text to BOW vector using bow_vectorize()\n",
                                    "    # 3. Print the original text and its corresponding vector\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "import numpy as np\n",
                                    "import string\n",
                                    "\n",
                                    "def build_vocab(docs):\n",
                                    "    \"\"\"\n",
                                    "    Build a vocabulary mapping each unique, cleaned word to a unique index.\n",
                                    "    \"\"\"\n",
                                    "    unique_words = set()\n",
                                    "    for doc in docs:\n",
                                    "        for word in doc.lower().split():\n",
                                    "            # strip punctuation from both ends\n",
                                    "            clean_word = word.strip(string.punctuation)\n",
                                    "            if clean_word:\n",
                                    "                unique_words.add(clean_word)\n",
                                    "    # sort for consistent ordering\n",
                                    "    return {word: idx for idx, word in enumerate(sorted(unique_words))}\n",
                                    "\n",
                                    "\n",
                                    "def bow_vectorize(text, vocab):\n",
                                    "    \"\"\"\n",
                                    "    Convert a single text into its Bag-of-Words vector using the provided vocab.\n",
                                    "    \"\"\"\n",
                                    "    vec = np.zeros(len(vocab), dtype=int)\n",
                                    "    for word in text.lower().split():\n",
                                    "        clean_word = word.strip(string.punctuation)\n",
                                    "        if clean_word in vocab:\n",
                                    "            vec[vocab[clean_word]] += 1\n",
                                    "    return vec\n",
                                    "\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    example_texts = [\n",
                                    "        \"RAG stands for retrieval augmented generation, and retrieval is a key component of RAG.\",\n",
                                    "        \"Data is crucial for retrieval processes, and without data, retrieval systems cannot function effectively.\"\n",
                                    "    ]\n",
                                    "\n",
                                    "    # Build the shared vocabulary\n",
                                    "    vocab = build_vocab(example_texts)\n",
                                    "    print(\"Vocabulary (word → index):\")\n",
                                    "    for word, idx in vocab.items():\n",
                                    "        print(f\"  {word:12} → {idx}\")\n",
                                    "    print()\n",
                                    "\n",
                                    "    # Vectorize each text and print the result\n",
                                    "    for txt in example_texts:\n",
                                    "        vec = bow_vectorize(txt, vocab)\n",
                                    "        print(f\"Text:\\n  {txt}\")\n",
                                    "        print(f\"BOW Vector:\\n  {vec}\\n\")\n",
                                    "```\n",
                                    "\n",
                                    "**Explanation of steps:**\n",
                                    "\n",
                                    "1. **build_vocab**  \n",
                                    "   - Aggregates all words (lowercased, punctuation-stripped) from every document into a set.  \n",
                                    "   - Sorts that set so the indices are deterministic.  \n",
                                    "   - Returns a mapping word → index.\n",
                                    "\n",
                                    "2. **bow_vectorize**  \n",
                                    "   - Creates a zero-filled NumPy array of length equal to the vocabulary.  \n",
                                    "   - Splits and cleans each word in the input text.  \n",
                                    "   - If the cleaned word exists in the vocabulary, increments the corresponding index.\n",
                                    "\n",
                                    "3. **Main execution**  \n",
                                    "   - Builds one shared vocabulary from all texts.  \n",
                                    "   - Prints the vocabulary mapping.  \n",
                                    "   - Converts each text into its BOW vector and prints both the text and its vector."
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
