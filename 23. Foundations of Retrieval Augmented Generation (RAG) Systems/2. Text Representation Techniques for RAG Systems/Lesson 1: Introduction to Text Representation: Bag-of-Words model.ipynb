{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Lesson 1: Introduction to Text Representation: Bag-of-Words model\n",
                                    "\n",
                                    "Welcome to the very first lesson of our course **“Text Representation Techniques for RAG Systems”**, part of our **“Foundations of RAG Systems”** path! In the first course of this learning path, you learned the fundamentals of RAG, how to structure a simple RAG workflow, and why combining retrieval with generation is so powerful. Now, we’ll shift our focus to how we can turn raw text into numerical data — a crucial step if we want our RAG systems to retrieve information accurately and feed it into downstream pipelines. In other words, we’ll focus on the **indexing component** of our RAG pipeline.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Learning Objectives\n",
                                    "\n",
                                    "1. Understand why we must transform text into a structured format for RAG workflows.  \n",
                                    "2. Explore the **Bag-of-Words (BOW)** method, a simple yet classic text representation technique.  \n",
                                    "\n",
                                    "By the end, you’ll know:\n",
                                    "- How words get mapped into vectors  \n",
                                    "- Why these representations matter for building robust retrieval systems  \n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Why Text Representation Is Essential\n",
                                    "\n",
                                    "RAG systems revolve around:\n",
                                    "1. Retrieving relevant documents based on a user’s query  \n",
                                    "2. Generating a final answer  \n",
                                    "\n",
                                    "Computers don’t process language like humans—they require **structured, numerical forms** of text to compare documents effectively. Without proper representation:\n",
                                    "\n",
                                    "- We can’t reliably measure similarity between two texts.  \n",
                                    "- Retrieving contextually relevant information becomes very difficult.  \n",
                                    "\n",
                                    "A straightforward solution is the **Bag-of-Words** method. It counts how often each word appears, providing a simple numerical snapshot of a document. While BOW ignores word order and nuances, it’s an excellent entry point for converting messy language into machine-friendly formats.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Understanding the BOW Model\n",
                                    "\n",
                                    "Consider these three sentences:\n",
                                    "\n",
                                    "1. “I love machine learning”  \n",
                                    "2. “Machine learning is fun”  \n",
                                    "3. “I love coding”  \n",
                                    "\n",
                                    "First, gather all unique words into a **vocabulary**:  \n",
                                    "```\n",
                                    "{ I, love, machine, learning, is, fun, coding }\n",
                                    "```\n",
                                    "\n",
                                    "| Word     | I | love | machine | learning | is | fun | coding |\n",
                                    "|----------|:-:|:----:|:-------:|:--------:|:-:|:---:|:------:|\n",
                                    "| **Index**| 0 |  1   |    2    |     3    | 4 |  5  |   6    |\n",
                                    "\n",
                                    "Next, transform each sentence into a numeric **frequency vector**:\n",
                                    "\n",
                                    "| Sentence                   | I | love | machine | learning | is | fun | coding |\n",
                                    "|----------------------------|:-:|:----:|:-------:|:--------:|:-:|:---:|:------:|\n",
                                    "| I love machine learning    | 1 |  1   |    1    |     1    | 0 |  0  |   0    |\n",
                                    "| Machine learning is fun    | 0 |  0   |    1    |     1    | 1 |  1  |   0    |\n",
                                    "| I love coding              | 1 |  1   |    0    |     0    | 0 |  0  |   1    |\n",
                                    "\n",
                                    "Each column corresponds to a word; each entry is its occurrence count.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Building a Basic Vocabulary\n",
                                    "\n",
                                    "In BOW, the first step is constructing a **vocabulary** dictionary:\n",
                                    "\n",
                                    "```python\n",
                                    "def build_vocab(docs):\n",
                                    "    unique_words = set()\n",
                                    "    for doc in docs:\n",
                                    "        for word in doc.lower().split():\n",
                                    "            clean_word = word.strip(\".,!?\")\n",
                                    "            if clean_word:\n",
                                    "                unique_words.add(clean_word)\n",
                                    "    # Sort for consistent ordering\n",
                                    "    return {word: idx for idx, word in enumerate(sorted(unique_words))}\n",
                                    "```\n",
                                    "\n",
                                    "**How it works:**\n",
                                    "1. Iterate through each document.  \n",
                                    "2. Lowercase and split into tokens.  \n",
                                    "3. Strip punctuation, add tokens to a `set` for uniqueness.  \n",
                                    "4. Sort and enumerate to assign each word an index.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Converting Text to Vectors\n",
                                    "\n",
                                    "Once you have a vocabulary, create a numeric BOW vector:\n",
                                    "\n",
                                    "```python\n",
                                    "import numpy as np\n",
                                    "\n",
                                    "def bow_vectorize(text, vocab):\n",
                                    "    vector = np.zeros(len(vocab), dtype=int)\n",
                                    "    for word in text.lower().split():\n",
                                    "        clean_word = word.strip(\".,!?\")\n",
                                    "        if clean_word in vocab:\n",
                                    "            vector[vocab[clean_word]] += 1\n",
                                    "    return vector\n",
                                    "```\n",
                                    "\n",
                                    "1. Initialize a zero vector of length `|vocab|`.  \n",
                                    "2. For each cleaned token, look up its index and increment the count.  \n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Conclusion and Next Steps\n",
                                    "\n",
                                    "In this lesson, you learned:\n",
                                    "- **Why** text must be represented numerically for RAG systems.  \n",
                                    "- **How** the Bag-of-Words model converts words into count-based vectors.  \n",
                                    "\n",
                                    "While BOW has limitations—ignoring word order and context—it’s an essential first step in any NLP workflow.  \n",
                                    "\n",
                                    "**Next Up:**  \n",
                                    "- Explore advanced methods that preserve semantics (e.g., embeddings from language models).  \n",
                                    "- Practice coding your own BOW pipeline with varied text inputs.  \n",
                                    "\n",
                                    "This foundation prepares you for more powerful semantic retrieval techniques and deeper RAG integration. Good luck, and have fun experimenting!  \n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Text Cleaning with Python\n",
                                    "\n",
                                    "You've just learned how to build a vocabulary and convert text into Bag-of-Words vectors. Now, let's put that knowledge into practice with a simple task.\n",
                                    "\n",
                                    "Your objective is to create a function called preprocess_string that processes a single string. Here's what you need to do:\n",
                                    "\n",
                                    "Split the string into words.\n",
                                    "Convert each word to lowercase.\n",
                                    "Remove punctuation from the start and end of each word (bonus points for doing it with a list comprehension!).\n",
                                    "This exercise will help you solidify your understanding of text preprocessing. Dive in and see how well you can clean up a string!\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "def preprocess_string(text):\n",
                                    "    # TODO: Split the text into words\n",
                                    "    # TODO: Convert words to lowercase and remove punctuation\n",
                                    "    # TODO: Return the cleaned tokens\n",
                                    "\n",
                                    "\n",
                                    "print(preprocess_string(\"Hello, World! We are preprocessing strings today.\"))\n",
                                    "\n",
                                    "\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Building a Vocabulary Dictionary\n",
                                    "\n",
                                    "Nice job on processing unique words and their counts! Now, let's take it a step further by creating a vocabulary dictionary.\n",
                                    "\n",
                                    "Your task is to build a function that:\n",
                                    "\n",
                                    "Takes a list of tokens.\n",
                                    "Sorts these words.\n",
                                    "Assigns each word a numeric index to form a vocabulary dictionary.\n",
                                    "This exercise will help you understand how to map words to indices, a key step in text representation. Dive in and see how well you can create a structured vocabulary!\n",
                                    "\n",
                                    "```python\n",
                                    "def preprocess_string(text):\n",
                                    "    words = text.split()\n",
                                    "    cleaned_tokens = [word.lower().strip(\".,!?\") for word in words]\n",
                                    "    return cleaned_tokens\n",
                                    "    \n",
                                    "    \n",
                                    "def build_vocab(tokens):\n",
                                    "    # TODO: Sort the unique tokens and assign each a numeric index\n",
                                    "    pass\n",
                                    "\n",
                                    "\n",
                                    "sentence = \"Hello, World! We are preprocessing strings today.\"\n",
                                    "tokens = preprocess_string(sentence)\n",
                                    "vocab = build_vocab(tokens)\n",
                                    "print(\"Vocabulary:\", vocab)\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "def preprocess_string(text):\n",
                                    "    words = text.split()\n",
                                    "    cleaned_tokens = [word.lower().strip(\".,!?\") for word in words]\n",
                                    "    return cleaned_tokens\n",
                                    "    \n",
                                    "    \n",
                                    "def build_vocab(tokens):\n",
                                    "    \"\"\"\n",
                                    "    Takes a list of tokens, sorts the unique words, \n",
                                    "    and assigns each word a numeric index.\n",
                                    "    \"\"\"\n",
                                    "    unique_tokens = sorted(set(tokens))\n",
                                    "    return {word: idx for idx, word in enumerate(unique_tokens)}\n",
                                    "\n",
                                    "\n",
                                    "# Example usage:\n",
                                    "sentence = \"Hello, World! We are preprocessing strings today.\"\n",
                                    "tokens = preprocess_string(sentence)\n",
                                    "vocab = build_vocab(tokens)\n",
                                    "print(\"Vocabulary:\", vocab)\n",
                                    "# Output:\n",
                                    "# Vocabulary: {'are': 0, 'hello': 1, 'preprocessing': 2, 'strings': 3, 'today': 4, 'we': 5, 'world': 6}\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Transform Text into Numeric Vectors"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Bag-of-Words Vectorization Task"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
