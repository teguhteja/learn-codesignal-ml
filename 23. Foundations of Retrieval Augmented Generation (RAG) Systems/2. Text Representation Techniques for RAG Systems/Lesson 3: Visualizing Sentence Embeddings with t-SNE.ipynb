{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Lesson 3: Visualizing Sentence Embeddings with t-SNE\n",
                                    "\n",
                                    "## Introduction\n",
                                    "\n",
                                    "Welcome to the third lesson in our course on **Text Representation Techniques for RAG systems**! In our previous lesson, we explored how to generate sentence embeddings and saw how these richer representations capture semantic meaning better than the classic Bag-of-Words.\n",
                                    "\n",
                                    "Now, we will build on that knowledge to visualize these embeddings in a two-dimensional space using **t-SNE** (t-distributed Stochastic Neighbor Embedding). By the end of this lesson, you'll have an interactive way to see how thematically similar sentences group closer together, reinforcing the idea that embeddings preserve meaningful relationships between sentences.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Understanding t-SNE\n",
                                    "\n",
                                    "t-SNE helps us visualize high-dimensional embeddings by compressing them into a lower-dimensional space (usually 2D or 3D for visualization) while preserving relative similarities:\n",
                                    "\n",
                                    "- **Similarity First:**  \n",
                                    "  t-SNE prioritizes keeping similar sentences close. It calculates pairwise similarities in the original space (using a probability distribution) so nearby embeddings get higher similarity scores than distant ones.\n",
                                    "\n",
                                    "- **Local Structure:**  \n",
                                    "  It preserves neighborhoods of related points rather than exact distances. This means clusters you see reflect genuine thematic groupings (e.g., NLP vs. Food), but axis values themselves have no intrinsic meaning.\n",
                                    "\n",
                                    "- **Perplexity Matters:**  \n",
                                    "  This parameter (typically between 5‚Äì50) controls neighborhood size.\n",
                                    "  - Lower values emphasize tight clusters (good for spotting subtopics).\n",
                                    "  - Higher values show broader trends (useful for separating major categories).\n",
                                    "\n",
                                    "- **Tradeoffs:**  \n",
                                    "  While powerful for visualization, t-SNE is computationally expensive for large datasets (it compares all sentence pairs). For RAG systems, it‚Äôs better suited for exploratory analysis of smaller samples than production-scale data.\n",
                                    "\n",
                                    "> **Why does this matter for RAG?**  \n",
                                    "> Seeing embeddings cluster by topic validates they're capturing semantic relationships‚Äîa prerequisite for effective retrieval. If NLP sentences scattered randomly, we'd question the embedding quality before even building the RAG pipeline, prompting us to reevaluate our model choice.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Building Our Data\n",
                                    "\n",
                                    "To demonstrate how t-SNE reveals natural groupings, we'll gather sentences on four different topics: **NLP**, **ML**, **Food**, and **Weather**. Then, we assign each sentence a category so we can later color-code and shape-code the points in our 2D visualization.\n",
                                    "\n",
                                    "```python\n",
                                    "def get_sentences_and_categories():\n",
                                    "    \"\"\"\n",
                                    "    Return the sentences and their corresponding categories.\n",
                                    "    \"\"\"\n",
                                    "    sentences = [\n",
                                    "        # Topic: NLP\n",
                                    "        \"RAG stands for Retrieval-Augmented Generation.\",\n",
                                    "        \"Retrieval is a crucial aspect of modern NLP systems.\",\n",
                                    "        \"Generating text with correct facts is challenging.\",\n",
                                    "        \"Large language models can generate coherent text.\",\n",
                                    "        \"GPT models have billions of parameters.\",\n",
                                    "        \"Natural Language Processing enables computers to understand human language.\",\n",
                                    "        \"Word embeddings capture semantic relationships between words.\",\n",
                                    "        \"Transformer architectures revolutionized NLP research.\",\n",
                                    "        \n",
                                    "        # Topic: Machine Learning\n",
                                    "        \"Machine learning benefits from large datasets.\",\n",
                                    "        \"Supervised learning requires labeled data.\",\n",
                                    "        \"Reinforcement learning is inspired by behavioral psychology.\",\n",
                                    "        \"Neural networks can learn complex functions.\",\n",
                                    "        \"Overfitting is a common problem in ML.\",\n",
                                    "        \"Unsupervised learning uncovers hidden patterns in data.\",\n",
                                    "        \"Feature engineering is critical for model performance.\",\n",
                                    "        \"Cross-validation helps in assessing model generalization.\",\n",
                                    "        \n",
                                    "        # Topic: Food\n",
                                    "        \"Bananas are commonly used in smoothies.\",\n",
                                    "        \"Oranges are rich in vitamin C.\",\n",
                                    "        \"Pizza is a popular Italian dish.\",\n",
                                    "        \"Cooking pasta requires boiling water.\",\n",
                                    "        \"Chocolate can be sweet or bitter.\",\n",
                                    "        \"Fresh salads are a healthy and refreshing meal.\",\n",
                                    "        \"Sushi combines rice, fish, and seaweed in a delicate balance.\",\n",
                                    "        \"Spices can transform simple ingredients into gourmet dishes.\",\n",
                                    "        \n",
                                    "        # Topic: Weather\n",
                                    "        \"It often rains in the Amazon rainforest.\",\n",
                                    "        \"Summers can be very hot in the desert.\",\n",
                                    "        \"Hurricanes form over warm ocean waters.\",\n",
                                    "        \"Snowstorms can disrupt transportation.\",\n",
                                    "        \"A sunny day can lift people's mood.\",\n",
                                    "        \"Foggy mornings are common in coastal regions.\",\n",
                                    "        \"Winter brings frosty nights and chilly winds.\",\n",
                                    "        \"Thunderstorms can produce lightning and heavy rain.\"\n",
                                    "    ]\n",
                                    "    \n",
                                    "    categories = ([\"NLP\"] * 8 + [\"ML\"] * 8 + [\"Food\"] * 8 + [\"Weather\"] * 8)\n",
                                    "    return sentences, categories\n",
                                    "\n",
                                    "def get_color_and_shape_maps():\n",
                                    "    \"\"\"\n",
                                    "    Return color and marker maps for each category.\n",
                                    "    \"\"\"\n",
                                    "    color_map = {\n",
                                    "        \"NLP\": \"red\",\n",
                                    "        \"ML\": \"blue\",\n",
                                    "        \"Food\": \"green\",\n",
                                    "        \"Weather\": \"purple\"\n",
                                    "    }\n",
                                    "    shape_map = {\n",
                                    "        \"NLP\": \"o\",\n",
                                    "        \"ML\": \"s\",\n",
                                    "        \"Food\": \"^\",\n",
                                    "        \"Weather\": \"X\"\n",
                                    "    }\n",
                                    "    return color_map, shape_map\n",
                                    "```\n",
                                    "\n",
                                    "- **`get_sentences_and_categories()`** returns two lists: one of sentences and another labeling each sentence‚Äôs category.\n",
                                    "- **`get_color_and_shape_maps()`** provides dictionaries to map each category to a specific color and marker shape (e.g., red circles for NLP).\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Generating and Reducing Embeddings\n",
                                    "\n",
                                    "Next, we encode the sentences into embeddings and then reduce them to two dimensions using t-SNE:\n",
                                    "\n",
                                    "```python\n",
                                    "import matplotlib.pyplot as plt\n",
                                    "from sklearn.manifold import TSNE\n",
                                    "from sentence_transformers import SentenceTransformer\n",
                                    "\n",
                                    "def compute_tsne_embeddings(\n",
                                    "    sentences,\n",
                                    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
                                    "    perplexity=10,\n",
                                    "    n_iter=3000,\n",
                                    "    random_state=42\n",
                                    "):\n",
                                    "    \"\"\"\n",
                                    "    Compute and return t-SNE reduced embeddings for the given sentences.\n",
                                    "    \"\"\"\n",
                                    "    # 1. Initialize a SentenceTransformer model.\n",
                                    "    model = SentenceTransformer(model_name)\n",
                                    "    \n",
                                    "    # 2. Convert each sentence into a high-dimensional embedding.\n",
                                    "    embeddings = model.encode(sentences)\n",
                                    "    \n",
                                    "    # 3. Configure t-SNE with chosen parameters.\n",
                                    "    tsne = TSNE(\n",
                                    "        n_components=2,\n",
                                    "        random_state=random_state,\n",
                                    "        perplexity=perplexity,\n",
                                    "        n_iter=n_iter\n",
                                    "    )\n",
                                    "    \n",
                                    "    # 4. Fit t-SNE on the embeddings and return a 2D representation.\n",
                                    "    return tsne.fit_transform(embeddings)\n",
                                    "```\n",
                                    "\n",
                                    "1. **Model Initialization:** Loads a pre-trained SentenceTransformer to generate embeddings.  \n",
                                    "2. **Embedding Generation:** `model.encode(sentences)` converts sentences into high-dimensional vectors.  \n",
                                    "3. **t-SNE Configuration:** Sets hyperparameters‚Äî`perplexity`, `n_iter`, and `random_state`‚Äîfor the TSNE instance.  \n",
                                    "4. **Dimensionality Reduction:** `tsne.fit_transform(embeddings)` reduces the embeddings to 2D points.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Plotting the Embeddings\n",
                                    "\n",
                                    "With our 2D points ready, we‚Äôll plot them to visualize topic clusters and add short labels for clarity:\n",
                                    "\n",
                                    "```python\n",
                                    "def plot_embeddings(\n",
                                    "    reduced_embeddings,\n",
                                    "    sentences,\n",
                                    "    categories,\n",
                                    "    color_map,\n",
                                    "    shape_map,\n",
                                    "    xlim=(-125, 150),\n",
                                    "    ylim=(-175, 125)\n",
                                    "):\n",
                                    "    \"\"\"\n",
                                    "    Plot the 2D embeddings with labels and a legend.\n",
                                    "    \"\"\"\n",
                                    "    # 1. Create the figure.\n",
                                    "    plt.figure(figsize=(10, 8))\n",
                                    "    \n",
                                    "    # 2. Plot each sentence as a scatter point.\n",
                                    "    for i, (sentence, category) in enumerate(zip(sentences, categories)):\n",
                                    "        x, y = reduced_embeddings[i]\n",
                                    "        plt.scatter(x, y, color=color_map[category], marker=shape_map[category])\n",
                                    "        plt.text(x - 2.5, y - 7.5, sentence[:20] + \"...\", fontsize=9)\n",
                                    "    \n",
                                    "    # 3. Build a legend.\n",
                                    "    for cat, color in color_map.items():\n",
                                    "        plt.scatter([], [], color=color, label=cat, marker=shape_map[cat])\n",
                                    "    plt.legend(loc=\"best\")\n",
                                    "    \n",
                                    "    # 4. Finalize plot.\n",
                                    "    plt.title(\"t-SNE Visualization of Sentence Embeddings\", fontsize=14)\n",
                                    "    plt.xlabel(\"t-SNE Dimension 1\", fontsize=12)\n",
                                    "    plt.ylabel(\"t-SNE Dimension 2\", fontsize=12)\n",
                                    "    plt.tight_layout()\n",
                                    "    plt.xlim(*xlim)\n",
                                    "    plt.ylim(*ylim)\n",
                                    "    plt.savefig('your_plot_image.png')\n",
                                    "```\n",
                                    "\n",
                                    "- **Scatter Plot:** Each sentence is shown as a colored, shaped marker.  \n",
                                    "- **Annotations:** The first 20 characters of each sentence appear next to its point.  \n",
                                    "- **Legend:** Empty markers illustrate which color/shape corresponds to each topic.  \n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Interpreting the t-SNE Plot\n",
                                    "\n",
                                    "The resulting t-SNE visualization reveals how sentence embeddings capture semantic similarity:\n",
                                    "\n",
                                    "- **Distinct Clusters:**  \n",
                                    "  - **NLP** (red circles)  \n",
                                    "  - **ML** (blue squares)  \n",
                                    "  - **Food** (green triangles)  \n",
                                    "  - **Weather** (purple X‚Äôs)  \n",
                                    "\n",
                                    "- **Cluster Proximity:**  \n",
                                    "  - NLP and ML clusters tend to be closer, reflecting related technical content.  \n",
                                    "  - Food and Weather are more distant, as they share fewer semantic overlaps.  \n",
                                    "\n",
                                    "- **Overlap & Insights:**  \n",
                                    "  - Some sentences (e.g., ‚ÄúGPT models have billions of parameters.‚Äù) may lie between NLP and ML clusters, highlighting shared vocabulary.  \n",
                                    "  - The plot helps you spot outliers or subtopic distinctions at a glance.\n",
                                    "\n",
                                    "This interactive view validates that embeddings preserve meaningful relationships‚Äîcrucial for debugging and improving RAG retrieval.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Conclusion and Next Steps\n",
                                    "\n",
                                    "You‚Äôve now:\n",
                                    "\n",
                                    "1. Represented text data with high-dimensional embeddings.  \n",
                                    "2. Used t-SNE to reduce embeddings to 2D.  \n",
                                    "3. Visualized clusters to uncover semantic relationships.\n",
                                    "\n",
                                    "Equipped with this workflow, you can explore your own text datasets, experiment with t-SNE parameters, and use interactive plots to gain deeper insights. In the next practice session, you‚Äôll get hands-on experience modifying code and observing how different settings affect clustering.\n",
                                    "\n",
                                    "> **Give it a try**, and have fun discovering the hidden patterns in your text!"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Visualize Sentence Clusters\n",
                                    "\n",
                                    "Great job on mastering sentence embeddings! Now, let's bring those concepts to life by visualizing them in action.\n",
                                    "\n",
                                    "Your task is simple: run the provided code to generate a scatter plot that reveals how different sentence clusters form, and observe how sentences with similar themes naturally group together.\n",
                                    "\n",
                                    "Feel free to experiment with the code! Tweak parameters, change sentences, or adjust categories to see how these changes affect the visualization. This hands-on exploration will deepen your understanding of how embeddings capture semantic relationships. Dive in and enjoy uncovering the hidden patterns in your data!\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "import matplotlib.pyplot as plt\n",
                                    "from sklearn.manifold import TSNE\n",
                                    "from sentence_transformers import SentenceTransformer\n",
                                    "\n",
                                    "\n",
                                    "def get_sentences_and_categories():\n",
                                    "    \"\"\"Return the sentences and their corresponding categories.\"\"\"\n",
                                    "    sentences = [\n",
                                    "        # Topic: NLP\n",
                                    "        \"RAG stands for Retrieval-Augmented Generation.\",\n",
                                    "        \"Retrieval is a crucial aspect of modern NLP systems.\",\n",
                                    "        \"Generating text with correct facts is challenging.\",\n",
                                    "        \"Large language models can generate coherent text.\",\n",
                                    "        \"GPT models have billions of parameters.\",\n",
                                    "        \"Natural Language Processing enables computers to understand human language.\",\n",
                                    "        \"Word embeddings capture semantic relationships between words.\",\n",
                                    "        \"Transformer architectures revolutionized NLP research.\",\n",
                                    "        \n",
                                    "        # Topic: Machine Learning\n",
                                    "        \"Machine learning benefits from large datasets.\",\n",
                                    "        \"Supervised learning requires labeled data.\",\n",
                                    "        \"Reinforcement learning is inspired by behavioral psychology.\",\n",
                                    "        \"Neural networks can learn complex functions.\",\n",
                                    "        \"Overfitting is a common problem in ML.\",\n",
                                    "        \"Unsupervised learning uncovers hidden patterns in data.\",\n",
                                    "        \"Feature engineering is critical for model performance.\",\n",
                                    "        \"Cross-validation helps in assessing model generalization.\",\n",
                                    "        \n",
                                    "        # Topic: Food\n",
                                    "        \"Bananas are commonly used in smoothies.\",\n",
                                    "        \"Oranges are rich in vitamin C.\",\n",
                                    "        \"Pizza is a popular Italian dish.\",\n",
                                    "        \"Cooking pasta requires boiling water.\",\n",
                                    "        \"Chocolate can be sweet or bitter.\",\n",
                                    "        \"Fresh salads are a healthy and refreshing meal.\",\n",
                                    "        \"Sushi combines rice, fish, and seaweed in a delicate balance.\",\n",
                                    "        \"Spices can transform simple ingredients into gourmet dishes.\",\n",
                                    "        \n",
                                    "        # Topic: Weather\n",
                                    "        \"It often rains in the Amazon rainforest.\",\n",
                                    "        \"Summers can be very hot in the desert.\",\n",
                                    "        \"Hurricanes form over warm ocean waters.\",\n",
                                    "        \"Snowstorms can disrupt transportation.\",\n",
                                    "        \"A sunny day can lift people's mood.\",\n",
                                    "        \"Foggy mornings are common in coastal regions.\",\n",
                                    "        \"Winter brings frosty nights and chilly winds.\",\n",
                                    "        \"Thunderstorms can produce lightning and heavy rain.\"\n",
                                    "    ]\n",
                                    "    \n",
                                    "    categories = ([\"NLP\"] * 8 + [\"ML\"] * 8 + [\"Food\"] * 8 + [\"Weather\"] * 8)\n",
                                    "    return sentences, categories\n",
                                    "\n",
                                    "\n",
                                    "def get_color_and_shape_maps():\n",
                                    "    \"\"\"Return color and marker maps for each category.\"\"\"\n",
                                    "    color_map = {\n",
                                    "        \"NLP\": \"red\",\n",
                                    "        \"ML\": \"blue\",\n",
                                    "        \"Food\": \"green\",\n",
                                    "        \"Weather\": \"purple\"\n",
                                    "    }\n",
                                    "    shape_map = {\n",
                                    "        \"NLP\": \"o\",\n",
                                    "        \"ML\": \"s\",\n",
                                    "        \"Food\": \"^\",\n",
                                    "        \"Weather\": \"X\"\n",
                                    "    }\n",
                                    "    return color_map, shape_map\n",
                                    "\n",
                                    "\n",
                                    "def compute_tsne_embeddings(sentences, model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
                                    "                              perplexity=10, max_iter=3000, random_state=42):\n",
                                    "    \"\"\"Compute and return t-SNE reduced embeddings for the given sentences.\"\"\"\n",
                                    "    model = SentenceTransformer(model_name)\n",
                                    "    embeddings = model.encode(sentences)\n",
                                    "    tsne = TSNE(n_components=2, random_state=random_state,\n",
                                    "                perplexity=perplexity, max_iter=max_iter)\n",
                                    "    return tsne.fit_transform(embeddings)\n",
                                    "\n",
                                    "\n",
                                    "def plot_embeddings(reduced_embeddings, sentences, categories, color_map, shape_map):\n",
                                    "    \"\"\"Plot the 2D embeddings with labels and a legend.\"\"\"\n",
                                    "    plt.figure(figsize=(10, 8))\n",
                                    "    for i, (sentence, category) in enumerate(zip(sentences, categories)):\n",
                                    "        x, y = reduced_embeddings[i]\n",
                                    "        plt.scatter(x, y, color=color_map[category], marker=shape_map[category])\n",
                                    "        # Display only the first 20 characters for clarity\n",
                                    "        plt.text(x - 2.5, y - 1.0, sentence[:20] + \"...\", fontsize=9)\n",
                                    "    \n",
                                    "    # Add an empty scatter for each category to create the legend\n",
                                    "    for cat, color in color_map.items():\n",
                                    "        plt.scatter([], [], color=color, label=cat, marker=shape_map[cat])\n",
                                    "    plt.legend(loc=\"best\")\n",
                                    "\n",
                                    "    plt.title(\"t-SNE Visualization of Sentence Embeddings\", fontsize=14)\n",
                                    "    plt.xlabel(\"t-SNE Dimension 1\", fontsize=12)\n",
                                    "    plt.ylabel(\"t-SNE Dimension 2\", fontsize=12)\n",
                                    "    plt.tight_layout()\n",
                                    "    plt.savefig('static/images/plot.png', bbox_inches='tight')\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    sentences, categories = get_sentences_and_categories()\n",
                                    "    color_map, shape_map = get_color_and_shape_maps()\n",
                                    "    reduced_embeddings = compute_tsne_embeddings(sentences)\n",
                                    "    plot_embeddings(reduced_embeddings, sentences, categories, color_map, shape_map)\n",
                                    "\n",
                                    "\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Explore t-SNE Perplexity Effects\n",
                                    "\n",
                                    "You've gained a solid understanding of generating and reducing sentence embeddings. Now, let's apply that knowledge to troubleshoot and refine the compute_tsne_embeddings function.\n",
                                    "\n",
                                    "In the given code, there is some bug that is causing the embeddings visualization to be pretty bad. Your task is to identify and fix any issues that are causing such a poor visualization.\n",
                                    "\n",
                                    "```python\n",
                                    "import matplotlib.pyplot as plt\n",
                                    "from sklearn.manifold import TSNE\n",
                                    "from sentence_transformers import SentenceTransformer\n",
                                    "\n",
                                    "def get_sentences_and_categories():\n",
                                    "    \"\"\"Return the sentences and their corresponding categories.\"\"\"\n",
                                    "    sentences = [\n",
                                    "        # Topic: NLP\n",
                                    "        \"RAG stands for Retrieval-Augmented Generation.\",\n",
                                    "        \"Retrieval is a crucial aspect of modern NLP systems.\",\n",
                                    "        \"Generating text with correct facts is challenging.\",\n",
                                    "        \"Large language models can generate coherent text.\",\n",
                                    "        \"GPT models have billions of parameters.\",\n",
                                    "        \"Natural Language Processing enables computers to understand human language.\",\n",
                                    "        \"Word embeddings capture semantic relationships between words.\",\n",
                                    "        \"Transformer architectures revolutionized NLP research.\",\n",
                                    "        \n",
                                    "        # Topic: Machine Learning\n",
                                    "        \"Machine learning benefits from large datasets.\",\n",
                                    "        \"Supervised learning requires labeled data.\",\n",
                                    "        \"Reinforcement learning is inspired by behavioral psychology.\",\n",
                                    "        \"Neural networks can learn complex functions.\",\n",
                                    "        \"Overfitting is a common problem in ML.\",\n",
                                    "        \"Unsupervised learning uncovers hidden patterns in data.\",\n",
                                    "        \"Feature engineering is critical for model performance.\",\n",
                                    "        \"Cross-validation helps in assessing model generalization.\",\n",
                                    "        \n",
                                    "        # Topic: Food\n",
                                    "        \"Bananas are commonly used in smoothies.\",\n",
                                    "        \"Oranges are rich in vitamin C.\",\n",
                                    "        \"Pizza is a popular Italian dish.\",\n",
                                    "        \"Cooking pasta requires boiling water.\",\n",
                                    "        \"Chocolate can be sweet or bitter.\",\n",
                                    "        \"Fresh salads are a healthy and refreshing meal.\",\n",
                                    "        \"Sushi combines rice, fish, and seaweed in a delicate balance.\",\n",
                                    "        \"Spices can transform simple ingredients into gourmet dishes.\",\n",
                                    "        \n",
                                    "        # Topic: Weather\n",
                                    "        \"It often rains in the Amazon rainforest.\",\n",
                                    "        \"Summers can be very hot in the desert.\",\n",
                                    "        \"Hurricanes form over warm ocean waters.\",\n",
                                    "        \"Snowstorms can disrupt transportation.\",\n",
                                    "        \"A sunny day can lift people's mood.\",\n",
                                    "        \"Foggy mornings are common in coastal regions.\",\n",
                                    "        \"Winter brings frosty nights and chilly winds.\",\n",
                                    "        \"Thunderstorms can produce lightning and heavy rain.\"\n",
                                    "    ]\n",
                                    "    \n",
                                    "    categories = ([\"NLP\"] * 8 + [\"ML\"] * 8 + [\"Food\"] * 8 + [\"Weather\"] * 8)\n",
                                    "    return sentences, categories\n",
                                    "\n",
                                    "def get_color_and_shape_maps():\n",
                                    "    \"\"\"Return color and marker maps for each category.\"\"\"\n",
                                    "    color_map = {\n",
                                    "        \"NLP\": \"red\",\n",
                                    "        \"ML\": \"blue\",\n",
                                    "        \"Food\": \"green\",\n",
                                    "        \"Weather\": \"purple\"\n",
                                    "    }\n",
                                    "    shape_map = {\n",
                                    "        \"NLP\": \"o\",\n",
                                    "        \"ML\": \"s\",\n",
                                    "        \"Food\": \"^\",\n",
                                    "        \"Weather\": \"X\"\n",
                                    "    }\n",
                                    "    return color_map, shape_map\n",
                                    "\n",
                                    "def compute_tsne_embeddings(sentences, model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
                                    "                            perplexity=10, max_iter=3000, random_state=42):\n",
                                    "    \"\"\"Compute and return t-SNE reduced embeddings for the given sentences.\"\"\"\n",
                                    "    model = SentenceTransformer(model_name)\n",
                                    "    embeddings = model.encode(sentences)\n",
                                    "    tsne = TSNE(n_components=2, random_state=random_state,\n",
                                    "                perplexity=perplexity, max_iter=max_iter)\n",
                                    "    return tsne.fit_transform(embeddings)\n",
                                    "\n",
                                    "def plot_embeddings(reduced_embeddings, sentences, categories, color_map, shape_map):\n",
                                    "    \"\"\"Plot the 2D embeddings with labels and a legend.\"\"\"\n",
                                    "    plt.figure(figsize=(10, 8))\n",
                                    "    for i, (sentence, category) in enumerate(zip(sentences, categories)):\n",
                                    "        x, y = reduced_embeddings[i]\n",
                                    "        plt.scatter(x, y, color=color_map[category], marker=shape_map[category])\n",
                                    "        plt.text(x - 2.5, y - 1, sentence[:20] + \"...\", fontsize=9)\n",
                                    "    \n",
                                    "    for cat, color in color_map.items():\n",
                                    "        plt.scatter([], [], color=color, label=cat, marker=shape_map[cat])\n",
                                    "    plt.legend(loc=\"best\")\n",
                                    "\n",
                                    "    plt.title(\"t-SNE Visualization of Sentence Embeddings\", fontsize=14)\n",
                                    "    plt.xlabel(\"t-SNE Dimension 1\", fontsize=12)\n",
                                    "    plt.ylabel(\"t-SNE Dimension 2\", fontsize=12)\n",
                                    "    plt.tight_layout()\n",
                                    "    plt.savefig('static/images/plot.png')\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    sentences, categories = get_sentences_and_categories()\n",
                                    "    color_map, shape_map = get_color_and_shape_maps()\n",
                                    "    \n",
                                    "    perplexity = 0.1\n",
                                    "    max_iter = 250\n",
                                    "    reduced_embeddings = compute_tsne_embeddings(sentences, perplexity=perplexity, max_iter=max_iter)\n",
                                    "    plot_embeddings(reduced_embeddings, sentences, categories, color_map, shape_map)\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Here are the key issues causing your t-SNE plot to look ‚Äúoff,‚Äù and how to fix them:\n",
                                    "\n",
                                    "1. **Perplexity too low**  \n",
                                    "   You set `perplexity = 0.1`, but t-SNE‚Äôs ‚Äúperplexity‚Äù really should lie between **5 and 50**.  Very low values collapse all points into tiny local clusters.\n",
                                    "\n",
                                    "2. **Too few iterations**  \n",
                                    "   You passed only `max_iter = 250` (and even used the wrong parameter name‚Äîsee next point).  t-SNE typically needs **‚â• 1 000** iterations to converge to a useful layout.\n",
                                    "\n",
                                    "3. **Wrong parameter name**  \n",
                                    "   scikit-learn‚Äôs TSNE class accepts `n_iter`, _not_ `max_iter`.  As written, your call  \n",
                                    "   ```python\n",
                                    "   TSNE(..., max_iter=max_iter)\n",
                                    "   ```  \n",
                                    "   silently ignores `max_iter`, so you‚Äôre actually running with the default `n_iter=1_000` anyway ‚Äî but since you passed so small a perplexity, it still collapses everything.\n",
                                    "\n",
                                    "4. **Sub-optimal initialization**  \n",
                                    "   By default t-SNE starts from random noise.  Using `init='pca'` often yields faster, more stable embeddings.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "### üîß Fixed `compute_tsne_embeddings`\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.manifold import TSNE\n",
                                    "from sentence_transformers import SentenceTransformer\n",
                                    "from sklearn.decomposition import PCA\n",
                                    "\n",
                                    "def compute_tsne_embeddings(\n",
                                    "    sentences,\n",
                                    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
                                    "    perplexity=30,\n",
                                    "    n_iter=1000,\n",
                                    "    random_state=42\n",
                                    "):\n",
                                    "    \"\"\"\n",
                                    "    Compute and return 2D t-SNE embeddings for the given sentences,\n",
                                    "    with PCA-based initialization and sensible defaults.\n",
                                    "    \"\"\"\n",
                                    "    # 1. Embed sentences\n",
                                    "    model = SentenceTransformer(model_name)\n",
                                    "    high_dim = model.encode(sentences)\n",
                                    "\n",
                                    "    # 2. (Optional) Pre-reduce to speed up t-SNE and remove noise\n",
                                    "    pca = PCA(n_components=50, random_state=random_state)\n",
                                    "    reduced50 = pca.fit_transform(high_dim)\n",
                                    "\n",
                                    "    # 3. t-SNE with proper params\n",
                                    "    tsne = TSNE(\n",
                                    "        n_components=2,\n",
                                    "        perplexity=perplexity,\n",
                                    "        n_iter=n_iter,\n",
                                    "        init='pca',\n",
                                    "        random_state=random_state\n",
                                    "    )\n",
                                    "\n",
                                    "    return tsne.fit_transform(reduced50)\n",
                                    "```\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "### üöÄ How to run it\n",
                                    "\n",
                                    "```python\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    sentences, categories = get_sentences_and_categories()\n",
                                    "    color_map, shape_map = get_color_and_shape_maps()\n",
                                    "\n",
                                    "    # Use a reasonable perplexity and enough iterations\n",
                                    "    reduced = compute_tsne_embeddings(\n",
                                    "        sentences,\n",
                                    "        perplexity=30,   # between 5‚Äì50\n",
                                    "        n_iter=1000      # or more, for convergence\n",
                                    "    )\n",
                                    "\n",
                                    "    plot_embeddings(reduced, sentences, categories, color_map, shape_map)\n",
                                    "```\n",
                                    "\n",
                                    "With those changes you‚Äôll get much cleaner, well-separated clusters that actually reflect your four topics."
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Adding a New Category\n",
                                    "\n",
                                    "You've gained a solid understanding of generating and reducing sentence embeddings. Now, let's apply that knowledge to troubleshoot and refine the compute_tsne_embeddings function.\n",
                                    "\n",
                                    "In the given code, there is some bug that is causing the embeddings visualization to be pretty bad. Your task is to identify and fix any issues that are causing such a poor visualization.\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "import matplotlib.pyplot as plt\n",
                                    "from sklearn.manifold import TSNE\n",
                                    "from sentence_transformers import SentenceTransformer\n",
                                    "\n",
                                    "def get_sentences_and_categories():\n",
                                    "    \"\"\"Return the sentences and their corresponding categories.\"\"\"\n",
                                    "    sentences = [\n",
                                    "        # Topic: NLP\n",
                                    "        \"RAG stands for Retrieval-Augmented Generation.\",\n",
                                    "        \"Retrieval is a crucial aspect of modern NLP systems.\",\n",
                                    "        \"Generating text with correct facts is challenging.\",\n",
                                    "        \"Large language models can generate coherent text.\",\n",
                                    "        \"GPT models have billions of parameters.\",\n",
                                    "        \"Natural Language Processing enables computers to understand human language.\",\n",
                                    "        \"Word embeddings capture semantic relationships between words.\",\n",
                                    "        \"Transformer architectures revolutionized NLP research.\",\n",
                                    "        \n",
                                    "        # Topic: Machine Learning\n",
                                    "        \"Machine learning benefits from large datasets.\",\n",
                                    "        \"Supervised learning requires labeled data.\",\n",
                                    "        \"Reinforcement learning is inspired by behavioral psychology.\",\n",
                                    "        \"Neural networks can learn complex functions.\",\n",
                                    "        \"Overfitting is a common problem in ML.\",\n",
                                    "        \"Unsupervised learning uncovers hidden patterns in data.\",\n",
                                    "        \"Feature engineering is critical for model performance.\",\n",
                                    "        \"Cross-validation helps in assessing model generalization.\",\n",
                                    "        \n",
                                    "        # Topic: Food\n",
                                    "        \"Bananas are commonly used in smoothies.\",\n",
                                    "        \"Oranges are rich in vitamin C.\",\n",
                                    "        \"Pizza is a popular Italian dish.\",\n",
                                    "        \"Cooking pasta requires boiling water.\",\n",
                                    "        \"Chocolate can be sweet or bitter.\",\n",
                                    "        \"Fresh salads are a healthy and refreshing meal.\",\n",
                                    "        \"Sushi combines rice, fish, and seaweed in a delicate balance.\",\n",
                                    "        \"Spices can transform simple ingredients into gourmet dishes.\",\n",
                                    "        \n",
                                    "        # Topic: Weather\n",
                                    "        \"It often rains in the Amazon rainforest.\",\n",
                                    "        \"Summers can be very hot in the desert.\",\n",
                                    "        \"Hurricanes form over warm ocean waters.\",\n",
                                    "        \"Snowstorms can disrupt transportation.\",\n",
                                    "        \"A sunny day can lift people's mood.\",\n",
                                    "        \"Foggy mornings are common in coastal regions.\",\n",
                                    "        \"Winter brings frosty nights and chilly winds.\",\n",
                                    "        \"Thunderstorms can produce lightning and heavy rain.\"\n",
                                    "    ]\n",
                                    "    \n",
                                    "    categories = ([\"NLP\"] * 8 + [\"ML\"] * 8 + [\"Food\"] * 8 + [\"Weather\"] * 8)\n",
                                    "    return sentences, categories\n",
                                    "\n",
                                    "def get_color_and_shape_maps():\n",
                                    "    \"\"\"Return color and marker maps for each category.\"\"\"\n",
                                    "    color_map = {\n",
                                    "        \"NLP\": \"red\",\n",
                                    "        \"ML\": \"blue\",\n",
                                    "        \"Food\": \"green\",\n",
                                    "        \"Weather\": \"purple\"\n",
                                    "    }\n",
                                    "    shape_map = {\n",
                                    "        \"NLP\": \"o\",\n",
                                    "        \"ML\": \"s\",\n",
                                    "        \"Food\": \"^\",\n",
                                    "        \"Weather\": \"X\"\n",
                                    "    }\n",
                                    "    return color_map, shape_map\n",
                                    "\n",
                                    "def compute_tsne_embeddings(sentences, model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
                                    "                            perplexity=10, max_iter=3000, random_state=42):\n",
                                    "    \"\"\"Compute and return t-SNE reduced embeddings for the given sentences.\"\"\"\n",
                                    "    model = SentenceTransformer(model_name)\n",
                                    "    embeddings = model.encode(sentences)\n",
                                    "    tsne = TSNE(n_components=2, random_state=random_state,\n",
                                    "                perplexity=perplexity, max_iter=max_iter)\n",
                                    "    return tsne.fit_transform(embeddings)\n",
                                    "\n",
                                    "def plot_embeddings(reduced_embeddings, sentences, categories, color_map, shape_map):\n",
                                    "    \"\"\"Plot the 2D embeddings with labels and a legend.\"\"\"\n",
                                    "    plt.figure(figsize=(10, 8))\n",
                                    "    for i, (sentence, category) in enumerate(zip(sentences, categories)):\n",
                                    "        x, y = reduced_embeddings[i]\n",
                                    "        plt.scatter(x, y, color=color_map[category], marker=shape_map[category])\n",
                                    "        plt.text(x - 2.5, y - 1, sentence[:20] + \"...\", fontsize=9)\n",
                                    "    \n",
                                    "    for cat, color in color_map.items():\n",
                                    "        plt.scatter([], [], color=color, label=cat, marker=shape_map[cat])\n",
                                    "    plt.legend(loc=\"best\")\n",
                                    "\n",
                                    "    plt.title(\"t-SNE Visualization of Sentence Embeddings\", fontsize=14)\n",
                                    "    plt.xlabel(\"t-SNE Dimension 1\", fontsize=12)\n",
                                    "    plt.ylabel(\"t-SNE Dimension 2\", fontsize=12)\n",
                                    "    plt.tight_layout()\n",
                                    "    plt.savefig('static/images/plot.png')\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    sentences, categories = get_sentences_and_categories()\n",
                                    "    color_map, shape_map = get_color_and_shape_maps()\n",
                                    "    \n",
                                    "    perplexity = 0.1\n",
                                    "    max_iter = 250\n",
                                    "    reduced_embeddings = compute_tsne_embeddings(sentences, perplexity=perplexity, max_iter=max_iter)\n",
                                    "    plot_embeddings(reduced_embeddings, sentences, categories, color_map, shape_map)\n",
                                    "\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Here are the main issues I see that will wreck t-SNE‚Äôs ability to pull apart your four topics:\n",
                                    "\n",
                                    "1. **Invalid/mis-named parameter**  \n",
                                    "   You‚Äôre passing `max_iter` to `TSNE(...)`, but in scikit-learn the correct argument is `n_iter`. Because `max_iter` is unrecognized, t-SNE is silently falling back to its default of 1 000 iterations under the hood (or possibly erroring, depending on your version).  \n",
                                    "\n",
                                    "2. **Perplexity way too low**  \n",
                                    "   You set `perplexity = 0.1`. Good practice is **5 ‚â§ perplexity ‚â§ 50** (and ‚â§ `(n_samples‚àí1)/3`). With 32 points, something like 5‚Äì10 is a better starting point.\n",
                                    "\n",
                                    "3. **Too few iterations (when you override properly)**  \n",
                                    "   Even if you fix the name to `n_iter`, 250 iterations is usually not enough to converge. I‚Äôd bump that to at least 1 000.\n",
                                    "\n",
                                    "4. **Random (‚Äúrandom‚Äù) initialization**  \n",
                                    "   By default t-SNE starts from a random 2D layout, which can make early clusters look like noise. Using `init='pca'` will give it a sensible starting arrangement.\n",
                                    "\n",
                                    "5. **No embedding normalization or PCA pre-reduction**  \n",
                                    "   Since t-SNE optimizes Euclidean distances, it often helps to (a) L2-normalize your sentence embeddings if you really care about *cosine* similarity, and/or (b) do a quick PCA to, say, 50D first (this denoises and speeds up the Barnes-Hut approximation).\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "### Revised `compute_tsne_embeddings`\n",
                                    "\n",
                                    "```python\n",
                                    "import matplotlib.pyplot as plt\n",
                                    "from sklearn.manifold import TSNE\n",
                                    "from sklearn.decomposition import PCA         # ‚Üê add this\n",
                                    "from sklearn.preprocessing import normalize  # ‚Üê and this\n",
                                    "from sentence_transformers import SentenceTransformer\n",
                                    "\n",
                                    "def get_sentences_and_categories():\n",
                                    "    \"\"\"Return the sentences and their corresponding categories.\"\"\"\n",
                                    "    sentences = [\n",
                                    "        # Topic: NLP\n",
                                    "        \"RAG stands for Retrieval-Augmented Generation.\",\n",
                                    "        \"Retrieval is a crucial aspect of modern NLP systems.\",\n",
                                    "        \"Generating text with correct facts is challenging.\",\n",
                                    "        \"Large language models can generate coherent text.\",\n",
                                    "        \"GPT models have billions of parameters.\",\n",
                                    "        \"Natural Language Processing enables computers to understand human language.\",\n",
                                    "        \"Word embeddings capture semantic relationships between words.\",\n",
                                    "        \"Transformer architectures revolutionized NLP research.\",\n",
                                    "        \n",
                                    "        # Topic: Machine Learning\n",
                                    "        \"Machine learning benefits from large datasets.\",\n",
                                    "        \"Supervised learning requires labeled data.\",\n",
                                    "        \"Reinforcement learning is inspired by behavioral psychology.\",\n",
                                    "        \"Neural networks can learn complex functions.\",\n",
                                    "        \"Overfitting is a common problem in ML.\",\n",
                                    "        \"Unsupervised learning uncovers hidden patterns in data.\",\n",
                                    "        \"Feature engineering is critical for model performance.\",\n",
                                    "        \"Cross-validation helps in assessing model generalization.\",\n",
                                    "        \n",
                                    "        # Topic: Food\n",
                                    "        \"Bananas are commonly used in smoothies.\",\n",
                                    "        \"Oranges are rich in vitamin C.\",\n",
                                    "        \"Pizza is a popular Italian dish.\",\n",
                                    "        \"Cooking pasta requires boiling water.\",\n",
                                    "        \"Chocolate can be sweet or bitter.\",\n",
                                    "        \"Fresh salads are a healthy and refreshing meal.\",\n",
                                    "        \"Sushi combines rice, fish, and seaweed in a delicate balance.\",\n",
                                    "        \"Spices can transform simple ingredients into gourmet dishes.\",\n",
                                    "        \n",
                                    "        # Topic: Weather\n",
                                    "        \"It often rains in the Amazon rainforest.\",\n",
                                    "        \"Summers can be very hot in the desert.\",\n",
                                    "        \"Hurricanes form over warm ocean waters.\",\n",
                                    "        \"Snowstorms can disrupt transportation.\",\n",
                                    "        \"A sunny day can lift people's mood.\",\n",
                                    "        \"Foggy mornings are common in coastal regions.\",\n",
                                    "        \"Winter brings frosty nights and chilly winds.\",\n",
                                    "        \"Thunderstorms can produce lightning and heavy rain.\"\n",
                                    "    ]\n",
                                    "    \n",
                                    "    categories = ([\"NLP\"] * 8 + [\"ML\"] * 8 + [\"Food\"] * 8 + [\"Weather\"] * 8)\n",
                                    "    return sentences, categories\n",
                                    "\n",
                                    "def get_color_and_shape_maps():\n",
                                    "    \"\"\"Return color and marker maps for each category.\"\"\"\n",
                                    "    color_map = {\n",
                                    "        \"NLP\": \"red\",\n",
                                    "        \"ML\": \"blue\",\n",
                                    "        \"Food\": \"green\",\n",
                                    "        \"Weather\": \"purple\"\n",
                                    "    }\n",
                                    "    shape_map = {\n",
                                    "        \"NLP\": \"o\",\n",
                                    "        \"ML\": \"s\",\n",
                                    "        \"Food\": \"^\",\n",
                                    "        \"Weather\": \"X\"\n",
                                    "    }\n",
                                    "    return color_map, shape_map\n",
                                    "\n",
                                    "def compute_tsne_embeddings(\n",
                                    "    sentences,\n",
                                    "    model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
                                    "    perplexity: float = 10.0,\n",
                                    "    n_iter: int = 1000,\n",
                                    "    random_state: int = 42\n",
                                    "):\n",
                                    "    model = SentenceTransformer(model_name)\n",
                                    "    embeddings = model.encode(sentences)\n",
                                    "    \n",
                                    "    # Normalize so Euclidean ‚âà Cosine\n",
                                    "    embeddings = normalize(embeddings, axis=1)\n",
                                    "\n",
                                    "    # Cap PCA components by samples & features\n",
                                    "    n_samples, n_features = embeddings.shape\n",
                                    "    pca_dim = min(50, n_samples, n_features)\n",
                                    "    pca = PCA(n_components=pca_dim, random_state=random_state)\n",
                                    "    reduced = pca.fit_transform(embeddings)\n",
                                    "\n",
                                    "    tsne = TSNE(\n",
                                    "        n_components=2,\n",
                                    "        perplexity=perplexity,\n",
                                    "        n_iter=n_iter,\n",
                                    "        init='pca',\n",
                                    "        random_state=random_state,\n",
                                    "        metric='euclidean'\n",
                                    "    )\n",
                                    "    return tsne.fit_transform(reduced)\n",
                                    "\n",
                                    "def plot_embeddings(reduced_embeddings, sentences, categories, color_map, shape_map):\n",
                                    "    \"\"\"Plot the 2D embeddings with labels and a legend.\"\"\"\n",
                                    "    plt.figure(figsize=(10, 8))\n",
                                    "    for i, (sentence, category) in enumerate(zip(sentences, categories)):\n",
                                    "        x, y = reduced_embeddings[i]\n",
                                    "        plt.scatter(x, y, color=color_map[category], marker=shape_map[category])\n",
                                    "        plt.text(x - 2.5, y - 1, sentence[:20] + \"...\", fontsize=9)\n",
                                    "    \n",
                                    "    for cat, color in color_map.items():\n",
                                    "        plt.scatter([], [], color=color, label=cat, marker=shape_map[cat])\n",
                                    "    plt.legend(loc=\"best\")\n",
                                    "\n",
                                    "    plt.title(\"t-SNE Visualization of Sentence Embeddings\", fontsize=14)\n",
                                    "    plt.xlabel(\"t-SNE Dimension 1\", fontsize=12)\n",
                                    "    plt.ylabel(\"t-SNE Dimension 2\", fontsize=12)\n",
                                    "    plt.tight_layout()\n",
                                    "    plt.savefig('static/images/plot.png')\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    sentences, categories = get_sentences_and_categories()\n",
                                    "    color_map, shape_map = get_color_and_shape_maps()\n",
                                    "\n",
                                    "    # Pick a reasonable perplexity (e.g. 5‚Äì15 for ~30 points) and enough iterations:\n",
                                    "    reduced_embeddings = compute_tsne_embeddings(\n",
                                    "        sentences,\n",
                                    "        perplexity=10.0,\n",
                                    "        n_iter=1000\n",
                                    "    )\n",
                                    "\n",
                                    "    plot_embeddings(reduced_embeddings, sentences, categories, color_map, shape_map)\n",
                                    "    plt.show()\n",
                                    "```\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "#### Why this helps\n",
                                    "\n",
                                    "- **`n_iter=1000`** gives t-SNE enough time to settle; you can even push to 2 000‚Äì3 000 if you like.  \n",
                                    "- **`perplexity=10`** balances local vs. global structure nicely with 32 samples.  \n",
                                    "- **`init='pca'`** means you don‚Äôt start from pure noise.  \n",
                                    "- **PCA ‚Üí t-SNE** often yields cleaner clusters and runs faster.  \n",
                                    "- **Normalization** lets the Euclidean metric approximate cosine similarity, which is what your sentence-transformers embeddings are really optimized for.\n",
                                    "\n",
                                    "With these changes you should see four well-separated ‚Äúislands‚Äù in your plot, one per category, instead of a noisy blob."
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "id": "cc93fc77",
                           "metadata": {},
                           "source": [
                                    "Great job visualizing sentence embeddings with t-SNE!\n",
                                    "\n",
                                    "Now, your task is to add a new category of your choice to the dataset. You'll need to:\n",
                                    "\n",
                                    "Add some sentences related to a topic of your choice\n",
                                    "Update the get_sentences_and_categories function to include your new category\n",
                                    "Adjust the color and shape maps to give your category a distinct appearance\n",
                                    "Run the code to see how your new sentences cluster with the existing ones\n",
                                    "This is your chance to experiment! Feel free to try different categories or even multiple categories to observe how semantically similar content tends to cluster together. Pay attention to cases where your new categories might overlap with existing ones - this can reveal interesting semantic relationships.\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "import matplotlib.pyplot as plt\n",
                                    "from sklearn.manifold import TSNE\n",
                                    "from sentence_transformers import SentenceTransformer\n",
                                    "\n",
                                    "def get_sentences_and_categories():\n",
                                    "    \"\"\"Return the sentences and their corresponding categories.\"\"\"\n",
                                    "    sentences = [\n",
                                    "        # Topic: NLP\n",
                                    "        \"RAG stands for Retrieval-Augmented Generation.\",\n",
                                    "        \"Retrieval is a crucial aspect of modern NLP systems.\",\n",
                                    "        \"Generating text with correct facts is challenging.\",\n",
                                    "        \"Large language models can generate coherent text.\",\n",
                                    "        \"GPT models have billions of parameters.\",\n",
                                    "        \"Natural Language Processing enables computers to understand human language.\",\n",
                                    "        \"Word embeddings capture semantic relationships between words.\",\n",
                                    "        \"Transformer architectures revolutionized NLP research.\",\n",
                                    "        \n",
                                    "        # Topic: Machine Learning\n",
                                    "        \"Machine learning benefits from large datasets.\",\n",
                                    "        \"Supervised learning requires labeled data.\",\n",
                                    "        \"Reinforcement learning is inspired by behavioral psychology.\",\n",
                                    "        \"Neural networks can learn complex functions.\",\n",
                                    "        \"Overfitting is a common problem in ML.\",\n",
                                    "        \"Unsupervised learning uncovers hidden patterns in data.\",\n",
                                    "        \"Feature engineering is critical for model performance.\",\n",
                                    "        \"Cross-validation helps in assessing model generalization.\",\n",
                                    "        \n",
                                    "        # Topic: Food\n",
                                    "        \"Bananas are commonly used in smoothies.\",\n",
                                    "        \"Oranges are rich in vitamin C.\",\n",
                                    "        \"Pizza is a popular Italian dish.\",\n",
                                    "        \"Cooking pasta requires boiling water.\",\n",
                                    "        \"Chocolate can be sweet or bitter.\",\n",
                                    "        \"Fresh salads are a healthy and refreshing meal.\",\n",
                                    "        \"Sushi combines rice, fish, and seaweed in a delicate balance.\",\n",
                                    "        \"Spices can transform simple ingredients into gourmet dishes.\",\n",
                                    "        \n",
                                    "        # Topic: Weather\n",
                                    "        \"It often rains in the Amazon rainforest.\",\n",
                                    "        \"Summers can be very hot in the desert.\",\n",
                                    "        \"Hurricanes form over warm ocean waters.\",\n",
                                    "        \"Snowstorms can disrupt transportation.\",\n",
                                    "        \"A sunny day can lift people's mood.\",\n",
                                    "        \"Foggy mornings are common in coastal regions.\",\n",
                                    "        \"Winter brings frosty nights and chilly winds.\",\n",
                                    "        \"Thunderstorms can produce lightning and heavy rain.\"\n",
                                    "        \n",
                                    "        # TODO: Add your new category sentences here\n",
                                    "    ]\n",
                                    "    \n",
                                    "    categories = ([\"NLP\"] * 8 + [\"ML\"] * 8 + [\"Food\"] * 8 + [\"Weather\"] * 8)\n",
                                    "    # TODO: Update categories list with your new category\n",
                                    "    return sentences, categories\n",
                                    "\n",
                                    "def get_color_and_shape_maps():\n",
                                    "    \"\"\"Return color and marker maps for each category.\"\"\"\n",
                                    "    color_map = {\n",
                                    "        \"NLP\": \"red\",\n",
                                    "        \"ML\": \"blue\",\n",
                                    "        \"Food\": \"green\",\n",
                                    "        \"Weather\": \"purple\"\n",
                                    "        # TODO: Add your new category color here\n",
                                    "    }\n",
                                    "    shape_map = {\n",
                                    "        \"NLP\": \"o\",\n",
                                    "        \"ML\": \"s\",\n",
                                    "        \"Food\": \"^\",\n",
                                    "        \"Weather\": \"X\"\n",
                                    "        # TODO: Add your new category shape here\n",
                                    "    }\n",
                                    "    return color_map, shape_map\n",
                                    "\n",
                                    "def compute_tsne_embeddings(sentences, model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
                                    "                              perplexity=10, max_iter=3000, random_state=42):\n",
                                    "    \"\"\"Compute and return t-SNE reduced embeddings for the given sentences.\"\"\"\n",
                                    "    model = SentenceTransformer(model_name)\n",
                                    "    embeddings = model.encode(sentences)\n",
                                    "    tsne = TSNE(n_components=2, random_state=random_state,\n",
                                    "                perplexity=perplexity, max_iter=max_iter)\n",
                                    "    return tsne.fit_transform(embeddings)\n",
                                    "\n",
                                    "def plot_embeddings(reduced_embeddings, sentences, categories, color_map, shape_map):\n",
                                    "    \"\"\"Plot the 2D embeddings with labels and a legend.\"\"\"\n",
                                    "    plt.figure(figsize=(10, 8))\n",
                                    "    for i, (sentence, category) in enumerate(zip(sentences, categories)):\n",
                                    "        x, y = reduced_embeddings[i]\n",
                                    "        plt.scatter(x, y, color=color_map[category], marker=shape_map[category])\n",
                                    "        plt.text(x - 2.5, y - 1.0, sentence[:20] + \"...\", fontsize=9)\n",
                                    "    \n",
                                    "    for cat, color in color_map.items():\n",
                                    "        plt.scatter([], [], color=color, label=cat, marker=shape_map[cat])\n",
                                    "    plt.legend(loc=\"best\")\n",
                                    "\n",
                                    "    plt.title(\"t-SNE Visualization of Sentence Embeddings\", fontsize=14)\n",
                                    "    plt.xlabel(\"t-SNE Dimension 1\", fontsize=12)\n",
                                    "    plt.ylabel(\"t-SNE Dimension 2\", fontsize=12)\n",
                                    "    plt.tight_layout()\n",
                                    "    plt.savefig('static/images/plot.png')\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    sentences, categories = get_sentences_and_categories()\n",
                                    "    color_map, shape_map = get_color_and_shape_maps()\n",
                                    "    reduced_embeddings = compute_tsne_embeddings(sentences)\n",
                                    "    plot_embeddings(reduced_embeddings, sentences, categories, color_map, shape_map)\n",
                                    "\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Here‚Äôs an example adding a **‚ÄúSports‚Äù** category‚Äîyou can, of course, swap in any topic you like. I‚Äôve added eight sports-related sentences, updated the category list, and chosen **orange** diamonds (‚ÄúD‚Äù) so they stand out:\n",
                                    "\n",
                                    "```python\n",
                                    "import matplotlib.pyplot as plt\n",
                                    "from sklearn.manifold import TSNE\n",
                                    "from sentence_transformers import SentenceTransformer\n",
                                    "\n",
                                    "def get_sentences_and_categories():\n",
                                    "    \"\"\"Return the sentences and their corresponding categories.\"\"\"\n",
                                    "    sentences = [\n",
                                    "        # Topic: NLP\n",
                                    "        \"RAG stands for Retrieval-Augmented Generation.\",\n",
                                    "        \"Retrieval is a crucial aspect of modern NLP systems.\",\n",
                                    "        \"Generating text with correct facts is challenging.\",\n",
                                    "        \"Large language models can generate coherent text.\",\n",
                                    "        \"GPT models have billions of parameters.\",\n",
                                    "        \"Natural Language Processing enables computers to understand human language.\",\n",
                                    "        \"Word embeddings capture semantic relationships between words.\",\n",
                                    "        \"Transformer architectures revolutionized NLP research.\",\n",
                                    "        \n",
                                    "        # Topic: Machine Learning\n",
                                    "        \"Machine learning benefits from large datasets.\",\n",
                                    "        \"Supervised learning requires labeled data.\",\n",
                                    "        \"Reinforcement learning is inspired by behavioral psychology.\",\n",
                                    "        \"Neural networks can learn complex functions.\",\n",
                                    "        \"Overfitting is a common problem in ML.\",\n",
                                    "        \"Unsupervised learning uncovers hidden patterns in data.\",\n",
                                    "        \"Feature engineering is critical for model performance.\",\n",
                                    "        \"Cross-validation helps in assessing model generalization.\",\n",
                                    "        \n",
                                    "        # Topic: Food\n",
                                    "        \"Bananas are commonly used in smoothies.\",\n",
                                    "        \"Oranges are rich in vitamin C.\",\n",
                                    "        \"Pizza is a popular Italian dish.\",\n",
                                    "        \"Cooking pasta requires boiling water.\",\n",
                                    "        \"Chocolate can be sweet or bitter.\",\n",
                                    "        \"Fresh salads are a healthy and refreshing meal.\",\n",
                                    "        \"Sushi combines rice, fish, and seaweed in a delicate balance.\",\n",
                                    "        \"Spices can transform simple ingredients into gourmet dishes.\",\n",
                                    "        \n",
                                    "        # Topic: Weather\n",
                                    "        \"It often rains in the Amazon rainforest.\",\n",
                                    "        \"Summers can be very hot in the desert.\",\n",
                                    "        \"Hurricanes form over warm ocean waters.\",\n",
                                    "        \"Snowstorms can disrupt transportation.\",\n",
                                    "        \"A sunny day can lift people's mood.\",\n",
                                    "        \"Foggy mornings are common in coastal regions.\",\n",
                                    "        \"Winter brings frosty nights and chilly winds.\",\n",
                                    "        \"Thunderstorms can produce lightning and heavy rain.\",\n",
                                    "        \n",
                                    "        # Topic: Sports\n",
                                    "        \"Soccer matches attract millions of fans worldwide.\",\n",
                                    "        \"Basketball players require agility and height.\",\n",
                                    "        \"Tennis matches can last over five hours.\",\n",
                                    "        \"Marathons test endurance more than speed.\",\n",
                                    "        \"Olympic athletes train years for their events.\",\n",
                                    "        \"Swimmers compete in lanes within a pool.\",\n",
                                    "        \"Cricket matches can span multiple days.\",\n",
                                    "        \"Formula 1 cars can exceed 200 mph.\"\n",
                                    "    ]\n",
                                    "    \n",
                                    "    categories = (\n",
                                    "        [\"NLP\"] * 8 +\n",
                                    "        [\"ML\"] * 8 +\n",
                                    "        [\"Food\"] * 8 +\n",
                                    "        [\"Weather\"] * 8 +\n",
                                    "        [\"Sports\"] * 8\n",
                                    "    )\n",
                                    "    return sentences, categories\n",
                                    "\n",
                                    "def get_color_and_shape_maps():\n",
                                    "    \"\"\"Return color and marker maps for each category.\"\"\"\n",
                                    "    color_map = {\n",
                                    "        \"NLP\": \"red\",\n",
                                    "        \"ML\": \"blue\",\n",
                                    "        \"Food\": \"green\",\n",
                                    "        \"Weather\": \"purple\",\n",
                                    "        \"Sports\": \"orange\"      # new category in orange\n",
                                    "    }\n",
                                    "    shape_map = {\n",
                                    "        \"NLP\": \"o\",\n",
                                    "        \"ML\": \"s\",\n",
                                    "        \"Food\": \"^\",\n",
                                    "        \"Weather\": \"X\",\n",
                                    "        \"Sports\": \"D\"          # diamond marker\n",
                                    "    }\n",
                                    "    return color_map, shape_map\n",
                                    "\n",
                                    "def compute_tsne_embeddings(sentences, model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
                                    "                            perplexity=10, max_iter=3000, random_state=42):\n",
                                    "    \"\"\"Compute and return t-SNE reduced embeddings for the given sentences.\"\"\"\n",
                                    "    model = SentenceTransformer(model_name)\n",
                                    "    embeddings = model.encode(sentences)\n",
                                    "    tsne = TSNE(n_components=2, random_state=random_state,\n",
                                    "                perplexity=perplexity, n_iter=max_iter, init='pca')\n",
                                    "    return tsne.fit_transform(embeddings)\n",
                                    "\n",
                                    "def plot_embeddings(reduced_embeddings, sentences, categories, color_map, shape_map):\n",
                                    "    \"\"\"Plot the 2D embeddings with labels and a legend.\"\"\"\n",
                                    "    plt.figure(figsize=(10, 8))\n",
                                    "    for i, (sentence, category) in enumerate(zip(sentences, categories)):\n",
                                    "        x, y = reduced_embeddings[i]\n",
                                    "        plt.scatter(x, y, color=color_map[category], marker=shape_map[category])\n",
                                    "        plt.text(x - 2.5, y - 1.0, sentence[:20] + \"...\", fontsize=9)\n",
                                    "    \n",
                                    "    # legend handles\n",
                                    "    for cat in color_map:\n",
                                    "        plt.scatter([], [], color=color_map[cat], marker=shape_map[cat], label=cat)\n",
                                    "    plt.legend(loc=\"best\")\n",
                                    "\n",
                                    "    plt.title(\"t-SNE Visualization of Sentence Embeddings\", fontsize=14)\n",
                                    "    plt.xlabel(\"t-SNE Dimension 1\", fontsize=12)\n",
                                    "    plt.ylabel(\"t-SNE Dimension 2\", fontsize=12)\n",
                                    "    plt.tight_layout()\n",
                                    "    plt.savefig('static/images/plot.png')\n",
                                    "    plt.show()\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    sentences, categories = get_sentences_and_categories()\n",
                                    "    color_map, shape_map = get_color_and_shape_maps()\n",
                                    "    reduced_embeddings = compute_tsne_embeddings(sentences)\n",
                                    "    plot_embeddings(reduced_embeddings, sentences, categories, color_map, shape_map)\n",
                                    "```\n",
                                    "\n",
                                    "**Next steps:**\n",
                                    "1. Save and run this script.\n",
                                    "2. Observe where the orange ‚ÄúSports‚Äù points land relative to NLP, ML, Food, and Weather.\n",
                                    "3. If you spot overlap (e.g. ‚Äúmarathons test endurance‚Äù might sit near ‚Äúreinforcement learning‚Äù because of the shared notion of ‚Äútraining‚Äù), that‚Äôs a neat semantic signal! \n",
                                    "\n",
                                    "Feel free to swap in your own category‚Äîsay **‚ÄúTravel‚Äù**, **‚ÄúMovies‚Äù**, **‚ÄúHealth‚Äù**, etc.‚Äîby following the same pattern."
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
