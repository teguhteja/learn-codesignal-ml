{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Lesson 4: Comparing Bag-of-Words and Embeddings-Based Semantic Search\n",
                                    "\n",
                                    "Welcome to our final lesson in this course about **Text Representation Techniques for RAG systems**! You’ve already explored the basics of Bag-of-Words (BOW) representations and experimented with sentence embeddings in earlier lessons. Now, we’re going to compare how these two methods differ in actual search scenarios. Think of this as a practical refresher on BOW and embeddings, but with an added focus on side-by-side comparison and deciding which approach might be best for different retrieval use cases.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## From Words To Meaning: Why We Need Both Approaches\n",
                                    "\n",
                                    "Before diving into the code, let’s clarify why both methods—from straightforward word matching to deeper semantic modeling—are valuable:\n",
                                    "\n",
                                    "- **Lexical Overlap (BOW)**  \n",
                                    "  This approach checks for exact word matches, making it easy to interpret how documents are scored. If your query has the phrase `\"external data\"`, any document containing those exact words gets a higher score. It’s simple, transparent, and efficient for many tasks—but can struggle with synonyms or varying phrasing.\n",
                                    "\n",
                                    "- **Semantic Similarity (Embeddings)**  \n",
                                    "  Here, we focus on the overall meaning rather than specific words. Two differently phrased sentences can still be close in the embedding space if they convey the same idea. This approach excels at capturing nuances. However, it depends on a trained model and requires more computation.\n",
                                    "\n",
                                    "> In some real-world settings, you might even combine both: run a quick lexical match and then refine the results with a more precise semantic model. Let’s see how these methods look in code so you can start comparing results for yourself.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Implementing Bag-of-Words Search\n",
                                    "\n",
                                    "Below is an example of how to implement a BOW-based search workflow. We first build a vocabulary, then vectorize each document and the query according to how often each word appears.\n",
                                    "\n",
                                    "```python\n",
                                    "def bow_vectorize(text, vocab):\n",
                                    "    \"\"\"\n",
                                    "    Convert a text into a Bag-of-Words vector by counting how many times \n",
                                    "    each token from our vocabulary appears in the text.\n",
                                    "    \"\"\"\n",
                                    "    vector = np.zeros(len(vocab), dtype=int)\n",
                                    "    for word in text.lower().split():\n",
                                    "        # Remove punctuation for consistency\n",
                                    "        clean_word = word.strip(\".,!?\")\n",
                                    "        if clean_word in vocab:\n",
                                    "            vector[vocab[clean_word]] += 1\n",
                                    "    return vector\n",
                                    "\n",
                                    "def bow_search(query, docs):\n",
                                    "    \"\"\"\n",
                                    "    Rank documents by lexical overlap using the BOW technique. \n",
                                    "    The dot product between the query vector and each document vector \n",
                                    "    indicates how many words they share.\n",
                                    "    \"\"\"\n",
                                    "    query_vec = bow_vectorize(query, VOCAB)\n",
                                    "    scores = []\n",
                                    "    for i, doc in enumerate(docs):\n",
                                    "        doc_vec = bow_vectorize(doc, VOCAB)\n",
                                    "        score = np.dot(query_vec, doc_vec)  # Higher score = more overlap\n",
                                    "        scores.append((i, score))\n",
                                    "    # Sort by descending overlap\n",
                                    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
                                    "    return scores\n",
                                    "```\n",
                                    "\n",
                                    "Let’s break this down:\n",
                                    "\n",
                                    "1. **`bow_vectorize`**  \n",
                                    "   - Splits the text into words, applies some light cleanup (punctuation removal), and counts occurrences.  \n",
                                    "   - If “external” appears once in the query, that contributes 1 to the corresponding position in the query vector.\n",
                                    "\n",
                                    "2. **`bow_search`**  \n",
                                    "   - Converts the query into a BOW vector, does the same for each document, and uses the dot product to measure shared token counts.  \n",
                                    "   - Documents with many overlapping terms move to the top of the list.\n",
                                    "\n",
                                    "> This method is straightforward and fast for situations when exact word usage is critical. But what if your query is phrased differently than the document’s text? That’s where embeddings shine.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Implementing Embedding-based Search\n",
                                    "\n",
                                    "To tackle the challenge of phrasing differences or synonyms, let’s look at embedding-based search:\n",
                                    "\n",
                                    "```python\n",
                                    "def cos_sim(a, b):\n",
                                    "    \"\"\"\n",
                                    "    Compute cosine similarity between two vectors, \n",
                                    "    indicating how similar they are.\n",
                                    "    \"\"\"\n",
                                    "    return np.dot(a, b) / (norm(a) * norm(b))\n",
                                    "\n",
                                    "def embedding_search(query, docs, model):\n",
                                    "    \"\"\"\n",
                                    "    Rank documents by comparing how semantically close they are \n",
                                    "    to the query in the embedding space using cosine similarity.\n",
                                    "    \"\"\"\n",
                                    "    # Encode both the query and documents into embeddings\n",
                                    "    query_emb = model.encode([query])[0]\n",
                                    "    doc_embs = model.encode(docs)\n",
                                    "\n",
                                    "    scores = []\n",
                                    "    for i, emb in enumerate(doc_embs):\n",
                                    "        score = cos_sim(query_emb, emb)\n",
                                    "        scores.append((i, score))\n",
                                    "    # Sort by semantic similarity in descending order\n",
                                    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
                                    "    return scores\n",
                                    "```\n",
                                    "\n",
                                    "In this snippet:\n",
                                    "\n",
                                    "- **`cos_sim`** computes the cosine similarity between two vectors. Vectors pointing in a similar direction get a higher score.  \n",
                                    "- **`embedding_search`** encodes the query and each document into high-dimensional embeddings using a pre-trained model, then ranks documents by cosine similarity.\n",
                                    "\n",
                                    "> This approach depends more on interpretive meaning than precise word matching. A query about “combining external data with generative models” can find documents discussing “merging external text into RAG systems,” even if some words differ.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Analyzing the Search Output\n",
                                    "\n",
                                    "Let’s compare results for the sample query:\n",
                                    "\n",
                                    "> **Query:**  \n",
                                    "> How does a system combine external data with language generation to improve responses?\n",
                                    "\n",
                                    "### BOW Search Results\n",
                                    "\n",
                                    "```\n",
                                    "Doc 3 | Score: 5 | Text: Media companies combine external data feeds with digital editing tools to optimize broadcast schedules.\n",
                                    "Doc 0 | Score: 4 | Text: Retrieval-Augmented Generation (RAG) enhances language models by integrating relevant external documents into the generation process.\n",
                                    "Doc 4 | Score: 3 | Text: Financial institutions analyze market data and use automated report generation to guide investment decisions.\n",
                                    "Doc 2 | Score: 2 | Text: By merging retrieved text with generative models, RAG overcomes the limitations of static training data.\n",
                                    "Doc 5 | Score: 2 | Text: Healthcare analytics platforms integrate patient records with predictive models to generate personalized care plans.\n",
                                    "Doc 1 | Score: 1 | Text: RAG systems retrieve information from large databases to provide contextual answers beyond what is stored in the model.\n",
                                    "Doc 6 | Score: 0 | Text: Bananas are popular fruits that are rich in essential nutrients such as potassium and vitamin C.\n",
                                    "```\n",
                                    "\n",
                                    "### Embedding-based Search Results\n",
                                    "\n",
                                    "```\n",
                                    "Doc 0 | Score: 0.5939 | Text: Retrieval-Augmented Generation (RAG) enhances language models by integrating relevant external documents into the generation process.\n",
                                    "Doc 1 | Score: 0.4375 | Text: RAG systems retrieve information from large databases to provide contextual answers beyond what is stored in the model.\n",
                                    "Doc 2 | Score: 0.4234 | Text: By merging retrieved text with generative models, RAG overcomes the limitations of static training data.\n",
                                    "Doc 3 | Score: 0.3179 | Text: Media companies combine external data feeds with digital editing tools to optimize broadcast schedules.\n",
                                    "Doc 4 | Score: 0.2539 | Text: Financial institutions analyze market data and use automated report generation to guide investment decisions.\n",
                                    "Doc 5 | Score: 0.2015 | Text: Healthcare analytics platforms integrate patient records with predictive models to generate personalized care plans.\n",
                                    "Doc 6 | Score: 0.0802 | Text: Bananas are popular fruits that are rich in essential nutrients such as potassium and vitamin C.\n",
                                    "```\n",
                                    "\n",
                                    "- **BOW** ranks **Doc 3** highest because of exact keyword matches (“combine” + “external”), even though **Doc 0** is more relevant to RAG.  \n",
                                    "- **Embeddings** correctly place **Doc 0** and **Doc 1** at the top, capturing the semantic relationship between “language generation” and “integrating external documents.”\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Conclusion And Next Steps\n",
                                    "\n",
                                    "In this lesson, we compared a **Bag-of-Words** search with an **embedding-based** semantic search and saw how each method ranks documents differently. BOW is agile for quick, vocabulary-based matches, while embeddings capture deeper connections between words and phrases.\n",
                                    "\n",
                                    "> **Next**, you’ll get hands-on practice implementing these approaches. Have fun exploring!\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Building a Bag of Words\n",
                                    "\n",
                                    "Congratulations on reaching this point in your learning journey! You've already explored the fundamentals of text processing, and now it's time to apply that knowledge to a practical exercise.\n",
                                    "\n",
                                    "In this activity, you'll work on the bow_vectorize function, a key component for converting text into a Bag-of-Words (BOW) vector. Your objective is to complete the function by implementing the following:\n",
                                    "\n",
                                    "Remove punctuation from each word in the text to ensure consistent matching.\n",
                                    "Count the occurrences of each word and update the vector accordingly.\n",
                                    "For instance, given the input text \"Hello, world! Hello.\" and a vocabulary containing \"hello\" and \"world\", the resulting vector should be [2, 1].\n",
                                    "\n",
                                    "This exercise will deepen your understanding of BOW vectors, preparing you for more advanced comparisons with embeddings. Dive in and enjoy the coding experience!\n",
                                    "\n",
                                    "```python\n",
                                    "import numpy as np\n",
                                    "from numpy.linalg import norm\n",
                                    "from sentence_transformers import SentenceTransformer\n",
                                    "\n",
                                    "\n",
                                    "KNOWLEDGE_BASE = [\n",
                                    "    \"Retrieval-Augmented Generation (RAG) enhances language models by integrating relevant external documents into the generation process.\",\n",
                                    "    \"RAG systems retrieve information from large databases to provide contextual answers beyond what is stored in the model.\",\n",
                                    "    \"By merging retrieved text with generative models, RAG overcomes the limitations of static training data.\",\n",
                                    "    \"Media companies combine external data feeds with digital editing tools to optimize broadcast schedules.\",\n",
                                    "    \"Financial institutions analyze market data and use automated report generation to guide investment decisions.\",\n",
                                    "    \"Healthcare analytics platforms integrate patient records with predictive models to generate personalized care plans.\",\n",
                                    "    \"Bananas are popular fruits that are rich in essential nutrients such as potassium and vitamin C.\"\n",
                                    "]\n",
                                    "\n",
                                    "\n",
                                    "def build_vocab(docs):\n",
                                    "    \"\"\"\n",
                                    "    Dynamically build a vocabulary from the given docs.\n",
                                    "    Each new word in the corpus is an entry in the vocabulary.\n",
                                    "    \"\"\"\n",
                                    "    unique_words = set()\n",
                                    "    for doc in docs:\n",
                                    "        for word in doc.lower().split():\n",
                                    "            clean_word = word.strip(\".,!?\")\n",
                                    "            if clean_word:\n",
                                    "                unique_words.add(clean_word)\n",
                                    "    return {word: idx for idx, word in enumerate(sorted(unique_words))}\n",
                                    "\n",
                                    "VOCAB = build_vocab(KNOWLEDGE_BASE)\n",
                                    "\n",
                                    "\n",
                                    "def bow_vectorize(text, vocab=VOCAB):\n",
                                    "    \"\"\"\n",
                                    "    Convert a text into a Bag-of-Words vector, using a shared vocabulary.\n",
                                    "    Each element counts how many times a particular token appears.\n",
                                    "    \"\"\"\n",
                                    "    vector = np.zeros(len(vocab), dtype=int)\n",
                                    "    for word in text.lower().split():\n",
                                    "        # TODO: Remove punctuation from the word to ensure consistent matching\n",
                                    "        clean_word = _______\n",
                                    "        # TODO: If the cleaned word exists in our vocabulary, increment its count in the vector\n",
                                    "        if clean_word in vocab:\n",
                                    "            _______\n",
                                    "    return vector\n",
                                    "\n",
                                    "\n",
                                    "def bow_search(query, docs):\n",
                                    "    \"\"\"\n",
                                    "    Rank documents by lexical overlap (BOW).\n",
                                    "    The dot product between query and doc vectors reflects how many\n",
                                    "    tokens they have in common.\n",
                                    "    \"\"\"\n",
                                    "    query_vec = bow_vectorize(query)\n",
                                    "    scores = []\n",
                                    "    for i, doc in enumerate(docs):\n",
                                    "        doc_vec = bow_vectorize(doc)\n",
                                    "        score = np.dot(query_vec, doc_vec)\n",
                                    "        scores.append((i, score))\n",
                                    "    # Sort documents so that higher lexical overlap is first\n",
                                    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
                                    "    return scores\n",
                                    "\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    query = \"How does a system combine external data with language generation to improve responses?\"\n",
                                    "    print(f\"Query: {query}\")\n",
                                    "\n",
                                    "    # BOW-based search\n",
                                    "    bow_results = bow_search(query, KNOWLEDGE_BASE)\n",
                                    "    print(\"BOW Search Results:\")\n",
                                    "    for idx, score in bow_results:\n",
                                    "        print(f\"  Doc {idx} | Score: {score} | Text: {KNOWLEDGE_BASE[idx]}\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "To complete the `bow_vectorize` function, you'll need to implement the following:\n",
                                    "\n",
                                    "1. **Remove Punctuation**: We need to ensure that punctuation is removed so that the words are consistently matched (e.g., \"hello\" and \"hello,\" should be considered the same).\n",
                                    "2. **Count Word Occurrences**: For each word in the `text`, we'll count its occurrences based on the provided vocabulary.\n",
                                    "\n",
                                    "Here's how you can modify the `bow_vectorize` function:\n",
                                    "\n",
                                    "1. **Remove punctuation**: You can use Python's `str.strip()` to remove punctuation or regular expressions to clean the words.\n",
                                    "2. **Count occurrences**: For each cleaned word, check if it exists in the vocabulary, and if so, increment the corresponding entry in the vector.\n",
                                    "\n",
                                    "### Completed Code:\n",
                                    "\n",
                                    "```python\n",
                                    "import numpy as np\n",
                                    "import string\n",
                                    "\n",
                                    "def bow_vectorize(text, vocab=VOCAB):\n",
                                    "    \"\"\"\n",
                                    "    Convert a text into a Bag-of-Words vector, using a shared vocabulary.\n",
                                    "    Each element counts how many times a particular token appears.\n",
                                    "    \"\"\"\n",
                                    "    # Initialize the vector with zeros\n",
                                    "    vector = np.zeros(len(vocab), dtype=int)\n",
                                    "    \n",
                                    "    # Remove punctuation and convert text to lowercase\n",
                                    "    for word in text.lower().split():\n",
                                    "        # Remove punctuation using str.translate and string.punctuation\n",
                                    "        clean_word = word.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
                                    "        \n",
                                    "        # If the cleaned word exists in the vocabulary, increment its count in the vector\n",
                                    "        if clean_word in vocab:\n",
                                    "            vector[vocab[clean_word]] += 1\n",
                                    "    \n",
                                    "    return vector\n",
                                    "```\n",
                                    "\n",
                                    "### Explanation:\n",
                                    "1. **`str.translate(str.maketrans(\"\", \"\", string.punctuation))`**: This removes all punctuation from the word using the `string.punctuation` constant.\n",
                                    "2. **Count word occurrences**: For each cleaned word, we check if it exists in the vocabulary. If it does, we increment its corresponding index in the vector.\n",
                                    "\n",
                                    "### Example:\n",
                                    "\n",
                                    "For the input `\"Hello, world! Hello.\"` and a vocabulary of `{\"hello\": 0, \"world\": 1}`, the resulting vector would be `[2, 1]`.\n",
                                    "\n",
                                    "### Next Steps:\n",
                                    "\n",
                                    "1. **Test the function**: You can run the `bow_vectorize` function with sample text to see how it converts the text into a vector based on the vocabulary.\n",
                                    "2. **Implement in search**: The `bow_search` function will now be able to rank documents based on their lexical overlap using the BOW vector.\n",
                                    "\n",
                                    "Let me know if you need further assistance with testing or additional functionality!"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Enhance Bag-of-Words with Bigrams\n",
                                    "\n",
                                    "You've done a great job understanding the basics of Bag-of-Words and embeddings. Now, let's enhance the Bag-of-Words approach by incorporating bigrams into the bow_vectorize function.\n",
                                    "\n",
                                    "Bigrams are a type of N-grams, which are contiguous sequences of n items from a given text. In the case of bigrams, n is 2, meaning each bigram consists of two consecutive words; for example, in the sentence \"RAG systems retrieve information\" the bigrams are \"RAG systems\", \"systems retrieve\", and \"retrieve information\".\n",
                                    "\n",
                                    "Your tasks are to:\n",
                                    "\n",
                                    "Modify build_vocab to include bigrams. This means that for each document, you should extract both individual words and pairs of consecutive words (bigrams) to add to the vocabulary.\n",
                                    "Update bow_vectorize to count bigrams. When vectorizing a text, ensure that both unigrams (single words) and bigrams are counted and represented in the vector.\n",
                                    "Integrate these changes into the bow_search function. This will allow the search to consider both individual words and word pairs, potentially improving the relevance of document rankings.\n",
                                    "By incorporating bigrams, you'll be able to capture more context from the text, which can lead to more accurate search results. Dive in and explore the impact of bigrams on search results!\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "import numpy as np\n",
                                    "from numpy.linalg import norm\n",
                                    "from sentence_transformers import SentenceTransformer\n",
                                    "\n",
                                    "KNOWLEDGE_BASE = [\n",
                                    "    \"Retrieval-Augmented Generation (RAG) enhances language models by integrating relevant external documents into the generation process.\",\n",
                                    "    \"RAG systems retrieve information from large databases to provide contextual answers beyond what is stored in the model.\",\n",
                                    "    \"By merging retrieved text with generative models, RAG overcomes the limitations of static training data.\",\n",
                                    "    \"Media companies combine external data feeds with digital editing tools to optimize broadcast schedules.\",\n",
                                    "    \"Financial institutions analyze market data and use automated report generation to guide investment decisions.\",\n",
                                    "    \"Healthcare analytics platforms integrate patient records with predictive models to generate personalized care plans.\",\n",
                                    "    \"Bananas are popular fruits that are rich in essential nutrients such as potassium and vitamin C.\"\n",
                                    "]\n",
                                    "\n",
                                    "\n",
                                    "def build_vocab(docs):\n",
                                    "    \"\"\"\n",
                                    "    Dynamically build a vocabulary from the given docs.\n",
                                    "    Each new word or bigram in the corpus is an entry in the vocabulary.\n",
                                    "    \"\"\"\n",
                                    "    unique_tokens = set()\n",
                                    "    for doc in docs:\n",
                                    "        words = [word.strip(\".,!?\") for word in doc.lower().split()]\n",
                                    "        for i in range(len(words)):\n",
                                    "            if words[i]:\n",
                                    "                unique_tokens.add(words[i])\n",
                                    "            # TODO: Add bigrams to the vocabulary\n",
                                    "    return {token: idx for idx, token in enumerate(sorted(unique_tokens))}\n",
                                    "\n",
                                    "\n",
                                    "VOCAB = build_vocab(KNOWLEDGE_BASE)\n",
                                    "\n",
                                    "\n",
                                    "def bow_vectorize(text, vocab=VOCAB):\n",
                                    "    \"\"\"\n",
                                    "    Convert a text into a Bag-of-Words vector, using a shared vocabulary.\n",
                                    "    Each element counts how many times a particular token or bigram appears.\n",
                                    "    \"\"\"\n",
                                    "    vector = np.zeros(len(vocab), dtype=int)\n",
                                    "    words = [word.strip(\".,!?\") for word in text.lower().split()]\n",
                                    "    for i in range(len(words)):\n",
                                    "        if words[i] in vocab:\n",
                                    "            vector[vocab[words[i]]] += 1\n",
                                    "        # TODO: Count bigrams in the vector\n",
                                    "    return vector\n",
                                    "\n",
                                    "\n",
                                    "def bow_search(query, docs):\n",
                                    "    \"\"\"\n",
                                    "    Rank documents by lexical overlap (BOW) using unigrams and bigrams.\n",
                                    "    The dot product between query and doc vectors reflects how many\n",
                                    "    tokens they have in common.\n",
                                    "    \"\"\"\n",
                                    "    query_vec = bow_vectorize(query)\n",
                                    "    scores = []\n",
                                    "    for i, doc in enumerate(docs):\n",
                                    "        doc_vec = bow_vectorize(doc)\n",
                                    "        score = np.dot(query_vec, doc_vec)\n",
                                    "        scores.append((i, score))\n",
                                    "    # Sort documents so that higher lexical overlap is first\n",
                                    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
                                    "    return scores\n",
                                    "\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    query = \"How does a system combine external data with language generation to improve responses?\"\n",
                                    "    print(f\"Query: {query}\")\n",
                                    "    \n",
                                    "    print(f\"Vocabulary: {VOCAB}\")\n",
                                    "\n",
                                    "    # BOW-based search\n",
                                    "    bow_results = bow_search(query, KNOWLEDGE_BASE)\n",
                                    "    print(\"BOW Search Results:\")\n",
                                    "    for idx, score in bow_results:\n",
                                    "        print(f\"  Doc {idx} | Score: {score} | Text: {KNOWLEDGE_BASE[idx]}\")\n",
                                    "\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "To incorporate bigrams into the Bag-of-Words (BOW) model, we need to:\n",
                                    "\n",
                                    "1. **Modify `build_vocab` to include bigrams**: This involves extracting both unigrams (single words) and bigrams (pairs of consecutive words) from each document.\n",
                                    "2. **Update `bow_vectorize` to count bigrams**: In addition to counting unigrams, we'll also count the occurrences of bigrams.\n",
                                    "3. **Modify the `bow_search` function**: Ensure that the search process accounts for both unigrams and bigrams.\n",
                                    "\n",
                                    "Here is the updated version of the code with bigram support:\n",
                                    "\n",
                                    "### Updated Code:\n",
                                    "\n",
                                    "```python\n",
                                    "import numpy as np\n",
                                    "\n",
                                    "KNOWLEDGE_BASE = [\n",
                                    "    \"Retrieval-Augmented Generation (RAG) enhances language models by integrating relevant external documents into the generation process.\",\n",
                                    "    \"RAG systems retrieve information from large databases to provide contextual answers beyond what is stored in the model.\",\n",
                                    "    \"By merging retrieved text with generative models, RAG overcomes the limitations of static training data.\",\n",
                                    "    \"Media companies combine external data feeds with digital editing tools to optimize broadcast schedules.\",\n",
                                    "    \"Financial institutions analyze market data and use automated report generation to guide investment decisions.\",\n",
                                    "    \"Healthcare analytics platforms integrate patient records with predictive models to generate personalized care plans.\",\n",
                                    "    \"Bananas are popular fruits that are rich in essential nutrients such as potassium and vitamin C.\"\n",
                                    "]\n",
                                    "\n",
                                    "def build_vocab(docs):\n",
                                    "    \"\"\"\n",
                                    "    Dynamically build a vocabulary from the given docs.\n",
                                    "    Each new word or bigram in the corpus is an entry in the vocabulary.\n",
                                    "    \"\"\"\n",
                                    "    unique_tokens = set()\n",
                                    "    for doc in docs:\n",
                                    "        words = [word.strip(\".,!?\") for word in doc.lower().split()]\n",
                                    "        for i in range(len(words)):\n",
                                    "            # Add individual word to vocabulary\n",
                                    "            if words[i]:\n",
                                    "                unique_tokens.add(words[i])\n",
                                    "            # Add bigrams (pair of consecutive words)\n",
                                    "            if i < len(words) - 1:\n",
                                    "                bigram = f\"{words[i]} {words[i+1]}\"\n",
                                    "                unique_tokens.add(bigram)\n",
                                    "    return {token: idx for idx, token in enumerate(sorted(unique_tokens))}\n",
                                    "\n",
                                    "\n",
                                    "VOCAB = build_vocab(KNOWLEDGE_BASE)\n",
                                    "\n",
                                    "\n",
                                    "def bow_vectorize(text, vocab=VOCAB):\n",
                                    "    \"\"\"\n",
                                    "    Convert a text into a Bag-of-Words vector, using a shared vocabulary.\n",
                                    "    Each element counts how many times a particular token or bigram appears.\n",
                                    "    \"\"\"\n",
                                    "    vector = np.zeros(len(vocab), dtype=int)\n",
                                    "    words = [word.strip(\".,!?\") for word in text.lower().split()]\n",
                                    "    \n",
                                    "    for i in range(len(words)):\n",
                                    "        # Count unigrams\n",
                                    "        if words[i] in vocab:\n",
                                    "            vector[vocab[words[i]]] += 1\n",
                                    "        # Count bigrams\n",
                                    "        if i < len(words) - 1:\n",
                                    "            bigram = f\"{words[i]} {words[i+1]}\"\n",
                                    "            if bigram in vocab:\n",
                                    "                vector[vocab[bigram]] += 1\n",
                                    "    return vector\n",
                                    "\n",
                                    "\n",
                                    "def bow_search(query, docs):\n",
                                    "    \"\"\"\n",
                                    "    Rank documents by lexical overlap (BOW) using unigrams and bigrams.\n",
                                    "    The dot product between query and doc vectors reflects how many\n",
                                    "    tokens they have in common.\n",
                                    "    \"\"\"\n",
                                    "    query_vec = bow_vectorize(query)\n",
                                    "    scores = []\n",
                                    "    for i, doc in enumerate(docs):\n",
                                    "        doc_vec = bow_vectorize(doc)\n",
                                    "        score = np.dot(query_vec, doc_vec)\n",
                                    "        scores.append((i, score))\n",
                                    "    # Sort documents so that higher lexical overlap is first\n",
                                    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
                                    "    return scores\n",
                                    "\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    query = \"How does a system combine external data with language generation to improve responses?\"\n",
                                    "    print(f\"Query: {query}\")\n",
                                    "    \n",
                                    "    print(f\"Vocabulary: {VOCAB}\")\n",
                                    "\n",
                                    "    # BOW-based search\n",
                                    "    bow_results = bow_search(query, KNOWLEDGE_BASE)\n",
                                    "    print(\"BOW Search Results:\")\n",
                                    "    for idx, score in bow_results:\n",
                                    "        print(f\"  Doc {idx} | Score: {score} | Text: {KNOWLEDGE_BASE[idx]}\")\n",
                                    "```\n",
                                    "\n",
                                    "### Key Changes:\n",
                                    "\n",
                                    "1. **`build_vocab`**: \n",
                                    "   - Now extracts both unigrams (individual words) and bigrams (pairs of consecutive words).\n",
                                    "   - Adds bigrams to the vocabulary, e.g., for the sentence `\"RAG systems retrieve information\"`, it adds the bigrams `\"RAG systems\"`, `\"systems retrieve\"`, and `\"retrieve information\"`.\n",
                                    "\n",
                                    "2. **`bow_vectorize`**:\n",
                                    "   - It now counts both unigrams and bigrams when processing the text.\n",
                                    "   - For each consecutive pair of words, it creates a bigram and updates the vector if the bigram exists in the vocabulary.\n",
                                    "\n",
                                    "3. **`bow_search`**:\n",
                                    "   - This function uses the `bow_vectorize` function to rank documents by their overlap with the query, considering both unigrams and bigrams.\n",
                                    "\n",
                                    "### Example of Impact:\n",
                                    "\n",
                                    "For the query `\"How does a system combine external data with language generation to improve responses?\"`, the search will now consider both the individual words and the two-word combinations (bigrams) when ranking the documents. This should lead to a more contextually relevant ranking of documents, as bigrams capture relationships between consecutive words that unigrams alone might miss.\n",
                                    "\n",
                                    "### Next Steps:\n",
                                    "\n",
                                    "1. **Test the system**: Run the script and analyze how incorporating bigrams affects the document ranking. You should see improved relevance in the results.\n",
                                    "2. **Further Optimizations**: You can experiment with trigrams or higher-order N-grams if needed to capture even more context.\n",
                                    "\n",
                                    "Let me know if you'd like to dive deeper into any part of this or have further questions!"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Bag of Words Search Task\n",
                                    "\n",
                                    "You've just explored how BOW and embeddings differ in search scenarios. Now, let's put that knowledge into practice by completing the bow_search function.\n",
                                    "\n",
                                    "Your tasks are to:\n",
                                    "\n",
                                    "Transform the query and documents into BOW vectors using bow_vectorize.\n",
                                    "Compute the dot product to measure overlap for each document.\n",
                                    "Return a list of document indices sorted by their lexical similarity scores in descending order.\n",
                                    "This exercise will help you see how document rankings change with different query inputs. Dive in and witness the impact of your work!\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "import numpy as np\n",
                                    "from numpy.linalg import norm\n",
                                    "from sentence_transformers import SentenceTransformer\n",
                                    "\n",
                                    "\n",
                                    "KNOWLEDGE_BASE = [\n",
                                    "    \"Retrieval-Augmented Generation (RAG) enhances language models by integrating relevant external documents into the generation process.\",\n",
                                    "    \"RAG systems retrieve information from large databases to provide contextual answers beyond what is stored in the model.\",\n",
                                    "    \"By merging retrieved text with generative models, RAG overcomes the limitations of static training data.\",\n",
                                    "    \"Media companies combine external data feeds with digital editing tools to optimize broadcast schedules.\",\n",
                                    "    \"Financial institutions analyze market data and use automated report generation to guide investment decisions.\",\n",
                                    "    \"Healthcare analytics platforms integrate patient records with predictive models to generate personalized care plans.\",\n",
                                    "    \"Bananas are popular fruits that are rich in essential nutrients such as potassium and vitamin C.\"\n",
                                    "]\n",
                                    "\n",
                                    "\n",
                                    "def build_vocab(docs):\n",
                                    "    \"\"\"\n",
                                    "    Dynamically build a vocabulary from the given docs.\n",
                                    "    Each new word in the corpus is an entry in the vocabulary.\n",
                                    "    \"\"\"\n",
                                    "    unique_words = set()\n",
                                    "    for doc in docs:\n",
                                    "        for word in doc.lower().split():\n",
                                    "            clean_word = word.strip(\".,!?\")\n",
                                    "            if clean_word:\n",
                                    "                unique_words.add(clean_word)\n",
                                    "    return {word: idx for idx, word in enumerate(sorted(unique_words))}\n",
                                    "\n",
                                    "VOCAB = build_vocab(KNOWLEDGE_BASE)\n",
                                    "\n",
                                    "\n",
                                    "def bow_vectorize(text, vocab=VOCAB):\n",
                                    "    \"\"\"\n",
                                    "    Convert a text into a Bag-of-Words vector, using a shared vocabulary.\n",
                                    "    Each element counts how many times a particular token appears.\n",
                                    "    \"\"\"\n",
                                    "    vector = np.zeros(len(vocab), dtype=int)\n",
                                    "    for word in text.lower().split():\n",
                                    "        clean_word = word.strip(\".,!?\")\n",
                                    "        if clean_word in vocab:\n",
                                    "            vector[vocab[clean_word]] += 1\n",
                                    "    return vector\n",
                                    "\n",
                                    "\n",
                                    "def bow_search(query, docs):\n",
                                    "    \"\"\"\n",
                                    "    Rank documents by lexical overlap (BOW).\n",
                                    "    The dot product between query and doc vectors reflects how many\n",
                                    "    tokens they have in common.\n",
                                    "    \"\"\"\n",
                                    "    # TODO: Transform the query into a BOW vector\n",
                                    "\n",
                                    "    # TODO: Transform each document into a BOW vector\n",
                                    "\n",
                                    "    # TODO: Compute the dot product between query and document to measure overlap\n",
                                    "\n",
                                    "    # TODO: Sort documents so that higher lexical overlap is first\n",
                                    "\n",
                                    "    # TODO: Return sorted scores\n",
                                    "    pass\n",
                                    "\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    query = \"How does a system combine external data with language generation to improve responses?\"\n",
                                    "    print(f\"Query: {query}\")\n",
                                    "\n",
                                    "    # BOW-based search\n",
                                    "    bow_results = bow_search(query, KNOWLEDGE_BASE)\n",
                                    "    print(\"BOW Search Results:\")\n",
                                    "    for idx, score in bow_results:\n",
                                    "        print(f\"  Doc {idx} | Score: {score} | Text: {KNOWLEDGE_BASE[idx]}\")\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "\n",
                                    "To complete the `bow_search` function, we need to follow these steps:\n",
                                    "\n",
                                    "1. **Transform the query into a BOW vector**: Use the `bow_vectorize` function to convert the query into a vector based on the vocabulary.\n",
                                    "2. **Transform each document into a BOW vector**: Apply the `bow_vectorize` function to each document in the knowledge base to get their BOW vectors.\n",
                                    "3. **Compute the dot product between the query and each document**: The dot product will indicate how much overlap there is between the query and each document, which is a measure of their similarity.\n",
                                    "4. **Sort documents by lexical similarity**: The documents should be sorted in descending order based on the similarity score.\n",
                                    "5. **Return the sorted scores**: The function will return a list of tuples containing the document index and its similarity score.\n",
                                    "\n",
                                    "Here is the completed `bow_search` function:\n",
                                    "\n",
                                    "### Updated Code:\n",
                                    "\n",
                                    "```python\n",
                                    "import numpy as np\n",
                                    "\n",
                                    "KNOWLEDGE_BASE = [\n",
                                    "    \"Retrieval-Augmented Generation (RAG) enhances language models by integrating relevant external documents into the generation process.\",\n",
                                    "    \"RAG systems retrieve information from large databases to provide contextual answers beyond what is stored in the model.\",\n",
                                    "    \"By merging retrieved text with generative models, RAG overcomes the limitations of static training data.\",\n",
                                    "    \"Media companies combine external data feeds with digital editing tools to optimize broadcast schedules.\",\n",
                                    "    \"Financial institutions analyze market data and use automated report generation to guide investment decisions.\",\n",
                                    "    \"Healthcare analytics platforms integrate patient records with predictive models to generate personalized care plans.\",\n",
                                    "    \"Bananas are popular fruits that are rich in essential nutrients such as potassium and vitamin C.\"\n",
                                    "]\n",
                                    "\n",
                                    "def build_vocab(docs):\n",
                                    "    \"\"\"\n",
                                    "    Dynamically build a vocabulary from the given docs.\n",
                                    "    Each new word in the corpus is an entry in the vocabulary.\n",
                                    "    \"\"\"\n",
                                    "    unique_words = set()\n",
                                    "    for doc in docs:\n",
                                    "        for word in doc.lower().split():\n",
                                    "            clean_word = word.strip(\".,!?\")\n",
                                    "            if clean_word:\n",
                                    "                unique_words.add(clean_word)\n",
                                    "    return {word: idx for idx, word in enumerate(sorted(unique_words))}\n",
                                    "\n",
                                    "VOCAB = build_vocab(KNOWLEDGE_BASE)\n",
                                    "\n",
                                    "\n",
                                    "def bow_vectorize(text, vocab=VOCAB):\n",
                                    "    \"\"\"\n",
                                    "    Convert a text into a Bag-of-Words vector, using a shared vocabulary.\n",
                                    "    Each element counts how many times a particular token appears.\n",
                                    "    \"\"\"\n",
                                    "    vector = np.zeros(len(vocab), dtype=int)\n",
                                    "    for word in text.lower().split():\n",
                                    "        clean_word = word.strip(\".,!?\")\n",
                                    "        if clean_word in vocab:\n",
                                    "            vector[vocab[clean_word]] += 1\n",
                                    "    return vector\n",
                                    "\n",
                                    "\n",
                                    "def bow_search(query, docs):\n",
                                    "    \"\"\"\n",
                                    "    Rank documents by lexical overlap (BOW).\n",
                                    "    The dot product between query and doc vectors reflects how many\n",
                                    "    tokens they have in common.\n",
                                    "    \"\"\"\n",
                                    "    # Transform the query into a BOW vector\n",
                                    "    query_vec = bow_vectorize(query)\n",
                                    "    \n",
                                    "    # Initialize a list to store document similarity scores\n",
                                    "    scores = []\n",
                                    "    \n",
                                    "    # Transform each document into a BOW vector and compute the dot product\n",
                                    "    for i, doc in enumerate(docs):\n",
                                    "        doc_vec = bow_vectorize(doc)\n",
                                    "        score = np.dot(query_vec, doc_vec)  # Dot product for overlap\n",
                                    "        scores.append((i, score))\n",
                                    "    \n",
                                    "    # Sort documents so that higher lexical overlap is first\n",
                                    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
                                    "    \n",
                                    "    return scores\n",
                                    "\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    query = \"How does a system combine external data with language generation to improve responses?\"\n",
                                    "    print(f\"Query: {query}\")\n",
                                    "\n",
                                    "    # BOW-based search\n",
                                    "    bow_results = bow_search(query, KNOWLEDGE_BASE)\n",
                                    "    print(\"BOW Search Results:\")\n",
                                    "    for idx, score in bow_results:\n",
                                    "        print(f\"  Doc {idx} | Score: {score} | Text: {KNOWLEDGE_BASE[idx]}\")\n",
                                    "```\n",
                                    "\n",
                                    "### Explanation of Changes:\n",
                                    "\n",
                                    "1. **Query Vectorization**: \n",
                                    "   - We use `bow_vectorize(query)` to convert the query into a vector based on the vocabulary.\n",
                                    "\n",
                                    "2. **Document Vectorization**:\n",
                                    "   - Each document in the `KNOWLEDGE_BASE` is also transformed into a BOW vector using `bow_vectorize(doc)`.\n",
                                    "\n",
                                    "3. **Dot Product Calculation**:\n",
                                    "   - For each document, the dot product between the query vector and the document vector is computed. The dot product essentially measures the overlap between the two vectors (how many words they share).\n",
                                    "\n",
                                    "4. **Sorting**:\n",
                                    "   - The documents are sorted by their similarity scores in descending order. The higher the score, the more similar the document is to the query.\n",
                                    "\n",
                                    "5. **Return Scores**:\n",
                                    "   - The function returns a sorted list of tuples where each tuple contains the document index and its similarity score.\n",
                                    "\n",
                                    "### Example Output:\n",
                                    "\n",
                                    "When you run the script with the query `\"How does a system combine external data with language generation to improve responses?\"`, the results will show which documents from the `KNOWLEDGE_BASE` are most similar to the query, based on the lexical overlap of their BOW vectors.\n",
                                    "\n",
                                    "Let me know if you'd like further adjustments or explanations!"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "id": "e210822f",
                           "metadata": {},
                           "source": [
                                    "You've just explored how BOW and embeddings differ in search scenarios. Now, let's apply that knowledge by completing the embedding_search function.\n",
                                    "\n",
                                    "Your tasks are to:\n",
                                    "\n",
                                    "Implement the cos_sim function to calculate cosine similarity.\n",
                                    "Encode the query and documents into embeddings.\n",
                                    "Calculate their similarity using the cos_sim function.\n",
                                    "Return a list of document indices ranked by semantic closeness to the query.\n",
                                    "This exercise will help you see how semantic search can enhance document retrieval. Dive in and see the impact of your work!\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "import numpy as np\n",
                                    "from numpy.linalg import norm\n",
                                    "from sentence_transformers import SentenceTransformer\n",
                                    "\n",
                                    "KNOWLEDGE_BASE = [\n",
                                    "    \"Retrieval-Augmented Generation (RAG) enhances language models by integrating relevant external documents into the generation process.\",\n",
                                    "    \"RAG systems retrieve information from large databases to provide contextual answers beyond what is stored in the model.\",\n",
                                    "    \"By merging retrieved text with generative models, RAG overcomes the limitations of static training data.\",\n",
                                    "    \"Media companies combine external data feeds with digital editing tools to optimize broadcast schedules.\",\n",
                                    "    \"Financial institutions analyze market data and use automated report generation to guide investment decisions.\",\n",
                                    "    \"Healthcare analytics platforms integrate patient records with predictive models to generate personalized care plans.\",\n",
                                    "    \"Bananas are popular fruits that are rich in essential nutrients such as potassium and vitamin C.\"\n",
                                    "]\n",
                                    "\n",
                                    "\n",
                                    "def cos_sim(a, b):\n",
                                    "    # TODO: Implement cosine similarity\n",
                                    "    return 0\n",
                                    "\n",
                                    "def embedding_search(query, docs, model):\n",
                                    "    # TODO: Encode the query into an embedding\n",
                                    "    # TODO: Encode the documents into embeddings\n",
                                    "    # TODO: Calculate and store the cosine similarity between query_emb and each document embedding\n",
                                    "    # TODO: Sort the scores in descending order of similarity\n",
                                    "    pass\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    query = \"How does a system combine external data with language generation to improve responses?\"\n",
                                    "    print(f\"Query: {query}\")\n",
                                    "\n",
                                    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
                                    "    emb_results = embedding_search(query, KNOWLEDGE_BASE, model)\n",
                                    "    print(\"\\nEmbedding-based Search Results:\")\n",
                                    "    for idx, score in emb_results:\n",
                                    "        print(f\"  Doc {idx} | Score: {score:.4f} | Text: {KNOWLEDGE_BASE[idx]}\")\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "To complete the `embedding_search` function, we need to:\n",
                                    "\n",
                                    "1. **Implement `cos_sim`**: This function calculates the cosine similarity between two vectors.\n",
                                    "2. **Encode the query and documents into embeddings**: We'll use a pre-trained model from `sentence-transformers` to convert the query and documents into vectors (embeddings).\n",
                                    "3. **Calculate similarity**: For each document, we'll compute the cosine similarity between the query and document embeddings.\n",
                                    "4. **Return ranked results**: We need to sort the documents by their semantic similarity to the query and return the sorted list of indices and scores.\n",
                                    "\n",
                                    "Let's go step by step.\n",
                                    "\n",
                                    "### 1. **Cosine Similarity (cos_sim) Implementation**:\n",
                                    "Cosine similarity is calculated as the dot product of two vectors divided by the product of their magnitudes.\n",
                                    "\n",
                                    "Formula:\n",
                                    "\\[\n",
                                    "\\text{cosine\\_similarity}(a, b) = \\frac{a \\cdot b}{||a|| \\cdot ||b||}\n",
                                    "\\]\n",
                                    "\n",
                                    "### 2. **Embedding the Query and Documents**:\n",
                                    "We'll use `SentenceTransformer` to encode both the query and the documents into embeddings.\n",
                                    "\n",
                                    "### 3. **Ranking by Similarity**:\n",
                                    "After computing the cosine similarity, we will sort the documents by their similarity to the query in descending order.\n",
                                    "\n",
                                    "Here is the implementation of the `embedding_search` function:\n",
                                    "\n",
                                    "### Updated Code:\n",
                                    "\n",
                                    "```python\n",
                                    "import numpy as np\n",
                                    "from numpy.linalg import norm\n",
                                    "from sentence_transformers import SentenceTransformer\n",
                                    "\n",
                                    "KNOWLEDGE_BASE = [\n",
                                    "    \"Retrieval-Augmented Generation (RAG) enhances language models by integrating relevant external documents into the generation process.\",\n",
                                    "    \"RAG systems retrieve information from large databases to provide contextual answers beyond what is stored in the model.\",\n",
                                    "    \"By merging retrieved text with generative models, RAG overcomes the limitations of static training data.\",\n",
                                    "    \"Media companies combine external data feeds with digital editing tools to optimize broadcast schedules.\",\n",
                                    "    \"Financial institutions analyze market data and use automated report generation to guide investment decisions.\",\n",
                                    "    \"Healthcare analytics platforms integrate patient records with predictive models to generate personalized care plans.\",\n",
                                    "    \"Bananas are popular fruits that are rich in essential nutrients such as potassium and vitamin C.\"\n",
                                    "]\n",
                                    "\n",
                                    "def cos_sim(a, b):\n",
                                    "    \"\"\"\n",
                                    "    Compute the cosine similarity between two vectors.\n",
                                    "    \"\"\"\n",
                                    "    return np.dot(a, b) / (norm(a) * norm(b))\n",
                                    "\n",
                                    "def embedding_search(query, docs, model):\n",
                                    "    \"\"\"\n",
                                    "    Rank documents based on semantic similarity with the query using embeddings.\n",
                                    "    \"\"\"\n",
                                    "    # Encode the query into an embedding\n",
                                    "    query_emb = model.encode([query])[0]\n",
                                    "    \n",
                                    "    # Encode all documents into embeddings\n",
                                    "    doc_embs = model.encode(docs)\n",
                                    "    \n",
                                    "    # Calculate cosine similarity between the query embedding and each document embedding\n",
                                    "    scores = []\n",
                                    "    for idx, doc_emb in enumerate(doc_embs):\n",
                                    "        score = cos_sim(query_emb, doc_emb)\n",
                                    "        scores.append((idx, score))\n",
                                    "    \n",
                                    "    # Sort documents based on similarity scores in descending order\n",
                                    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
                                    "    \n",
                                    "    return scores\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    query = \"How does a system combine external data with language generation to improve responses?\"\n",
                                    "    print(f\"Query: {query}\")\n",
                                    "\n",
                                    "    # Initialize the model\n",
                                    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
                                    "\n",
                                    "    # Perform the embedding-based search\n",
                                    "    emb_results = embedding_search(query, KNOWLEDGE_BASE, model)\n",
                                    "\n",
                                    "    # Print the results\n",
                                    "    print(\"\\nEmbedding-based Search Results:\")\n",
                                    "    for idx, score in emb_results:\n",
                                    "        print(f\"  Doc {idx} | Score: {score:.4f} | Text: {KNOWLEDGE_BASE[idx]}\")\n",
                                    "```\n",
                                    "\n",
                                    "### Explanation:\n",
                                    "\n",
                                    "1. **`cos_sim(a, b)`**: \n",
                                    "   - This function calculates the cosine similarity between two vectors `a` and `b` by using the formula mentioned above. The `np.dot(a, b)` computes the dot product, and `norm(a)` and `norm(b)` compute the magnitudes of the vectors.\n",
                                    "   \n",
                                    "2. **`embedding_search(query, docs, model)`**: \n",
                                    "   - The query is encoded into an embedding using `model.encode([query])`. We use `SentenceTransformer` to get a dense vector representation of the query.\n",
                                    "   - Similarly, we encode the documents into embeddings using `model.encode(docs)`.\n",
                                    "   - We then compute the cosine similarity between the query embedding and each document embedding.\n",
                                    "   - The results are sorted by their similarity score in descending order.\n",
                                    "   \n",
                                    "3. **Model**: \n",
                                    "   - We use the `sentence-transformers/all-MiniLM-L6-v2` model for encoding the query and documents into embeddings. This model is efficient and commonly used for semantic similarity tasks.\n",
                                    "\n",
                                    "### Example Output:\n",
                                    "\n",
                                    "For the query `\"How does a system combine external data with language generation to improve responses?\"`, the search results will show the documents in the `KNOWLEDGE_BASE` ranked by their semantic similarity to the query.\n",
                                    "\n",
                                    "Let me know if you need any further adjustments or clarifications!"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
