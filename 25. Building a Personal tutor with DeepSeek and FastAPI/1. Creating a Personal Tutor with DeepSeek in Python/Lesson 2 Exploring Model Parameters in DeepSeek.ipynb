{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Lesson 2 Exploring Model Parameters in DeepSeek\n",
                                    "\n",
                                    "\n",
                                    "**Welcome back!** In the previous lesson, you learned how to send a simple message to DeepSeek’s language model and receive a response. Now, we will take a step further by exploring model parameters that allow you to customize the AI tutor’s responses. These parameters are crucial for tailoring the tutor’s behavior to meet specific educational needs. In this lesson, we will focus on four key parameters:\n",
                                    "\n",
                                    "- `max_tokens`\n",
                                    "- `temperature`\n",
                                    "- `presence_penalty`\n",
                                    "- `frequency_penalty`\n",
                                    "\n",
                                    "Understanding these parameters will enable you to control the creativity, length, and content of the AI’s explanations, enhancing your personal tutor’s effectiveness.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Controlling Response Length with `max_tokens`\n",
                                    "\n",
                                    "The `max_tokens` parameter sets a hard limit on the number of tokens the AI can generate in its response. A “token” can be a whole word or just part of a word. For example:\n",
                                    "\n",
                                    "- `\"tutor\"` might be one token  \n",
                                    "- `\"explanation\"` could be split into multiple tokens  \n",
                                    "\n",
                                    "It’s important to note that token counts vary across different models, words, and languages — so the same text might have a different token count depending on these factors.\n",
                                    "\n",
                                    "When you set `max_tokens`, you specify the maximum number of tokens the AI can produce. This is a strict limit: the model will stop generating text once it reaches this count, even if it results in an incomplete answer.\n",
                                    "\n",
                                    "Here’s an example where we set `max_tokens` to 150:\n",
                                    "\n",
                                    "```python\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=150\n",
                                    ")\n",
                                    "````\n",
                                    "\n",
                                    "By setting `max_tokens` to 150, you impose a hard limit on the number of tokens the AI tutor can generate in its explanation. Note that this parameter doesn’t make the model inherently more concise—it simply restricts explanation length. It’s primarily valuable for managing usage rates and controlling the cost of API requests when building your personal tutor.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Exploring `temperature`\n",
                                    "\n",
                                    "The `temperature` parameter controls the randomness or creativity of the AI’s responses:\n",
                                    "\n",
                                    "* **Low temperature** (e.g., `0.2`) → More deterministic, focused, and predictable\n",
                                    "* **High temperature** (e.g., `0.8`) → More diverse, creative, and varied responses\n",
                                    "\n",
                                    "Example with `temperature = 0.6`:\n",
                                    "\n",
                                    "```python\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    temperature=0.6\n",
                                    ")\n",
                                    "```\n",
                                    "\n",
                                    "A temperature of 0.6 strikes a balance between creativity and factual accuracy. Experiment with different values to find the right balance for your tutoring scenarios:\n",
                                    "\n",
                                    "* **Precision-critical tasks** (math, science) → Lower temperature\n",
                                    "* **Creative tasks** (writing, brainstorming) → Higher temperature\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Encouraging New Topics with `presence_penalty`\n",
                                    "\n",
                                    "The `presence_penalty` parameter encourages the AI to introduce new concepts by penalizing the reuse of words that have already appeared in the conversation:\n",
                                    "\n",
                                    "* **Low** (e.g., `0.0`) → Less discouraged from repeating words\n",
                                    "* **High** (e.g., `1.0`) → Strongly encouraged to explore new topics\n",
                                    "\n",
                                    "Example with `presence_penalty = 0.5`:\n",
                                    "\n",
                                    "```python\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    presence_penalty=0.5\n",
                                    ")\n",
                                    "```\n",
                                    "\n",
                                    "With a presence penalty of 0.5, the AI is more likely to introduce fresh concepts and varied explanations—ideal when you want students to see a broader range of ideas.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Reducing Repetition with `frequency_penalty`\n",
                                    "\n",
                                    "The `frequency_penalty` parameter helps reduce repetition by penalizing the model for using the same words or phrases multiple times:\n",
                                    "\n",
                                    "* **Low** (e.g., `0.0`) → Allows more repetition (reinforces key concepts)\n",
                                    "* **High** (e.g., `1.0`) → Reduces repetition (promotes variety)\n",
                                    "\n",
                                    "While both penalties address repetition, they differ:\n",
                                    "\n",
                                    "* **Presence penalty** → Discourages repeating words across the conversation\n",
                                    "* **Frequency penalty** → Discourages repeating words within a single response\n",
                                    "\n",
                                    "Example with `frequency_penalty = 0.2`:\n",
                                    "\n",
                                    "```python\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    frequency_penalty=0.2\n",
                                    ")\n",
                                    "```\n",
                                    "\n",
                                    "A frequency penalty of 0.2 reduces redundancy while still allowing some repetition for emphasis, resulting in more engaging content.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Example: Implementing All Parameters in Code\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the DeepSeek client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a query\n",
                                    "prompt = \"Tell me a fun fact about space.\"\n",
                                    "\n",
                                    "# Get response with specific parameters to adjust explanation depth and style\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=150,        # Limits explanation length\n",
                                    "    temperature=0.6,       # Controls explanation creativity\n",
                                    "    presence_penalty=0.5,  # Encourages new concepts\n",
                                    "    frequency_penalty=0.2, # Reduces repetitive details\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Answer:\", reply)\n",
                                    "```\n",
                                    "\n",
                                    "This example shows how to combine all four parameters to fine-tune the AI tutor’s behavior. Run this code to see how creativity, length, and content diversity are balanced according to your settings.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Summary and Preparation for Practice\n",
                                    "\n",
                                    "In this lesson, you’ve learned how to use key model parameters to customize AI tutor responses:\n",
                                    "\n",
                                    "1. **`max_tokens`**: Controls response length\n",
                                    "2. **`temperature`**: Adjusts creativity\n",
                                    "3. **`presence_penalty`**: Promotes new topic introduction\n",
                                    "4. **`frequency_penalty`**: Prevents excessive repetition\n",
                                    "\n",
                                    "As you move on to the practice exercises, experiment with different parameter combinations to observe their effects firsthand. This hands-on practice will reinforce your understanding and prepare you for the next unit, where we’ll delve deeper into managing tutoring sessions and message types.\n",
                                    "\n",
                                    "**Keep up the great work, and enjoy building your personal tutor with DeepSeek!**\n",
                                    "\n",
                                    "```\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Exploring Default AI Behavior with Basic Parameters\n",
                                    "\n",
                                    "Nice progress in understanding how to interact with the AI model! Now, let's see the default behavior of the AI without any additional parameters.\n",
                                    "\n",
                                    "Run the given code as it is, without making any changes to the parameters. This will give you a baseline for comparison when you start adding more parameters.\n",
                                    "\n",
                                    "Enjoy the process and see what the AI comes up with!\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# Get response with only model and messages parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "It looks like you’ve provided a minimal example that calls the DeepSeek model without any extra parameters, relying entirely on the API’s defaults. How can I help you with this snippet? For example, would you like me to:\n",
                                    "\n",
                                    "* Explain what default parameter values (e.g. `max_tokens`, `temperature`) the API will use when none are provided?\n",
                                    "* Illustrate how the output might look (with a sample “sunset over the ocean” response)?\n",
                                    "* Show you how to modify this snippet to include custom parameters (like we did in the previous lesson)?\n",
                                    "\n",
                                    "Let me know what you’d like to focus on!\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Controlling Response Length with max_tokens Parameter\n",
                                    "\n",
                                    "Now, let's focus on controlling the length of the AI's response. Your task is to add the max_tokens parameter to the code. This will help you ensure that the AI's responses are concise and within a desired length.\n",
                                    "\n",
                                    "Here's what you need to do:\n",
                                    "\n",
                                    "Add the max_tokens parameter to limit the response length.\n",
                                    "Set it to a value like 100 to see how it affects the output.\n",
                                    "This exercise will give you a clear view of how to manage response length effectively. Dive in and see the impact!\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    # TODO: Add the max_tokens parameter and set it to 100 to limit response length\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=100  # Limits the response to at most 100 tokens\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "```\n",
                                    "\n",
                                    "With `max_tokens=100`, the model will stop generating once it reaches that token limit, ensuring your output stays concise.\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Adding Temperature Parameter to Control AI Creativity\n",
                                    "\n",
                                    "Nice work on understanding model parameters! Now, let's put that knowledge into practice by adding a key parameter to the code. Your task is to:\n",
                                    "\n",
                                    "Add the temperature parameter to control the AI's creativity.\n",
                                    "Set it to a low value for more focused responses, such as 0.2.\n",
                                    "This exercise will help you see how small changes can influence the AI's behavior. Dive in and see the impact firsthand!\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=100,\n",
                                    "    # TODO: Add the temperature parameter and set it to a low value\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=100,       # Limits the response to at most 100 tokens\n",
                                    "    temperature=0.2       # Lower randomness for a more focused, deterministic answer\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "```\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Exploring High Temperature Settings for AI Responses\n",
                                    "\n",
                                    "Well done on exploring model parameters! Now, let's see how the setting the temperature too high affects AI responses.\n",
                                    "\n",
                                    "Your task is to change the temperature from 0.2 to a much higher value, such as 1.7.\n",
                                    "\n",
                                    "Observe how this impacts the AI's creativity and randomness. Note that a super high temperature can make the response unpredictable and potentially out of control, leading to outputs that may lack coherence or relevance.\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=100,\n",
                                    "    temperature=0.2  # TODO: Set the temperature to 1.7\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=100,\n",
                                    "    temperature=1.7  # Much higher randomness for very creative/unpredictable responses\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "```\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Implementing Presence Penalty to Encourage Topic Diversity\n",
                                    "\n",
                                    "Cosmo\n",
                                    "Just now\n",
                                    "Read message aloud\n",
                                    "Great job on mastering the basics of model parameters! Now, let's apply what you've learned by adding the presence_penalty parameter to the code.\n",
                                    "\n",
                                    "The presence_penalty parameter works by penalizing the AI for using words that have already appeared in the conversation, thus promoting diversity in the dialogue. A low value (e.g., 0.0) means less penalty, allowing the AI to repeat topics more freely, while a high value (e.g., 1.0) strongly encourages the AI to introduce new topics by avoiding repetition.\n",
                                    "\n",
                                    "Your task is to add the presence_penalty parameter with a value of 0.8 to encourage new topics in the AI's responses. This exercise will help you understand how to make conversations more dynamic. Jump in and see the difference it makes!\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# TODO: Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=100,\n",
                                    "    # TODO: Add presence_penalty parameter to encourage new topics\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=100,\n",
                                    "    presence_penalty=0.8  # Encourages the AI to introduce new topics by penalizing repetition\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "```\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Reducing Repetition with Frequency Penalty Parameter\n",
                                    "\n",
                                    "You've done well in understanding how to control AI responses! Now, let's focus on customizing the AI's output by using the frequency_penalty parameter to minimize repetition.\n",
                                    "\n",
                                    "The frequency_penalty parameter helps reduce repetition in the AI's responses by penalizing the AI for using the same words or phrases multiple times within its response. A low value (e.g., 0.0) allows for more repetition, while a high value (e.g., 1.0) discourages it. In this task, setting it to 0.9 will strongly reduce repetition, encouraging more varied and dynamic responses.\n",
                                    "\n",
                                    "Your task is to add the frequency_penalty parameter with a value of 0.9 to the code. This will result in responses that avoid repeating words, making the conversation more engaging and diverse.\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# TODO: Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=100,\n",
                                    "    # TODO: Add a very high frequency penalty to minimize repetition\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Berikut adalah versi yang telah diperbarui dari kode Anda, dengan penambahan parameter `frequency_penalty` bernilai `0.9` untuk meminimalkan pengulangan:\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# Get response with specific parameters, including high frequency penalty\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=100,\n",
                                    "    frequency_penalty=0.9  # ✅ Strongly reduces repetition\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "```\n",
                                    "\n",
                                    "📌 **Penjelasan Singkat:**\n",
                                    "\n",
                                    "* `frequency_penalty=0.9` membuat model **menghindari penggunaan kata yang sama secara berulang**, menghasilkan output yang lebih beragam dan ekspresif.\n",
                                    "\n",
                                    "Jika Anda ingin hasil yang lebih kreatif lagi, Anda juga bisa mengkombinasikan dengan `temperature` yang lebih tinggi (misalnya `temperature=0.8`). Ingin saya bantu menambahkan juga?\n"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
