{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Unit 3 Customizing TF-IDF Vectorization Parameters in NLP\n",
                                    "\n",
                                    "# Introduction\n",
                                    "Hello and glad to have you back in our exciting journey on **Natural Language Processing**! This lesson is geared towards enriching your understanding of the **Term Frequency-Inverse Document Frequency Vectorizer**, popularly known as the **TF-IDF Vectorizer**. In particular, we'll focus on customizing two key parameters of the `TfidfVectorizer` function: `ngram_range` and `max_features`. Tinkering with these parameters can help us refine our feature matrix, paving the way for more refined machine learning models. Ready? Let’s dive in!\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## The Power of TF-IDF Parameter Customization\n",
                                    "\n",
                                    "During text preprocessing, your decision on the parameters of `TfidfVectorizer` can significantly impact your **Natural Language Processing** (NLP) pipelines. In this lesson, our primary focus will be on two key parameters: **ngram_range** and **max_features**.\n",
                                    "\n",
                                    "Customizing these parameters offers two main advantages. First, it enables us to control the complexity of our machine learning models. By tuning these parameters, we can manage our computational resources more efficiently and prevent our models from overfitting or underfitting. Second, it allows us to extract more informative features from our text data, potentially enhancing the performance of our models.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## N-gram Range\n",
                                    "\n",
                                    "In **NLP**, an **n-gram** is a contiguous sequence of *n* items from a given text or speech. The item could be a character, syllable, word, and so on. For example, an n-gram of size 1 is referred to as a \"**unigram**\"; size 2 is a \"**bigram**\" (or, less commonly, a \"digram\"); size 3 is a \"**trigram**.\" The concept of n-grams is broadly utilized across various NLP applications, including language modeling, information retrieval, and text prediction, where capturing the statistical properties of text becomes crucial for the underlying model's performance.\n",
                                    "\n",
                                    "But how does the concept of n-grams apply to our **TF-IDF vectorization**? The application becomes evident through the use of the `ngram_range` parameter. This parameter, defined as a tuple `(min_n, max_n)`, specifies the minimum and maximum size of n-grams to be included in the vectorization process. `min_n` and `max_n` determine the lower and upper boundary of the n-gram sizes, allowing the extraction of n-grams within this range. For instance, setting `ngram_range` to `(1, 3)` means that the vectorizer will extract unigrams, bigrams, and trigrams, thus incorporating a broader context into the feature set used for machine learning models.\n",
                                    "\n",
                                    "Choosing the right n-gram range can significantly impact your **NLP** tasks. For instance, while unigrams may not capture the context effectively (e.g., \"not good\" versus \"good\"), bigrams, trigrams, or even higher-level n-grams may capture more contextual information. However, using a larger n-gram range can also lead to higher dimensionality and thus increased computational cost. It’s a trade-off that needs thoughtful consideration.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Limiting Vocabulary Size with Max Features\n",
                                    "\n",
                                    "The **max_features** parameter in `TfidfVectorizer` caps the number of top features considered in the vocabulary based on term frequency. Opting for a `max_features` limit is beneficial not just for conserving memory and reducing processing time, but also for enhancing model accuracy. By focusing on the top terms, you may filter out noise—less informative features that could potentially lead to overfitting. This approach forces the model to concentrate on the most impactful words only.\n",
                                    "\n",
                                    "Selecting the right `max_features` count is crucial. A heuristic method involves analyzing word frequencies within your corpus. For example, setting a threshold where only words appearing more than a specified number of times are included can help in fine-tuning this parameter. If a corpus of 100 words reveals that 20 occur less than 50 times, setting `max_features` to 80 might optimize performance without significant information loss.\n",
                                    "\n",
                                    "However, the challenge lies in selecting the optimal value for `max_features`. Too low a value may exclude meaningful terms, losing critical information, while too high a value could diminish the effectiveness of dimensionality reduction. The key is finding the right balance, which varies depending on the dataset's size and the diversity of the content, as well as the goals of the NLP task at hand.\n",
                                    "\n",
                                    "Ultimately, determining the optimal `max_features` value is an iterative process. It might involve experimenting with different thresholds and observing how they impact model performance across various datasets. This strategic limitation of vocabulary size aids in maintaining a lean, efficient NLP pipeline that is both resourceful and insightful.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Implementing & Understanding Custom TF-IDF Parameters\n",
                                    "\n",
                                    "Now let's go back to our code example. You can see that we imported the necessary libraries and loaded our dataset, similarly to what we did in the previous lesson. The main focus here is the line of code where we set our custom parameters for the `TfidfVectorizer`.\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                                    "from datasets import load_dataset\n",
                                    "\n",
                                    "# Load the SMS Spam Collection dataset\n",
                                    "sms_spam = load_dataset('codesignal/sms-spam-collection')\n",
                                    "\n",
                                    "# Convert to pandas DataFrame for convenient handling\n",
                                    "df = pd.DataFrame(sms_spam['train'])\n",
                                    "\n",
                                    "# Use TF-IDF with custom parameters like n-gram range and max feature\n",
                                    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=1000)\n",
                                    "```\n",
                                    "\n",
                                    "In this line, we're setting the `ngram_range` to `(1, 2)`. This implies that our vectorizer will consider both **unigrams** and **bigrams**. Next, the `max_features` parameter is set to 1000; hence only the top 1000 most frequently occurring words will be included in the feature set.\n",
                                    "\n",
                                    "With these parameter settings, we then fit our `TfidfVectorizer` to our dataset and print out the shape of our feature matrix. The output of this line gives us a quick grasp of the dimensionality of our data after **TF-IDF vectorization**.\n",
                                    "\n",
                                    "```python\n",
                                    "# Fit Vectorizer\n",
                                    "X_tfidf = vectorizer.fit_transform(df['message'])\n",
                                    "\n",
                                    "# Print shape of feature matrix\n",
                                    "print(X_tfidf.shape)\n",
                                    "```\n",
                                    "\n",
                                    "The output of the above code will be:\n",
                                    "\n",
                                    "```\n",
                                    "(5572, 1000)\n",
                                    "```\n",
                                    "\n",
                                    "This output indicates that the feature matrix has 5572 samples, and each sample is represented in a space of the top 1000 features extracted through **TF-IDF vectorization**. This illustrates how the `ngram_range` and `max_features` parameters directly influence the structure and dimensionality of the resulting vectorized data.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Lesson Summary\n",
                                    "\n",
                                    "Well done! We've enriched our understanding of **TF-IDF vectorization** by exploring how to customize n-grams and maximum features. Navigating the trade-offs involved in parameter adjustment is a critical skill in **NLP**, and now you're equipped with the knowledge to do just that. To cement your understanding, the upcoming practice exercises will challenge you to fine-tune **TF-IDF parameters**, which will further develop your skills. Keep practicing, and happy coding!"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Customized TF-IDF Vectorization Parameters\n",
                                    "\n",
                                    "In this task, we'll observe the use of ngram_range as (1, 2) and max_features as 1000 in our TF-IDF vectorization on the SMS Spam Collection dataset to refine the feature matrix. Explore the impact on the feature matrix's structure by executing the provided code. No code modifications are required; simply press Run to see the results.\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                                    "from datasets import load_dataset\n",
                                    "\n",
                                    "# Load the SMS Spam Collection dataset\n",
                                    "sms_spam = load_dataset('codesignal/sms-spam-collection')\n",
                                    "\n",
                                    "# Convert to pandas DataFrame for convenient handling\n",
                                    "df = pd.DataFrame(sms_spam['train'])\n",
                                    "\n",
                                    "# Using TF-IDF with custom parameters like n-gram range and max features\n",
                                    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=1000)\n",
                                    "X_tfidf = vectorizer.fit_transform(df['message'])\n",
                                    "\n",
                                    "print(X_tfidf.shape)\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                                    "from datasets import load_dataset\n",
                                    "\n",
                                    "# Load the SMS Spam Collection dataset\n",
                                    "sms_spam = load_dataset('codesignal/sms-spam-collection')\n",
                                    "\n",
                                    "# Convert to pandas DataFrame for convenient handling\n",
                                    "df = pd.DataFrame(sms_spam['train'])\n",
                                    "\n",
                                    "# Use TF-IDF with custom parameters\n",
                                    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_features=500)\n",
                                    "\n",
                                    "# Fit Vectorizer to 'message' column of the dataset\n",
                                    "X_tfidf = vectorizer.fit_transform(df['message'])\n",
                                    "\n",
                                    "# Print shape of feature matrix\n",
                                    "print(X_tfidf.shape)\n",
                                    "\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Updating TF-IDF Parameters for Text Vectorization\n",
                                    "\n",
                                    "After exploring how to customize parameters in TF-IDF vectorization, a crucial phase arrives: fixing a bug where our code veers off course. This task involves a snippet intended for applying TF-IDF vectorization to the SMS Spam Collection dataset, which, unfortunately, misuses one of the parameters. Your aim is to correct this bug and ensure the parameters are set correctly.\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                                    "from datasets import load_dataset\n",
                                    "\n",
                                    "# Load the SMS Spam Collection dataset\n",
                                    "sms_spam = load_dataset('codesignal/sms-spam-collection')\n",
                                    "\n",
                                    "# Convert to pandas DataFrame for convenient handling\n",
                                    "df = pd.DataFrame(sms_spam['train'])\n",
                                    "\n",
                                    "# There's something wrong with how the parameters are set here. Can you spot and fix it?\n",
                                    "vectorizer = TfidfVectorizer(ngram_range=(2, 1), max_features=1000)\n",
                                    "X_tfidf = vectorizer.fit_transform(df['message'])\n",
                                    "\n",
                                    "print(X_tfidf.shape)\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "The bug in the provided code lies in the `ngram_range` parameter within the `TfidfVectorizer`.\n",
                                    "\n",
                                    "The `ngram_range` parameter expects a tuple `(min_n, max_n)` where `min_n` is the lower bound and `max_n` is the upper bound for the n-grams. The current setting `(2, 1)` is incorrect because `min_n` (2) is greater than `max_n` (1). This will result in an empty vocabulary and an error or unexpected behavior.\n",
                                    "\n",
                                    "To fix this, you should set `ngram_range` to `(1, 2)` if you intend to include both unigrams (single words) and bigrams (two-word phrases).\n",
                                    "\n",
                                    "Here's the corrected code:\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                                    "from datasets import load_dataset\n",
                                    "\n",
                                    "# Load the SMS Spam Collection dataset\n",
                                    "sms_spam = load_dataset('codesignal/sms-spam-collection')\n",
                                    "\n",
                                    "# Convert to pandas DataFrame for convenient handling\n",
                                    "df = pd.DataFrame(sms_spam['train'])\n",
                                    "\n",
                                    "# Corrected: ngram_range should be (min_n, max_n) where min_n <= max_n\n",
                                    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=1000)\n",
                                    "X_tfidf = vectorizer.fit_transform(df['message'])\n",
                                    "\n",
                                    "print(X_tfidf.shape)\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Fixing TF-IDF Vectorization Bugs\n",
                                    "\n",
                                    "Building on your newly acquired knowledge of parameter customization in TF-IDF vectorization, let's dive deeper into tweaking these settings. Your challenge is to adjust the TfidfVectorizer parameters to refine the feature extraction process more effectively. Specifically, you will set up the ngram_range to consider both unigrams and bigrams, while also limiting the feature set to the 1000 most frequent terms. This task is designed to enhance your understanding of how adjusting ngram_range and max_features impacts the resulting feature matrix\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                                    "from datasets import load_dataset\n",
                                    "\n",
                                    "# Load the SMS Spam Collection dataset\n",
                                    "sms_spam = load_dataset('codesignal/sms-spam-collection')\n",
                                    "\n",
                                    "# Convert to pandas DataFrame for convenient handling\n",
                                    "df = pd.DataFrame(sms_spam['train'])\n",
                                    "\n",
                                    "# TODO: Use TF-IDF with custom parameters like n-gram range and max features\n",
                                    "vectorizer = TfidfVectorizer(______)\n",
                                    "X_tfidf = vectorizer.fit_transform(df['message'])\n",
                                    "\n",
                                    "print(X_tfidf.shape)\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "To adjust the `TfidfVectorizer` parameters to consider both unigrams and bigrams, and to limit the feature set to the 1000 most frequent terms, you need to set the `ngram_range` parameter to `(1, 2)` and the `max_features` parameter to `1000`.\n",
                                    "\n",
                                    "Here's the corrected code:\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                                    "from datasets import load_dataset\n",
                                    "\n",
                                    "# Load the SMS Spam Collection dataset\n",
                                    "sms_spam = load_dataset('codesignal/sms-spam-collection')\n",
                                    "\n",
                                    "# Convert to pandas DataFrame for convenient handling\n",
                                    "df = pd.DataFrame(sms_spam['train'])\n",
                                    "\n",
                                    "# TODO: Use TF-IDF with custom parameters like n-gram range and max features\n",
                                    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=1000)\n",
                                    "X_tfidf = vectorizer.fit_transform(df['message'])\n",
                                    "\n",
                                    "print(X_tfidf.shape)\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Customizing TF-IDF Vectorization Parameters\n",
                                    "\n",
                                    "Having navigated through practical exercises to fine-tune TF-IDF parameters, you’ve now reached a significant milestone. This final task encapsulates your exploration and understanding of customizing the TfidfVectorizer parameters, specifically ngram_range and max_features, which are crucial for enhancing NLP tasks. Here, you'll consolidate your learning by crafting a code block from scratch, aimed at applying TF-IDF vectorization with specified parameters. This exercise is not merely about demonstrating your grasp of the syntax; it's also about applying thoughtful considerations on how these parameters influence the analysis outcome. Let’s apply your skills in a scenario that directly relates to everything you've practiced so far.\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                                    "from datasets import load_dataset\n",
                                    "\n",
                                    "# Loading the SMS Spam Collection dataset\n",
                                    "sms_spam = load_dataset('codesignal/sms-spam-collection')\n",
                                    "\n",
                                    "# Converting the loaded dataset into a DataFrame\n",
                                    "df = pd.DataFrame(sms_spam['train'])\n",
                                    "\n",
                                    "# TODO: Initialize the TfidfVectorizer with specific parameters\n",
                                    "\n",
                                    "# TODO: Apply the vectorizer to the 'message' column\n",
                                    "\n",
                                    "# TODO: Print the shape of the resulting feature matrix\n",
                                    "\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Mastering Custom TF-IDF Vectorization"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
