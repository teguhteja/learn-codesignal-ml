{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Unit 4 Optimizing TF-IDF Vectorization by Eliminating Stop Words\n",
                                    "\n",
                                    "# Topic Overview\n",
                                    "---\n",
                                    "\n",
                                    "Welcome! In this lesson, we're going to explore **removing stop words in TF-IDF Vectorization**. As you learn how to filter out these common words during the vectorization process, you'll uncover how to reveal more meaningful information in your text data.\n",
                                    "\n",
                                    "## Understanding Stop-words in NLP (Recap and Significance in Vectorization)\n",
                                    "---\n",
                                    "\n",
                                    "As we've already navigated through the terrain of stop words in a previous lesson, it's crucial to recall their role as we dive deeper into the specifics of TF-IDF vectorization. **Stop words**, often the most frequently occurring words in a language, do not carry significant meaning on their own within a text — words like \"the\", \"is\", \"at\", and \"which\". Removing these words during the vectorization process is not merely a cleansing step but a methodical approach to refine our data for more insightful analysis.\n",
                                    "\n",
                                    "By filtering out stop words, we significantly **reduce the dimensionality of our data**. This is a key step in enhancing computational efficiency as it lessens the volume of data to process, thereby speeding up algorithmic computations. Moreover, the exclusion of these words minimizes the noise in our text data, enabling our NLP models to focus on the more meaningful words that contribute to the essence of the content. Consequently, this practice has a direct positive impact on the performance of our NLP algorithms, allowing for a more accurate and insightful text analysis.\n",
                                    "\n",
                                    "This recap underscores the strategic importance of stop word removal within the realm of text vectorization, setting the stage for our exploration into implementing this process with TF-IDF vectorization.\n",
                                    "\n",
                                    "## Implementing Stopwords Removal with TF-IDF Vectorization\n",
                                    "---\n",
                                    "\n",
                                    "The `TfidfVectorizer` from Scikit-Learn provides a highly versatile way to handle stop words through its `stop_words` parameter, thereby allowing for either the utilization of a pre-defined list or the application of a custom list of stopwords. Let's break down both approaches to give you a comprehensive understanding and the tools to implement each method as needed.\n",
                                    "\n",
                                    "### Using Pre-defined Stop Words\n",
                                    "---\n",
                                    "\n",
                                    "For many applications, the **predefined list of stop words** in various languages provided by `TfidfVectorizer` is more than sufficient. This can be easily applied by setting the `stop_words` parameter to the desired language, such as `'english'`.\n",
                                    "\n",
                                    "Let's employ the predefined English stop words to vectorize the 'message' column of an **SMS Spam Collection** dataset loaded into a Pandas DataFrame named `df`:\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                                    "\n",
                                    "# Initialize the TfidfVectorizer with English stop words\n",
                                    "vectorizer = TfidfVectorizer(stop_words='english')\n",
                                    "\n",
                                    "# Tokenize and build vocab\n",
                                    "X_tfidf = vectorizer.fit_transform(df['message'])\n",
                                    "\n",
                                    "# Output the shape of the TF-IDF matrix\n",
                                    "print(X_tfidf.shape)\n",
                                    "```\n",
                                    "\n",
                                    "This script produces a TF-IDF matrix with dimensions indicating the reduction in features due to the removal of stop words:\n",
                                    "\n",
                                    "```\n",
                                    "(5572, 8444)\n",
                                    "```\n",
                                    "\n",
                                    "Here, 5,572 rows correspond to the dataset messages, and 8,444 columns represent the unique words after excluding stop words, showcasing the effectiveness of pre-defined stop word removal in refining our data.\n",
                                    "\n",
                                    "The shape of the TF-IDF vectorized output represents the dimensions of our TF-IDF matrix. Each row in the matrix corresponds to a text message in our dataset, and each column corresponds to a unique word in our text data. The value in each cell in the matrix represents the TF-IDF score of the corresponding word in the corresponding message.\n",
                                    "\n",
                                    "### Applying Custom Stop Words\n",
                                    "---\n",
                                    "\n",
                                    "If your analysis requires a more tailored approach, `TfidfVectorizer` enables the **integration of a custom list of stop words**. This feature is particularly useful when dealing with domain-specific jargon or texts in languages not covered by the predefined lists.\n",
                                    "\n",
                                    "The following example demonstrates how to vectorize the same dataset messages while applying a custom list of stop words:\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                                    "\n",
                                    "# Define a custom list of stop words\n",
                                    "custom_stop_words = ['custom', 'list', 'of', 'stop', 'words']\n",
                                    "\n",
                                    "# Initialize the TfidfVectorizer with the custom stop words\n",
                                    "vectorizer = TfidfVectorizer(stop_words=custom_stop_words)\n",
                                    "\n",
                                    "# Tokenize and build vocab\n",
                                    "X_tfidf_custom = vectorizer.fit_transform(df['message'])\n",
                                    "```\n",
                                    "\n",
                                    "In this scenario, the output will similarly reflect the dimensions of the TF-IDF matrix post the exclusion of the custom stop words specified. The exact changes in dimensions will depend on how many of these custom words were present in your text data to begin with.\n",
                                    "\n",
                                    "Both methods of removing stop words enhance the relevancy and quality of your dataset for NLP tasks by eliminating unnecessary noise. Whether using the inbuilt English stop words functionality for quick analysis or going the extra mile with a custom list for specialized needs, `TfidfVectorizer` equips you with the flexibility to adapt your data preprocessing steps accordingly.\n",
                                    "\n",
                                    "---\n",
                                    "## Lesson Summary\n",
                                    "---\n",
                                    "\n",
                                    "Today, you learned about **stop words**, their influence in NLP, and how to remove them using the **TF-IDF vectorizer** from Python's Scikit-Learn library. This process is vital in reducing the dimensionality of your text data, improving computational efficiency, and enhancing the performance of NLP algorithms.\n",
                                    "\n",
                                    "By practicing the removal of stopwords from different types of text and datasets, you'll extend your skills and create more sophisticated NLP models. So, let's keep advancing — every text you analyze is an opportunity to improve your model's performance."
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Run TF-IDF With Stop Words Removal\n",
                                    "\n",
                                    "In this exercise, we apply TF-IDF vectorization with stop words removal to the SMS Spam Collection dataset using Scikit-Learn's TfidfVectorizer. This method efficiently filters out common words, enhancing model performance and computational efficiency. Simply execute the given code to see the reduction in dimensionality and improvement in data quality.\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "from datasets import load_dataset\n",
                                    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                                    "\n",
                                    "# Load the SMS Spam Collection dataset\n",
                                    "sms_spam = load_dataset('codesignal/sms-spam-collection')\n",
                                    "\n",
                                    "# Convert to pandas DataFrame for convenient handling\n",
                                    "df = pd.DataFrame(sms_spam['train'])\n",
                                    "\n",
                                    "# Remove stop words to the TF-IDF vectorization\n",
                                    "vectorizer = TfidfVectorizer(stop_words='english')\n",
                                    "X_tfidf = vectorizer.fit_transform(df['message'])\n",
                                    "\n",
                                    "print(X_tfidf.shape)\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "The error in the provided code is that the `stop_words` parameter is not set in the `TfidfVectorizer` initialization. To effectively remove English stop words, you need to specify `stop_words='english'` when creating the `TfidfVectorizer` instance.\n",
                                    "\n",
                                    "Here's the corrected code:\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "from datasets import load_dataset\n",
                                    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                                    "\n",
                                    "# Load the SMS Spam Collection dataset\n",
                                    "sms_spam = load_dataset('codesignal/sms-spam-collection')\n",
                                    "\n",
                                    "# Convert to pandas DataFrame for convenient handling\n",
                                    "df = pd.DataFrame(sms_spam['train'])\n",
                                    "\n",
                                    "# Attempt to remove stop words in the TF-IDF vectorization\n",
                                    "# Correction: Add stop_words='english' to the TfidfVectorizer\n",
                                    "vectorizer = TfidfVectorizer(stop_words='english')\n",
                                    "X_tfidf = vectorizer.fit_transform(df['message'])\n",
                                    "\n",
                                    "print(X_tfidf.shape)\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Fixing TF-IDF Vectorization Stop Words\n",
                                    "\n",
                                    "Stellar Navigator, your initial journey into the realm of TF-IDF Vectorization utilized a predefined list of English stopwords. However, the cosmos of text data often requires a more tailored approach. Now, let's enhance your code by transitioning from the default 'english' stopword list to a custom list that excludes specific terms like 'a', 'an', 'the', 'and'. Apply these changes to your code to see the impact of using a more personalized stopword list on your analysis.\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                                    "from datasets import load_dataset\n",
                                    "\n",
                                    "# load dataset\n",
                                    "sms_spam = load_dataset('codesignal/sms-spam-collection')\n",
                                    "df = pd.DataFrame(sms_spam['train'])\n",
                                    "\n",
                                    "# TODO: Define a custom list of stop words\n",
                                    "\n",
                                    "# Initialize the TfidfVectorizer with the custom stop words\n",
                                    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
                                    "\n",
                                    "# Perform Tf-IDF vectorization\n",
                                    "X_tfidf = vectorizer.fit_transform(df['message'])\n",
                                    "\n",
                                    "# Output the shape of the TF-IDF matrix\n",
                                    "print(X_tfidf.shape)\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "To implement a custom list of stop words, you need to define a Python list containing the words you want to exclude and then pass this list to the `stop_words` parameter of the `TfidfVectorizer`.\n",
                                    "\n",
                                    "Here's the corrected code:\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                                    "from datasets import load_dataset\n",
                                    "\n",
                                    "# load dataset\n",
                                    "sms_spam = load_dataset('codesignal/sms-spam-collection')\n",
                                    "df = pd.DataFrame(sms_spam['train'])\n",
                                    "\n",
                                    "# TODO: Define a custom list of stop words\n",
                                    "custom_stop_words = ['a', 'an', 'the', 'and']\n",
                                    "\n",
                                    "# Initialize the TfidfVectorizer with the custom stop words\n",
                                    "vectorizer = TfidfVectorizer(stop_words=custom_stop_words) # Changed \"english\" to custom_stop_words\n",
                                    "\n",
                                    "# Perform Tf-IDF vectorization\n",
                                    "X_tfidf = vectorizer.fit_transform(df['message'])\n",
                                    "\n",
                                    "# Output the shape of the TF-IDF matrix\n",
                                    "print(X_tfidf.shape)\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Customizing Stop Words for TF-IDF Vectorization\n",
                                    "\n",
                                    "Brilliant, Space Explorer! Let's continue building your expertise in handling stop words with TF-IDF Vectorization. Remember, we aim to eliminate those common words to improve the relevancy of our data. Add the code to remove English stop words during vectorization.\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                                    "from datasets import load_dataset\n",
                                    "\n",
                                    "# Loading dataset\n",
                                    "sms_spam = load_dataset('codesignal/sms-spam-collection')\n",
                                    "df = pd.DataFrame(sms_spam['train'])\n",
                                    "\n",
                                    "# TODO: Initialize a vectorizer that filters out english stop words\n",
                                    "\n",
                                    "# Fitting vectorizer\n",
                                    "X_tfidf = vectorizer.fit_transform(df['message'])\n",
                                    "\n",
                                    "# Printing the shape of the TF-IDF matrix\n",
                                    "print(X_tfidf.shape)\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                                    "from datasets import load_dataset\n",
                                    "\n",
                                    "# Loading dataset\n",
                                    "sms_spam = load_dataset('codesignal/sms-spam-collection')\n",
                                    "df = pd.DataFrame(sms_spam['train'])\n",
                                    "\n",
                                    "# TODO: Initialize a vectorizer that filters out english stop words\n",
                                    "vectorizer = TfidfVectorizer(stop_words='english')\n",
                                    "\n",
                                    "# Fitting vectorizer\n",
                                    "X_tfidf = vectorizer.fit_transform(df['message'])\n",
                                    "\n",
                                    "# Printing the shape of the TF-IDF matrix\n",
                                    "print(X_tfidf.shape)\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Adding Stop Words Removal to TF-IDF Vectorizer\n",
                                    "\n",
                                    "Building on the insights and techniques you've learned, this final challenge asks you to encapsulate your newfound skills into one cohesive task. You've already seen how removing stop words can streamline TF-IDF vectorization, making your data more relevant for analysis. Now, you'll apply this knowledge hands-on by preparing the SMS Spam Collection dataset for further NLP tasks. This step is essential for enhancing the performance of NLP models, as it allows them to focus on the more meaningful content of the dataset.\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "from datasets import load_dataset\n",
                                    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                                    "\n",
                                    "# Loading the SMS Spam Collection dataset \n",
                                    "sms_spam = load_dataset('codesignal/sms-spam-collection')\n",
                                    "\n",
                                    "# Converting the dataset to a pandas DataFrame for ease of handling\n",
                                    "df = pd.DataFrame(sms_spam['train'])\n",
                                    "\n",
                                    "# TODO: Initialize TfidfVectorizer with stop words set to remove English stop words\n",
                                    "\n",
                                    "# TODO: Fit the vectorizer to the 'message' column and transform it into a TF-IDF matrix\n",
                                    "\n",
                                    "# TODO: Print the shape of the TF-IDF matrix to see the number of messages and terms\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "To complete the task, you need to add the following lines of code:\n",
                                    "\n",
                                    "1.  Initialize `TfidfVectorizer` with `stop_words='english'`.\n",
                                    "2.  Fit and transform the 'message' column of your DataFrame using the vectorizer.\n",
                                    "3.  Print the shape of the resulting TF-IDF matrix.\n",
                                    "\n",
                                    "Here's the completed code:\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "from datasets import load_dataset\n",
                                    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                                    "\n",
                                    "# Loading the SMS Spam Collection dataset\n",
                                    "sms_spam = load_dataset('codesignal/sms-spam-collection')\n",
                                    "\n",
                                    "# Converting the dataset to a pandas DataFrame for ease of handling\n",
                                    "df = pd.DataFrame(sms_spam['train'])\n",
                                    "\n",
                                    "# Initialize TfidfVectorizer with stop words set to remove English stop words\n",
                                    "vectorizer = TfidfVectorizer(stop_words='english')\n",
                                    "\n",
                                    "# Fit the vectorizer to the 'message' column and transform it into a TF-IDF matrix\n",
                                    "tfidf_matrix = vectorizer.fit_transform(df['message'])\n",
                                    "\n",
                                    "# Print the shape of the TF-IDF matrix to see the number of messages and terms\n",
                                    "print(\"Shape of TF-IDF matrix:\", tfidf_matrix.shape)\n",
                                    "```"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
