{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3 Hyperparameter Tuning Using GridSearchCV\n",
    "\n",
    "Welcome to today's lesson on **Hyperparameter Tuning Using GridSearchCV**! Our goal is to optimize a Gradient Boosting model to predict Tesla ($TSLA) stock prices more accurately. This lesson will guide you through the process of hyperparameter tuning using GridSearchCV, focusing on understanding key hyperparameters, setting up a hyperparameter grid, and implementing GridSearchCV to find better model parameters.\n",
    "\n",
    "---\n",
    "\n",
    "## Brief Revision of Loading and Preparing the Dataset\n",
    "\n",
    "Before diving into hyperparameter tuning, let's quickly revise how we load and prepare our dataset. We start by loading the Tesla dataset, adding technical indicators, and splitting the data into training and testing sets.\n",
    "\n",
    "Here's a quick overview of the code:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset\n",
    "tesla = load_dataset('codesignal/tsla-historic-prices')\n",
    "tesla_df = pd.DataFrame(tesla['train'])\n",
    "\n",
    "# Feature Engineering\n",
    "tesla_df['SMA_5'] = tesla_df['Adj Close'].rolling(window=5).mean()\n",
    "tesla_df['SMA_10'] = tesla_df['Adj Close'].rolling(window=10).mean()\n",
    "tesla_df['EMA_5'] = tesla_df['Adj Close'].ewm(span=5, adjust=False).mean()\n",
    "tesla_df['EMA_10'] = tesla_df['Adj Close'].ewm(span=10, adjust=False).mean()\n",
    "\n",
    "# Drop NaN values created by moving averages\n",
    "tesla_df.dropna(inplace=True)\n",
    "\n",
    "# Select features and target\n",
    "features = tesla_df[['Open', 'High', 'Low', 'Close', 'Volume', 'SMA_5', 'SMA_10', 'EMA_5', 'EMA_10']].values\n",
    "target = tesla_df['Adj Close'].shift(-1).dropna().values  # Predicting next day's close price\n",
    "features = features[:-1]  # Align features and target arrays correctly for time series forecasting\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=42)\n",
    "```\n",
    "\n",
    "The code above loads the Tesla historic prices dataset, applies feature engineering to add technical indicators like Simple Moving Averages (SMA) and Exponential Moving Averages (EMA), and preprocesses the dataset by removing NaN values. It then selects relevant features and the target variables, preparing the data for training and testing by splitting it into training and testing sets. The line `target = tesla_df['Adj Close'].shift(-1).dropna().values` is used for predicting the next day's closing price. The line `features = features[:-1]` ensures that the features and target arrays are aligned correctly for a time series forecasting task where you want to predict the next day's closing price.\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction to Hyperparameter Tuning\n",
    "\n",
    "Hyperparameters are configuration settings used to tune how our models learn. Examples include `learning_rate`, `n_estimators`, and `max_depth` in Gradient Boosting. Proper hyperparameter tuning can significantly improve model performance.\n",
    "\n",
    "Imagine you're trying to make the perfect soup. Hyperparameter tuning is like adjusting the seasoning to get the best flavor. Just like too much salt or too little pepper can ruin the dish, poor hyperparameters can underperform our model.\n",
    "\n",
    "The downside of this approach, however, is that it takes much more time, as every combination of hyperparameters is being tested.\n",
    "\n",
    "---\n",
    "\n",
    "## Setting up a Hyperparameter Grid\n",
    "\n",
    "To find the best hyperparameters, we'll need to test various combinations. This is where the hyperparameter grid comes in. We define a set of values to test for each hyperparameter.\n",
    "\n",
    "Here are the key hyperparameters we'll tune:\n",
    "\n",
    "- **learning_rate**: This controls the contribution of each tree to the final prediction. A smaller learning rate means the model learns more slowly but can achieve better performance with proper tuning.\n",
    "- **n_estimators**: This is the number of boosting stages (trees) to be used in the model. More boosting stages can improve performance but may also lead to overfitting.\n",
    "- **max_depth**: This determines the maximum depth of the trees. Deeper trees can capture more complex patterns but may also overfit the training data.\n",
    "\n",
    "Here's how to set up a hyperparameter grid:\n",
    "\n",
    "```python\n",
    "# Setting up the hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 4]\n",
    "}\n",
    "```\n",
    "\n",
    "In this grid, each combination of `learning_rate`, `n_estimators`, and `max_depth` will be tested. In this `param_grid` dictionary, the keys are hyperparameter names, and mapped lists contain their possible values.\n",
    "\n",
    "---\n",
    "\n",
    "## Implementing GridSearchCV\n",
    "\n",
    "GridSearchCV automates the process of hyperparameter tuning by searching for the best combination of parameters in our grid.\n",
    "\n",
    "Here's how to implement GridSearchCV:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "model = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid, cv=3)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "In the code above, we first import the necessary libraries. We then instantiate the `GridSearchCV` object with a `GradientBoostingRegressor` and our predefined `param_grid`. The `cv=3` parameter specifies that 3-fold cross-validation should be used, meaning the data will be split into three subsets, and the model will be trained and validated three times, each time using a different subset for validation and the remaining subsets for training. This helps ensure the model's performance is robust and not dependent on a particular train-test split. Finally, we fit the `GridSearchCV` object to the training data, which involves training multiple models using different hyperparameter combinations and selecting the best one based on cross-validation results.\n",
    "\n",
    "---\n",
    "\n",
    "## Evaluating and Interpreting Results\n",
    "\n",
    "Once GridSearchCV has found the best parameters, we need to evaluate and interpret the results.\n",
    "\n",
    "```python\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters found:\", model.best_params_)\n",
    "# Output:\n",
    "# Best parameters found: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
    "```\n",
    "\n",
    "Now, using the combination of hyperparameters that resulted in the best model performance, let's calculate the error using these parameters:\n",
    "\n",
    "```python\n",
    "# Predict with the best estimator\n",
    "best_model = model.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Calculate and print Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error with best params:\", mse)\n",
    "# Output:\n",
    "# Mean Squared Error with best params: 22.27547097230719\n",
    "```\n",
    "\n",
    "This indicates the model's accuracy using the optimized hyperparameters, with a lower MSE indicating better accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "## Visualizing Predictions\n",
    "\n",
    "Visualizing predictions helps us understand how well our model is performing and identify any patterns or discrepancies between the actual and predicted values. By plotting the actual values against the predicted values, we can visually assess the model's accuracy and spot areas where the predictions may be off. This is crucial for interpreting the effectiveness of our hyperparameter tuning and understanding the model's behavior.\n",
    "\n",
    "```python\n",
    "# Plotting predictions vs actual values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(range(len(y_test)), y_test, label='Actual', alpha=0.7)\n",
    "plt.scatter(range(len(y_test)), predictions, label='Predicted', alpha=0.7)\n",
    "plt.title('Actual vs Predicted Values with Tuned Hyperparameters')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Here, we visualize the comparison between actual values and predictions. The closer these points are together, the better the model's predictive performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Lesson Summary\n",
    "\n",
    "Great job! You've now learned how to use GridSearchCV for hyperparameter tuning to optimize a Gradient Boosting model. This process involves defining a hyperparameter grid, implementing GridSearchCV, and evaluating the results. Applying these techniques will significantly enhance your model's performance and ensure more accurate predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting Cross-Validation Folds in GridSearchCV\n",
    "\n",
    "To tweak your `GridSearchCV` settings as requested:\n",
    "\n",
    "1. Change the `cv` parameter from 2 to 4 to perform 4-fold cross-validation.\n",
    "2. Modify the hyperparameter grid to include different options for `learning_rate` and `n_estimators`.\n",
    "\n",
    "Here's the updated code with these adjustments:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "tesla = load_dataset('codesignal/tsla-historic-prices')\n",
    "tesla_df = pd.DataFrame(tesla['train'])\n",
    "\n",
    "# Feature Engineering\n",
    "tesla_df['SMA_5'] = tesla_df['Adj Close'].rolling(window=5).mean()\n",
    "tesla_df['SMA_10'] = tesla_df['Adj Close'].rolling(window=10).mean()\n",
    "tesla_df['EMA_5'] = tesla_df['Adj Close'].ewm(span=5, adjust=False).mean()\n",
    "tesla_df['EMA_10'] = tesla_df['Adj Close'].ewm(span=10, adjust=False).mean()\n",
    "\n",
    "# Drop NaN values created by moving averages\n",
    "tesla_df.dropna(inplace=True)\n",
    "\n",
    "# Select features and target\n",
    "features = tesla_df[['Open', 'High', 'Low', 'Close', 'Volume', 'SMA_5', 'SMA_10', 'EMA_5', 'EMA_10']].values\n",
    "target = tesla_df['Adj Close'].shift(-1).dropna().values  # Predicting next day's close price\n",
    "features = features[:-1]\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=42)\n",
    "\n",
    "# Setting up the hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # Added 0.2 as an additional learning rate option\n",
    "    'n_estimators': [100, 200, 300],   # Added 300 as an additional number of estimators option\n",
    "    'max_depth': [3, 4]\n",
    "}\n",
    "\n",
    "# Instantiate the GridSearchCV object with 4-fold cross-validation\n",
    "model = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid, cv=4)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters found:\", model.best_params_)\n",
    "\n",
    "# Predict with the best estimator\n",
    "best_model = model.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Calculate and print Mean Squared Error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error with best params:\", mse)\n",
    "\n",
    "# Plotting predictions vs actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(range(len(y_test)), y_test, label='Actual', alpha=0.7)\n",
    "plt.scatter(range(len(y_test)), predictions, label='Predicted', alpha=0.7)\n",
    "plt.title('Actual vs Predicted Values with Tuned Hyperparameters')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Changes Made:\n",
    "- **Cross-Validation (`cv`):** Changed from `cv=2` to `cv=4` for 4-fold cross-validation.\n",
    "- **Hyperparameter Grid (`param_grid`):** Added additional options for `learning_rate` (`0.2`) and `n_estimators` (`300`) to the grid for more comprehensive model tuning.\n",
    "\n",
    "These adjustments should help in improving the model's validation accuracy by exploring a wider range of hyperparameter combinations and using a more robust cross-validation strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Debugging with GridSearchCV\n",
    "\n",
    "Hey there, Space Explorer! 🚀\n",
    "\n",
    "I've identified the issue in your code. The problem is that you intended to use `GridSearchCV` for hyperparameter tuning, but instead, you directly instantiated and fitted the `GradientBoostingRegressor` without actually using `GridSearchCV`. Additionally, you tried to access `model.best_params_`, which only exists if you used `GridSearchCV`.\n",
    "\n",
    "Let me fix the code for you:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "tesla = load_dataset('codesignal/tsla-historic-prices')\n",
    "tesla_df = pd.DataFrame(tesla['train'])\n",
    "\n",
    "# Feature Engineering\n",
    "tesla_df['SMA_5'] = tesla_df['Adj Close'].rolling(window=5).mean()\n",
    "tesla_df['SMA_10'] = tesla_df['Adj Close'].rolling(window=10).mean()\n",
    "tesla_df['EMA_5'] = tesla_df['Adj Close'].ewm(span=5, adjust=False).mean()\n",
    "tesla_df['EMA_10'] = tesla_df['Adj Close'].ewm(span=10, adjust=False).mean()\n",
    "\n",
    "# Drop NaN values created by moving averages\n",
    "tesla_df.dropna(inplace=True)\n",
    "\n",
    "# Select features and target\n",
    "features = tesla_df[['Open', 'High', 'Low', 'Close', 'Volume', 'SMA_5', 'SMA_10', 'EMA_5', 'EMA_10']].values\n",
    "target = tesla_df['Adj Close'].shift(-1).dropna().values  # Predicting next day's close price\n",
    "\n",
    "# Ensure alignment\n",
    "features = features[:-1]\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=42)\n",
    "\n",
    "# Setting up the hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 4]\n",
    "}\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "grid_search = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid, cv=4)\n",
    "\n",
    "# Fit the model to the training data using GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found by GridSearchCV\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "\n",
    "# Predict with the best estimator found by GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Calculate and print Mean Squared Error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error with best params:\", mse)\n",
    "\n",
    "# Plotting predictions vs actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(range(len(y_test)), y_test, label='Actual', alpha=0.7)\n",
    "plt.scatter(range(len(y_test)), predictions, label='Predicted', alpha=0.7)\n",
    "plt.title('Actual vs Predicted Values with Tuned Hyperparameters')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Key Fixes:\n",
    "- **Replaced `GradientBoostingRegressor` with `GridSearchCV`:** The model instantiation now uses `GridSearchCV` to perform hyperparameter tuning.\n",
    "- **Accessing Best Parameters:** The correct method to find the best parameters is by using `grid_search.best_params_`.\n",
    "- **Predicting with the Best Model:** The predictions are made using `grid_search.best_estimator_`, which is the model with the best hyperparameters found during the search.\n",
    "\n",
    "This should now run smoothly and perform hyperparameter tuning as intended! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning and Model Visualization\n",
    "\n",
    "Hey there, Space Explorer! 🚀\n",
    "\n",
    "I've identified the issue in your code. The problem is that you intended to use `GridSearchCV` for hyperparameter tuning, but instead, you directly instantiated and fitted the `GradientBoostingRegressor` without actually using `GridSearchCV`. Additionally, you tried to access `model.best_params_`, which only exists if you used `GridSearchCV`.\n",
    "\n",
    "Let me fix the code for you:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "tesla = load_dataset('codesignal/tsla-historic-prices')\n",
    "tesla_df = pd.DataFrame(tesla['train'])\n",
    "\n",
    "# Feature Engineering\n",
    "tesla_df['SMA_5'] = tesla_df['Adj Close'].rolling(window=5).mean()\n",
    "tesla_df['SMA_10'] = tesla_df['Adj Close'].rolling(window=10).mean()\n",
    "tesla_df['EMA_5'] = tesla_df['Adj Close'].ewm(span=5, adjust=False).mean()\n",
    "tesla_df['EMA_10'] = tesla_df['Adj Close'].ewm(span=10, adjust=False).mean()\n",
    "\n",
    "# Drop NaN values created by moving averages\n",
    "tesla_df.dropna(inplace=True)\n",
    "\n",
    "# Select features and target\n",
    "features = tesla_df[['Open', 'High', 'Low', 'Close', 'Volume', 'SMA_5', 'SMA_10', 'EMA_5', 'EMA_10']].values\n",
    "target = tesla_df['Adj Close'].shift(-1).dropna().values  # Predicting next day's close price\n",
    "\n",
    "# Ensure alignment\n",
    "features = features[:-1]\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=42)\n",
    "\n",
    "# Setting up the hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 4]\n",
    "}\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "grid_search = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid, cv=4)\n",
    "\n",
    "# Fit the model to the training data using GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found by GridSearchCV\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "\n",
    "# Predict with the best estimator found by GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Calculate and print Mean Squared Error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error with best params:\", mse)\n",
    "\n",
    "# Plotting predictions vs actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(range(len(y_test)), y_test, label='Actual', alpha=0.7)\n",
    "plt.scatter(range(len(y_test)), predictions, label='Predicted', alpha=0.7)\n",
    "plt.title('Actual vs Predicted Values with Tuned Hyperparameters')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Key Fixes:\n",
    "- **Replaced `GradientBoostingRegressor` with `GridSearchCV`:** The model instantiation now uses `GridSearchCV` to perform hyperparameter tuning.\n",
    "- **Accessing Best Parameters:** The correct method to find the best parameters is by using `grid_search.best_params_`.\n",
    "- **Predicting with the Best Model:** The predictions are made using `grid_search.best_estimator_`, which is the model with the best hyperparameters found during the search.\n",
    "\n",
    "This should now run smoothly and perform hyperparameter tuning as intended! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV for Hyperparameter Tuning\n",
    "\n",
    "The stars are aligning, Stellar Navigator! Let's complete the code so you can find the best hyperparameters and shine bright in your data journey. Here’s how you can fill in the blanks:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "tesla = load_dataset('codesignal/tsla-historic-prices')\n",
    "tesla_df = pd.DataFrame(tesla['train'])\n",
    "\n",
    "# Feature Engineering\n",
    "tesla_df['Price_Range'] = tesla_df['High'] - tesla_df['Low']\n",
    "tesla_df['Daily_Return'] = tesla_df['Adj Close'] / tesla_df['Open'] - 1\n",
    "tesla_df['Volatility'] = tesla_df['Price_Range'].rolling(window=5).std()\n",
    "tesla_df['Average_Volume'] = tesla_df['Volume'].rolling(window=5).mean()\n",
    "\n",
    "# Drop NaN values created by rolling operations\n",
    "tesla_df.dropna(inplace=True)\n",
    "\n",
    "# Select features and target\n",
    "features = tesla_df[['Open', 'High', 'Low', 'Close', 'Volume', 'Price_Range', 'Daily_Return', 'Volatility', 'Average_Volume']].values\n",
    "target = tesla_df['Adj Close'].shift(-1).dropna().values  # Predicting next day's close price\n",
    "features = features[:-1]\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=42)\n",
    "\n",
    "# Set up the hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "model = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid, cv=3)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters found:\", model.best_params_)\n",
    "\n",
    "# Predict with the best estimator\n",
    "best_model = model.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Calculate and print Mean Squared Error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error with best params:\", mse)\n",
    "\n",
    "# Plot predictions vs actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(range(len(y_test)), y_test, label='Actual', alpha=0.7)\n",
    "plt.scatter(range(len(y_test)), predictions, label='Predicted', alpha=0.7)\n",
    "plt.title('Actual vs Predicted Values with Tuned Hyperparameters')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Key Points to Add:\n",
    "1. **Hyperparameter Grid (`param_grid`):**\n",
    "   - Expanded the range of `learning_rate`, `n_estimators`, and `max_depth` to explore a broader hyperparameter space.\n",
    "\n",
    "2. **Model Fitting:**\n",
    "   - Fit the `GridSearchCV` model using `model.fit(X_train, y_train)`.\n",
    "\n",
    "3. **Best Parameters & Prediction:**\n",
    "   - Extracted the best model and parameters using `model.best_params_` and `model.best_estimator_`.\n",
    "   - Predicted with the best estimator and calculated the mean squared error.\n",
    "\n",
    "4. **Visualization:**\n",
    "   - Plotted the predictions against the actual values to visually compare model performance.\n",
    "\n",
    "With these stellar adjustments, your hyperparameter tuning should be out of this world! 🌟"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with GridSearchCV\n",
    "\n",
    "Here’s your fully implemented code to optimize a Gradient Boosting model using the Tesla dataset. This code covers everything from loading the dataset, calculating technical indicators, setting up and training the model with `GridSearchCV`, and finally evaluating and visualizing the results.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset\n",
    "tesla = load_dataset('codesignal/tsla-historic-prices')\n",
    "tesla_df = pd.DataFrame(tesla['train'])\n",
    "\n",
    "# Calculate 20-day Simple Moving Averages (SMA) on the dataset\n",
    "tesla_df['SMA_20'] = tesla_df['Adj Close'].rolling(window=20).mean()\n",
    "\n",
    "# Drop rows with NaN values after calculating the moving averages\n",
    "tesla_df.dropna(inplace=True)\n",
    "\n",
    "# Select relevant features and prepare the target variable\n",
    "# The target will be - predicting next day's `Adj Close` price\n",
    "features = tesla_df[['Open', 'High', 'Low', 'Close', 'Volume', 'SMA_20']].values\n",
    "target = tesla_df['Adj Close'].shift(-1).dropna().values\n",
    "\n",
    "# Align features with the target\n",
    "features = features[:-1]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=42)\n",
    "\n",
    "# Set up the hyperparameter grid for learning_rate, n_estimators, and max_depth\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Instantiate the GridSearchCV object with GradientBoostingRegressor\n",
    "model = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid, cv=3)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters found by GridSearchCV\n",
    "print(\"Best parameters found:\", model.best_params_)\n",
    "\n",
    "# Use the best estimator to predict on the test set\n",
    "best_model = model.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Calculate and print the Mean Squared Error for the predictions\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error with best params:\", mse)\n",
    "\n",
    "# Plot predictions against actual values using matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(range(len(y_test)), y_test, label='Actual', alpha=0.7)\n",
    "plt.scatter(range(len(y_test)), predictions, label='Predicted', alpha=0.7)\n",
    "plt.title('Actual vs Predicted Values with Tuned Hyperparameters')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Explanation of the Steps:\n",
    "\n",
    "1. **Loading the Dataset**: The dataset is loaded using `load_dataset`, and converted into a DataFrame for easier manipulation.\n",
    "\n",
    "2. **Calculating Technical Indicators**: A 20-day Simple Moving Average (SMA) is calculated on the adjusted closing price (`Adj Close`).\n",
    "\n",
    "3. **Cleaning the Data**: Rows with NaN values, which result from the moving average calculation, are dropped to ensure no missing data during training.\n",
    "\n",
    "4. **Preparing Features and Target**: Features include the stock's open, high, low, close, volume, and the newly calculated SMA. The target is set to the next day's adjusted closing price.\n",
    "\n",
    "5. **Splitting Data**: The dataset is split into training and testing sets to evaluate the model's performance.\n",
    "\n",
    "6. **Setting Up GridSearchCV**: A grid of hyperparameters is defined for `learning_rate`, `n_estimators`, and `max_depth`. `GridSearchCV` is used to find the optimal combination of these hyperparameters.\n",
    "\n",
    "7. **Training the Model**: The model is trained on the training data with cross-validation.\n",
    "\n",
    "8. **Evaluating the Model**: The best parameters are printed, predictions are made on the test set, and the Mean Squared Error (MSE) is calculated to measure the model's performance.\n",
    "\n",
    "9. **Visualizing Results**: The actual vs. predicted values are plotted to visualize how well the model performs.\n",
    "\n",
    "This complete implementation should help you fine-tune the Gradient Boosting model effectively. Happy tuning, Space Voyager! 🚀"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
