{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here's the content formatted in Markdown:\n",
    "\n",
    "---\n",
    "\n",
    "# Lesson Overview\n",
    "\n",
    "Welcome! In today's lesson, we will learn how to split a dataset into training and testing sets. This is a crucial step in preparing your data for machine learning models to ensure they generalize well to unseen data.\n",
    "\n",
    "**Lesson Goal:** By the end of this lesson, you will understand how to split financial datasets, such as Tesla's stock data, into training and testing sets using Python.\n",
    "\n",
    "## Revision of Preprocessing Steps\n",
    "\n",
    "Before we delve into splitting the dataset, let's briefly review the preprocessing steps we have covered so far. The dataset has been loaded, new features have been engineered, and the features have been scaled.\n",
    "\n",
    "Here's the code for those steps for a quick revision:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datasets\n",
    "\n",
    "# Loading and preprocessing the dataset (revision)\n",
    "data = datasets.load_dataset('codesignal/tsla-historic-prices')\n",
    "tesla_df = pd.DataFrame(data['train'])\n",
    "tesla_df['High-Low'] = tesla_df['High'] - tesla_df['Low']\n",
    "tesla_df['Price-Open'] = tesla_df['Close'] - tesla_df['Open']\n",
    "\n",
    "# Defining features and target\n",
    "features = tesla_df[['High-Low', 'Price-Open', 'Volume']].values\n",
    "# Target is the column that we are trying to predict\n",
    "target = tesla_df['Close'].values\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "```\n",
    "\n",
    "## Understanding the Importance of Splitting Datasets\n",
    "\n",
    "To avoid overfitting, where a model learns the training data too well and performs poorly on new, unseen data, it's important to evaluate your machine learning model on data it has never seen before. This is where splitting datasets into training and testing sets comes into play.\n",
    "\n",
    "### Why Split?\n",
    "\n",
    "- **Training Set:** Used to train the machine learning model.\n",
    "- **Testing Set:** Used to evaluate the model's performance and check its ability to generalize to unseen data.\n",
    "\n",
    "This ensures that your model's performance is not just tailored to the training data but can be generalized to new inputs.\n",
    "\n",
    "## Implementing Dataset Split with `train_test_split`\n",
    "\n",
    "The `train_test_split` function from `sklearn.model_selection` helps us easily split the data.\n",
    "\n",
    "**Parameters of `train_test_split`:**\n",
    "\n",
    "- `test_size`: The proportion of the dataset to include in the test split (e.g., 0.25 means 25% of the data will be used for testing).\n",
    "- `train_size`: The proportion of the dataset to include in the train split (optional if `test_size` is provided).\n",
    "- `random_state`: Controls the shuffling applied to the data before the split. Providing a fixed value ensures reproducibility.\n",
    "\n",
    "Let's split our scaled features and targets into training and testing sets:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.25, random_state=42)\n",
    "```\n",
    "\n",
    "The `train_test_split` function will split our dataset into training and testing sets:\n",
    "\n",
    "- `features_scaled` and `target` are the inputs.\n",
    "- `test_size=0.25` means 25% of the data goes to the test set.\n",
    "- `random_state=42` ensures reproducibility. The state can be any other number, too.\n",
    "\n",
    "## Verifying Shapes and Contents of the Split Data\n",
    "\n",
    "After splitting the dataset, it's important to verify the shapes and the contents of the resulting sets to ensure the split was done correctly.\n",
    "\n",
    "### Checking Shapes:\n",
    "\n",
    "Print the shapes of the training and testing sets to confirm the split ratio is as expected.\n",
    "\n",
    "### Inspecting Sample Rows:\n",
    "\n",
    "Print a few rows of the training and testing sets to visually inspect the data.\n",
    "\n",
    "Let's check our split data:\n",
    "\n",
    "```python\n",
    "# Verify splits\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Testing features shape: {X_test.shape}\")\n",
    "\n",
    "print(f\"First 5 rows of training features: \\n{X_train[:5]}\")\n",
    "print(f\"First 5 training targets: {y_train[:5]}\\n\")\n",
    "\n",
    "print(f\"First 5 rows of testing features: \\n{X_test[:5]}\")\n",
    "print(f\"First 5 testing targets: {y_test[:5]}\")\n",
    "```\n",
    "\n",
    "The output of the above code will be:\n",
    "\n",
    "```\n",
    "Training features shape: (2510, 3)\n",
    "Testing features shape: (837, 3)\n",
    "First 5 rows of training features: \n",
    "[[-4.66075964e-01  6.80184955e-02  3.11378946e-01]\n",
    " [ 4.01701510e+00  5.04529577e+00 -4.61555718e-02]\n",
    " [ 2.04723437e+00  3.09900603e+00  9.43022378e-04]\n",
    " [-5.30579018e-01 -2.30986178e-02 -5.67163058e-01]\n",
    " [-4.78854883e-01 -5.79376618e-02 -6.94451021e-01]]\n",
    "First 5 training targets: [ 17.288    355.666656 222.419998  15.000667  13.092   ]\n",
    "\n",
    "First 5 rows of testing features: \n",
    "[[-0.36226203  0.2087143   0.69346624]\n",
    " [ 1.27319589  1.04049732  0.58204785]\n",
    " [-0.53556882 -0.03231093 -0.86874821]\n",
    " [-0.49029475  0.07773304 -0.51784526]\n",
    " [ 3.0026057  -4.41816938 -0.31923731]]\n",
    "First 5 testing targets: [ 23.209333 189.606674  14.730667  16.763332 325.733337]\n",
    "```\n",
    "\n",
    "This output confirms that our dataset has been successfully split into training and testing sets, showing the shape of each set and giving us a glimpse into the rows of our features and targets post-split. It's an important validation step to ensure our data is ready for machine learning model training and evaluation.\n",
    "\n",
    "## Lesson Summary\n",
    "\n",
    "Great job! In this lesson, we:\n",
    "\n",
    "- Discussed the importance of splitting datasets to avoid overfitting.\n",
    "- Implemented `train_test_split` to divide the dataset into training and testing sets.\n",
    "- Verified the shapes and inspected sample rows of the resulting splits.\n",
    "\n",
    "These steps are crucial for ensuring that your machine learning models can generalize well to new data. Up next, you'll have some practice exercises to solidify your understanding and improve your data preparation skills. Keep going!\n",
    "\n",
    "--- \n",
    "\n",
    "This Markdown format is clean, well-structured, and suitable for lesson notes or documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust the Dataset Split Ratio\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datasets\n",
    "\n",
    "# Load the dataset\n",
    "data = datasets.load_dataset('codesignal/tsla-historic-prices')\n",
    "tesla_df = pd.DataFrame(data['train'])\n",
    "\n",
    "# Create new features\n",
    "tesla_df['High-Low'] = tesla_df['High'] - tesla_df['Low']\n",
    "tesla_df['Price-Open'] = tesla_df['Close'] - tesla_df['Open']\n",
    "\n",
    "# Define features and target\n",
    "features = tesla_df[['High-Low', 'Price-Open', 'Volume']].values\n",
    "target = tesla_df['Close'].values\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.30, random_state=42)\n",
    "\n",
    "# Verify splits\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Testing features shape: {X_test.shape}\")\n",
    "\n",
    "print(f\"First 5 rows of training features: \\n{X_train[:5]}\")\n",
    "print(f\"First 5 training targets: {y_train[:5]}\\n\")\n",
    "\n",
    "print(f\"First 5 rows of testing features: \\n{X_test[:5]}\")\n",
    "print(f\"First 5 testing targets: {y_test[:5]}\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix the Dataset Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in the Blanks: Splitting and Scaling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Dataset into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess and Split Tesla Stock Data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
