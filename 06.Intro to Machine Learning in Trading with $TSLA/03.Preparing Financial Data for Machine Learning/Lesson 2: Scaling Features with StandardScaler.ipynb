{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2\n",
    "\n",
    "## Topic Overview\n",
    "\n",
    "In today's lesson, you'll learn how to standardize financial data using the `StandardScaler` from the `sklearn` library. Scaling features ensure that all data contribute equally to machine learning models, improving their performance and robustness.\n",
    "\n",
    "**Lesson Goal:** By the end of this lesson, you will be able to effectively scale financial features and understand the importance of this step in preparing data for machine learning.\n",
    "\n",
    "## Revision: Loading and Preprocessing the Dataset\n",
    "\n",
    "Let's quickly recall how to load and preprocess the Tesla stock dataset:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import datasets\n",
    "\n",
    "# Load the dataset\n",
    "data = datasets.load_dataset('codesignal/tsla-historic-prices')\n",
    "tesla_df = pd.DataFrame(data['train'])\n",
    "\n",
    "# Feature Engineering: creating new features\n",
    "tesla_df['High-Low'] = tesla_df['High'] - tesla_df['Low']\n",
    "tesla_df['Price-Open'] = tesla_df['Close'] - tesla_df['Open']\n",
    "```\n",
    "\n",
    "We've successfully loaded the Tesla dataset and created new features: `High-Low` and `Price-Open`.\n",
    "\n",
    "## Introduction to Feature Scaling\n",
    "\n",
    "Feature scaling is crucial for machine learning for several reasons:\n",
    "\n",
    "- **Equal Contribution:** Ensures all features contribute equally to the model.\n",
    "- **Improved Convergence:** Helps in faster convergence during model training by making gradients less sensitive to feature magnitude.\n",
    "- **Prevent Dominance:** Prevents features with larger scales from dominating those with smaller scales.\n",
    "\n",
    "Feature scaling is particularly useful in scenarios like:\n",
    "\n",
    "- **Predicting House Prices:** Square footage in thousands vs. the number of bedrooms in single digits.\n",
    "- **Stock Market Analysis:** Stock price in hundreds vs. trading volume in millions.\n",
    "- **Health Data:** Age in the 0-100 range vs. blood pressure in the hundreds.\n",
    "- **Retail Sales Prediction:** Number of items sold vs. store rating in single digits.\n",
    "\n",
    "These examples highlight the importance of scaling to ensure uniform treatment of features, thereby enhancing model performance.\n",
    "\n",
    "## Defining Standardization\n",
    "\n",
    "Standardization involves transforming your data so that the mean of each feature is 0 and the standard deviation is 1. This process ensures all features are on the same scale, improving the performance and robustness of machine learning models. The formula for standardization is:\n",
    "\n",
    "\\[\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "\n",
    "- \\( z \\) is the standardized value,\n",
    "- \\( x \\) is the original value,\n",
    "- \\( \\mu \\) is the mean of the feature, calculated as the average of all values of that feature,\n",
    "- \\( \\sigma \\) is the standard deviation of the feature, which measures the amount of variation or dispersion of the values.\n",
    "\n",
    "By applying this formula, each feature will have a mean of 0 and a standard deviation of 1, enabling more stable and faster convergence during the training of machine learning models.\n",
    "\n",
    "## Implementing StandardScaler on Financial Data\n",
    "\n",
    "Let's proceed to scale our features using `StandardScaler` from `sklearn`. The `StandardScaler` standardizes features by removing the mean and scaling to unit variance.\n",
    "\n",
    "First, we define our features:\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Defining features\n",
    "features = tesla_df[['High-Low', 'Price-Open', 'Volume']].values\n",
    "```\n",
    "\n",
    "Now, let's initialize the scaler and apply it to our features:\n",
    "\n",
    "```python\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "```\n",
    "\n",
    "Here, `fit_transform` computes the mean and standard deviation to scale the data and then returns the transformed version.\n",
    "\n",
    "## Inspecting Scaled Features\n",
    "\n",
    "It's essential to inspect and validate the scaled features to ensure they have been correctly normalized. Let's display the first few rows of the scaled features:\n",
    "\n",
    "```python\n",
    "# Displaying the first few scaled features\n",
    "print(\"Scaled features (first 5 rows):\\n\", features_scaled[:5])\n",
    "```\n",
    "\n",
    "The output of the above code will be:\n",
    "\n",
    "```\n",
    "Scaled features (first 5 rows):\n",
    " [[-0.48165383  0.08560547  2.29693712]\n",
    " [-0.48579183 -0.02912844  2.00292929]\n",
    " [-0.50368231 -0.04721815  0.33325453]\n",
    " [-0.51901702 -0.0599476  -0.23997882]\n",
    " [-0.52169457 -0.06145506  0.08156432]]\n",
    "```\n",
    "\n",
    "This output demonstrates that our features have been successfully scaled to have a standardized scale, specifically with mean values hovering around 0 and standard deviation about 1. This scaling ensures equality in feature contribution to the machine learning model.\n",
    "\n",
    "## Validating Scaled Features\n",
    "\n",
    "After scaling your features, it's important to check the mean and standard deviation to ensure they are correctly standardized. You can do this using the following code:\n",
    "\n",
    "```python\n",
    "# Checking mean values and standard deviations of scaled features\n",
    "scaled_means = features_scaled.mean(axis=0)\n",
    "scaled_stds = features_scaled.std(axis=0)\n",
    "\n",
    "print(\"\\nMean values of scaled features:\", scaled_means)\n",
    "print(\"Standard deviations of scaled features:\", scaled_stds)\n",
    "```\n",
    "\n",
    "The output will show that the means are close to 0 and the standard deviations are close to 1:\n",
    "\n",
    "```\n",
    "Mean values of scaled features: [ 3.39667875e-17  5.57267607e-18 -6.79335750e-17]\n",
    "Standard deviations of scaled features: [1. 1. 1.]\n",
    "```\n",
    "\n",
    "This validation confirms that your features have been successfully scaled.\n",
    "\n",
    "## Lesson Summary\n",
    "\n",
    "In this lesson, we revisited loading and preprocessing the Tesla stock dataset, discussed the importance of scaling features, and implemented `StandardScaler` to normalize our financial data features. By inspecting the scaled features, we ensured they were correctly normalized.\n",
    "\n",
    "Experiment with scaling other features in the dataset to understand their impact further. This practice will reinforce your understanding and skill in data preprocessing, which is vital for building effective and reliable machine-learning models. Happy coding!\n",
    "\n",
    "---\n",
    "\n",
    "This formatting should make the content easier to read and follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling a Single Feature with StandardScaler\n",
    "\n",
    "Let's focus on scaling only the `Volume` feature and adding it as a new column `Volume_Scaled` in our dataset. Here's how you can modify the code:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = datasets.load_dataset('codesignal/tsla-historic-prices')\n",
    "tesla_df = pd.DataFrame(data['train'])\n",
    "\n",
    "# Feature Engineering: creating new features\n",
    "tesla_df['High-Low'] = tesla_df['High'] - tesla_df['Low']\n",
    "tesla_df['Price-Open'] = tesla_df['Close'] - tesla_df['Open']\n",
    "\n",
    "# Scaling only the Volume feature\n",
    "scaler = StandardScaler()\n",
    "tesla_df['Volume_Scaled'] = scaler.fit_transform(tesla_df[['Volume']])\n",
    "\n",
    "# Displaying the first few rows of the new Volume_Scaled feature\n",
    "print(tesla_df[['Volume', 'Volume_Scaled']].head())\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "1. **Scaling the Volume Feature:** \n",
    "   - `tesla_df['Volume_Scaled'] = scaler.fit_transform(tesla_df[['Volume']])`: This line scales the `Volume` column using `StandardScaler` and adds the scaled values as a new column called `Volume_Scaled`.\n",
    "\n",
    "2. **Display the Scaled Feature:**\n",
    "   - The `print` statement shows the original `Volume` and the new `Volume_Scaled` features for the first five rows, allowing you to compare the unscaled and scaled data.\n",
    "\n",
    "This modification helps you focus on feature scaling for a single column while integrating the scaled feature back into the original DataFrame. ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify and Fix the Code\n",
    "\n",
    "The issue in your code lies in the use of `scaler.transform(features)` instead of `scaler.fit_transform(features)`. The `fit_transform` method is necessary for computing the mean and standard deviation before transforming the data. The `transform` method is used only when the scaler has already been fitted.\n",
    "\n",
    "Hereâ€™s the corrected code:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datasets\n",
    "\n",
    "# Load the dataset\n",
    "data = datasets.load_dataset('codesignal/tsla-historic-prices')\n",
    "tesla_df = pd.DataFrame(data['train'])\n",
    "\n",
    "# Feature Engineering: creating new features\n",
    "tesla_df['High-Low'] = tesla_df['High'] - tesla_df['Low']\n",
    "tesla_df['Price-Open'] = tesla_df['Close'] - tesla_df['Open']\n",
    "\n",
    "# Defining features\n",
    "features = tesla_df[['High-Low', 'Price-Open', 'Volume']].values\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)  # Corrected here\n",
    "\n",
    "# Displaying the first few scaled features\n",
    "print(\"Scaled features (first 5 rows):\\n\", features_scaled[:5])\n",
    "\n",
    "# Checking mean values and standard deviations of scaled features\n",
    "scaled_means = features_scaled.mean(axis=0)\n",
    "scaled_stds = features_scaled.std(axis=0)\n",
    "\n",
    "print(\"\\nMean values of scaled features:\", scaled_means)\n",
    "print(\"Standard deviations of scaled features:\", scaled_stds)\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "- **Issue:** The code was using `scaler.transform(features)` without first fitting the scaler. This would throw an error because the scaler wasn't trained on the data yet.\n",
    "- **Fix:** Replace `transform` with `fit_transform`, which fits the scaler to the data and then transforms it, ensuring that the scaling is applied correctly.\n",
    "\n",
    "Now the code will run correctly and produce the scaled features needed for further analysis or machine learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Financial Features with StandardScaler\n",
    "\n",
    "Here's the completed code to properly scale the features using `StandardScaler` and validate the scaling:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datasets\n",
    "\n",
    "# Load the dataset\n",
    "data = datasets.load_dataset('codesignal/tsla-historic-prices')\n",
    "tesla_df = pd.DataFrame(data['train'])\n",
    "\n",
    "# Feature Engineering: creating new features\n",
    "tesla_df['High-Low'] = tesla_df['High'] - tesla_df['Low']\n",
    "tesla_df['Price-Open'] = tesla_df['Close'] - tesla_df['Open']\n",
    "\n",
    "# Defining features\n",
    "# Features include new columns and 'Volume' column\n",
    "features = tesla_df[['Open', 'High', 'Low', 'Close', 'Volume', 'High-Low', 'Price-Open']]\n",
    "\n",
    "# Initialize the StandardScaler and scale the features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Displaying the first few scaled features\n",
    "print(\"Scaled features (first 5 rows):\\n\", features_scaled[:5])\n",
    "\n",
    "# Checking mean values and standard deviations of scaled features\n",
    "scaled_means = features_scaled.mean(axis=0)\n",
    "scaled_stds = features_scaled.std(axis=0)\n",
    "\n",
    "print(\"\\nMean values of scaled features:\", scaled_means)\n",
    "print(\"Standard deviations of scaled features:\", scaled_stds)\n",
    "```\n",
    "\n",
    "### Title: Scaling Features and Validating with StandardScaler\n",
    "\n",
    "### Conclusion:\n",
    "The code successfully scales the defined features from the Tesla stock dataset using `StandardScaler`. It first loads the dataset and performs feature engineering to create new columns. Then, it initializes `StandardScaler`, fits it to the features, transforms the features, and prints the scaled values. Finally, it validates the scaling by printing the mean values and standard deviations of the scaled features. This ensures the features are scaled properly for further analysis or modeling tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Feature Scaling Using StandardScaler\n",
    "\n",
    "Here's the code with the missing pieces filled in to scale the features correctly using `StandardScaler` and display the first few rows of the scaled features:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datasets\n",
    "\n",
    "# Load the Tesla stock dataset\n",
    "data = datasets.load_dataset('codesignal/tsla-historic-prices')\n",
    "tesla_df = pd.DataFrame(data['train'])\n",
    "\n",
    "# Feature Engineering: creating new features\n",
    "# Create a new feature with a value corresponding to a daily price change\n",
    "tesla_df['Daily_Change'] = tesla_df['Close'] - tesla_df['Open']\n",
    "# Create a new feature with a value equal to the mean price during the day\n",
    "tesla_df['Mean_Price'] = (tesla_df['High'] + tesla_df['Low']) / 2\n",
    "\n",
    "# Defining features\n",
    "features = tesla_df[['Daily_Change', 'Mean_Price', 'Volume', 'Open']].values\n",
    "\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Displaying the first few scaled features\n",
    "print(\"Scaled features (first 5 rows):\\n\", features_scaled[:5])\n",
    "\n",
    "# Check mean values and standard deviations of scaled features\n",
    "scaled_means = features_scaled.mean(axis=0)\n",
    "scaled_stds = features_scaled.std(axis=0)\n",
    "\n",
    "print(\"\\nMean values of scaled features:\", scaled_means)\n",
    "print(\"Standard deviations of scaled features:\", scaled_stds)\n",
    "```\n",
    "\n",
    "### Title: Feature Scaling and Validation with Tesla Stock Data\n",
    "\n",
    "### Conclusion:\n",
    "The code successfully generates new features, `Daily_Change` and `Mean_Price`, and then scales them along with the `Volume` and `Open` columns using `StandardScaler`. After scaling, it displays the first few rows of the scaled features and checks the mean values and standard deviations to ensure that the features have been standardized correctly. This provides a solid foundation for further data analysis or model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Data Scaling Implementation\n",
    "\n",
    "Here's the complete implementation that loads the Tesla dataset, creates new features, scales them with `StandardScaler`, and validates the scaled features according to the given TODOs:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Tesla dataset using `datasets.load_dataset`\n",
    "data = datasets.load_dataset('codesignal/tsla-historic-prices')\n",
    "\n",
    "# Convert the dataset to a pandas DataFrame\n",
    "tesla_df = pd.DataFrame(data['train'])\n",
    "\n",
    "# Create new features: 'Volatility' and 'Daily_Average'\n",
    "# Volatility represents the price fluctuation daily range relative to the opening price.\n",
    "tesla_df['Volatility'] = (tesla_df['High'] - tesla_df['Low']) / tesla_df['Open']\n",
    "# Daily_Average represents the average of the daily high and low prices.\n",
    "tesla_df['Daily_Average'] = (tesla_df['High'] + tesla_df['Low']) / 2\n",
    "\n",
    "# Define the features from the DataFrame\n",
    "# The features will include Volatility, Daily_Average, and Volume\n",
    "features = tesla_df[['Volatility', 'Daily_Average', 'Volume']].values\n",
    "\n",
    "# Initialize the StandardScaler and scale the features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Print the first 5 rows of the scaled features\n",
    "print(\"Scaled features (first 5 rows):\\n\", features_scaled[:5])\n",
    "\n",
    "# Check and print the mean values and standard deviations of the scaled features\n",
    "scaled_means = features_scaled.mean(axis=0)\n",
    "scaled_stds = features_scaled.std(axis=0)\n",
    "\n",
    "print(\"\\nMean values of scaled features:\", scaled_means)\n",
    "print(\"Standard deviations of scaled features:\", scaled_stds)\n",
    "```\n",
    "\n",
    "### Title: Tesla Stock Feature Engineering and Scaling\n",
    "\n",
    "### Conclusion:\n",
    "The implementation successfully loads the Tesla stock dataset, creates two new featuresâ€”`Volatility` and `Daily_Average`â€”and scales them along with the `Volume` column using `StandardScaler`. The scaled features are printed, and their mean values and standard deviations are checked to ensure proper scaling. This process standardizes the features, making them ready for further data analysis or modeling tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65855a6d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
