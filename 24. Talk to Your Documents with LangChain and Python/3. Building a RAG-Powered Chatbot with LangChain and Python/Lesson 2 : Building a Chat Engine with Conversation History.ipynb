{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Lesson 2 : Building a Chat Engine with Conversation History\n",
                                    "\n",
                                    "# Building a Chat Engine with Conversation History\n",
                                    "\n",
                                    "Welcome to the second unit of our course on building a RAG-powered chatbot! In the previous lesson, we built a document processor that forms the retrieval component of our RAG system. Today, we'll focus on the conversational aspect by creating a chat engine that can maintain conversation history.\n",
                                    "\n",
                                    "While our document processor is excellent at finding relevant information, a complete RAG system needs a way to interact with users in a natural, conversational manner. This is where our chat engine comes in. The chat engine is responsible for managing the conversation flow, formatting prompts with relevant context, and maintaining a history of the interaction.\n",
                                    "\n",
                                    "## Understanding the Chat Engine\n",
                                    "\n",
                                    "The chat engine we'll build today will:\n",
                                    "\n",
                                    "* Manage interactions with the language model\n",
                                    "* Optionally maintain a history of the conversation for display or logging\n",
                                    "* Format prompts with relevant context from our document processor\n",
                                    "* Provide methods to reset the conversation history when needed\n",
                                    "\n",
                                    "By the end of this lesson, you'll have a fully functional chat engine that can be integrated with the document processor we built previously to create a complete RAG system.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Creating the ChatEngine Class Structure\n",
                                    "\n",
                                    "Let's begin by setting up the basic structure of our ChatEngine class. This class will encapsulate all the functionality needed for managing conversations with the language model.\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "from langchain.schema.messages import SystemMessage, HumanMessage, AIMessage\n",
                                    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
                                    "\n",
                                    "class ChatEngine:\n",
                                    "    def __init__(self):\n",
                                    "        self.chat_model = ChatOpenAI()\n",
                                    "        self.system_message = (\n",
                                    "            \"You are a helpful assistant that ONLY answers questions based on the \"\n",
                                    "            \"provided context. If no relevant context is provided, do NOT answer the \"\n",
                                    "            \"question and politely inform the user that you don't have the necessary \"\n",
                                    "            \"information to answer their question accurately.\"\n",
                                    "        )\n",
                                    "        \n",
                                    "        # Define the prompt template with explicit system and human messages\n",
                                    "        self.prompt = ChatPromptTemplate.from_messages([\n",
                                    "            SystemMessagePromptTemplate.from_template(self.system_message),\n",
                                    "            HumanMessagePromptTemplate.from_template(\n",
                                    "                \"Context:\\n{context}\\n\\nQuestion: {question}\"\n",
                                    "            )\n",
                                    "        ])\n",
                                    "        \n",
                                    "        # Optionally, keep conversation history for display/logging only\n",
                                    "        self.conversation_history = []\n",
                                    "```\n",
                                    "\n",
                                    "### Key points in this initialization:\n",
                                    "\n",
                                    "* **Chat Model**: We initialize `self.chat_model` using `ChatOpenAI()` to create an instance of the OpenAI chat model for generating responses.\n",
                                    "* **System Message**: We define strict instructions that guide the AI's behavior, telling it to only answer questions based on provided context and to politely decline if no relevant context is available.\n",
                                    "* **Prompt Template**: We use `ChatPromptTemplate.from_messages()` to explicitly define both the system and human message templates. The system message sets the assistant's behavior, and the human message template includes placeholders for context and question.\n",
                                    "* **Conversation History**: We initialize an empty list to optionally keep track of the conversation for display or logging purposes. This history is not sent to the model in this implementation.\n",
                                    "\n",
                                    "This structure ensures our chat engine can properly communicate with the language model while optionally maintaining a record of the conversation.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Understanding Prompt Templates in LangChain\n",
                                    "\n",
                                    "Let's take a closer look at how we define the prompt template in our `ChatEngine` class. This part is crucial for controlling how information is passed to the language model.\n",
                                    "\n",
                                    "```python\n",
                                    "self.prompt = ChatPromptTemplate.from_messages([\n",
                                    "    SystemMessagePromptTemplate.from_template(self.system_message),\n",
                                    "    HumanMessagePromptTemplate.from_template(\n",
                                    "        \"Context:\\n{context}\\n\\nQuestion: {question}\"\n",
                                    "    )\n",
                                    "])\n",
                                    "```\n",
                                    "\n",
                                    "### Hereâ€™s what each component does and what it returns:\n",
                                    "\n",
                                    "* **SystemMessagePromptTemplate.from\\_template**\n",
                                    "  This method takes a string template (our system instructions) and returns a `SystemMessagePromptTemplate` object. This object knows how to generate a system message for the chat model by filling in any placeholders if needed.\n",
                                    "\n",
                                    "* **HumanMessagePromptTemplate.from\\_template**\n",
                                    "  This method takes a string template for the user's message (with placeholders for context and question) and returns a `HumanMessagePromptTemplate` object. This object can generate a human message for the chat model by filling in those placeholders.\n",
                                    "\n",
                                    "* **ChatPromptTemplate.from\\_messages**\n",
                                    "  This method takes a list of message prompt templates (like the two above) and returns a `ChatPromptTemplate` object. This object can generate a full list of formatted messages (system and human) ready to be sent to the chat model, using the values you provide for the placeholders.\n",
                                    "\n",
                                    "### Key Difference:\n",
                                    "\n",
                                    "* The `.from_template` methods create individual message templates (for either system or human messages).\n",
                                    "* The `.from_messages` method combines multiple message templates into a single prompt template that can generate the full message sequence for the chat model.\n",
                                    "\n",
                                    "By using these together, we can clearly separate the instructions (system message) from the user input (human message), and then combine them into the exact format the language model expects.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Building the Message Handling System\n",
                                    "\n",
                                    "Now that we have our basic class structure, let's implement the core functionality: sending messages and receiving responses. The `send_message` method will handle this process.\n",
                                    "\n",
                                    "```python\n",
                                    "def send_message(self, user_message, context=\"\"):\n",
                                    "    \"\"\"Send a message to the chat engine and get a response\"\"\"\n",
                                    "    # Format the messages using the prompt template (includes system message)\n",
                                    "    messages = self.prompt.format_messages(\n",
                                    "        context=context,\n",
                                    "        question=user_message\n",
                                    "    )\n",
                                    "    # Get the response from the model\n",
                                    "    response = self.chat_model.invoke(messages)\n",
                                    "    \n",
                                    "    # Optionally, track the conversation for display/logging\n",
                                    "    self.conversation_history.append(HumanMessage(content=user_message))\n",
                                    "    self.conversation_history.append(AIMessage(content=response.content))\n",
                                    "    \n",
                                    "    # Return the AI's response content\n",
                                    "    return response.content\n",
                                    "```\n",
                                    "\n",
                                    "### Explanation:\n",
                                    "\n",
                                    "* **Format Messages**: We use our prompt template to fill in placeholders with the provided context and question. The system message is always included.\n",
                                    "* **Get Response**: We invoke the chat model with our formatted messages using `self.chat_model.invoke(messages)`.\n",
                                    "* **Update History**: We append the user's message and the AI's response to the conversation history for display or logging.\n",
                                    "* **Return Result**: We return the content of the response to be displayed to the user.\n",
                                    "\n",
                                    "Note: In this implementation, conversation history is not sent to the model. Each response is based only on the current context and question, which is typical for RAG systems.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Implementing Conversation Management\n",
                                    "\n",
                                    "An important aspect of any chat system is the ability to manage the conversation state. Let's implement a method to reset the conversation history:\n",
                                    "\n",
                                    "```python\n",
                                    "def reset_conversation(self):\n",
                                    "    \"\"\"Reset the conversation history (for display/logging only)\"\"\"\n",
                                    "    self.conversation_history = []\n",
                                    "```\n",
                                    "\n",
                                    "### Purpose:\n",
                                    "\n",
                                    "* **Reset**: Clears the conversation history. This is useful for display or logging purposes, and allows users to start fresh when needed.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Testing Our Chat Engine Without Context\n",
                                    "\n",
                                    "Let's see how our chat engine behaves when we don't provide any context. This is important because, in a RAG system, the assistant should not \"hallucinate\" answersâ€”it should only respond based on the information it has.\n",
                                    "\n",
                                    "### Test Code:\n",
                                    "\n",
                                    "```python\n",
                                    "from chat_engine import ChatEngine\n",
                                    "\n",
                                    "# Initialize the chat engine\n",
                                    "chat_engine = ChatEngine()\n",
                                    "\n",
                                    "# Send a message without context (should politely decline)\n",
                                    "query = \"What is the capital of France?\"\n",
                                    "response = chat_engine.send_message(query)\n",
                                    "print(f\"Question: {query}\")\n",
                                    "print(f\"Answer: {response}\")\n",
                                    "\n",
                                    "# Print conversation history\n",
                                    "print(\"\\nConversation history:\")\n",
                                    "print(chat_engine.conversation_history)\n",
                                    "```\n",
                                    "\n",
                                    "### Expected Output:\n",
                                    "\n",
                                    "```\n",
                                    "Question: What is the capital of France?\n",
                                    "Answer: I'm sorry, but based on the provided context, I don't have the necessary information to answer your question accurately. If you could provide additional context, I'd be happy to help.\n",
                                    "\n",
                                    "Conversation history:\n",
                                    "[HumanMessage(content='What is the capital of France?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm sorry, but based on the provided context, I don't have the necessary information to answer your question accurately. If you could provide additional context, I'd be happy to help.\", additional_kwargs={}, response_metadata={})]\n",
                                    "```\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Testing With Context\n",
                                    "\n",
                                    "Now, let's test the chat engine with some relevant context. This simulates the scenario where our document processor has retrieved useful information, and we want the assistant to answer using only that context.\n",
                                    "\n",
                                    "### Test Code:\n",
                                    "\n",
                                    "```python\n",
                                    "# Send a message with context (should answer using only the context)\n",
                                    "context = \"\"\"Paris is the capital and most populous city of France. \n",
                                    "The Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral are among its most famous landmarks.\"\"\"\n",
                                    "query = \"Tell me about the landmarks mentioned.\"\n",
                                    "\n",
                                    "# Get response with context provided\n",
                                    "response = chat_engine.send_message(query, context)\n",
                                    "\n",
                                    "# Display the question and answer\n",
                                    "print(f\"\\nQuestion with context: {query}\")\n",
                                    "print(f\"Answer: {response}\")\n",
                                    "\n",
                                    "# Print updated conversation history\n",
                                    "print(\"\\nUpdated conversation history:\")\n",
                                    "print(chat_engine.conversation_history)\n",
                                    "```\n",
                                    "\n",
                                    "### Expected Output:\n",
                                    "\n",
                                    "```\n",
                                    "Question with context: Tell me about the landmarks mentioned.\n",
                                    "Answer: The Eiffel Tower is an iconic iron structure in Paris, known for its intricate lattice metalwork and panoramic views from the top. The Louvre Museum is a historic monument housing a vast collection of art, including the famous painting of the Mona Lisa. Notre-Dame Cathedral is a stunning Gothic cathedral known for its architecture and historical significance as a religious and cultural symbol in Paris.\n",
                                    "\n",
                                    "Updated conversation history:\n",
                                    "[HumanMessage(content='What is the capital of France?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm sorry, but based on the provided context, I don't have the necessary information to answer your question accurately. If you could provide additional context, I'd be happy to help.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me about the landmarks mentioned.', additional_kwargs={}, response_metadata={}), AIMessage(content='The Eiffel Tower is an iconic iron structure in Paris, known for its intricate lattice metalwork and panoramic views from the top. The Louvre Museum is a historic monument housing a vast collection of art, including the famous painting of the Mona Lisa. Notre-Dame Cathedral is a stunning Gothic cathedral known for its architecture and historical significance as a religious and cultural symbol in Paris.', additional_kwargs={}, response_metadata={})]\n",
                                    "```\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Resetting the Conversation\n",
                                    "\n",
                                    "Finally, let's see how to reset the conversation history. This is useful if you want to clear the previous exchanges.\n",
                                    "\n",
                                    "```python\n",
                                    "# Reset the conversation history (for display/logging only)\n",
                                    "chat_engine.reset_conversation()\n",
                                    "print(\"\\nConversation history has been reset.\")\n",
                                    "\n",
                                    "# Print conversation history after reset\n",
                                    "print(\"\\nConversation history after reset:\")\n",
                                    "print(chat_engine.conversation_history)\n",
                                    "```\n",
                                    "\n",
                                    "### Expected Output:\n",
                                    "\n",
                                    "```\n",
                                    "Conversation history has been reset.\n",
                                    "\n",
                                    "Conversation history after reset:\n",
                                    "[]\n",
                                    "```\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Summary and Practice Preview\n",
                                    "\n",
                                    "In this lesson, we've built a chat engine for our RAG chatbot using explicit system and human message templates. We've learned how to:\n",
                                    "\n",
                                    "* Create a `ChatEngine` class that manages conversations with a language model\n",
                                    "* Define system messages to guide the AI's behavior\n",
                                    "* Format prompts with context and questions using templates\n",
                                    "* Optionally maintain conversation history for display or logging\n",
                                    "* Implement methods to send messages and reset conversation history\n",
                                    "* Test our chat engine with various scenarios\n",
                                    "\n",
                                    "Our chat engine complements the document processor we built in the previous lesson. While the document processor handles the retrieval of relevant information, the chat engine manages the conversation and presents this information to the user in a natural way. In the next unit, we'll integrate the document processor and chat engine to create a complete RAG system. This integration will allow our chatbot to automatically retrieve relevant context from documents based on user queries, creating a seamless experience where users can ask questions about their documents and receive informed, contextual responses.\n",
                                    "\n",
                                    "Get ready to practice what you've learned and take your RAG chatbot to the next level!\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Initializing the Chat Engine\n",
                                    "\n",
                                    "You've done a fantastic job understanding the ChatEngine class! Now, let's focus on completing the **init** method. Your task is to:\n",
                                    "\n",
                                    "Instantiate the chat model using ChatOpenAI.\n",
                                    "Define a system message that instructs the AI to answer questions only based on the provided context.\n",
                                    "Initialize the conversation history as an empty list (for display/logging only).\n",
                                    "Once you've completed these steps, verify your work by printing both the system message and the conversation history to ensure they are set up correctly. This will confirm that your initialization is working as intended. Dive in and see how your chat engine starts to take shape!\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "from langchain.schema.messages import SystemMessage, HumanMessage, AIMessage\n",
                                    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
                                    "\n",
                                    "\n",
                                    "class ChatEngine:\n",
                                    "    def __init__(self):\n",
                                    "        # TODO: Instantiate the chat model using ChatOpenAI\n",
                                    "        # TODO: Define the system message with strict instructions\n",
                                    "        # TODO: Initialize conversation history as an empty list\n",
                                    "\n",
                                    "\n",
                                    "from chat_engine import ChatEngine\n",
                                    "\n",
                                    "# Initialize the chat engine\n",
                                    "chat_engine = ChatEngine()\n",
                                    "\n",
                                    "# TODO: Print the system message to verify it is set correctly\n",
                                    "\n",
                                    "# TODO: Print the conversation history to verify it starts as an empty list\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Here's how you can complete the `__init__` method for the `ChatEngine` class. This will involve initializing the chat model, defining the system message, and setting up the conversation history as an empty list.\n",
                                    "\n",
                                    "### Updated Code for `ChatEngine`:\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "from langchain.schema.messages import SystemMessage, HumanMessage, AIMessage\n",
                                    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
                                    "\n",
                                    "\n",
                                    "class ChatEngine:\n",
                                    "    def __init__(self):\n",
                                    "        # Instantiate the chat model using ChatOpenAI\n",
                                    "        self.chat_model = ChatOpenAI()\n",
                                    "\n",
                                    "        # Define the system message with strict instructions\n",
                                    "        self.system_message = (\n",
                                    "            \"You are a helpful assistant that ONLY answers questions based on the \"\n",
                                    "            \"provided context. If no relevant context is provided, do NOT answer the \"\n",
                                    "            \"question and politely inform the user that you don't have the necessary \"\n",
                                    "            \"information to answer their question accurately.\"\n",
                                    "        )\n",
                                    "        \n",
                                    "        # Initialize conversation history as an empty list (for display/logging only)\n",
                                    "        self.conversation_history = []\n",
                                    "\n",
                                    "        # Optionally, define the prompt template (can be expanded as needed)\n",
                                    "        self.prompt = ChatPromptTemplate.from_messages([\n",
                                    "            SystemMessagePromptTemplate.from_template(self.system_message),\n",
                                    "            HumanMessagePromptTemplate.from_template(\n",
                                    "                \"Context:\\n{context}\\n\\nQuestion: {question}\"\n",
                                    "            )\n",
                                    "        ])\n",
                                    "\n",
                                    "\n",
                                    "# Initialize the chat engine in main.py\n",
                                    "chat_engine = ChatEngine()\n",
                                    "\n",
                                    "# Print the system message to verify it is set correctly\n",
                                    "print(\"System Message:\", chat_engine.system_message)\n",
                                    "\n",
                                    "# Print the conversation history to verify it starts as an empty list\n",
                                    "print(\"\\nConversation History:\", chat_engine.conversation_history)\n",
                                    "```\n",
                                    "\n",
                                    "### Explanation of the Code:\n",
                                    "\n",
                                    "1. **Chat Model**:\n",
                                    "   The `self.chat_model = ChatOpenAI()` instantiates the OpenAI chat model, which will be used to generate responses based on the prompts we define.\n",
                                    "\n",
                                    "2. **System Message**:\n",
                                    "   The `self.system_message` defines the behavior of the AI model. It instructs the assistant to answer questions only based on the provided context and politely inform the user if there is no relevant context.\n",
                                    "\n",
                                    "3. **Conversation History**:\n",
                                    "   `self.conversation_history = []` initializes an empty list to track the conversation for display or logging purposes. This list will store both the user's messages and the AI's responses.\n",
                                    "\n",
                                    "4. **Prompt Template**:\n",
                                    "   The `self.prompt` defines how the conversation messages are structured (system message and human message). This is a basic setup that ensures the assistant works according to the instructions.\n",
                                    "\n",
                                    "### Verifying the Setup:\n",
                                    "\n",
                                    "Once you run the code, you should see the following outputs printed to verify that everything is set up correctly:\n",
                                    "\n",
                                    "```\n",
                                    "System Message: You are a helpful assistant that ONLY answers questions based on the provided context. If no relevant context is provided, do NOT answer the question and politely inform the user that you don't have the necessary information to answer their question accurately.\n",
                                    "\n",
                                    "Conversation History: []\n",
                                    "```\n",
                                    "\n",
                                    "This confirms that the `ChatEngine` class is properly initialized with the correct system message and an empty conversation history, as intended.\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Integrating Prompt Templates\n",
                                    "\n",
                                    "Now, let's enhance the __init__ method by integrating a prompt template using explicit system and human message templates. Here's what you need to do:\n",
                                    "\n",
                                    "In chat_engine.py:\n",
                                    "\n",
                                    "Use SystemMessagePromptTemplate and HumanMessagePromptTemplate together with ChatPromptTemplate.from_messages to create a prompt template that:\n",
                                    "Includes a system message instructing the model to answer questions based only on the provided context.\n",
                                    "Includes a human message template with placeholders for both context and question parameters.\n",
                                    "Store this template in the self.prompt attribute.\n",
                                    "In main.py:\n",
                                    "\n",
                                    "Format the prompt template with sample context and question values using self.prompt.format_messages.\n",
                                    "Print the formatted messages as a single object to verify their structure.\n",
                                    "By completing these steps, you'll ensure your chat engine is ready to handle context-based queries effectively using explicit message templates.\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "from langchain.schema.messages import SystemMessage, HumanMessage, AIMessage\n",
                                    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
                                    "\n",
                                    "\n",
                                    "class ChatEngine:\n",
                                    "    def __init__(self):\n",
                                    "        self.chat_model = ChatOpenAI()\n",
                                    "        self.system_message = (\n",
                                    "            \"You are a helpful assistant that ONLY answers questions based on the \"\n",
                                    "            \"provided context. If no relevant context is provided, do NOT answer the \"\n",
                                    "            \"question and politely inform the user that you don't have the necessary \"\n",
                                    "            \"information to answer their question accurately.\"\n",
                                    "        )\n",
                                    "        \n",
                                    "        # TODO: Define the prompt template using ChatPromptTemplate.from_messages,\n",
                                    "        # SystemMessagePromptTemplate, and HumanMessagePromptTemplate.\n",
                                    "        # The template should include a system message and a human message with placeholders for context and question.\n",
                                    "        \n",
                                    "        # Optionally, keep conversation history for display/logging only\n",
                                    "        self.conversation_history = []\n",
                                    "\n",
                                    "\n",
                                    "from chat_engine import ChatEngine\n",
                                    "\n",
                                    "# Initialize the chat engine\n",
                                    "chat_engine = ChatEngine()\n",
                                    "\n",
                                    "# Define a sample context\n",
                                    "sample_context = \"The board game 'Catan' involves players collecting resources to build roads and settlements.\"\n",
                                    "\n",
                                    "# Define a sample question related to the context\n",
                                    "sample_question = \"What do players do in the game 'Catan'?\"\n",
                                    "\n",
                                    "# TODO: Format the prompt template with the sample context and question\n",
                                    "\n",
                                    "# TODO: Print the formatted messages to verify their structure\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "To integrate the prompt templates in the `ChatEngine` class, we'll follow the steps mentioned: creating a `SystemMessagePromptTemplate` and a `HumanMessagePromptTemplate` and then using `ChatPromptTemplate.from_messages` to assemble them into a complete prompt template. We'll also format this template with the given context and question in `main.py`.\n",
                                    "\n",
                                    "Hereâ€™s how to implement the required changes:\n",
                                    "\n",
                                    "### Updated `chat_engine.py`\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "from langchain.schema.messages import SystemMessage, HumanMessage, AIMessage\n",
                                    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
                                    "\n",
                                    "class ChatEngine:\n",
                                    "    def __init__(self):\n",
                                    "        # Instantiate the chat model using ChatOpenAI\n",
                                    "        self.chat_model = ChatOpenAI()\n",
                                    "\n",
                                    "        # Define the system message with strict instructions\n",
                                    "        self.system_message = (\n",
                                    "            \"You are a helpful assistant that ONLY answers questions based on the \"\n",
                                    "            \"provided context. If no relevant context is provided, do NOT answer the \"\n",
                                    "            \"question and politely inform the user that you don't have the necessary \"\n",
                                    "            \"information to answer their question accurately.\"\n",
                                    "        )\n",
                                    "        \n",
                                    "        # Define the prompt template using SystemMessagePromptTemplate and HumanMessagePromptTemplate\n",
                                    "        self.prompt = ChatPromptTemplate.from_messages([\n",
                                    "            SystemMessagePromptTemplate.from_template(self.system_message),\n",
                                    "            HumanMessagePromptTemplate.from_template(\n",
                                    "                \"Context:\\n{context}\\n\\nQuestion: {question}\"\n",
                                    "            )\n",
                                    "        ])\n",
                                    "        \n",
                                    "        # Optionally, keep conversation history for display/logging only\n",
                                    "        self.conversation_history = []\n",
                                    "```\n",
                                    "\n",
                                    "### Explanation:\n",
                                    "\n",
                                    "* **System Message**: The system message instructs the assistant to only answer based on the provided context.\n",
                                    "* **Prompt Template**: The `ChatPromptTemplate` is created using `SystemMessagePromptTemplate` and `HumanMessagePromptTemplate`. The `HumanMessage` template includes placeholders for `context` and `question`.\n",
                                    "* **Conversation History**: This is an optional feature to track the history of the conversation for display/logging.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "### Updated `main.py`\n",
                                    "\n",
                                    "In `main.py`, we will format the prompt template with sample context and question values and then print the formatted messages.\n",
                                    "\n",
                                    "```python\n",
                                    "from chat_engine import ChatEngine\n",
                                    "\n",
                                    "# Initialize the chat engine\n",
                                    "chat_engine = ChatEngine()\n",
                                    "\n",
                                    "# Define a sample context\n",
                                    "sample_context = \"The board game 'Catan' involves players collecting resources to build roads and settlements.\"\n",
                                    "\n",
                                    "# Define a sample question related to the context\n",
                                    "sample_question = \"What do players do in the game 'Catan'?\"\n",
                                    "\n",
                                    "# Format the prompt template with the sample context and question\n",
                                    "formatted_messages = chat_engine.prompt.format_messages(\n",
                                    "    context=sample_context,\n",
                                    "    question=sample_question\n",
                                    ")\n",
                                    "\n",
                                    "# Print the formatted messages to verify their structure\n",
                                    "for message in formatted_messages:\n",
                                    "    print(f\"{message.__class__.__name__}: {message.content}\")\n",
                                    "```\n",
                                    "\n",
                                    "### Explanation:\n",
                                    "\n",
                                    "* **Sample Context and Question**: We define `sample_context` and `sample_question` to simulate a user query and relevant context.\n",
                                    "* **Formatting the Prompt**: The `self.prompt.format_messages` method fills in the placeholders (`context` and `question`) in the prompt template.\n",
                                    "* **Printing the Messages**: We loop through the `formatted_messages` and print each messageâ€™s class name and content to ensure the formatting is correct.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "### Expected Output\n",
                                    "\n",
                                    "When you run `main.py`, you should see output similar to this:\n",
                                    "\n",
                                    "```\n",
                                    "SystemMessage: You are a helpful assistant that ONLY answers questions based on the provided context. If no relevant context is provided, do NOT answer the question and politely inform the user that you don't have the necessary information to answer their question accurately.\n",
                                    "HumanMessage: Context:\n",
                                    "The board game 'Catan' involves players collecting resources to build roads and settlements.\n",
                                    "\n",
                                    "Question: What do players do in the game 'Catan'?\n",
                                    "```\n",
                                    "\n",
                                    "This output confirms that the system message and human message are properly formatted and ready to be used in the chat engine. You have successfully integrated the prompt templates into the `ChatEngine` class!\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Implementing the Send Message Method\n",
                                    "\n",
                                    "Next, let's implement the message handling method, which is crucial for interactions with the chat model.\n",
                                    "\n",
                                    "Here's what you need to do:\n",
                                    "\n",
                                    "Implement a method that accepts two parameters:\n",
                                    "A string containing the user's query\n",
                                    "An optional string parameter for the context relevant to answering the query\n",
                                    "Use the prompt template (which includes both a system and a human message) to format messages, incorporating both the context and the user's query\n",
                                    "Use the chat model to get a response based on the formatted messages\n",
                                    "Append the user's message and the AI's response to the conversation history\n",
                                    "Return the content of the response\n",
                                    "After implementing this method, test it by adding code in main.py to call it with a sample context and question. This will help you verify that your implementation correctly formats the message, interacts with the chat model, and returns the expected response. Let's see how your chat engine comes to life!\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "from langchain.schema.messages import SystemMessage, HumanMessage, AIMessage\n",
                                    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
                                    "\n",
                                    "\n",
                                    "class ChatEngine:\n",
                                    "    def __init__(self):\n",
                                    "        self.chat_model = ChatOpenAI()\n",
                                    "        self.system_message = (\n",
                                    "            \"You are a helpful assistant that ONLY answers questions based on the \"\n",
                                    "            \"provided context. If no relevant context is provided, do NOT answer the \"\n",
                                    "            \"question and politely inform the user that you don't have the necessary \"\n",
                                    "            \"information to answer their question accurately.\"\n",
                                    "        )\n",
                                    "        \n",
                                    "        # Define the prompt template with explicit system and human messages\n",
                                    "        self.prompt = ChatPromptTemplate.from_messages([\n",
                                    "            SystemMessagePromptTemplate.from_template(self.system_message),\n",
                                    "            HumanMessagePromptTemplate.from_template(\n",
                                    "                \"Context:\\n{context}\\n\\nQuestion: {question}\"\n",
                                    "            )\n",
                                    "        ])\n",
                                    "        \n",
                                    "        # Optionally, keep conversation history for display/logging only\n",
                                    "        self.conversation_history = []\n",
                                    "\n",
                                    "    # TODO: Implement a method to send a message to the chat engine and get a response\n",
                                    "    # This method should take a user_message (str) and optional context (str)\n",
                                    "        # TODO: Format the message using the prompt template\n",
                                    "        \n",
                                    "        # TODO: Get the response from the model\n",
                                    "        \n",
                                    "        # TODO: Add both the user message and AI response to the conversation history\n",
                                    "        \n",
                                    "        # TODO: Return the response content\n",
                                    "\n",
                                    "\n",
                                    "\n",
                                    "from chat_engine import ChatEngine\n",
                                    "\n",
                                    "# Initialize the chat engine\n",
                                    "chat_engine = ChatEngine()\n",
                                    "\n",
                                    "# Define a sample context\n",
                                    "context = (\"Mars is the fourth planet from the Sun and the second-smallest planet \"\n",
                                    "           \"in the Solar System. It is often called the 'Red Planet' because of \"\n",
                                    "           \"its reddish appearance due to iron oxide (rust) on its surface. \"\n",
                                    "           \"Mars has two small moons named Phobos and Deimos.\")\n",
                                    "\n",
                                    "# Define a sample question related to the context\n",
                                    "query = \"How is Mars often called?\"\n",
                                    "\n",
                                    "# TODO: Send a message with context and get a response\n",
                                    "\n",
                                    "# TODO: Print the question and answer        \n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "To implement the `send_message` method in the `ChatEngine` class, we'll follow the steps outlined:\n",
                                    "\n",
                                    "1. **Format the message**: We'll format the message using the prompt template, which includes both the system message and the user's query.\n",
                                    "2. **Get the response**: We'll use the `chat_model` to get a response based on the formatted message.\n",
                                    "3. **Update the conversation history**: We'll append the user's message and the AI's response to the conversation history.\n",
                                    "4. **Return the response content**: Finally, we will return the content of the response from the AI model.\n",
                                    "\n",
                                    "Here's the updated code for the `ChatEngine` class and the main script to test the functionality:\n",
                                    "\n",
                                    "### Updated `chat_engine.py`\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "from langchain.schema.messages import SystemMessage, HumanMessage, AIMessage\n",
                                    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
                                    "\n",
                                    "class ChatEngine:\n",
                                    "    def __init__(self):\n",
                                    "        # Instantiate the chat model using ChatOpenAI\n",
                                    "        self.chat_model = ChatOpenAI()\n",
                                    "\n",
                                    "        # Define the system message with strict instructions\n",
                                    "        self.system_message = (\n",
                                    "            \"You are a helpful assistant that ONLY answers questions based on the \"\n",
                                    "            \"provided context. If no relevant context is provided, do NOT answer the \"\n",
                                    "            \"question and politely inform the user that you don't have the necessary \"\n",
                                    "            \"information to answer their question accurately.\"\n",
                                    "        )\n",
                                    "        \n",
                                    "        # Define the prompt template using SystemMessagePromptTemplate and HumanMessagePromptTemplate\n",
                                    "        self.prompt = ChatPromptTemplate.from_messages([\n",
                                    "            SystemMessagePromptTemplate.from_template(self.system_message),\n",
                                    "            HumanMessagePromptTemplate.from_template(\n",
                                    "                \"Context:\\n{context}\\n\\nQuestion: {question}\"\n",
                                    "            )\n",
                                    "        ])\n",
                                    "        \n",
                                    "        # Optionally, keep conversation history for display/logging only\n",
                                    "        self.conversation_history = []\n",
                                    "\n",
                                    "    def send_message(self, user_message, context=\"\"):\n",
                                    "        \"\"\"Send a message to the chat engine and get a response\"\"\"\n",
                                    "        # Format the messages using the prompt template (includes system message)\n",
                                    "        messages = self.prompt.format_messages(\n",
                                    "            context=context,\n",
                                    "            question=user_message\n",
                                    "        )\n",
                                    "        \n",
                                    "        # Get the response from the model\n",
                                    "        response = self.chat_model.invoke(messages)\n",
                                    "        \n",
                                    "        # Add both the user message and AI response to the conversation history\n",
                                    "        self.conversation_history.append(HumanMessage(content=user_message))\n",
                                    "        self.conversation_history.append(AIMessage(content=response.content))\n",
                                    "        \n",
                                    "        # Return the response content\n",
                                    "        return response.content\n",
                                    "```\n",
                                    "\n",
                                    "### Testing the `send_message` Method in `main.py`\n",
                                    "\n",
                                    "Now, let's add the code in `main.py` to call the `send_message` method with a sample context and query:\n",
                                    "\n",
                                    "```python\n",
                                    "from chat_engine import ChatEngine\n",
                                    "\n",
                                    "# Initialize the chat engine\n",
                                    "chat_engine = ChatEngine()\n",
                                    "\n",
                                    "# Define a sample context\n",
                                    "context = (\"Mars is the fourth planet from the Sun and the second-smallest planet \"\n",
                                    "           \"in the Solar System. It is often called the 'Red Planet' because of \"\n",
                                    "           \"its reddish appearance due to iron oxide (rust) on its surface. \"\n",
                                    "           \"Mars has two small moons named Phobos and Deimos.\")\n",
                                    "\n",
                                    "# Define a sample question related to the context\n",
                                    "query = \"How is Mars often called?\"\n",
                                    "\n",
                                    "# Send a message with context and get a response\n",
                                    "response = chat_engine.send_message(query, context)\n",
                                    "\n",
                                    "# Print the question and answer        \n",
                                    "print(f\"Question: {query}\")\n",
                                    "print(f\"Answer: {response}\")\n",
                                    "\n",
                                    "# Optionally, print the conversation history for verification\n",
                                    "print(\"\\nConversation History:\")\n",
                                    "for message in chat_engine.conversation_history:\n",
                                    "    print(f\"{message.__class__.__name__}: {message.content}\")\n",
                                    "```\n",
                                    "\n",
                                    "### Explanation:\n",
                                    "\n",
                                    "1. **`send_message` Method**:\n",
                                    "\n",
                                    "   * The method formats the message using the `prompt` template.\n",
                                    "   * It sends the formatted message to the chat model, retrieves the response, and appends both the user's message and the AI's response to the conversation history.\n",
                                    "   * It returns the AI's response content.\n",
                                    "\n",
                                    "2. **Testing in `main.py`**:\n",
                                    "\n",
                                    "   * We define a sample context and query related to Mars.\n",
                                    "   * The `send_message` method is called with the query and context, and the response is printed.\n",
                                    "   * The conversation history is printed to verify the messages.\n",
                                    "\n",
                                    "### Expected Output:\n",
                                    "\n",
                                    "When you run the code, the output should look something like this:\n",
                                    "\n",
                                    "```\n",
                                    "Question: How is Mars often called?\n",
                                    "Answer: Mars is often called the 'Red Planet' due to its reddish appearance caused by iron oxide (rust) on its surface.\n",
                                    "\n",
                                    "Conversation History:\n",
                                    "HumanMessage: How is Mars often called?\n",
                                    "AIMessage: Mars is often called the 'Red Planet' due to its reddish appearance caused by iron oxide (rust) on its surface.\n",
                                    "```\n",
                                    "\n",
                                    "This confirms that the `send_message` method works correctly, interacting with the chat model, formatting messages, and maintaining the conversation history.\n",
                                    "\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Testing Chat Engine Without Context\n",
                                    "\n",
                                    "This time, let's put the send_message method to the test by calling it without any context.\n",
                                    "\n",
                                    "Modify the existing code to call the send_message method with your query but without passing any context (remove the context parameter from the function call).\n",
                                    "\n",
                                    "This exercise will help you see how the chat engine behaves when context is missing, highlighting the importance of context in generating accurate responses. Dive in and see how your chat engine handles this scenario!\n",
                                    "\n",
                                    "```python\n",
                                    "from chat_engine import ChatEngine\n",
                                    "\n",
                                    "# Initialize the chat engine\n",
                                    "chat_engine = ChatEngine()\n",
                                    "\n",
                                    "# Define a sample context\n",
                                    "context = (\"Mars is the fourth planet from the Sun and the second-smallest planet \"\n",
                                    "           \"in the Solar System. It is often called the 'Red Planet' because of \"\n",
                                    "           \"its reddish appearance due to iron oxide (rust) on its surface. \"\n",
                                    "           \"Mars has two small moons named Phobos and Deimos.\")\n",
                                    "\n",
                                    "# Define a sample question related to the context\n",
                                    "query = \"How is Mars often called?\"\n",
                                    "\n",
                                    "# TODO: Send a message without the context and get a response\n",
                                    "response = chat_engine.send_message(query, context)\n",
                                    "\n",
                                    "# Print the question and answer\n",
                                    "print(f\"Question with context: {query}\")\n",
                                    "print(f\"Answer: {response}\")\n",
                                    "\n",
                                    "\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "from langchain.schema.messages import SystemMessage, HumanMessage, AIMessage\n",
                                    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
                                    "\n",
                                    "\n",
                                    "class ChatEngine:\n",
                                    "    def __init__(self):\n",
                                    "        self.chat_model = ChatOpenAI()\n",
                                    "        self.system_message = (\n",
                                    "            \"You are a helpful assistant that ONLY answers questions based on the \"\n",
                                    "            \"provided context. If no relevant context is provided, do NOT answer the \"\n",
                                    "            \"question and politely inform the user that you don't have the necessary \"\n",
                                    "            \"information to answer their question accurately.\"\n",
                                    "        )\n",
                                    "        \n",
                                    "        # Define the prompt template with explicit system and human messages\n",
                                    "        self.prompt = ChatPromptTemplate.from_messages([\n",
                                    "            SystemMessagePromptTemplate.from_template(self.system_message),\n",
                                    "            HumanMessagePromptTemplate.from_template(\n",
                                    "                \"Context:\\n{context}\\n\\nQuestion: {question}\"\n",
                                    "            )\n",
                                    "        ])\n",
                                    "        \n",
                                    "        # Optionally, keep conversation history for display/logging only\n",
                                    "        self.conversation_history = []\n",
                                    "\n",
                                    "    def send_message(self, user_message, context=\"\"):\n",
                                    "        \"\"\"Send a message to the chat engine and get a response\"\"\"\n",
                                    "        # Format the messages using the prompt template (includes system message)\n",
                                    "        messages = self.prompt.format_messages(\n",
                                    "            context=context,\n",
                                    "            question=user_message\n",
                                    "        )\n",
                                    "        # Get the response from the model\n",
                                    "        response = self.chat_model.invoke(messages)\n",
                                    "        \n",
                                    "        # Track the conversation for display/logging\n",
                                    "        self.conversation_history.append(HumanMessage(content=user_message))\n",
                                    "        self.conversation_history.append(AIMessage(content=response.content))\n",
                                    "        return response.content\n",
                                    "\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Hereâ€™s how to modify the test code in `main.py` to call `send_message` **without any context**, so you can see how the chat engine behaves when no relevant information is provided:\n",
                                    "\n",
                                    "```python\n",
                                    "from chat_engine import ChatEngine\n",
                                    "\n",
                                    "# Initialize the chat engine\n",
                                    "chat_engine = ChatEngine()\n",
                                    "\n",
                                    "# Define a sample question (no context provided)\n",
                                    "query = \"How is Mars often called?\"\n",
                                    "\n",
                                    "# Send a message without passing context (default is empty string)\n",
                                    "response = chat_engine.send_message(query)  # context parameter omitted\n",
                                    "\n",
                                    "# Print the question and answer\n",
                                    "print(f\"Question without context: {query}\")\n",
                                    "print(f\"Answer: {response}\")\n",
                                    "\n",
                                    "# Optionally, print conversation history to verify\n",
                                    "print(\"\\nConversation History:\")\n",
                                    "for message in chat_engine.conversation_history:\n",
                                    "    print(f\"{message.__class__.__name__}: {message.content}\")\n",
                                    "```\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "### What to expect:\n",
                                    "\n",
                                    "Because the system message instructs the AI to only answer based on provided context, and here no context is given, the assistant should politely decline to answer, something like:\n",
                                    "\n",
                                    "```\n",
                                    "Question without context: How is Mars often called?\n",
                                    "Answer: I'm sorry, but based on the provided context, I don't have the necessary information to answer your question accurately. If you could provide additional context, I'd be happy to help.\n",
                                    "\n",
                                    "Conversation History:\n",
                                    "HumanMessage: How is Mars often called?\n",
                                    "AIMessage: I'm sorry, but based on the provided context, I don't have the necessary information to answer your question accurately. If you could provide additional context, I'd be happy to help.\n",
                                    "```\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "### Summary\n",
                                    "\n",
                                    "* Remove the `context` argument when calling `send_message`.\n",
                                    "* The assistant respects the system instructions and will not guess or hallucinate without context.\n",
                                    "* Conversation history will still track the question and the polite refusal answer.\n",
                                    "\n",
                                    "This test demonstrates the importance of providing relevant context in a RAG-powered chatbot to get accurate and useful responses.\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Resetting Conversation History\n",
                                    "\n",
                                    "Let's add an important feature to your chat engineâ€”the ability to clear the conversation history!\n",
                                    "\n",
                                    "In the ChatEngine class, implement the method that resets the conversation history by clearing the conversation_history list.\n",
                                    "Test your implementation by calling this method, and then printing the conversation history to verify it is empty.\n",
                                    "This is a small but powerful addition that will make your chatbot more flexible and prevent it from getting confused by lengthy conversation histories. Give it a try!\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "from langchain.schema.messages import SystemMessage, HumanMessage, AIMessage\n",
                                    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
                                    "\n",
                                    "\n",
                                    "class ChatEngine:\n",
                                    "    def __init__(self):\n",
                                    "        self.chat_model = ChatOpenAI()\n",
                                    "        self.system_message = (\n",
                                    "            \"You are a helpful assistant that ONLY answers questions based on the \"\n",
                                    "            \"provided context. If no relevant context is provided, do NOT answer the \"\n",
                                    "            \"question and politely inform the user that you don't have the necessary \"\n",
                                    "            \"information to answer their question accurately.\"\n",
                                    "        )\n",
                                    "        \n",
                                    "        # Define the prompt template with explicit system and human messages\n",
                                    "        self.prompt = ChatPromptTemplate.from_messages([\n",
                                    "            SystemMessagePromptTemplate.from_template(self.system_message),\n",
                                    "            HumanMessagePromptTemplate.from_template(\n",
                                    "                \"Context:\\n{context}\\n\\nQuestion: {question}\"\n",
                                    "            )\n",
                                    "        ])\n",
                                    "        \n",
                                    "        # Optionally, keep conversation history for display/logging only\n",
                                    "        self.conversation_history = []\n",
                                    "\n",
                                    "    def send_message(self, user_message, context=\"\"):\n",
                                    "        \"\"\"Send a message to the chat engine and get a response\"\"\"\n",
                                    "        # Format the messages using the prompt template (includes system message)\n",
                                    "        messages = self.prompt.format_messages(\n",
                                    "            context=context,\n",
                                    "            question=user_message\n",
                                    "        )\n",
                                    "        # Get the response from the model\n",
                                    "        response = self.chat_model.invoke(messages)\n",
                                    "        \n",
                                    "        # Optionally, track the conversation for display/logging\n",
                                    "        self.conversation_history.append(HumanMessage(content=user_message))\n",
                                    "        self.conversation_history.append(AIMessage(content=response.content))\n",
                                    "        return response.content\n",
                                    "\n",
                                    "    # TODO: Implement a method to reset the conversation history\n",
                                    "\n",
                                    "\n",
                                    "\n",
                                    "from chat_engine import ChatEngine\n",
                                    "\n",
                                    "# Initialize the chat engine\n",
                                    "chat_engine = ChatEngine()\n",
                                    "\n",
                                    "# Define a sample context about Mars\n",
                                    "context = (\"Mars is the fourth planet from the Sun and the second-smallest planet \"\n",
                                    "           \"in the Solar System. It is often called the 'Red Planet' because of \"\n",
                                    "           \"its reddish appearance due to iron oxide (rust) on its surface. \"\n",
                                    "           \"Mars has two small moons named Phobos and Deimos.\")\n",
                                    "\n",
                                    "# Define a sample question related to the context\n",
                                    "query = \"Why does the planet have that color?\"\n",
                                    "\n",
                                    "# Send a message with context and get a response\n",
                                    "response = chat_engine.send_message(query, context)\n",
                                    "\n",
                                    "# Print the question and answer\n",
                                    "print(f\"Question with context: {query}\")\n",
                                    "print(f\"Answer: {response}\")\n",
                                    "\n",
                                    "# Print the conversation history\n",
                                    "print(\"\\nConversation history:\")\n",
                                    "print(chat_engine.conversation_history)\n",
                                    "\n",
                                    "# Send another question about Mars\n",
                                    "query2 = \"What are the names of Mars' moons?\"\n",
                                    "response2 = chat_engine.send_message(query2, context)\n",
                                    "print(f\"\\nQuestion with context: {query2}\")\n",
                                    "print(f\"Answer: {response2}\")\n",
                                    "\n",
                                    "# Print updated conversation history\n",
                                    "print(\"\\nUpdated conversation history:\")\n",
                                    "print(chat_engine.conversation_history)\n",
                                    "\n",
                                    "# TODO: Reset the conversation history\n",
                                    "\n",
                                    "# TODO: Print conversation history after reset\n",
                                    "\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "from langchain.schema.messages import SystemMessage, HumanMessage, AIMessage\n",
                                    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
                                    "\n",
                                    "\n",
                                    "class ChatEngine:\n",
                                    "    def __init__(self):\n",
                                    "        self.chat_model = ChatOpenAI()\n",
                                    "        self.system_message = (\n",
                                    "            \"You are a helpful assistant that ONLY answers questions based on the \"\n",
                                    "            \"provided context. If no relevant context is provided, do NOT answer the \"\n",
                                    "            \"question and politely inform the user that you don't have the necessary \"\n",
                                    "            \"information to answer their question accurately.\"\n",
                                    "        )\n",
                                    "        \n",
                                    "        # Define the prompt template with explicit system and human messages\n",
                                    "        self.prompt = ChatPromptTemplate.from_messages([\n",
                                    "            SystemMessagePromptTemplate.from_template(self.system_message),\n",
                                    "            HumanMessagePromptTemplate.from_template(\n",
                                    "                \"Context:\\n{context}\\n\\nQuestion: {question}\"\n",
                                    "            )\n",
                                    "        ])\n",
                                    "        \n",
                                    "        # Optionally, keep conversation history for display/logging only\n",
                                    "        self.conversation_history = []\n",
                                    "\n",
                                    "    def send_message(self, user_message, context=\"\"):\n",
                                    "        \"\"\"Send a message to the chat engine and get a response\"\"\"\n",
                                    "        # Format the messages using the prompt template (includes system message)\n",
                                    "        messages = self.prompt.format_messages(\n",
                                    "            context=context,\n",
                                    "            question=user_message\n",
                                    "        )\n",
                                    "        # Get the response from the model\n",
                                    "        response = self.chat_model.invoke(messages)\n",
                                    "        \n",
                                    "        # Optionally, track the conversation for display/logging\n",
                                    "        self.conversation_history.append(HumanMessage(content=user_message))\n",
                                    "        self.conversation_history.append(AIMessage(content=response.content))\n",
                                    "        return response.content\n",
                                    "\n",
                                    "    def reset_conversation(self):\n",
                                    "        \"\"\"Reset the conversation history (for display/logging only)\"\"\"\n",
                                    "        self.conversation_history = []\n",
                                    "\n",
                                    "\n",
                                    "# ----------------------- Testing in main.py -----------------------\n",
                                    "\n",
                                    "from chat_engine import ChatEngine\n",
                                    "\n",
                                    "# Initialize the chat engine\n",
                                    "chat_engine = ChatEngine()\n",
                                    "\n",
                                    "# Define a sample context about Mars\n",
                                    "context = (\"Mars is the fourth planet from the Sun and the second-smallest planet \"\n",
                                    "           \"in the Solar System. It is often called the 'Red Planet' because of \"\n",
                                    "           \"its reddish appearance due to iron oxide (rust) on its surface. \"\n",
                                    "           \"Mars has two small moons named Phobos and Deimos.\")\n",
                                    "\n",
                                    "# Define a sample question related to the context\n",
                                    "query = \"Why does the planet have that color?\"\n",
                                    "\n",
                                    "# Send a message with context and get a response\n",
                                    "response = chat_engine.send_message(query, context)\n",
                                    "\n",
                                    "# Print the question and answer\n",
                                    "print(f\"Question with context: {query}\")\n",
                                    "print(f\"Answer: {response}\")\n",
                                    "\n",
                                    "# Print the conversation history\n",
                                    "print(\"\\nConversation history:\")\n",
                                    "print(chat_engine.conversation_history)\n",
                                    "\n",
                                    "# Send another question about Mars\n",
                                    "query2 = \"What are the names of Mars' moons?\"\n",
                                    "response2 = chat_engine.send_message(query2, context)\n",
                                    "print(f\"\\nQuestion with context: {query2}\")\n",
                                    "print(f\"Answer: {response2}\")\n",
                                    "\n",
                                    "# Print updated conversation history\n",
                                    "print(\"\\nUpdated conversation history:\")\n",
                                    "print(chat_engine.conversation_history)\n",
                                    "\n",
                                    "# Reset the conversation history\n",
                                    "chat_engine.reset_conversation()\n",
                                    "\n",
                                    "# Print conversation history after reset\n",
                                    "print(\"\\nConversation history after reset:\")\n",
                                    "print(chat_engine.conversation_history)\n",
                                    "```\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "### Explanation:\n",
                                    "\n",
                                    "* The `reset_conversation` method simply clears the `conversation_history` list.\n",
                                    "* After sending two messages and printing the history, we call `reset_conversation()` to clear it.\n",
                                    "* Printing the history after reset should show an empty list `[]`.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "### Expected Output Snippet:\n",
                                    "\n",
                                    "```\n",
                                    "Question with context: Why does the planet have that color?\n",
                                    "Answer: Mars appears red due to iron oxide (rust) on its surface, giving it its distinctive color.\n",
                                    "\n",
                                    "Conversation history:\n",
                                    "[HumanMessage(content='Why does the planet have that color?'), AIMessage(content='Mars appears red due to iron oxide (rust) on its surface, giving it its distinctive color.')]\n",
                                    "\n",
                                    "Question with context: What are the names of Mars' moons?\n",
                                    "Answer: Mars has two small moons named Phobos and Deimos.\n",
                                    "\n",
                                    "Updated conversation history:\n",
                                    "[HumanMessage(content=\"What are the names of Mars' moons?\"), AIMessage(content=\"Mars has two small moons named Phobos and Deimos.\")]\n",
                                    "\n",
                                    "Conversation history after reset:\n",
                                    "[]\n",
                                    "```\n",
                                    "\n",
                                    "This confirms your chat engine now supports resetting conversation history!\n"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
