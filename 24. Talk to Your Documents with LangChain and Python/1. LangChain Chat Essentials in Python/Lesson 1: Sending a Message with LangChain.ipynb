{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Lesson 1: Sending a Message with LangChain\n",
                                    "\n",
                                    "\n",
                                    "Welcome to the first lesson of the **LangChain Chat Essentials in Python** course. In this course, we will embark on an exciting journey into the world of conversational AI using LangChain.\n",
                                    "\n",
                                    "LangChain is a powerful framework that simplifies the process of interacting with large language models (LLMs). It provides developers with a set of tools and interfaces to effectively utilize AI capabilities for a wide range of applications, such as chatbots, content generation, and more. LangChain abstracts the complexities involved in model communication, allowing developers to focus on building innovative solutions.\n",
                                    "\n",
                                    "Beyond basic interactions, LangChain offers advanced features like conversation history management, context handling, and customizable model parameters. These features make it an excellent choice for developing sophisticated AI-driven applications.\n",
                                    "\n",
                                    "In this lesson, we will concentrate on the essential skills needed to send messages to AI models using LangChain. While LangChain supports a variety of models and providers, we will specifically focus on working with OpenAI, laying the groundwork for more advanced topics in future lessons.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Setting Up the Environment\n",
                                    "\n",
                                    "Before we dive into the code, it's important to ensure that your Python environment is set up correctly. You will need to install the `langchain-openai` library, which provides the necessary components to work with OpenAI models through the LangChain framework.\n",
                                    "\n",
                                    "The `langchain-openai` package is specifically designed to integrate OpenAI's models with LangChain's architecture. It contains all the classes and utilities needed to communicate with OpenAI's API.\n",
                                    "\n",
                                    "To install this library, run:\n",
                                    "\n",
                                    "```bash\n",
                                    "pip install langchain-openai\n",
                                    "```\n",
                                    "\n",
                                    "This single package provides everything you need to start working with OpenAI models in LangChain. It handles the API communication, response parsing, and model configuration, allowing you to focus on building your applications rather than managing the underlying infrastructure.\n",
                                    "\n",
                                    "> **Note:** In the CodeSignal environment, these steps are already taken care of, so you can focus on learning and experimenting with the code.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Setting the OpenAI API Key as an Environment Variable\n",
                                    "\n",
                                    "In this course, you'll be using the CodeSignal coding environment, where everything is preconfigured. You don’t need to worry about setting up an API key or configuring environment variables—it’s all handled for you.\n",
                                    "\n",
                                    "However, it’s still useful to understand how this process works in case you want to set it up on your own computer in the future. To work with OpenAI models outside of CodeSignal, you need to:\n",
                                    "\n",
                                    "1. Sign up on the OpenAI website.\n",
                                    "2. Add a payment method.\n",
                                    "3. Obtain an API key.\n",
                                    "\n",
                                    "To keep your API key secure, store it in an environment variable. This prevents you from hard-coding sensitive information in your code.\n",
                                    "\n",
                                    "```bash\n",
                                    "# On macOS/Linux\n",
                                    "export OPENAI_API_KEY=your_api_key_here\n",
                                    "```\n",
                                    "\n",
                                    "```batch\n",
                                    ":: On Windows (Command Prompt)\n",
                                    "set OPENAI_API_KEY=your_api_key_here\n",
                                    "```\n",
                                    "\n",
                                    "```powershell\n",
                                    "# On Windows (PowerShell)\n",
                                    "$env:OPENAI_API_KEY=\"your_api_key_here\"\n",
                                    "```\n",
                                    "\n",
                                    "These commands set the environment variable for the current session. When using CodeSignal, you can skip these and jump straight into experimenting with OpenAI models.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Understanding the ChatOpenAI Class\n",
                                    "\n",
                                    "With your OpenAI API key securely set, you can now utilize LangChain to communicate with OpenAI models. The `ChatOpenAI` class is a crucial part of LangChain that enables interaction with OpenAI’s chat-based models like GPT-3.5 and GPT-4. It acts as a bridge, allowing you to send messages and receive responses in a conversational format.\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "\n",
                                    "# Create an instance of ChatOpenAI\n",
                                    "chat = ChatOpenAI()\n",
                                    "```\n",
                                    "\n",
                                    "Here, we import `ChatOpenAI` and create an instance named `chat`. By default, it uses OpenAI’s default settings and model. While customization options exist, we’ll focus on basic usage for now.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Sending a Message\n",
                                    "\n",
                                    "To communicate with the OpenAI model, call the `invoke` method on your `ChatOpenAI` instance. This method accepts a string (or list of messages) and returns an object containing the AI’s reply.\n",
                                    "\n",
                                    "```python\n",
                                    "# Send a message to the AI model\n",
                                    "response = chat.invoke(\"Hello, how are you?\")\n",
                                    "```\n",
                                    "\n",
                                    "LangChain automatically formats the message for the model. In later lessons, we’ll explore more structured message formats.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Extracting the Response\n",
                                    "\n",
                                    "Once you have the response object, extract the generated text via its `content` attribute.\n",
                                    "\n",
                                    "```python\n",
                                    "# Display the AI’s response\n",
                                    "print(\"AI Response:\")\n",
                                    "print(response.content)\n",
                                    "```\n",
                                    "\n",
                                    "Example output:\n",
                                    "\n",
                                    "> **AI Response:**\n",
                                    "> I’m an AI model, so I don’t have feelings, but I’m here to help you!\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Complete Code Example\n",
                                    "\n",
                                    "Putting it all together:\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "\n",
                                    "# Create an instance of ChatOpenAI\n",
                                    "chat = ChatOpenAI()\n",
                                    "\n",
                                    "# Send a message to the AI model\n",
                                    "response = chat.invoke(\"Hello, how are you?\")\n",
                                    "\n",
                                    "# Display the AI’s response\n",
                                    "print(\"AI Response:\")\n",
                                    "print(response.content)\n",
                                    "```\n",
                                    "\n",
                                    "Run this script to see the AI’s reply printed to the console.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Working with Other AI Providers in LangChain\n",
                                    "\n",
                                    "One of LangChain’s strengths is its consistent interface across different model providers. For example, to integrate Anthropic’s Claude models:\n",
                                    "\n",
                                    "1. Install the Anthropic package:\n",
                                    "\n",
                                    "   ```bash\n",
                                    "   pip install langchain-anthropic\n",
                                    "   ```\n",
                                    "\n",
                                    "2. Set your Anthropic API key:\n",
                                    "\n",
                                    "   ```bash\n",
                                    "   # On macOS/Linux\n",
                                    "   export ANTHROPIC_API_KEY=your_anthropic_api_key_here\n",
                                    "\n",
                                    "   # On Windows (Command Prompt)\n",
                                    "   set ANTHROPIC_API_KEY=your_anthropic_api_key_here\n",
                                    "\n",
                                    "   # On Windows (PowerShell)\n",
                                    "   $env:ANTHROPIC_API_KEY=\"your_anthropic_api_key_here\"\n",
                                    "   ```\n",
                                    "\n",
                                    "3. Use the `ChatAnthropic` class:\n",
                                    "\n",
                                    "   ```python\n",
                                    "   from langchain_anthropic import ChatAnthropic\n",
                                    "\n",
                                    "   # Create an instance of ChatAnthropic with a specific model\n",
                                    "   chat = ChatAnthropic(model=\"claude-3-7-sonnet-latest\")\n",
                                    "\n",
                                    "   # Send a message to Claude\n",
                                    "   response = chat.invoke(\"Hello, how are you?\")\n",
                                    "\n",
                                    "   # Display Claude's response\n",
                                    "   print(\"Claude's Response:\")\n",
                                    "   print(response.content)\n",
                                    "   ```\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Working with Local Models in LangChain\n",
                                    "\n",
                                    "LangChain also supports local models, which can run offline and avoid API costs. For example, using Ollama to run Llama 2 locally:\n",
                                    "\n",
                                    "1. Install the Ollama package:\n",
                                    "\n",
                                    "   ```bash\n",
                                    "   pip install langchain-ollama\n",
                                    "   ```\n",
                                    "\n",
                                    "2. Use the `ChatOllama` class:\n",
                                    "\n",
                                    "   ```python\n",
                                    "   from langchain_ollama import ChatOllama\n",
                                    "\n",
                                    "   # Create a chat instance for a local model\n",
                                    "   chat = ChatOllama(model=\"llama2\")\n",
                                    "\n",
                                    "   # Send a message to the local model\n",
                                    "   response = chat.invoke(\"Hello, how are you?\")\n",
                                    "\n",
                                    "   # Display the response\n",
                                    "   print(\"Local Model Response:\")\n",
                                    "   print(response.content)\n",
                                    "   ```\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Summary and Next Steps\n",
                                    "\n",
                                    "In this lesson, you learned:\n",
                                    "\n",
                                    "* How to set up your environment for LangChain + OpenAI.\n",
                                    "* How to configure your API key securely.\n",
                                    "* How to initialize and use the `ChatOpenAI` class to send messages.\n",
                                    "* How to extract and display responses.\n",
                                    "* That LangChain’s interface is model-agnostic, supporting cloud providers (Anthropic) and local models (Ollama).\n",
                                    "\n",
                                    "As you move on to the practice exercises, experiment with different messages and observe the AI’s behavior. In future lessons, we will dive into advanced topics like customizing model parameters and managing conversation history. Happy coding!\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Crafting Your Own AI Question\n",
                                    "\n",
                                    "You've learned about the basics of LangChain and how it helps you communicate with AI models, now let's put that knowledge into practice! In this exercise, you'll modify a simple script to ask the AI a question of your choice.\n",
                                    "\n",
                                    "Your task is to change the existing question in the code to a new question that you come up with. This will provide you with practical experience in crafting and sending personalized messages to an AI model using the invoke method.\n",
                                    "\n",
                                    "After making this change, run the code to see how the AI responds to your new question. This practical experience will help solidify your understanding of the basic workflow for interacting with language models through LangChain.\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "\n",
                                    "# Create a ChatOpenAI instance\n",
                                    "chat = ChatOpenAI()\n",
                                    "\n",
                                    "# TODO: Ask the AI a different question\n",
                                    "response = chat.invoke(\"Hello, how are you?\")\n",
                                    "\n",
                                    "# Print the AI's response\n",
                                    "print(\"AI Response:\")\n",
                                    "print(response.content)\n",
                                    "```\n",
                                    "\n",
                                    "**Providing code modification**\n",
                                    "\n",
                                    "The user needs to modify the script by replacing the question string to ask a new question. I should show them the changed code snippet in a markdown block, so they can easily copy it. I should also suggest that they run the updated code to observe the AI's response to their chosen question. Maybe I should ask them what question they plan to use, though... It'll make for a good collaborative moment. Let's proceed with showing them the modified script first.\n",
                                    "\n",
                                    "\n",
                                    "Thought for 5 seconds\n",
                                    "\n",
                                    "\n",
                                    "Here’s the script updated to ask a new question. In this example, we’ll ask the AI for “three quick tips for writing effective prompts for AI models.”\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "\n",
                                    "# Create a ChatOpenAI instance\n",
                                    "chat = ChatOpenAI()\n",
                                    "\n",
                                    "# Ask the AI a different question\n",
                                    "response = chat.invoke(\"What are three quick tips for writing effective prompts for AI models?\")\n",
                                    "\n",
                                    "# Print the AI's response\n",
                                    "print(\"AI Response:\")\n",
                                    "print(response.content)\n",
                                    "```\n",
                                    "\n",
                                    "1. Replace the string inside `chat.invoke(...)` with whatever question you’d like to try.\n",
                                    "2. Run the script.\n",
                                    "3. Observe and experiment with the AI’s reply—then feel free to tweak your question and run again to see how the responses change!\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Fixing a Common LangChain Mistake\n",
                                    "\n",
                                    "Now that you've learned how to send a basic message to an AI model, let's practice fixing a common issue that can occur when using LangChain.\n",
                                    "\n",
                                    "The code has a minor issue with how the response is being processed. In this exercise, you'll identify and fix a small mistake in a script that's communicating with an AI model.\n",
                                    "\n",
                                    "This type of troubleshooting is a valuable skill that will help you build more robust AI applications in the future.\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "\n",
                                    "# Create a ChatOpenAI instance\n",
                                    "chat = ChatOpenAI()\n",
                                    "\n",
                                    "# Send a message to the AI model\n",
                                    "response = chat.invoke(\"What's the capital of France?\")\n",
                                    "\n",
                                    "# Print the AI's response\n",
                                    "print(\"AI Response:\")\n",
                                    "print(response)\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Thought for a couple of seconds\n",
                                    "\n",
                                    "\n",
                                    "Here’s the corrected script. The key fix is to access the `content` attribute of the `response` object, rather than printing the object itself:\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "\n",
                                    "# Create a ChatOpenAI instance\n",
                                    "chat = ChatOpenAI()\n",
                                    "\n",
                                    "# Send a message to the AI model\n",
                                    "response = chat.invoke(\"What's the capital of France?\")\n",
                                    "\n",
                                    "# Print the AI's response (access the .content attribute)\n",
                                    "print(\"AI Response:\")\n",
                                    "print(response.content)\n",
                                    "```\n",
                                    "\n",
                                    "**What changed?**\n",
                                    "\n",
                                    "* **Before:** `print(response)`\n",
                                    "* **After:**  `print(response.content)`\n",
                                    "\n",
                                    "The `response` returned by `invoke` is an object that holds metadata plus the generated text in its `content` field. Printing `response.content` ensures you see just the AI’s reply.\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Building a Complete LangChain Script\n",
                                    "\n",
                                    "It's time to build a complete LangChain script from scratch! In this exercise, you'll create all the components needed to communicate with an OpenAI model.\n",
                                    "\n",
                                    "Starting with just the import statement, you'll need to:\n",
                                    "\n",
                                    "Create a ChatOpenAI instance.\n",
                                    "Use the invoke method to send a simple message to the model.\n",
                                    "Print the response with clear formatting.\n",
                                    "This hands-on practice will help you solidify the complete workflow for interacting with AI models through LangChain. By writing the code yourself, you'll gain confidence in your ability to build AI-powered applications!\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "\n",
                                    "# TODO: Create a ChatOpenAI instance\n",
                                    "\n",
                                    "# TODO: Send a message to the AI model\n",
                                    "\n",
                                    "# TODO: Print the AI's response with appropriate formatting\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "\n",
                                    "# Create a ChatOpenAI instance\n",
                                    "chat = ChatOpenAI()\n",
                                    "\n",
                                    "# Send a message to the AI model\n",
                                    "response = chat.invoke(\"Tell me a fun fact about space exploration.\")\n",
                                    "\n",
                                    "# Print the AI's response with clear formatting\n",
                                    "print(\"=== AI Response Start ===\")\n",
                                    "print(response.content)\n",
                                    "print(\"=== AI Response End ===\")\n",
                                    "```\n",
                                    "\n",
                                    "Thought for a few seconds\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "\n",
                                    "# Create a ChatOpenAI instance\n",
                                    "chat = ChatOpenAI()\n",
                                    "\n",
                                    "# Send a message to the AI model\n",
                                    "response = chat.invoke(\"Tell me a fun fact about space exploration.\")\n",
                                    "\n",
                                    "# Print the AI's response with clear formatting\n",
                                    "print(\"=== AI Response Start ===\")\n",
                                    "print(response.content)\n",
                                    "print(\"=== AI Response End ===\")\n",
                                    "```\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Switching Providers with LangChain Interface\n",
                                    "\n",
                                    "Imagine your company's OpenAI API key has expired, and you only have access to an Anthropic API key now. You need to quickly update your chatbot code to keep it running.\n",
                                    "\n",
                                    "In this exercise, you'll modify a script that asks the simple question \"Who are you?\" to work with Anthropic's Claude model instead of OpenAI.\n",
                                    "\n",
                                    "Your task is to:\n",
                                    "\n",
                                    "Update the import statement to use ChatAnthropic from langchain_anthropic\n",
                                    "Replace the ChatOpenAI instance with a ChatAnthropic instance using the \"claude-3-7-sonnet-latest\" model\n",
                                    "This exercise demonstrates one of LangChain's key strengths - its consistent interface across different AI providers. The Anthropic API key is already set up for you, so you can focus on making the code changes and comparing see Claude in action with LangChain!\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "# TODO: Change the import to use ChatAnthropic from langchain_anthropic\n",
                                    "from langchain_openai import ChatOpenAI\n",
                                    "\n",
                                    "# TODO: Replace this with a ChatAnthropic instance using the claude-3-7-sonnet-latest model\n",
                                    "chat = ChatOpenAI()\n",
                                    "\n",
                                    "# Send a message to the AI model\n",
                                    "response = chat.invoke(\"Who are you?\")\n",
                                    "\n",
                                    "# Print the AI's response\n",
                                    "print(\"AI Response:\")\n",
                                    "print(response.content)\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "**Modifying the code for compatibility**\n",
                                    "\n",
                                    "Looks like the user is asking for help switching an OpenAI-based chatbot script to work with Anthropic's Claude model. I’ll need to update the import to `ChatAnthropic` from `langchain_anthropic`. After that, I'll replace the previous `ChatOpenAI` with a `ChatAnthropic` instance, specifying the correct model, “claude-3-7-sonnet-latest.” This is a neat exercise to show LangChain’s flexibility, allowing code to adapt easily across different AI providers. Let's make sure I follow all these steps carefully!\n",
                                    "\n",
                                    "\n",
                                    "Thought for 4 seconds\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_anthropic import ChatAnthropic\n",
                                    "\n",
                                    "# Create a ChatAnthropic instance using Claude\n",
                                    "chat = ChatAnthropic(model=\"claude-3-7-sonnet-latest\")\n",
                                    "\n",
                                    "# Send a message to the Claude model\n",
                                    "response = chat.invoke(\"Who are you?\")\n",
                                    "\n",
                                    "# Print the model's response\n",
                                    "print(\"AI Response:\")\n",
                                    "print(response.content)\n",
                                    "```\n"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
