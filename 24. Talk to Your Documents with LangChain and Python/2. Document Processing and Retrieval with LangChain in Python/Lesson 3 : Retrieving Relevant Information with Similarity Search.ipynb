{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Lesson 3 : Retrieving Relevant Information with Similarity Search\n",
                                    "\n",
                                    "\n",
                                    "Welcome back! In the previous lesson, we explored how to generate embeddings for document chunks using OpenAI and LangChain. Today, we will build on that knowledge by diving into vector databases and how they enable the efficient retrieval of relevant information through similarity search.\n",
                                    "\n",
                                    "Vector databases are specialized storage systems designed to handle high-dimensional vector data‚Äîsuch as the embeddings we generated in the last lesson. They are crucial for performing similarity searches, which allow us to find document chunks that are semantically similar to a given query. In this lesson, we will focus on using **FAISS**, a powerful tool developed by Facebook AI, to create a local vector storage. This will enable us to efficiently store and search through our embeddings, paving the way for advanced document retrieval tasks.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Preparing Documents and Embedding Model\n",
                                    "\n",
                                    "Before we can perform a similarity search, we need to prepare our document and initialize our embedding model. Here‚Äôs a quick recap:\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_community.document_loaders import PyPDFLoader\n",
                                    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                                    "from langchain_openai import OpenAIEmbeddings\n",
                                    "\n",
                                    "# Define the file path\n",
                                    "file_path = \"data/the_adventure_of_the_blue_carbuncle.pdf\"\n",
                                    "\n",
                                    "# Create a loader for our document\n",
                                    "loader = PyPDFLoader(file_path)\n",
                                    "\n",
                                    "# Load the document\n",
                                    "docs = loader.load()\n",
                                    "\n",
                                    "# Split the document into chunks\n",
                                    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
                                    "split_docs = text_splitter.split_documents(docs)\n",
                                    "\n",
                                    "# Initialize the OpenAI embedding model\n",
                                    "embedding_model = OpenAIEmbeddings()\n",
                                    "````\n",
                                    "\n",
                                    "This snippet loads a PDF, splits it into 1 000-character chunks (with 100-character overlap), and initializes the OpenAI embeddings model.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Creating Embeddings and Vector Store\n",
                                    "\n",
                                    "With our document chunks ready and embedding model initialized, the next step is to generate embeddings and create a vector store. We‚Äôll use **FAISS** for this:\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_community.vectorstores import FAISS\n",
                                    "\n",
                                    "# Generate embeddings for all chunks and create a FAISS vector store\n",
                                    "vectorstore = FAISS.from_documents(split_docs, embedding_model)\n",
                                    "```\n",
                                    "\n",
                                    "`FAISS.from_documents(...)` does the following under the hood:\n",
                                    "\n",
                                    "1. Takes each chunk in `split_docs`.\n",
                                    "2. Converts each chunk‚Äôs text into a high-dimensional embedding via `embedding_model`.\n",
                                    "3. Indexes all vectors in a FAISS index for ultra-fast similarity search.\n",
                                    "4. Returns a vector store that links each vector back to its original document metadata.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Performing Similarity Search\n",
                                    "\n",
                                    "Now that our FAISS index is ready, we can query it for semantically relevant chunks:\n",
                                    "\n",
                                    "```python\n",
                                    "# Define our search query\n",
                                    "query = \"What was the main clue?\"\n",
                                    "\n",
                                    "# Retrieve the top 3 most similar chunks\n",
                                    "retrieved_docs = vectorstore.similarity_search(query, k=3)\n",
                                    "\n",
                                    "# Display the first 300 characters of each result\n",
                                    "for doc in retrieved_docs:\n",
                                    "    print(doc.page_content[:300], \"...\\n\")\n",
                                    "```\n",
                                    "\n",
                                    "**Sample Output**\n",
                                    "\n",
                                    "```\n",
                                    "The little man stood glancing from one to the\n",
                                    "other of us with half-frightened, half-hopeful eyes,\n",
                                    "as one who is not sure whether he is on the verge\n",
                                    "of a windfall or of a catastrophe. Then he stepped\n",
                                    "into the cab, and in half an hour we were back in\n",
                                    "the sitting-room at Baker Street. Nothing had been ...\n",
                                    "\n",
                                    "less innocent aspect. Here is the stone; the stone\n",
                                    "came from the goose, and the goose came from Mr.\n",
                                    "Henry Baker, the gentleman with the bad hat and\n",
                                    "all the other characteristics with which I have bored\n",
                                    "you. So now we must set ourselves very seriously\n",
                                    "to Ô¨Ånding this gentleman and ascertaining what\n",
                                    "pa ...\n",
                                    "\n",
                                    "she found matters as described by the last\n",
                                    "witness. Inspector Bradstreet, B division,\n",
                                    "gave evidence as to the arrest of Horner,\n",
                                    "who struggled frantically, and protested his\n",
                                    "innocence in the strongest terms. Evidence\n",
                                    "of a previous conviction for robbery having\n",
                                    "been given against the prisoner, the mag ...\n",
                                    "```\n",
                                    "\n",
                                    "Even though the exact phrase ‚Äúmain clue‚Äù doesn‚Äôt appear, FAISS retrieves passages discussing the key evidence (the blue carbuncle, witness testimony, etc.)‚Äîall relevant to our query.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Summary and Next Steps\n",
                                    "\n",
                                    "In this lesson you learned:\n",
                                    "\n",
                                    "1. **How to load, split, and embed documents** with LangChain.\n",
                                    "2. **How to build a FAISS vector store** to index those embeddings.\n",
                                    "3. **How to perform a similarity search** to retrieve semantically related text chunks.\n",
                                    "\n",
                                    "üîç **Practice Exercise**: Try using different queries or documents (e.g., another public domain text) and observe how FAISS returns the most relevant passages. This hands-on practice will solidify your understanding before we move on to the next unit.\n",
                                    "\n",
                                    "Keep up the great work, and see you in the next lesson! üöÄ\n",
                                    "\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Exploring Vector Store Details\n",
                                    "\n",
                                    "You've been doing well with understanding document processing and embeddings. Now, let's explore of our vector store create using FAISS.\n",
                                    "\n",
                                    "Just run the code and observe the output:\n",
                                    "\n",
                                    "It will show the number of document chunks created.\n",
                                    "It will display the embedding dimensions used.\n",
                                    "This will help you see how the setup works. Enjoy exploring the results!\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import OpenAIEmbeddings\n",
                                    "from langchain_community.document_loaders import PyPDFLoader\n",
                                    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                                    "from langchain_community.vectorstores import FAISS\n",
                                    "\n",
                                    "# Define the file path\n",
                                    "file_path = \"data/the_adventure_of_the_blue_carbuncle.pdf\"\n",
                                    "\n",
                                    "# Create a loader for our document\n",
                                    "loader = PyPDFLoader(file_path)\n",
                                    "\n",
                                    "# Load the document\n",
                                    "docs = loader.load()\n",
                                    "\n",
                                    "# Split the document into chunks\n",
                                    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
                                    "split_docs = text_splitter.split_documents(docs)\n",
                                    "\n",
                                    "# Initialize the OpenAI embedding model\n",
                                    "embedding_model = OpenAIEmbeddings()\n",
                                    "\n",
                                    "# Store document vectors in FAISS using the embedding model\n",
                                    "vectorstore = FAISS.from_documents(split_docs, embedding_model)\n",
                                    "\n",
                                    "# Print the number of documents and embedding dimensions\n",
                                    "print(f\"Number of documents: {len(vectorstore.docstore._dict)}\")\n",
                                    "print(f\"Embedding dimensions: {vectorstore.index.d}\")\n",
                                    "\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Formulate a Query for the Similarity Search\n",
                                    "\n",
                                    "Well done understanding vector stores. Now, let's perform your first similarity search on a document using FAISS.\n",
                                    "\n",
                                    "Your task is to formulate a question about the document to guide the search. Here are some example questions you might consider:\n",
                                    "\n",
                                    "\"What is the main event?\"\n",
                                    "\"Who is the main character?\"\n",
                                    "\"What is the setting of the story?\"\n",
                                    "Once you've crafted your question, execute the code to perform the similarity search and retrieve relevant information from the document. Dive in and see how effectively you can extract meaningful insights!\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import OpenAIEmbeddings\n",
                                    "from langchain_community.document_loaders import PyPDFLoader\n",
                                    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                                    "from langchain_community.vectorstores import FAISS\n",
                                    "\n",
                                    "# Define the file path\n",
                                    "file_path = \"data/the_adventure_of_the_blue_carbuncle.pdf\"\n",
                                    "\n",
                                    "# Create a loader for our document\n",
                                    "loader = PyPDFLoader(file_path)\n",
                                    "\n",
                                    "# Load the document\n",
                                    "docs = loader.load()\n",
                                    "\n",
                                    "# Split the document into chunks\n",
                                    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
                                    "split_docs = text_splitter.split_documents(docs)\n",
                                    "\n",
                                    "# Initialize the OpenAI embedding model\n",
                                    "embedding_model = OpenAIEmbeddings()\n",
                                    "\n",
                                    "# Store document vectors in FAISS using the embedding model\n",
                                    "vectorstore = FAISS.from_documents(split_docs, embedding_model)\n",
                                    "\n",
                                    "# TODO: Write a question about the document for the similarity search\n",
                                    "query = \"_________________________\"\n",
                                    "\n",
                                    "# Perform similarity search to find the top 3 most relevant document chunks\n",
                                    "retrieved_docs = vectorstore.similarity_search(query, k=3)\n",
                                    "\n",
                                    "# Print the content of the retrieved documents\n",
                                    "for doc in retrieved_docs:\n",
                                    "    print(doc.page_content[:300], \"...\\n\")\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Here‚Äôs the completed snippet with a query asking for the main character in the story:\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import OpenAIEmbeddings\n",
                                    "from langchain_community.document_loaders import PyPDFLoader\n",
                                    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                                    "from langchain_community.vectorstores import FAISS\n",
                                    "\n",
                                    "# Define the file path\n",
                                    "file_path = \"data/the_adventure_of_the_blue_carbuncle.pdf\"\n",
                                    "\n",
                                    "# Create a loader for our document\n",
                                    "loader = PyPDFLoader(file_path)\n",
                                    "\n",
                                    "# Load the document\n",
                                    "docs = loader.load()\n",
                                    "\n",
                                    "# Split the document into chunks\n",
                                    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
                                    "split_docs = text_splitter.split_documents(docs)\n",
                                    "\n",
                                    "# Initialize the OpenAI embedding model\n",
                                    "embedding_model = OpenAIEmbeddings()\n",
                                    "\n",
                                    "# Store document vectors in FAISS using the embedding model\n",
                                    "vectorstore = FAISS.from_documents(split_docs, embedding_model)\n",
                                    "\n",
                                    "# Ask about the main character in the story\n",
                                    "query = \"Who is the main character in The Adventure of the Blue Carbuncle?\"\n",
                                    "\n",
                                    "# Perform similarity search to find the top 3 most relevant document chunks\n",
                                    "retrieved_docs = vectorstore.similarity_search(query, k=3)\n",
                                    "\n",
                                    "# Print the content of the retrieved document snippets\n",
                                    "for doc in retrieved_docs:\n",
                                    "    print(doc.page_content[:300], \"...\\n\")\n",
                                    "```\n",
                                    "\n",
                                    "Running this will retrieve and print the passages that most closely discuss Sherlock Holmes (the main character) and related context.\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Adjusting Document Retrieval Quantity\n",
                                    "\n",
                                    "Nice work on learning how to perform similarity searches! Now, let's explore how to adjust the number of document chunks retrieved during a search.\n",
                                    "\n",
                                    "Currently, the code retrieves the top 3 most relevant document chunks. Your task is to change this number to 5.\n",
                                    "\n",
                                    "This small change will help you understand how to control the amount of context you retrieve related to a query.. Dive in and see the difference!\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import OpenAIEmbeddings\n",
                                    "from langchain_community.document_loaders import PyPDFLoader\n",
                                    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                                    "from langchain_community.vectorstores import FAISS\n",
                                    "\n",
                                    "# Define the file path\n",
                                    "file_path = \"data/the_adventure_of_the_blue_carbuncle.pdf\"\n",
                                    "\n",
                                    "# Create a loader for our document\n",
                                    "loader = PyPDFLoader(file_path)\n",
                                    "\n",
                                    "# Load the document\n",
                                    "docs = loader.load()\n",
                                    "\n",
                                    "# Split the document into chunks\n",
                                    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
                                    "split_docs = text_splitter.split_documents(docs)\n",
                                    "\n",
                                    "# Initialize the OpenAI embedding model\n",
                                    "embedding_model = OpenAIEmbeddings()\n",
                                    "\n",
                                    "# Store document vectors in FAISS using the embedding model\n",
                                    "vectorstore = FAISS.from_documents(split_docs, embedding_model)\n",
                                    "\n",
                                    "# Define the search query\n",
                                    "query = \"What was the main clue?\"\n",
                                    "\n",
                                    "# TODO: Change the number of retrieved document chunks to 5\n",
                                    "retrieved_docs = vectorstore.similarity_search(query, k=3)\n",
                                    "\n",
                                    "# Print the content of the retrieved documents\n",
                                    "for doc in retrieved_docs:\n",
                                    "    print(doc.page_content[:300], \"...\\n\")\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import OpenAIEmbeddings\n",
                                    "from langchain_community.document_loaders import PyPDFLoader\n",
                                    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                                    "from langchain_community.vectorstores import FAISS\n",
                                    "\n",
                                    "# Define the file path\n",
                                    "file_path = \"data/the_adventure_of_the_blue_carbuncle.pdf\"\n",
                                    "\n",
                                    "# Create a loader for our document\n",
                                    "loader = PyPDFLoader(file_path)\n",
                                    "\n",
                                    "# Load the document\n",
                                    "docs = loader.load()\n",
                                    "\n",
                                    "# Split the document into chunks\n",
                                    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
                                    "split_docs = text_splitter.split_documents(docs)\n",
                                    "\n",
                                    "# Initialize the OpenAI embedding model\n",
                                    "embedding_model = OpenAIEmbeddings()\n",
                                    "\n",
                                    "# Store document vectors in FAISS using the embedding model\n",
                                    "vectorstore = FAISS.from_documents(split_docs, embedding_model)\n",
                                    "\n",
                                    "# Define the search query\n",
                                    "query = \"What was the main clue?\"\n",
                                    "\n",
                                    "# Retrieve the top 5 most relevant document chunks\n",
                                    "retrieved_docs = vectorstore.similarity_search(query, k=5)\n",
                                    "\n",
                                    "# Print the content of the retrieved document snippets\n",
                                    "for doc in retrieved_docs:\n",
                                    "    print(doc.page_content[:300], \"...\\n\")\n",
                                    "```\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Similarity Search with FAISS\n",
                                    "\n",
                                    "Finally, let's put all your knowledge into practice by creating a vector store using FAISS and performing a similarity search.\n",
                                    "\n",
                                    "Your task is to:\n",
                                    "\n",
                                    "Generate and store document vectors in FAISS using the embeddings model that has already been initialized for you.\n",
                                    "Define a search query related to the Sherlock Holmes story.\n",
                                    "Perform a similarity search to retrieve the top 5 most relevant document chunks.\n",
                                    "Print the first 100 characters of each retrieved document.\n",
                                    "This exercise will help you see how effectively you can retrieve relevant information from the text using vector similarity.\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import OpenAIEmbeddings\n",
                                    "from langchain_community.document_loaders import PyPDFLoader\n",
                                    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                                    "from langchain_community.vectorstores import FAISS\n",
                                    "\n",
                                    "# Define the file path\n",
                                    "file_path = \"data/the_adventure_of_the_blue_carbuncle.pdf\"\n",
                                    "\n",
                                    "# Create a loader for our document\n",
                                    "loader = PyPDFLoader(file_path)\n",
                                    "\n",
                                    "# Load the document\n",
                                    "docs = loader.load()\n",
                                    "\n",
                                    "# Split the document into chunks\n",
                                    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
                                    "split_docs = text_splitter.split_documents(docs)\n",
                                    "\n",
                                    "# Initialize the OpenAI embedding model\n",
                                    "embedding_model = OpenAIEmbeddings()\n",
                                    "\n",
                                    "# TODO: Generate and store document vectors in FAISS using the embeddings model\n",
                                    "\n",
                                    "# TODO: Define a search query\n",
                                    "\n",
                                    "# TODO: Perform a similarity search to retrieve the top 5 most relevant document chunks\n",
                                    "\n",
                                    "# TODO: Print the first 100 characters of each retrieved document\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import OpenAIEmbeddings\n",
                                    "from langchain_community.document_loaders import PyPDFLoader\n",
                                    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                                    "from langchain_community.vectorstores import FAISS\n",
                                    "\n",
                                    "# Define the file path\n",
                                    "file_path = \"data/the_adventure_of_the_blue_carbuncle.pdf\"\n",
                                    "\n",
                                    "# Create a loader for our document\n",
                                    "loader = PyPDFLoader(file_path)\n",
                                    "\n",
                                    "# Load the document\n",
                                    "docs = loader.load()\n",
                                    "\n",
                                    "# Split the document into chunks\n",
                                    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
                                    "split_docs = text_splitter.split_documents(docs)\n",
                                    "\n",
                                    "# Initialize the OpenAI embedding model\n",
                                    "embedding_model = OpenAIEmbeddings()\n",
                                    "\n",
                                    "# Generate and store document vectors in FAISS using the embeddings model\n",
                                    "vectorstore = FAISS.from_documents(split_docs, embedding_model)\n",
                                    "\n",
                                    "# Define a search query\n",
                                    "query = \"What was the main clue in the mystery?\"\n",
                                    "\n",
                                    "# Perform a similarity search to retrieve the top 5 most relevant document chunks\n",
                                    "retrieved_docs = vectorstore.similarity_search(query, k=5)\n",
                                    "\n",
                                    "# Print the first 100 characters of each retrieved document chunk\n",
                                    "for i, doc in enumerate(retrieved_docs, start=1):\n",
                                    "    snippet = doc.page_content[:100].replace(\"\\n\", \" \")\n",
                                    "    print(f\"Result {i}: {snippet}...\\n\")\n",
                                    "```\n"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
