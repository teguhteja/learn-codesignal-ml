{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Lesson 2 : Generating Document Embeddings with OpenAI\n",
                                    "\n",
                                    "\n",
                                    "Welcome back! In the previous lesson, you learned how to load and split documents using LangChain, setting the foundation for more advanced document processing tasks. Today, we will take the next step by exploring **embeddings**, a crucial concept in document processing.\n",
                                    "\n",
                                    "Embeddings are numerical representations of text data that capture the semantic meaning of words, phrases, or entire documents. They allow Large Language Models (LLMs) to understand and process text in a meaningful way. By converting text into embeddings, you can perform tasks such as similarity search, clustering, and classification.\n",
                                    "\n",
                                    "In this lesson, you will:\n",
                                    "\n",
                                    "1. Generate embeddings for document chunks using OpenAI and LangChain.\n",
                                    "2. Understand how embeddings power context retrieval systems.\n",
                                    "3. Prepare for context retrieval tasks in future lessons.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Embeddings and Language Models\n",
                                    "\n",
                                    "Embeddings play a vital role in context retrieval systems. Think of them as a way to translate human language into a format computers can compare—like giving machines their own secret decoder ring!\n",
                                    "\n",
                                    "Consider these three sentences:\n",
                                    "\n",
                                    "> 1. \"The Avengers assembled to fight Thanos\"\n",
                                    "> 2. \"Earth's mightiest heroes united against the Mad Titan\"\n",
                                    "> 3. \"My soufflé collapsed in the oven again\"\n",
                                    "\n",
                                    "Despite different wording, sentences 1 and 2 share the same meaning and will produce embeddings (vectors) that lie close together in embedding space. Sentence 3, a baking disaster, will end up far away.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Context Retrieval Systems\n",
                                    "\n",
                                    "Here’s how embeddings fit into a practical retrieval pipeline:\n",
                                    "\n",
                                    "1. **Document Processing**\n",
                                    "   Break documents into chunks (like slicing a pizza).\n",
                                    "\n",
                                    "2. **Embedding Generation**\n",
                                    "   Convert each chunk into a vector (assign each slice its own flavor profile).\n",
                                    "\n",
                                    "3. **Storage**\n",
                                    "   Store vectors in a vector database (our digital pizza fridge).\n",
                                    "\n",
                                    "4. **Query Processing**\n",
                                    "   Convert a user’s question into an embedding.\n",
                                    "\n",
                                    "5. **Similarity Search**\n",
                                    "   Find chunks whose embeddings best match the query embedding.\n",
                                    "\n",
                                    "6. **Response Generation**\n",
                                    "   Use the top-matching chunks as context for an LLM to generate an answer.\n",
                                    "\n",
                                    "*Example:*\n",
                                    "If you have a huge library of movie scripts and someone asks, “Who said ‘I’ll be back’?”, the system retrieves script passages that embed closest to that question—even if they use synonyms like “Arnold’s famous catchphrase.”\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Document Loading and Splitting\n",
                                    "\n",
                                    "Before generating embeddings, load and split your document as learned previously:\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_community.document_loaders import PyPDFLoader\n",
                                    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                                    "\n",
                                    "# 1. Define the file path\n",
                                    "file_path = \"data/the_adventure_of_the_blue_carbuncle.pdf\"\n",
                                    "\n",
                                    "# 2. Load the PDF\n",
                                    "loader = PyPDFLoader(file_path)\n",
                                    "docs = loader.load()\n",
                                    "\n",
                                    "# 3. Split into chunks\n",
                                    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
                                    "split_docs = text_splitter.split_documents(docs)\n",
                                    "```\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## OpenAI Embeddings and LangChain\n",
                                    "\n",
                                    "LangChain provides a unified interface to many embedding models. To use OpenAI’s embeddings, simply import and initialize:\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import OpenAIEmbeddings\n",
                                    "\n",
                                    "# Initialize the OpenAI embedding model\n",
                                    "embedding_model = OpenAIEmbeddings()\n",
                                    "```\n",
                                    "\n",
                                    "This class uses your existing OpenAI API key and defaults to a performant embedding model.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Configuring Embedding Model Parameters\n",
                                    "\n",
                                    "You can customize the embedding generation:\n",
                                    "\n",
                                    "```python\n",
                                    "embedding_model = OpenAIEmbeddings(\n",
                                    "    model=\"text-embedding-3-small\",  # choice of embedding model\n",
                                    "    dimensions=1536,                 # vector length\n",
                                    "    chunk_size=1000                  # batch size for text processing\n",
                                    ")\n",
                                    "```\n",
                                    "\n",
                                    "* **model**: Select between fast or more accurate embedding engines.\n",
                                    "* **dimensions**: Controls vector detail (higher = more dimensions).\n",
                                    "* **chunk\\_size**: Controls how many chunks process at once.\n",
                                    "\n",
                                    "Defaults work well for most projects. Tweak these as you gain experience.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Generating an Embedding with OpenAI\n",
                                    "\n",
                                    "Convert a single chunk into an embedding:\n",
                                    "\n",
                                    "```python\n",
                                    "# Extract the first chunk’s text\n",
                                    "document_text = split_docs[0].page_content\n",
                                    "\n",
                                    "# Generate its embedding vector\n",
                                    "embedding_vector = embedding_model.embed_query(document_text)\n",
                                    "```\n",
                                    "\n",
                                    "`embed_query()` returns a list of floats representing your text in high-dimensional space.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Inspecting Embedding Vectors\n",
                                    "\n",
                                    "Peek at the first few elements:\n",
                                    "\n",
                                    "```python\n",
                                    "print(f\"First 5 values: {embedding_vector[:5]}\")\n",
                                    "```\n",
                                    "\n",
                                    "Example output:\n",
                                    "\n",
                                    "```\n",
                                    "First 5 values: [0.01057, -0.00014, 0.00523, -0.02460, -0.01267]\n",
                                    "```\n",
                                    "\n",
                                    "Despite appearing random, these numbers encode meaning. Similar texts yield similar vectors.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Vector Databases for Embedding Storage\n",
                                    "\n",
                                    "To build a full retrieval system, store and search millions of embeddings efficiently. Vector databases excel at this:\n",
                                    "\n",
                                    "* **Chroma**: Lightweight open-source vector store.\n",
                                    "* **FAISS**: High-performance library by Facebook AI.\n",
                                    "* **Pinecone**: Managed vector database service.\n",
                                    "* **Weaviate**: Open-source search engine with vector support.\n",
                                    "\n",
                                    "These systems use Approximate Nearest Neighbors (ANN) algorithms to make similarity searches lightning-fast.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## Summary and Next Steps\n",
                                    "\n",
                                    "In this lesson you:\n",
                                    "\n",
                                    "* Learned what embeddings are and why they matter.\n",
                                    "* Saw how embeddings power context retrieval systems.\n",
                                    "* Generated and inspected embeddings using OpenAI and LangChain.\n",
                                    "* Explored vector database options for large-scale storage.\n",
                                    "\n",
                                    "Next, you’ll apply these concepts in hands-on exercises to generate different embeddings and practice similarity search. Then, we’ll integrate a vector database to build a complete retrieval pipeline. Keep up the great work!\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Creating Document Embeddings with OpenAI\n",
                                    "\n",
                                    "Your first task is to dive into the world of embeddings by generating one for a single document chunk from a PDF.\n",
                                    "\n",
                                    "Begin by initializing the OpenAIEmbeddings object.\n",
                                    "Extract the text content from one of the document chunks.\n",
                                    "Generate the embedding using the embed\\_query method on the extracted text.\n",
                                    "Display the first few elements of the resulting embedding vector.\n",
                                    "This exercise will help you understand how to convert text into a numerical representation and see how this step fits into the overall document processing pipeline. Dive in and see how embeddings bring text to life!\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import OpenAIEmbeddings\n",
                                    "from langchain_community.document_loaders import PyPDFLoader\n",
                                    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                                    "\n",
                                    "# Define the file path\n",
                                    "file_path = \"data/the_adventure_of_the_blue_carbuncle.pdf\"\n",
                                    "\n",
                                    "# Create a loader for our document\n",
                                    "loader = PyPDFLoader(file_path)\n",
                                    "\n",
                                    "# Load the document\n",
                                    "docs = loader.load()\n",
                                    "\n",
                                    "# Split the document into chunks\n",
                                    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
                                    "split_docs = text_splitter.split_documents(docs)\n",
                                    "\n",
                                    "# TODO: Initialize the OpenAIEmbeddings object\n",
                                    "\n",
                                    "# TODO: Generate embeddings for the first document chunk\n",
                                    "\n",
                                    "# TODO: Print the first few elements of the embedding vector\n",
                                    "\n",
                                    "```\n",
                                    "Here’s how you can complete the stub to generate and inspect an embedding for the first chunk:\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import OpenAIEmbeddings\n",
                                    "from langchain_community.document_loaders import PyPDFLoader\n",
                                    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                                    "\n",
                                    "# Define the file path\n",
                                    "file_path = \"data/the_adventure_of_the_blue_carbuncle.pdf\"\n",
                                    "\n",
                                    "# 1. Load and split the document\n",
                                    "loader = PyPDFLoader(file_path)\n",
                                    "docs = loader.load()\n",
                                    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
                                    "split_docs = text_splitter.split_documents(docs)\n",
                                    "\n",
                                    "# 2. Initialize the embeddings model\n",
                                    "embeddings = OpenAIEmbeddings()  # you can pass your OpenAI API key here if needed\n",
                                    "\n",
                                    "# 3. Extract text from the first chunk\n",
                                    "first_chunk_text = split_docs[0].page_content\n",
                                    "\n",
                                    "# 4. Generate the embedding vector\n",
                                    "embedding_vector = embeddings.embed_query(first_chunk_text)\n",
                                    "\n",
                                    "# 5. Display the first few elements\n",
                                    "print(\"First 5 dimensions of the embedding vector:\")\n",
                                    "print(embedding_vector[:5])\n",
                                    "```\n",
                                    "\n",
                                    "**What this does:**\n",
                                    "\n",
                                    "1. **Loads** your PDF and **splits** it into ≈1 000-token chunks with 100-token overlap.\n",
                                    "2. **Initializes** the `OpenAIEmbeddings` object (make sure your environment variable `OPENAI_API_KEY` is set, or pass `openai_api_key=\"...\"` to the constructor).\n",
                                    "3. **Extracts** the raw text of the first chunk.\n",
                                    "4. **Calls** `embed_query(...)`, which returns a list of floats (the embedding).\n",
                                    "5. **Prints** the first five dimensions so you can see how the text is numerically represented.\n",
                                    "\n",
                                    "When you run this, you should see output like:\n",
                                    "\n",
                                    "```\n",
                                    "First 5 dimensions of the embedding vector:\n",
                                    "[0.01234567, -0.00432109, 0.02345678, ...]\n",
                                    "```\n",
                                    "\n",
                                    "Those numbers are the beginning of your \\~1 536-dimensional embedding (exact size depends on the model).\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Experiment with Embedding Parameters\n",
                                    "\n",
                                    "\n",
                                    "Now, let's take it a step further by experimenting with different configurations for the OpenAIEmbeddings object.\n",
                                    "\n",
                                    "Modify the OpenAIEmbeddings instance to use:\n",
                                    "\n",
                                    "model=\"text-embedding-3-large\"\n",
                                    "dimensions=2048\n",
                                    "Observe the printed values to see how these changes affect the results. This exercise will help you understand the flexibility of embeddings and how different settings can impact your document processing tasks.\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import OpenAIEmbeddings\n",
                                    "from langchain_community.document_loaders import PyPDFLoader\n",
                                    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                                    "\n",
                                    "# Define the file path\n",
                                    "file_path = \"data/the_adventure_of_the_blue_carbuncle.pdf\"\n",
                                    "\n",
                                    "# Create a loader for our document\n",
                                    "loader = PyPDFLoader(file_path)\n",
                                    "\n",
                                    "# Load the document\n",
                                    "docs = loader.load()\n",
                                    "\n",
                                    "# Split the document into chunks\n",
                                    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
                                    "split_docs = text_splitter.split_documents(docs)\n",
                                    "\n",
                                    "# TODO: Initialize the OpenAIEmbeddings object with different parameters, such as:\n",
                                    "# - model = \"text-embedding-3-large\"\n",
                                    "# - dimensions = 2048\n",
                                    "embedding_model = OpenAIEmbeddings()\n",
                                    "\n",
                                    "# Generate embeddings for the first document chunk\n",
                                    "embedding_vector = embedding_model.embed_query(split_docs[0].page_content)\n",
                                    "\n",
                                    "# Print the first few elements of the embedding vector\n",
                                    "print(embedding_vector[:5])\n",
                                    "```\n",
                                    "\n",
                                    "Here’s the updated snippet showing how to pass in a different model name and override the embedding dimensionality, plus a quick check of the resulting vector size:\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import OpenAIEmbeddings\n",
                                    "from langchain_community.document_loaders import PyPDFLoader\n",
                                    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                                    "\n",
                                    "# Define the file path\n",
                                    "file_path = \"data/the_adventure_of_the_blue_carbuncle.pdf\"\n",
                                    "\n",
                                    "# 1. Load and split the document\n",
                                    "loader = PyPDFLoader(file_path)\n",
                                    "docs = loader.load()\n",
                                    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
                                    "split_docs = text_splitter.split_documents(docs)\n",
                                    "\n",
                                    "# 2. Initialize the embeddings model with custom settings\n",
                                    "embedding_model = OpenAIEmbeddings(\n",
                                    "    model=\"text-embedding-3-large\",  # switch to the larger embedding model\n",
                                    "    dimensions=2048                  # override default dimensionality\n",
                                    "    # (ensure your LangChain version supports this parameter)\n",
                                    ")\n",
                                    "\n",
                                    "# 3. Generate embeddings for the first chunk\n",
                                    "first_chunk_text = split_docs[0].page_content\n",
                                    "embedding_vector = embedding_model.embed_query(first_chunk_text)\n",
                                    "\n",
                                    "# 4. Inspect the output\n",
                                    "print(f\"Embedding vector length: {len(embedding_vector)}\")\n",
                                    "print(\"First 5 dimensions:\", embedding_vector[:5])\n",
                                    "```\n",
                                    "\n",
                                    "**What to look for when you run this:**\n",
                                    "\n",
                                    "* **Vector length** should now report `2048`, confirming the dimensionality change.\n",
                                    "* **The numerical values** in `embedding_vector[:5]` will differ from your previous run (and from the smaller-model output), reflecting how “text-embedding-3-large” encodes text in a higher-capacity space.\n",
                                    "\n",
                                    "Feel free to experiment with other model names or dimensions to see how the geometry of your embedding space shifts!\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "id": "175ae1e4",
                           "metadata": {},
                           "source": [
                                    "## Fix the Embedding Model Bug\n",
                                    "\n",
                                    "Great job on learning how to load and split documents! Now, let's troubleshoot a code that's causing errors. Your task is to find and fix this bug to ensure the embeddings are generated correctly.\n",
                                    "\n",
                                    "This exercise should help you understand the difference between embedding models and chat models. Dive in and enhance your skills!\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import OpenAIEmbeddings\n",
                                    "from langchain_community.document_loaders import PyPDFLoader\n",
                                    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                                    "\n",
                                    "# Define the file path\n",
                                    "file_path = \"data/the_adventure_of_the_blue_carbuncle.pdf\"\n",
                                    "\n",
                                    "# Create a loader for our document\n",
                                    "loader = PyPDFLoader(file_path)\n",
                                    "\n",
                                    "# Load the document\n",
                                    "docs = loader.load()\n",
                                    "\n",
                                    "# Split the document into chunks\n",
                                    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
                                    "split_docs = text_splitter.split_documents(docs)\n",
                                    "\n",
                                    "# Initialize the OpenAIEmbeddings object\n",
                                    "embedding_model = OpenAIEmbeddings(\n",
                                    "    model=\"gpt-4\",\n",
                                    "    dimensions=2048\n",
                                    ")\n",
                                    "\n",
                                    "# Generate embeddings for the first document chunk\n",
                                    "embedding_vector = embedding_model.embed_query(split_docs[0].page_content)\n",
                                    "\n",
                                    "# Print the first few elements of the embedding vector\n",
                                    "print(embedding_vector[:5])\n",
                                    "```\n",
                                    "\n",
                                    "The error here is that you’re trying to use a **chat** model (“gpt-4”) with the embeddings API. Chat models don’t support `embed_query`, so you’ll get an error. To fix it, switch to a supported **embedding** model—e.g. `\"text-embedding-3-large\"`—and (if needed) set your desired `dimensions`. Here’s the corrected snippet:\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import OpenAIEmbeddings\n",
                                    "from langchain_community.document_loaders import PyPDFLoader\n",
                                    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                                    "\n",
                                    "# Define the file path\n",
                                    "file_path = \"data/the_adventure_of_the_blue_carbuncle.pdf\"\n",
                                    "\n",
                                    "# Load and split the document\n",
                                    "loader = PyPDFLoader(file_path)\n",
                                    "docs = loader.load()\n",
                                    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
                                    "split_docs = text_splitter.split_documents(docs)\n",
                                    "\n",
                                    "# ❌ Buggy: chat model cannot embed\n",
                                    "# embedding_model = OpenAIEmbeddings(\n",
                                    "#     model=\"gpt-4\",\n",
                                    "#     dimensions=2048\n",
                                    "# )\n",
                                    "\n",
                                    "# ✅ Fixed: use an embedding model\n",
                                    "embedding_model = OpenAIEmbeddings(\n",
                                    "    model=\"text-embedding-3-large\",\n",
                                    "    dimensions=2048\n",
                                    ")\n",
                                    "\n",
                                    "# Generate embeddings for the first chunk\n",
                                    "first_chunk_text = split_docs[0].page_content\n",
                                    "embedding_vector = embedding_model.embed_query(first_chunk_text)\n",
                                    "\n",
                                    "# Inspect the output\n",
                                    "print(f\"Embedding vector length: {len(embedding_vector)}\")  # should be 2048\n",
                                    "print(\"First 5 dimensions:\", embedding_vector[:5])\n",
                                    "```\n",
                                    "\n",
                                    "**Key takeaway:**\n",
                                    "\n",
                                    "* **Chat models** like `gpt-4` are for conversation; they don’t support `embed_query`.\n",
                                    "* **Embedding models** (e.g. `text-embedding-3-large`, `text-embedding-ada-002`) are designed to return numerical vectors of fixed dimension.\n",
                                    "\n",
                                    "With this change, your call to `embed_query` will succeed, returning a 2048-dimensional vector you can inspect or feed into downstream tasks.\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Exploring Embedding Dimensions\n",
                                    "\n",
                                    "Well done learning about generating embeddings! Now, let's explore the dimensionality of these embeddings to deepen your understanding.\n",
                                    "\n",
                                    "Your task is to print the length of the embedding vector using the len() function to see its dimensionality. Observe how the vector length will match the dimension specified in the OpenAIEmbeddings initialization.\n",
                                    "\n",
                                    "This exercise will help you grasp how the dimensions of an embedding relate to its informational capacity and computational needs.\n",
                                    "\n",
                                    "```python\n",
                                    "from langchain_openai import OpenAIEmbeddings\n",
                                    "from langchain_community.document_loaders import PyPDFLoader\n",
                                    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                                    "\n",
                                    "# Define the file path\n",
                                    "file_path = \"data/the_adventure_of_the_blue_carbuncle.pdf\"\n",
                                    "\n",
                                    "# Create a loader for our document\n",
                                    "loader = PyPDFLoader(file_path)\n",
                                    "\n",
                                    "# Load the document\n",
                                    "docs = loader.load()\n",
                                    "\n",
                                    "# Split the document into chunks\n",
                                    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
                                    "split_docs = text_splitter.split_documents(docs)\n",
                                    "\n",
                                    "# Initialize the OpenAIEmbeddings object\n",
                                    "embedding_model = OpenAIEmbeddings(\n",
                                    "    model=\"text-embedding-3-large\",\n",
                                    "    dimensions=2048\n",
                                    ")\n",
                                    "\n",
                                    "# Generate embeddings for the first document chunk\n",
                                    "embedding_vector = embedding_model.embed_query(split_docs[0].page_content)\n",
                                    "\n",
                                    "# TODO: Print the length of the embedding vector to explore its dimensionality\n",
                                    "```\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "# ... previous code ...\n",
                                    "\n",
                                    "# Generate embeddings for the first document chunk\n",
                                    "embedding_vector = embedding_model.embed_query(split_docs[0].page_content)\n",
                                    "\n",
                                    "# Print the length of the embedding vector\n",
                                    "print(f\"Embedding dimensionality: {len(embedding_vector)}\")\n",
                                    "```\n",
                                    "\n",
                                    "When you run this, you should see:\n",
                                    "\n",
                                    "```\n",
                                    "Embedding dimensionality: 2048\n",
                                    "```\n",
                                    "\n",
                                    "confirming that your embedding vector has 2048 dimensions.\n"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
