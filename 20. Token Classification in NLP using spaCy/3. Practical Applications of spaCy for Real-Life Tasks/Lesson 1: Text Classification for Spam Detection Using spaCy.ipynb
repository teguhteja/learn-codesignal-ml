{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Lesson 1: Text Classification for Spam Detection Using spaCy\n",
                                    "\n",
                                    "Introduction to Text Classification\n",
                                    "Welcome! In today's lesson, we will delve into the world of Text Classification. Text Classification refers to the process of categorizing or classifying text into organized groups. It explains the significance of text in Natural Language Processing (NLP), as it helps in organizing data, simplifying search, enabling proper mapping and consistency.\n",
                                    "\n",
                                    "In this practical exercise of spam detection, you will see how Text Classification plays a considerable role. Spam detection is a real-world problem where we differentiate unwanted emails (spam) from real ones (ham).\n",
                                    "\n",
                                    "At a high level, text classification involves converting text data into some kind of numerical feature vectors, which can then be used by machine learning models to categorize. We will dig deeper into this as we progress through the lesson. Let's get started.\n",
                                    "\n",
                                    "Setting up a spaCy Text Classification Pipeline\n",
                                    "Before beginning the coding exercise, we need to understand the concept of pipelines in spaCy. In simple terms, a pipeline is a sequence of data processing components in SpaCy. It is designed to take raw text data and perform several operations to convert the text data into valuable insights and information.\n",
                                    "\n",
                                    "```python\n",
                                    "# Load a blank spaCy model\n",
                                    "nlp = spacy.blank(\"en\")\n",
                                    "```\n",
                                    "\n",
                                    "In previous courses, spacy.load(\"en_core_web_sm\") was utilized to load a pre-trained model with components for common NLP tasks. In contrast, spacy.blank(\"en\") initializes a blank model specific for English, allowing for customization by adding only the necessary components for specific tasks like text classification for spam detection.\n",
                                    "\n",
                                    "Data Preparation and Labeling\n",
                                    "Effective data preparation is a critical step in any machine learning project. In text classification, labeled data plays a crucial role. The labels act as a form of instruction set for the model to learn and understand the patterns in the data.\n",
                                    "\n",
                                    "```python\n",
                                    "# Sample dataset with labels\n",
                                    "training_data = [\n",
                                    "    (\"Buy cheap watches now!\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Get your discount codes today\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    # More examples...\n",
                                    "]\n",
                                    "```\n",
                                    "\n",
                                    "This dataset contains a mix of both types of messages that will help train the model effectively. Each text is paired with annotations indicating whether it is spam or ham.\n",
                                    "\n",
                                    "Adding and Configuring Text Classifier in the Pipeline\n",
                                    "With our dataset and initial pipeline setup in place, the next step is to incorporate a text classifier into the pipeline. We'll utilize the TextCatBOW (Bag-of-Words) configuration for this purpose. The Bag-of-Words model represents a text as a 'bag' of its words, disregarding grammar and word order but focusing on word frequency, which is effective for capturing patterns.\n",
                                    "\n",
                                    "```python\n",
                                    "# Add the text classifier to the pipeline\n",
                                    "config = {\n",
                                    "    \"threshold\": 0.5,  # Decision threshold for labels\n",
                                    "    \"model\": {\n",
                                    "        \"@architectures\": \"spacy.TextCatBOW.v1\",  # Classifier architecture\n",
                                    "        \"exclusive_classes\": True,  # Mutually exclusive labels\n",
                                    "        \"ngram_size\": 1,  # Use unigrams\n",
                                    "        \"no_output_layer\": False  # Include output layer\n",
                                    "    }\n",
                                    "}\n",
                                    "textcat = nlp.add_pipe(\"textcat\", config=config)\n",
                                    "textcat.add_label(\"SPAM\")\n",
                                    "textcat.add_label(\"HAM\")\n",
                                    "```\n",
                                    "\n",
                                    "This configuration allows the pipeline to leverage the Bag-of-Words architecture in distinguishing between different types of text data, tailored specifically for spam detection.\n",
                                    "\n",
                                    "Training the Text Classifier\n",
                                    "Now that our pipeline has the text classifier, we can proceed to train it. Model training essentially involves running the model through a loop where it can learn from the training data as well as its mistakes (also referred to as 'loss'). Each run is an iteration, and it is common to run these iterative training loops multiple times to fine-tune the model.\n",
                                    "\n",
                                    "```python\n",
                                    "# Training the classifier\n",
                                    "def train_spam_detector(training_data, nlp, textcat, n_iter=30):\n",
                                    "    optimizer = nlp.initialize(lambda: (\n",
                                    "        Example.from_dict(nlp.make_doc(text), annotations)\n",
                                    "        for text, annotations in training_data\n",
                                    "    ))\n",
                                    "    \n",
                                    "    for i in range(n_iter):\n",
                                    "        losses = {}\n",
                                    "        for text, annotations in training_data:\n",
                                    "            doc = nlp.make_doc(text)\n",
                                    "            example = Example.from_dict(doc, annotations)\n",
                                    "            nlp.update([example], sgd=optimizer, losses=losses)\n",
                                    "        print(f\"Iteration {i} - Loss: {losses}\")\n",
                                    "\n",
                                    "train_spam_detector(training_data, nlp, textcat)\n",
                                    "```\n",
                                    "\n",
                                    "In the train_spam_detector() function, several critical methods are employed:\n",
                                    "- **nlp.initialize**: This method prepares the pipeline and optimizer for training. It sets up the weights of the model according to the architecture and configuration.\n",
                                    "- **nlp.make_doc**: This converts a text string into a spaCy Doc object, which is a container that holds the processed text and is integral to how spaCy handles text data.\n",
                                    "- **nlp.update**: This function performs an optimization step during training. It takes a batch of examples and updates the model's weights, improving its accuracy based on the loss computed.\n",
                                    "\n",
                                    "This output shows the loss at each iteration during the training process, which helps in understanding how the model is learning and improving. The reduction in loss value signifies the model is better classifying texts over iterations.\n",
                                    "\n",
                                    "Model Evaluation\n",
                                    "Once the model is trained, it's time to evaluate its performance. To achieve this, we test the model on some new data that it hasn't seen during the training process. This provides insights into how well the model generalizes its learning to unseen data.\n",
                                    "\n",
                                    "```python\n",
                                    "# Test the trained model\n",
                                    "test_texts = [\n",
                                    "    \"Exclusive deal just for you!\",\n",
                                    "    \"Can we reschedule the meeting?\",\n",
                                    "    ...\n",
                                    "]\n",
                                    "\n",
                                    "for text in test_texts:\n",
                                    "    doc = nlp(text)\n",
                                    "    print(f\"Text: {text}\")\n",
                                    "    for cat, score in doc.cats.items():\n",
                                    "        print(f\"  {cat}: {score:.4f}\")\n",
                                    "    print(\"\\n\")\n",
                                    "\n",
                                    "# Output:\n",
                                    "# Text: Exclusive deal just for you!\n",
                                    "#   SPAM: 0.5940\n",
                                    "#   HAM: 0.4060\n",
                                    "\n",
                                    "# Text: Can we reschedule the meeting?\n",
                                    "#   SPAM: 0.3539\n",
                                    "#   HAM: 0.6461\n",
                                    "```\n",
                                    "\n",
                                    "Great work! In this lesson, you have delved deep into Text Classification using spaCy, specifically focusing on the scenario of spam detection. You learned how to set up a text classification pipeline, prepare data for training, add and configure a text classifier to the pipeline using the Bag-of-Words model, train the model, and evaluate its performance. The practical exercise allowed you to apply these concepts and gain real hands-on experience in this versatile field of Natural Language Processing. In the next lessons, we will continue to build on these foundations and explore more advanced topics. Keep practicing and happy coding!"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Spam Detection: Modify Test Texts\n",
                                    "\n",
                                    "Stellar Navigator, can you modify the test_texts in the code? Replace the existing texts in test_texts with sentences that our model would classify as SPAM. Once you've replaced the sentences, run the code to confirm that the model correctly tags your sentences.\n",
                                    "\n",
                                    "```python\n",
                                    "import spacy\n",
                                    "from spacy.training import Example\n",
                                    "\n",
                                    "\n",
                                    "# Load a blank spaCy model\n",
                                    "nlp = spacy.blank(\"en\")\n",
                                    "\n",
                                    "# Enhanced sample dataset\n",
                                    "training_data = [\n",
                                    "    (\"Buy cheap watches now!\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Get your discount codes today\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Call me asap\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}}),\n",
                                    "    (\"Lunch meeting at 1 pm?\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}})\n",
                                    "]\n",
                                    "\n",
                                    "# Add the text classifier to the pipeline\n",
                                    "config = {\n",
                                    "    \"threshold\": 0.5,\n",
                                    "    \"model\": {\n",
                                    "        \"@architectures\": \"spacy.TextCatBOW.v1\",\n",
                                    "        \"exclusive_classes\": True,\n",
                                    "        \"ngram_size\": 1,\n",
                                    "        \"no_output_layer\": False\n",
                                    "    }\n",
                                    "}\n",
                                    "textcat = nlp.add_pipe(\"textcat\", config=config)\n",
                                    "textcat.add_label(\"SPAM\")\n",
                                    "textcat.add_label(\"HAM\")\n",
                                    "\n",
                                    "# Training the classifier\n",
                                    "def train_spam_detector(training_data, nlp, textcat, n_iter=30):\n",
                                    "    optimizer = nlp.initialize(lambda: (\n",
                                    "        Example.from_dict(nlp.make_doc(text), annotations)\n",
                                    "        for text, annotations in training_data\n",
                                    "    ))\n",
                                    "  \n",
                                    "    for i in range(n_iter):\n",
                                    "        losses = {}\n",
                                    "        for text, annotations in training_data:\n",
                                    "            doc = nlp.make_doc(text)\n",
                                    "            example = Example.from_dict(doc, annotations)\n",
                                    "            nlp.update([example], sgd=optimizer, losses=losses)\n",
                                    "\n",
                                    "\n",
                                    "train_spam_detector(training_data, nlp, textcat)\n",
                                    "\n",
                                    "\n",
                                    "# TODO: Replace the texts with sentences that our model would classify as SPAM\n",
                                    "test_texts = [\n",
                                    "    \"Let's discuss our project over a cup of coffee\",\n",
                                    "    \"Do not forget our meeting tomorrow morning\"\n",
                                    "]\n",
                                    "\n",
                                    "for text in test_texts:\n",
                                    "    doc = nlp(text)\n",
                                    "    print(f\"Text: {text}\")\n",
                                    "    for cat, score in doc.cats.items():\n",
                                    "        print(f\"  {cat}: {score:.4f}\")\n",
                                    "    print(\"\\n\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Here’s the modified code with the `test_texts` replaced by sentences that the model would likely classify as SPAM. The new sentences include common phrases often associated with spam messages:\n",
                                    "\n",
                                    "```python\n",
                                    "import spacy\n",
                                    "from spacy.training import Example\n",
                                    "\n",
                                    "# Load a blank spaCy model\n",
                                    "nlp = spacy.blank(\"en\")\n",
                                    "\n",
                                    "# Enhanced sample dataset\n",
                                    "training_data = [\n",
                                    "    (\"Buy cheap watches now!\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Get your discount codes today\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Call me asap\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}}),\n",
                                    "    (\"Lunch meeting at 1 pm?\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}})\n",
                                    "]\n",
                                    "\n",
                                    "# Add the text classifier to the pipeline\n",
                                    "config = {\n",
                                    "    \"threshold\": 0.5,\n",
                                    "    \"model\": {\n",
                                    "        \"@architectures\": \"spacy.TextCatBOW.v1\",\n",
                                    "        \"exclusive_classes\": True,\n",
                                    "        \"ngram_size\": 1,\n",
                                    "        \"no_output_layer\": False\n",
                                    "    }\n",
                                    "}\n",
                                    "textcat = nlp.add_pipe(\"textcat\", config=config)\n",
                                    "textcat.add_label(\"SPAM\")\n",
                                    "textcat.add_label(\"HAM\")\n",
                                    "\n",
                                    "# Training the classifier\n",
                                    "def train_spam_detector(training_data, nlp, textcat, n_iter=30):\n",
                                    "    optimizer = nlp.initialize(lambda: (\n",
                                    "        Example.from_dict(nlp.make_doc(text), annotations)\n",
                                    "        for text, annotations in training_data\n",
                                    "    ))\n",
                                    "    \n",
                                    "    for i in range(n_iter):\n",
                                    "        losses = {}\n",
                                    "        for text, annotations in training_data:\n",
                                    "            doc = nlp.make_doc(text)\n",
                                    "            example = Example.from_dict(doc, annotations)\n",
                                    "            nlp.update([example], sgd=optimizer, losses=losses)\n",
                                    "\n",
                                    "train_spam_detector(training_data, nlp, textcat)\n",
                                    "\n",
                                    "# Replace the texts with sentences that our model would classify as SPAM\n",
                                    "test_texts = [\n",
                                    "    \"Congratulations! You've won a $1000 gift card.\",\n",
                                    "    \"Click here to claim your free trial now!\",\n",
                                    "    \"Act now! Limited time offer just for you.\",\n",
                                    "    \"You have been selected for a special promotion!\",\n",
                                    "    \"Earn money from home with this simple trick.\"\n",
                                    "]\n",
                                    "\n",
                                    "for text in test_texts:\n",
                                    "    doc = nlp(text)\n",
                                    "    print(f\"Text: {text}\")\n",
                                    "    for cat, score in doc.cats.items():\n",
                                    "        print(f\"  {cat}: {score:.4f}\")\n",
                                    "    print(\"\\n\")\n",
                                    "```\n",
                                    "\n",
                                    "### Explanation of Changes:\n",
                                    "\n",
                                    "1. **Updated `test_texts`**: The sentences in `test_texts` have been replaced with typical spam messages that are likely to be classified as SPAM by the model.\n",
                                    "\n",
                                    "2. **Model Evaluation**: The code will now evaluate these new test sentences, and you should see the model's confidence scores for each category (SPAM and HAM) printed out.\n",
                                    "\n",
                                    "This setup will help you confirm that the model correctly identifies spam messages based on the training data provided.\n",
                                    "\n",
                                    "Execution Result:\n",
                                    "\n",
                                    "```\n",
                                    "Text: Congratulations! You've won a $1000 gift card.\n",
                                    "  SPAM: 0.5514\n",
                                    "  HAM: 0.4486\n",
                                    "\n",
                                    "\n",
                                    "Text: Click here to claim your free trial now!\n",
                                    "  SPAM: 0.6495\n",
                                    "  HAM: 0.3505\n",
                                    "\n",
                                    "\n",
                                    "Text: Act now! Limited time offer just for you.\n",
                                    "  SPAM: 0.6017\n",
                                    "  HAM: 0.3983\n",
                                    "\n",
                                    "\n",
                                    "Text: You have been selected for a special promotion!\n",
                                    "  SPAM: 0.5514\n",
                                    "  HAM: 0.4486\n",
                                    "\n",
                                    "\n",
                                    "Text: Earn money from home with this simple trick.\n",
                                    "  SPAM: 0.5000\n",
                                    "  HAM: 0.5000\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Enhance Training Data for Model\n",
                                    "\n",
                                    "Stellar Navigator, we have a blank in our training_data. Add the extra provided spam and ham examples to it to enhance the model. The examples are:\n",
                                    "\n",
                                    "```Python\n",
                                    "(\"Get rich quick! Visit now\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "(\"Congratulations! You've won a prize\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "(\"Important information about your account\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}}),\n",
                                    "(\"Don't miss our meeting tomorrow\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}})\n",
                                    "```\n",
                                    "\n",
                                    "Check the changes these cause in the model's performance.\n",
                                    "\n",
                                    "Here’s the updated code with the additional spam and ham examples added to the `training_data`. This will enhance the model's training set, allowing it to learn from a broader range of examples. After updating the training data, the model will be retrained, and we can evaluate its performance on the test texts.\n",
                                    "\n",
                                    "```python\n",
                                    "import spacy\n",
                                    "from spacy.training import Example\n",
                                    "\n",
                                    "# Load a blank spaCy model\n",
                                    "nlp = spacy.blank(\"en\")\n",
                                    "\n",
                                    "# Enhanced sample dataset with additional examples\n",
                                    "training_data = [\n",
                                    "    (\"Buy cheap watches now!\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Get your discount codes today\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Call me asap\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}}),\n",
                                    "    (\"Lunch meeting at 1 pm?\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}}),\n",
                                    "    (\"Get rich quick! Visit now\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Congratulations! You've won a prize\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Important information about your account\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}}),\n",
                                    "    (\"Don't miss our meeting tomorrow\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}})\n",
                                    "]\n",
                                    "\n",
                                    "# Add the text classifier to the pipeline\n",
                                    "config = {\n",
                                    "    \"threshold\": 0.5,\n",
                                    "    \"model\": {\n",
                                    "        \"@architectures\": \"spacy.TextCatBOW.v1\",\n",
                                    "        \"exclusive_classes\": True,\n",
                                    "        \"ngram_size\": 1,\n",
                                    "        \"no_output_layer\": False\n",
                                    "    }\n",
                                    "}\n",
                                    "textcat = nlp.add_pipe(\"textcat\", config=config)\n",
                                    "textcat.add_label(\"SPAM\")\n",
                                    "textcat.add_label(\"HAM\")\n",
                                    "\n",
                                    "# Training the classifier\n",
                                    "def train_spam_detector(training_data, nlp, textcat, n_iter=30):\n",
                                    "    optimizer = nlp.initialize(lambda: (\n",
                                    "        Example.from_dict(nlp.make_doc(text), annotations)\n",
                                    "        for text, annotations in training_data\n",
                                    "    ))\n",
                                    "    \n",
                                    "    for i in range(n_iter):\n",
                                    "        losses = {}\n",
                                    "        for text, annotations in training_data:\n",
                                    "            doc = nlp.make_doc(text)\n",
                                    "            example = Example.from_dict(doc, annotations)\n",
                                    "            nlp.update([example], sgd=optimizer, losses=losses)\n",
                                    "\n",
                                    "train_spam_detector(training_data, nlp, textcat)\n",
                                    "\n",
                                    "# Replace the texts with sentences that our model would classify as SPAM\n",
                                    "test_texts = [\n",
                                    "    \"Congratulations! You've won a $1000 gift card.\",\n",
                                    "    \"Click here to claim your free trial now!\",\n",
                                    "    \"Act now! Limited time offer just for you.\",\n",
                                    "    \"You have been selected for a special promotion!\",\n",
                                    "    \"Earn money from home with this simple trick.\"\n",
                                    "]\n",
                                    "\n",
                                    "for text in test_texts:\n",
                                    "    doc = nlp(text)\n",
                                    "    print(f\"Text: {text}\")\n",
                                    "    for cat, score in doc.cats.items():\n",
                                    "        print(f\"  {cat}: {score:.4f}\")\n",
                                    "    print(\"\\n\")\n",
                                    "```\n",
                                    "\n",
                                    "### Explanation of Changes:\n",
                                    "\n",
                                    "1. **Updated `training_data`**: The additional spam and ham examples have been added to the `training_data` list. This includes phrases that are commonly associated with spam and legitimate messages.\n",
                                    "\n",
                                    "2. **Model Training**: The model is retrained with the enhanced dataset, which should improve its ability to classify texts accurately.\n",
                                    "\n",
                                    "3. **Model Evaluation**: The same test texts are evaluated to see how the changes in training data affect the model's performance.\n",
                                    "\n",
                                    "### Expected Outcome:\n",
                                    "\n",
                                    "After running the updated code, you should see the model's confidence scores for each test text. The additional training examples should help the model better distinguish between spam and ham messages, potentially leading to improved accuracy in its classifications. \n",
                                    "\n",
                                    "You can expect the output to show the confidence scores for SPAM and HAM categories for each test text, reflecting the model's performance after the enhancements.\n",
                                    "\n",
                                    "Execution Result:\n",
                                    "\n",
                                    "```sh\n",
                                    "Text: Congratulations! You've won a $1000 gift card.\n",
                                    "  SPAM: 0.8188\n",
                                    "  HAM: 0.1812\n",
                                    "\n",
                                    "\n",
                                    "Text: Click here to claim your free trial now!\n",
                                    "  SPAM: 0.6716\n",
                                    "  HAM: 0.3284\n",
                                    "\n",
                                    "\n",
                                    "Text: Act now! Limited time offer just for you.\n",
                                    "  SPAM: 0.6710\n",
                                    "  HAM: 0.3290\n",
                                    "\n",
                                    "\n",
                                    "Text: You have been selected for a special promotion!\n",
                                    "  SPAM: 0.6967\n",
                                    "  HAM: 0.3033\n",
                                    "\n",
                                    "\n",
                                    "Text: Earn money from home with this simple trick.\n",
                                    "  SPAM: 0.4943\n",
                                    "  HAM: 0.5057\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Add Extra Category to Classifier\n",
                                    "\n",
                                    "Great work, stellar navigator! Now, let's modify our text classifier to recognize a new category \"PROMOTION\". Your task is to add an appropriate TODO in the code to allow our model to identify this new category.\n",
                                    "\n",
                                    "```python\n",
                                    "import spacy\n",
                                    "from spacy.training import Example\n",
                                    "\n",
                                    "# Load a blank spaCy model\n",
                                    "nlp = spacy.blank(\"en\")\n",
                                    "\n",
                                    "# Enhanced sample dataset with an additional category PROMOTION\n",
                                    "training_data = [\n",
                                    "    (\"Buy cheap watches now!\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0, \"PROMOTION\": 0}}),\n",
                                    "    (\"Get your discount codes today\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0, \"PROMOTION\": 0}}),\n",
                                    "    (\"Call me asap\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1, \"PROMOTION\": 0}}),\n",
                                    "    (\"Lunch meeting at 1 pm?\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1, \"PROMOTION\": 0}}),\n",
                                    "    (\"Limited time offer, shop now!\", {\"cats\": {\"SPAM\": 0, \"HAM\": 0, \"PROMOTION\": 1}}),\n",
                                    "    (\"Free shipping on all orders!\", {\"cats\": {\"SPAM\": 0, \"HAM\": 0, \"PROMOTION\": 1}})\n",
                                    "]\n",
                                    "\n",
                                    "# Add the text classifier to the pipeline with extra category\n",
                                    "config = {\n",
                                    "    \"threshold\": 0.5,\n",
                                    "    \"model\": {\n",
                                    "        \"@architectures\": \"spacy.TextCatBOW.v1\",\n",
                                    "        \"exclusive_classes\": True,\n",
                                    "        \"ngram_size\": 1,\n",
                                    "        \"no_output_layer\": False\n",
                                    "    }\n",
                                    "}\n",
                                    "textcat = nlp.add_pipe(\"textcat\", config=config)\n",
                                    "textcat.add_label(\"SPAM\")\n",
                                    "textcat.add_label(\"HAM\")\n",
                                    "# TODO: Add the label for the extra category\n",
                                    "\n",
                                    "# Training the classifier\n",
                                    "def train_spam_detector(training_data, nlp, textcat, n_iter=30):\n",
                                    "    optimizer = nlp.initialize(lambda: (\n",
                                    "        Example.from_dict(nlp.make_doc(text), annotations)\n",
                                    "        for text, annotations in training_data\n",
                                    "    ))\n",
                                    "    \n",
                                    "    for i in range(n_iter):\n",
                                    "        losses = {}\n",
                                    "        for text, annotations in training_data:\n",
                                    "            doc = nlp.make_doc(text)\n",
                                    "            example = Example.from_dict(doc, annotations)\n",
                                    "            nlp.update([example], sgd=optimizer, losses=losses)\n",
                                    "        print(f\"Iteration {i} - Loss: {losses}\")\n",
                                    "\n",
                                    "train_spam_detector(training_data, nlp, textcat)\n",
                                    "\n",
                                    "# Test the trained model with new texts including the PROMOTION category\n",
                                    "test_texts = [\n",
                                    "    \"Exclusive deal just for you!\",\n",
                                    "    \"Can we reschedule the meeting?\",\n",
                                    "    \"Limited time offer, shop now!\",\n",
                                    "    \"Free shipping on all orders!\"\n",
                                    "]\n",
                                    "\n",
                                    "for text in test_texts:\n",
                                    "    doc = nlp(text)\n",
                                    "    print(f\"Text: {text}\")\n",
                                    "    for cat, score in doc.cats.items():\n",
                                    "        print(f\"  {cat}: {score:.4f}\")\n",
                                    "    print(\"\\n\")\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "To modify your text classifier to recognize the new category \"PROMOTION\", you need to add a label for this category in the code. Here’s the updated code with the appropriate TODO implemented:\n",
                                    "\n",
                                    "import spacy\n",
                                    "from spacy.training import Example\n",
                                    "\n",
                                    "# Load a blank spaCy model\n",
                                    "nlp = spacy.blank(\"en\")\n",
                                    "\n",
                                    "# Enhanced sample dataset with an additional category PROMOTION\n",
                                    "training_data = [\n",
                                    "    (\"Buy cheap watches now!\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0, \"PROMOTION\": 0}}),\n",
                                    "    (\"Get your discount codes today\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0, \"PROMOTION\": 0}}),\n",
                                    "    (\"Call me asap\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1, \"PROMOTION\": 0}}),\n",
                                    "    (\"Lunch meeting at 1 pm?\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1, \"PROMOTION\": 0}}),\n",
                                    "    (\"Limited time offer, shop now!\", {\"cats\": {\"SPAM\": 0, \"HAM\": 0, \"PROMOTION\": 1}}),\n",
                                    "    (\"Free shipping on all orders!\", {\"cats\": {\"SPAM\": 0, \"HAM\": 0, \"PROMOTION\": 1}})\n",
                                    "]\n",
                                    "\n",
                                    "# Add the text classifier to the pipeline with extra category\n",
                                    "config = {\n",
                                    "    \"threshold\": 0.5,\n",
                                    "    \"model\": {\n",
                                    "        \"@architectures\": \"spacy.TextCatBOW.v1\",\n",
                                    "        \"exclusive_classes\": True,\n",
                                    "        \"ngram_size\": 1,\n",
                                    "        \"no_output_layer\": False\n",
                                    "    }\n",
                                    "}\n",
                                    "textcat = nlp.add_pipe(\"textcat\", config=config)\n",
                                    "textcat.add_label(\"SPAM\")\n",
                                    "textcat.add_label(\"HAM\")\n",
                                    "textcat.add_label(\"PROMOTION\")  # TODO: Add the label for the extra category\n",
                                    "\n",
                                    "# Training the classifier\n",
                                    "def train_spam_detector(training_data, nlp, textcat, n_iter=30):\n",
                                    "    optimizer = nlp.initialize(lambda: (\n",
                                    "        Example.from_dict(nlp.make_doc(text), annotations)\n",
                                    "        for text, annotations in training_data\n",
                                    "    ))\n",
                                    "\n",
                                    "    for i in range(n_iter):\n",
                                    "        losses = {}\n",
                                    "        for text, annotations in training_data:\n",
                                    "            doc = nlp.make_doc(text)\n",
                                    "            example = Example.from_dict(doc, annotations)\n",
                                    "            nlp.update([example], sgd=optimizer, losses=losses)\n",
                                    "        print(f\"Iteration {i} - Loss: {losses}\")\n",
                                    "\n",
                                    "train_spam_detector(training_data, nlp, textcat)\n",
                                    "\n",
                                    "# Test the trained model with new texts including the PROMOTION category\n",
                                    "test_texts = [\n",
                                    "    \"Exclusive deal just for you!\",\n",
                                    "    \"Can we reschedule the meeting?\",\n",
                                    "    \"Limited time offer, shop now!\",\n",
                                    "    \"Free shipping on all orders!\"\n",
                                    "]\n",
                                    "\n",
                                    "for text in test_texts:\n",
                                    "    doc = nlp(text)\n",
                                    "    print(f\"Text: {text}\")\n",
                                    "    for cat, score in doc.cats.items():\n",
                                    "        print(f\"  {cat}: {score:.4f}\")\n",
                                    "    print(\"\\n\")\n",
                                    "\n",
                                    "### Changes Made:\n",
                                    "- Added the line `textcat.add_label(\"PROMOTION\")` to register the new category in the text classifier.\n",
                                    "\n",
                                    "Now, your model will be able to recognize the \"PROMOTION\" category along with \"SPAM\" and \"HAM\". If you have any further questions or need additional modifications, feel free to ask!"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Build a Spam Classifier Pipeline\n",
                                    "\n",
                                    "Stellar Navigator, get ready to steer the spaceship solo! It's time to write the full text classification pipeline for spam detection from scratch.\n",
                                    "\n",
                                    "Implement the process of creating the pipeline, preparing training data, adding a text classifier, training the classifier, and evaluating the model.\n",
                                    "\n",
                                    "```python\n",
                                    "import spacy\n",
                                    "from spacy.training import Example\n",
                                    "\n",
                                    "# TODO: Create a blank spaCy model\n",
                                    "\n",
                                    "training_data = [\n",
                                    "    (\"Buy cheap watches now!\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Get your discount codes today\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Call me asap\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}}),\n",
                                    "    (\"Lunch meeting at 1 pm?\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}}),\n",
                                    "    (\"Get rich quick! Visit now\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Congratulations! You've won a prize\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Important information about your account\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}}),\n",
                                    "    (\"Don't miss our meeting tomorrow\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}})\n",
                                    "]\n",
                                    "\n",
                                    "# TODO: Create configuration for text classifier pipeline\n",
                                    "\n",
                                    "# TODO: Add text classifier to the pipeline with labels\n",
                                    "\n",
                                    "# TODO: Define train_spam_detector function to train the model\n",
                                    "\n",
                                    "# TODO: Feed the training data to your function to train the model\n",
                                    "\n",
                                    "# TODO: Prepare test texts \n",
                                    "\n",
                                    "# TODO: Classify the test texts using the trained model and print the results\n",
                                    "\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Here’s a complete implementation of a text classification pipeline for spam detection using spaCy. This code includes creating a blank model, preparing training data, adding a text classifier, training the classifier, and evaluating the model.\n",
                                    "\n",
                                    "import spacy\n",
                                    "from spacy.training import Example\n",
                                    "\n",
                                    "# Create a blank spaCy model\n",
                                    "nlp = spacy.blank(\"en\")\n",
                                    "\n",
                                    "# Prepare training data\n",
                                    "training_data = [\n",
                                    "    (\"Buy cheap watches now!\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Get your discount codes today\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Call me asap\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}}),\n",
                                    "    (\"Lunch meeting at 1 pm?\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}}),\n",
                                    "    (\"Get rich quick! Visit now\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Congratulations! You've won a prize\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Important information about your account\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}}),\n",
                                    "    (\"Don't miss our meeting tomorrow\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}})\n",
                                    "]\n",
                                    "\n",
                                    "# Create configuration for text classifier pipeline\n",
                                    "config = {\n",
                                    "    \"threshold\": 0.5,\n",
                                    "    \"model\": {\n",
                                    "        \"@architectures\": \"spacy.TextCatBOW.v1\",\n",
                                    "        \"exclusive_classes\": True,\n",
                                    "        \"ngram_size\": 1,\n",
                                    "        \"no_output_layer\": False\n",
                                    "    }\n",
                                    "}\n",
                                    "\n",
                                    "# Add text classifier to the pipeline with labels\n",
                                    "textcat = nlp.add_pipe(\"textcat\", config=config)\n",
                                    "textcat.add_label(\"SPAM\")\n",
                                    "textcat.add_label(\"HAM\")\n",
                                    "\n",
                                    "# Define train_spam_detector function to train the model\n",
                                    "def train_spam_detector(training_data, nlp, textcat, n_iter=30):\n",
                                    "    optimizer = nlp.initialize(lambda: (\n",
                                    "        Example.from_dict(nlp.make_doc(text), annotations)\n",
                                    "        for text, annotations in training_data\n",
                                    "    ))\n",
                                    "\n",
                                    "    for i in range(n_iter):\n",
                                    "        losses = {}\n",
                                    "        for text, annotations in training_data:\n",
                                    "            doc = nlp.make_doc(text)\n",
                                    "            example = Example.from_dict(doc, annotations)\n",
                                    "            nlp.update([example], sgd=optimizer, losses=losses)\n",
                                    "        print(f\"Iteration {i} - Loss: {losses}\")\n",
                                    "\n",
                                    "# Feed the training data to your function to train the model\n",
                                    "train_spam_detector(training_data, nlp, textcat)\n",
                                    "\n",
                                    "# Prepare test texts\n",
                                    "test_texts = [\n",
                                    "    \"Exclusive deal just for you!\",\n",
                                    "    \"Can we reschedule the meeting?\",\n",
                                    "    \"Get rich quick! Visit now\",\n",
                                    "    \"Important information about your account\"\n",
                                    "]\n",
                                    "\n",
                                    "# Classify the test texts using the trained model and print the results\n",
                                    "for text in test_texts:\n",
                                    "    doc = nlp(text)\n",
                                    "    print(f\"Text: {text}\")\n",
                                    "    for cat, score in doc.cats.items():\n",
                                    "        print(f\"  {cat}: {score:.4f}\")\n",
                                    "    print(\"\\n\")\n",
                                    "\n",
                                    "### Explanation of the Code:\n",
                                    "\n",
                                    "1. **Creating a Blank Model**: A blank spaCy model is created using `spacy.blank(\"en\")`.\n",
                                    "\n",
                                    "2. **Preparing Training Data**: The training data consists of pairs of text and their corresponding categories (SPAM or HAM).\n",
                                    "\n",
                                    "3. **Configuration for Text Classifier**: A configuration dictionary is created to set up the text classifier.\n",
                                    "\n",
                                    "4. **Adding the Text Classifier**: The text classifier is added to the pipeline, and the labels \"SPAM\" and \"HAM\" are registered.\n",
                                    "\n",
                                    "5. **Training Function**: The `train_spam_detector` function is defined to train the model using the provided training data.\n",
                                    "\n",
                                    "6. **Training the Model**: The training data is fed into the training function to train the model.\n",
                                    "\n",
                                    "7. **Testing the Model**: A set of test texts is prepared, and the trained model is used to classify these texts. The results are printed, showing the probability scores for each category.\n",
                                    "\n",
                                    "This pipeline is now ready to classify text as spam or ham based on the training data provided. If you have any further questions or need additional modifications, feel free to ask!"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "id": "6de1d502",
                           "metadata": {},
                           "source": [
                                    "## Build a Spam Classifier Pipeline\n",
                                    "\n",
                                    "Stellar Navigator, get ready to steer the spaceship solo! It's time to write the full text classification pipeline for spam detection from scratch.\n",
                                    "\n",
                                    "Implement the process of creating the pipeline, preparing training data, adding a text classifier, training the classifier, and evaluating the model.\n",
                                    "\n",
                                    "```python\n",
                                    "import spacy\n",
                                    "from spacy.training import Example\n",
                                    "\n",
                                    "# TODO: Create a blank spaCy model\n",
                                    "\n",
                                    "training_data = [\n",
                                    "    (\"Buy cheap watches now!\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Get your discount codes today\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Call me asap\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}}),\n",
                                    "    (\"Lunch meeting at 1 pm?\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}}),\n",
                                    "    (\"Get rich quick! Visit now\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Congratulations! You've won a prize\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Important information about your account\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}}),\n",
                                    "    (\"Don't miss our meeting tomorrow\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}})\n",
                                    "]\n",
                                    "\n",
                                    "# TODO: Create configuration for text classifier pipeline\n",
                                    "\n",
                                    "# TODO: Add text classifier to the pipeline with labels\n",
                                    "\n",
                                    "# TODO: Define train_spam_detector function to train the model\n",
                                    "\n",
                                    "# TODO: Feed the training data to your function to train the model\n",
                                    "\n",
                                    "# TODO: Prepare test texts \n",
                                    "\n",
                                    "# TODO: Classify the test texts using the trained model and print the results\n",
                                    "\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "\n",
                                    "Here’s a complete implementation of a text classification pipeline for spam detection using spaCy. This code includes creating a blank model, preparing training data, adding a text classifier, training the classifier, and evaluating the model.\n",
                                    "\n",
                                    "import spacy\n",
                                    "from spacy.training import Example\n",
                                    "\n",
                                    "# Create a blank spaCy model\n",
                                    "nlp = spacy.blank(\"en\")\n",
                                    "\n",
                                    "# Prepare training data\n",
                                    "training_data = [\n",
                                    "    (\"Buy cheap watches now!\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Get your discount codes today\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Call me asap\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}}),\n",
                                    "    (\"Lunch meeting at 1 pm?\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}}),\n",
                                    "    (\"Get rich quick! Visit now\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Congratulations! You've won a prize\", {\"cats\": {\"SPAM\": 1, \"HAM\": 0}}),\n",
                                    "    (\"Important information about your account\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}}),\n",
                                    "    (\"Don't miss our meeting tomorrow\", {\"cats\": {\"SPAM\": 0, \"HAM\": 1}})\n",
                                    "]\n",
                                    "\n",
                                    "# Create configuration for text classifier pipeline\n",
                                    "config = {\n",
                                    "    \"threshold\": 0.5,\n",
                                    "    \"model\": {\n",
                                    "        \"@architectures\": \"spacy.TextCatBOW.v1\",\n",
                                    "        \"exclusive_classes\": True,\n",
                                    "        \"ngram_size\": 1,\n",
                                    "        \"no_output_layer\": False\n",
                                    "    }\n",
                                    "}\n",
                                    "\n",
                                    "# Add text classifier to the pipeline with labels\n",
                                    "textcat = nlp.add_pipe(\"textcat\", config=config)\n",
                                    "textcat.add_label(\"SPAM\")\n",
                                    "textcat.add_label(\"HAM\")\n",
                                    "\n",
                                    "# Define train_spam_detector function to train the model\n",
                                    "def train_spam_detector(training_data, nlp, textcat, n_iter=30):\n",
                                    "    optimizer = nlp.initialize(lambda: (\n",
                                    "        Example.from_dict(nlp.make_doc(text), annotations)\n",
                                    "        for text, annotations in training_data\n",
                                    "    ))\n",
                                    "\n",
                                    "    for i in range(n_iter):\n",
                                    "        losses = {}\n",
                                    "        for text, annotations in training_data:\n",
                                    "            doc = nlp.make_doc(text)\n",
                                    "            example = Example.from_dict(doc, annotations)\n",
                                    "            nlp.update([example], sgd=optimizer, losses=losses)\n",
                                    "        print(f\"Iteration {i} - Loss: {losses}\")\n",
                                    "\n",
                                    "# Feed the training data to your function to train the model\n",
                                    "train_spam_detector(training_data, nlp, textcat)\n",
                                    "\n",
                                    "# Prepare test texts\n",
                                    "test_texts = [\n",
                                    "    \"Exclusive deal just for you!\",\n",
                                    "    \"Can we reschedule the meeting?\",\n",
                                    "    \"Get rich quick! Visit now\",\n",
                                    "    \"Important information about your account\"\n",
                                    "]\n",
                                    "\n",
                                    "# Classify the test texts using the trained model and print the results\n",
                                    "for text in test_texts:\n",
                                    "    doc = nlp(text)\n",
                                    "    print(f\"Text: {text}\")\n",
                                    "    for cat, score in doc.cats.items():\n",
                                    "        print(f\"  {cat}: {score:.4f}\")\n",
                                    "    print(\"\\n\")\n",
                                    "\n",
                                    "### Explanation of the Code:\n",
                                    "\n",
                                    "1. **Creating a Blank Model**: A blank spaCy model is created using `spacy.blank(\"en\")`.\n",
                                    "\n",
                                    "2. **Preparing Training Data**: The training data consists of pairs of text and their corresponding categories (SPAM or HAM).\n",
                                    "\n",
                                    "3. **Configuration for Text Classifier**: A configuration dictionary is created to set up the text classifier.\n",
                                    "\n",
                                    "4. **Adding the Text Classifier**: The text classifier is added to the pipeline, and the labels \"SPAM\" and \"HAM\" are registered.\n",
                                    "\n",
                                    "5. **Training Function**: The `train_spam_detector` function is defined to train the model using the provided training data.\n",
                                    "\n",
                                    "6. **Training the Model**: The training data is fed into the training function to train the model.\n",
                                    "\n",
                                    "7. **Testing the Model**: A set of test texts is prepared, and the trained model is used to classify these texts. The results are printed, showing the probability scores for each category.\n",
                                    "\n",
                                    "This pipeline is now ready to classify text as spam or ham based on the training data provided. If you have any further questions or need additional modifications, feel free to ask!"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
