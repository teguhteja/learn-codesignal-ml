{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Lesson 4: Unveiling the Essentials of Entity Recognition with spaCy\n",
                                    "\n",
                                    "\n",
                                    "Hello and welcome to the next exciting part of our journey with Natural Language Processing! In today's lesson, we focus on one of the vital components in NLP – Entity Recognition, and we are going to see it in action using Python and spaCy. Our goal for today's lesson is to grasp the core concepts behind Entity Recognition, understand why it's important, and be able to implement it in Python using spaCy.\n",
                                    "\n",
                                    "## Understanding Entity Recognition in NLP\n",
                                    "\n",
                                    "So, what exactly is Entity Recognition? Entity Recognition or Named Entity Recognition (NER) is a task in information extraction that involves identifying and classifying named entities (like persons, places, organizations) present in a text into pre-defined categories. It is essentially the process by which an algorithm can read a string of text and say, \"Ah, this part of the text refers to a place, and this part refers to a person!\"\n",
                                    "\n",
                                    "Let's consider an example to understand this better. Given a sentence - \"Apple Inc. is planning to open a new office in San Francisco.\" Named entity recognition will help us identify \"Apple Inc.\" as an organization and \"San Francisco\" as a geographical entity.\n",
                                    "\n",
                                    "Named Entity Recognition plays a crucial role in various NLP applications like information retrieval (search engines), machine translation, question answering systems, and more. It helps algorithms better understand the context of the sentences and extract important attributes from the text.\n",
                                    "\n",
                                    "## Practical Implementation of Entity Recognition\n",
                                    "\n",
                                    "With a theoretical understanding of Entity Recognition, let's now delve into its practical implementation using Python and the spaCy library. As mentioned above, spaCy has a built-in Named Entity Recognition system that can recognize a wide variety of named or numerical entities. This comes as a part of spaCy's statistical models, and not all the language models support it. However, the model we are using, `en_core_web_sm`, supports Named Entity Recognition.\n",
                                    "\n",
                                    "When you call `nlp` on a text, spaCy first tokenizes the text to produce a `Doc` object. The `Doc` is then processed in several different steps – this is also known as the processing pipeline. The pipeline used by the `en_core_web_sm` model consists of a tagger, a parser, and an entity recognizer. Each pipeline component returns the processed `Doc`, which is then passed on to the next component.\n",
                                    "\n",
                                    "Upon calling `nlp` with our text, the model’s pipeline is applied to the `Doc`, returning a processed `Doc` object. Having gone through the pipeline, the `Doc` object now holds all the information about the entities that have been recognized.\n",
                                    "\n",
                                    "## Executing Entity Recognition on Reuters Dataset\n",
                                    "\n",
                                    "Now that we understand how spaCy's Entity Recognizer works, let's go ahead and execute it on a real-world dataset. For this lesson, we will use the in-built Reuters dataset from the Natural Language Toolkit (NLTK) library. Specifically, we will aim to extract entities from articles in the 'Crude' category.\n",
                                    "\n",
                                    "To start with, we import the necessary libraries and load the English model using `spacy.load(\"en_core_web_sm\")`. Next, we fetch an article from the 'Crude' category using `reuters.raw(fileids=reuters.fileids(categories='crude')[0])`. The raw text of the first article in this category is processed through our pipeline by calling `nlp(text)`.\n",
                                    "\n",
                                    "```python\n",
                                    "# Import necessary libraries\n",
                                    "from nltk.corpus import reuters\n",
                                    "import spacy\n",
                                    "\n",
                                    "# Load English tokenizer, tagger, parser, NER, and word vectors\n",
                                    "nlp = spacy.load(\"en_core_web_sm\")\n",
                                    "\n",
                                    "# Define the text for extraction\n",
                                    "text = reuters.raw(fileids=reuters.fileids(categories='crude')[0])\n",
                                    "\n",
                                    "# Process the text\n",
                                    "doc = nlp(text)\n",
                                    "\n",
                                    "# Print the entity, starting and ending index, and label\n",
                                    "for ent in doc.ents:\n",
                                    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
                                    "```\n",
                                    "The `Doc` object holds a collection of `Token` objects, which also hold their respective predicted entities. Here, we iterate over each `ent` in `doc.ents` and print out the text of the entity, its starting and ending index in the document, and its label.\n",
                                    "\n",
                                    "The output of the above code will be:\n",
                                    "\n",
                                    "```sh\n",
                                    "JAPAN 0 5 GPE\n",
                                    "The Ministry of International Trade 52 87 ORG\n",
                                    "MITI 104 108 ORG\n",
                                    "August 170 176 DATE\n",
                                    "Japanese 209 217 NORP\n",
                                    "MITI 266 270 ORG\n",
                                    "the year 2000 340 353 DATE\n",
                                    "550 357 360 CARDINAL\n",
                                    "600 386 389 CARDINAL\n",
                                    "Japanese 476 484 NORP\n",
                                    "MITI 594 598 ORG\n",
                                    "the Agency of Natural Resources and Energy 711 755 ORG\n",
                                    "MITI 793 797 ORG\n",
                                    "Japan 945 950 GPE\n",
                                    "the fiscal year ended March 31 973 1003 DATE\n",
                                    "an estimated 27 1015 1030 CARDINAL\n",
                                    "a kilowatt/hour 1040 1055 TIME\n",
                                    "23 1080 1082 CARDINAL\n",
                                    "21 1117 1119 CARDINAL\n",
                                    "```\n",
                                    "\n",
                                    "This output shows various entities extracted from the Reuters article including geopolitical entities (GPE), organizations (ORG), nationalities (NORP), dates, and cardinal numbers. It illustrates the powerful capability of spaCy in identifying different types of entities in text, which is fundamental for many NLP tasks.\n",
                                    "\n",
                                    "This entity recognition code helps us understand how the spaCy library processes text and how we can utilize its power to identify various entities in practically any type of textual data. This knowledge will be crucial when we move forward to the next lesson on Entity Linking.\n",
                                    "\n",
                                    "## Lesson Summary and Hands-On Practice\n",
                                    "\n",
                                    "Congratulations! You have learned the importance of Entity Recognition in NLP and implemented it efficiently using the spaCy library in Python.\n",
                                    "\n",
                                    "You have seen how we can process text and identify named entities, such as organizations, persons, and geographical locations, among others. To further strengthen your understanding, we encourage you to experiment with a variety of texts and categories within the Reuters dataset, or other text data of your interest.\n",
                                    "\n",
                                    "In the next lesson, we will further compound our learning by studying custom NLP pipeline components and their practical implementation. Stay tuned!\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Filtering Out Organization Entities\n",
                                    "\n",
                                    "Fantastic job, Space Explorer! Now, let's focus more on the organization entities (ORG) in our text. Modify the provided code to only print entities that have been recognized as organizations. Keep the listed items: the entity's text, starting index, ending index, and label.\n",
                                    "\n",
                                    "```python\n",
                                    "# Import necessary libraries\n",
                                    "from nltk.corpus import reuters\n",
                                    "import spacy\n",
                                    "\n",
                                    "# Load English tokenizer, tagger, parser, NER, and word vectors\n",
                                    "nlp = spacy.load(\"en_core_web_sm\")\n",
                                    "\n",
                                    "# Define the text for extraction\n",
                                    "text = reuters.raw(fileids=reuters.fileids(categories='crude')[0])\n",
                                    "\n",
                                    "# Process the text\n",
                                    "doc = nlp(text)\n",
                                    "\n",
                                    "# Print the entity, starting and ending index, and label\n",
                                    "for ent in doc.ents:\n",
                                    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Here's the modified code that filters and prints only the recognized organization entities (ORG) from the text. The output will include the entity's text, starting index, ending index, and label.\n",
                                    "\n",
                                    "# Import necessary libraries\n",
                                    "from nltk.corpus import reuters\n",
                                    "import spacy\n",
                                    "\n",
                                    "# Load English tokenizer, tagger, parser, NER, and word vectors\n",
                                    "nlp = spacy.load(\"en_core_web_sm\")\n",
                                    "\n",
                                    "# Define the text for extraction\n",
                                    "text = reuters.raw(fileids=reuters.fileids(categories='crude')[0])\n",
                                    "\n",
                                    "# Process the text\n",
                                    "doc = nlp(text)\n",
                                    "\n",
                                    "# Print only organization entities (ORG)\n",
                                    "for ent in doc.ents:\n",
                                    "    if ent.label_ == \"ORG\":  # Check if the entity is an organization\n",
                                    "        print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
                                    "\n",
                                    "### Explanation of Changes:\n",
                                    "\n",
                                    "1. **Filtering for Organizations**: The loop now includes a conditional statement (`if ent.label_ == \"ORG\":`) to check if the recognized entity is classified as an organization.\n",
                                    "\n",
                                    "2. **Output**: Only the organization entities will be printed, along with their text, starting index, ending index, and label.\n",
                                    "\n",
                                    "You can run this modified code, and it will display only the organization entities found in the selected Reuters article."
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Identifying Specific Entities in Custom Text"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Extracting 'ORG' and 'GPE' Entities with Spacy"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Unique Geopolitical Entities in Reuters Dataset"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
