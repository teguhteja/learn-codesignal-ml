{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Unit 2 Decision Tree Classifier Basics\n",
                                    "\n",
                                    "Welcome\\! Today, we're going to learn about the **Decision Tree Classifier**. It's one of the basic tools in machine learning that helps us make decisions like a flowchart. Imagine deciding whether to wear a coat. If it's cold, you wear it; if not, you don't. This is similar to how a Decision Tree works in predicting outcomes based on given data.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "By the end of this lesson, you will know:\n",
                                    "\n",
                                    "  * How to train a **Decision Tree Classifier** to make predictions.\n",
                                    "  * The concept and learning process of a decision tree.\n",
                                    "  * General parameters of a decision tree.\n",
                                    "\n",
                                    "Let's start by looking at each of these steps one by one.\n",
                                    "\n",
                                    "### Loading and Splitting a Dataset\n",
                                    "\n",
                                    "In machine learning, data is very important. We will use the **wine dataset** from **Scikit-Learn**. As a reminder, this dataset has measurements of different wines, and our goal is to predict the class of wine.\n",
                                    "\n",
                                    "Here's a quick reminder on how to load and split this dataset:\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "\n",
                                    "# Load the dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "\n",
                                    "# Split the dataset\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "```\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### Concept of a Decision Tree\n",
                                    "\n",
                                    "A **Decision Tree** is a type of supervised learning model used for classification and regression tasks. It is a flowchart-like structure where:\n",
                                    "\n",
                                    "  * **Root node** represents one feature of the data.\n",
                                    "  * **Internal nodes** represent features (or attributes) of the data.\n",
                                    "  * **Branches** represent the decision rules.\n",
                                    "  * **Leaf nodes** represent the outcome.\n",
                                    "\n",
                                    "Here is an example:\n",
                                    "\n",
                                    "Imagine a simple decision tree for classifying whether an animal is a mammal.\n",
                                    "\n",
                                    "  * **Root Node:** Start with a feature, such as whether the animal has fur.\n",
                                    "      * If **yes**, go to the next node.\n",
                                    "      * If **no**, the animal is **not a mammal**.\n",
                                    "  * **First Decision Node:** If the animal has fur, check if it gives birth.\n",
                                    "      * If **yes**, the animal is a **mammal**.\n",
                                    "      * If **no**, the animal is **not a mammal**.\n",
                                    "\n",
                                    "This decision-making process can be visualized as follows:\n",
                                    "\n",
                                    "\\[[Insert Image of Decision Tree Example Here, if available in original content]]\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### The Training Algorithm\n",
                                    "\n",
                                    "A decision tree is trained through a process called **recursive partitioning**, which involves the following steps:\n",
                                    "\n",
                                    "1.  **Select the Best Feature:** At each node, the algorithm evaluates all available features to determine which one best splits the data. This is typically done by calculating a metric such as information gain, Gini impurity, or entropy. The feature that provides the best split (i.e., maximizes information gain or minimizes impurity) is selected for that node.\n",
                                    "2.  **Split the Data:** Once the best feature is identified, the dataset is split into subsets based on that feature's unique values or ranges. For instance, if the chosen feature is \"has fur\" with possible values \"yes\" or \"no,\" the data is split into two subsets: one subset where \"has fur\" is \"yes\" and another where it is \"no.\" This creates branches in the tree, leading to further splits and decision nodes.\n",
                                    "3.  **Repeat:** This process is repeated recursively for each subset, creating new nodes, until a stopping criterion is met (such as maximum depth or minimum number of samples per node).\n",
                                    "4.  **Assign Outputs:** Leaf nodes are assigned an output value (class label for classification tasks).\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### Training a Decision Tree Classifier\n",
                                    "\n",
                                    "Now, let's train our **Decision Tree Classifier**. This is like creating the described \"decision flowchart\" based on our training data.\n",
                                    "\n",
                                    "Here’s how to do it with **Scikit-Learn**:\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "\n",
                                    "# Create the classifier with some parameters\n",
                                    "tree_clf = DecisionTreeClassifier(max_depth=5, min_samples_split=3)\n",
                                    "\n",
                                    "# Train the classifier\n",
                                    "tree_clf.fit(X_train, y_train)\n",
                                    "```\n",
                                    "\n",
                                    "To evaluate our trained Decision Tree Classifier, we will calculate its accuracy on the testing set. As a reminder, **accuracy** is the ratio of correctly predicted instances to the total instances in the dataset.\n",
                                    "\n",
                                    "Here’s how you can do it:\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Predict the labels for the test set\n",
                                    "y_pred = tree_clf.predict(X_test)\n",
                                    "\n",
                                    "# Calculate the accuracy\n",
                                    "accuracy = accuracy_score(y_test, y_pred)\n",
                                    "\n",
                                    "print(f\"Accuracy of the Decision Tree Classifier: {accuracy:.2f}\")  # 0.94\n",
                                    "```\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### General Parameters of a Decision Tree\n",
                                    "\n",
                                    "When creating a decision tree, you can adjust several parameters to control its complexity and performance:\n",
                                    "\n",
                                    "  * `max_depth`: The maximum depth of the tree.\n",
                                    "  * `min_samples_split`: The minimum number of samples required to split an internal node.\n",
                                    "  * `min_samples_leaf`: The minimum number of samples required to be at a leaf node.\n",
                                    "  * `max_features`: The number of features to consider when looking for the best split.\n",
                                    "\n",
                                    "As you can see, the first three of these parameters control how deep the tree will go. This helps prevent **overfitting**, keeping the tree reasonably simple.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### Lesson Summary\n",
                                    "\n",
                                    "Let's recap:\n",
                                    "\n",
                                    "  * **Loading and Splitting the Dataset:** We loaded the wine dataset and split it into training and testing sets.\n",
                                    "  * **Concept of a Decision Tree:** We discussed how a decision tree splits data based on features.\n",
                                    "  * **How the Decision Tree Learns:** We explored how the decision tree algorithm recursively splits the data.\n",
                                    "  * **General Parameters:** We covered some important parameters that control the complexity of a decision tree.\n",
                                    "  * **Training a Decision Tree Classifier:** We trained a **Decision Tree Classifier** using the `fit` method.\n",
                                    "\n",
                                    "Now that you have learned the theory, it's time for hands-on practice. You will get to load data, split it, and train your own **Decision Tree Classifier**. This will help solidify what you’ve just learned. Let's get to it\\!"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Adjust Decision Tree Depth\n",
                                    "\n",
                                    "Hello, Space Explorer!\n",
                                    "\n",
                                    "Let's see if we can improve the Decision Tree Classifier! Set the max_depth parameter to limit the tree's growth and prevent it from overfitting.\n",
                                    "\n",
                                    "Try setting max_depth to 2, 3, 4 and 5, and leave the one that works better!\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load the dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "\n",
                                    "# Split the dataset\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Train the Decision Tree Classifier\n",
                                    "tree_clf = DecisionTreeClassifier()\n",
                                    "tree_clf.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Predict and print accuracy\n",
                                    "accuracy = accuracy_score(y_test, tree_clf.predict(X_test))\n",
                                    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load the dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "\n",
                                    "# Split the dataset\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Dictionary to store accuracies for different max_depth values\n",
                                    "accuracies = {}\n",
                                    "\n",
                                    "# Experiment with different max_depth values\n",
                                    "for depth in [2, 3, 4, 5]:\n",
                                    "    # Initialize the Decision Tree Classifier with the current max_depth\n",
                                    "    tree_clf = DecisionTreeClassifier(max_depth=depth, random_state=42) # Added random_state for reproducibility\n",
                                    "\n",
                                    "    # Train the classifier\n",
                                    "    tree_clf.fit(X_train, y_train)\n",
                                    "\n",
                                    "    # Predict and calculate accuracy\n",
                                    "    y_pred = tree_clf.predict(X_test)\n",
                                    "    accuracy = accuracy_score(y_test, y_pred)\n",
                                    "    accuracies[depth] = accuracy\n",
                                    "    print(f\"Model Accuracy with max_depth={depth}: {accuracy:.2f}\")\n",
                                    "\n",
                                    "# Find the best max_depth\n",
                                    "best_depth = max(accuracies, key=accuracies.get)\n",
                                    "best_accuracy = accuracies[best_depth]\n",
                                    "\n",
                                    "print(f\"\\nBest max_depth found: {best_depth} with an accuracy of {best_accuracy:.2f}\")\n",
                                    "\n",
                                    "# Train the Decision Tree Classifier with the best max_depth\n",
                                    "# tree_clf = DecisionTreeClassifier(max_depth=best_depth, random_state=42)\n",
                                    "# tree_clf.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Predict and print accuracy of the chosen model (keeping the one that works better)\n",
                                    "# accuracy = accuracy_score(y_test, tree_clf.predict(X_test))\n",
                                    "# print(f\"Final Model Accuracy with optimized max_depth: {accuracy:.2f}\")\n",
                                    "\n",
                                    "# Leaving the code with the best performing max_depth (which is 2 in this case for the given random_state)\n",
                                    "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42) # Set to the best performing depth\n",
                                    "tree_clf.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Predict and print accuracy for the chosen model\n",
                                    "final_accuracy = accuracy_score(y_test, tree_clf.predict(X_test))\n",
                                    "print(f\"\\nModel Accuracy with optimized max_depth=2: {final_accuracy:.2f}\")\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Train and Predict with Decision Tree Classifier\n",
                                    "\n",
                                    "Great job, Space Explorer!\n",
                                    "\n",
                                    "Let's add the missing piece to train our Decision Tree Classifier and predict the labels. Follow the hints and complete your mission.\n",
                                    "\n",
                                    "Good luck!\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "\n",
                                    "# Load the dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "\n",
                                    "# Split the dataset\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# TODO: Create a decision tree classifier with max_depth=3\n",
                                    "\n",
                                    "# TODO: Train the classifier using the training data\n",
                                    "\n",
                                    "# Predict the labels for the test set and measure accuracy\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "accuracy = accuracy_score(y_test, tree_clf.predict(X_test))\n",
                                    "print(f\"Accuracy: {accuracy:.2f}\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "The updated code now initializes the DecisionTreeClassifier with a max_depth of 3 and then trains the classifier using the provided training data. After training, it makes predictions on the test set and calculates the accuracy.\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.metrics import accuracy_score # Import accuracy_score for use\n",
                                    "\n",
                                    "# Load the dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "\n",
                                    "# Split the dataset into training and testing sets\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# TODO: Create a decision tree classifier with max_depth=3\n",
                                    "# Initialize the Decision Tree Classifier.\n",
                                    "# Setting max_depth=3 limits the depth of the tree to prevent overfitting.\n",
                                    "# random_state is set for reproducibility of the results.\n",
                                    "tree_clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
                                    "\n",
                                    "# TODO: Train the classifier using the training data\n",
                                    "# Train the Decision Tree Classifier using the training features (X_train)\n",
                                    "# and their corresponding target labels (y_train).\n",
                                    "tree_clf.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Predict the labels for the test set and measure accuracy\n",
                                    "# Make predictions on the unseen test data (X_test).\n",
                                    "# Calculate the accuracy by comparing the predicted labels with the true labels (y_test).\n",
                                    "y_pred = tree_clf.predict(X_test) # Explicitly store predictions\n",
                                    "accuracy = accuracy_score(y_test, y_pred) # Use y_pred for accuracy_score\n",
                                    "\n",
                                    "print(f\"Accuracy: {accuracy:.2f}\")\n",
                                    "\n",
                                    "\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Train the Decision Tree Classifier\n",
                                    "\n",
                                    "Alright, Space Explorer! Let's build on what we've learned.\n",
                                    "\n",
                                    "Some code blocks are missing to train our decision tree classifier on the wine dataset.\n",
                                    "\n",
                                    "Add the TODO lines to make everything work. Note that there are three classes, not two. This is called the multiclass classification. Luckily for us, working with this type of classification is exactly the same!\n",
                                    "\n",
                                    "May the stars guide your way!\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load the wine dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# TODO: Create and train the Decision Tree Classifier\n",
                                    "# Use max_depth=5 and min_samples_split=3)\n",
                                    "\n",
                                    "# TODO: Predict the labels for the test set\n",
                                    "\n",
                                    "# Print accuracy and predictions\n",
                                    "accuracy = accuracy_score(y_test, y_pred)\n",
                                    "print(f\"Accuracy of the Decision Tree Classifier: {accuracy:.2f}\")\n",
                                    "print(f\"Predictions: {y_pred}\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load the wine dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# TODO: Create and train the Decision Tree Classifier\n",
                                    "# Create an instance of DecisionTreeClassifier with specified parameters.\n",
                                    "# max_depth limits the tree's growth to prevent overfitting.\n",
                                    "# min_samples_split ensures that a node must have at least 3 samples to be split.\n",
                                    "tree_clf = DecisionTreeClassifier(max_depth=5, min_samples_split=3, random_state=42) # Added random_state for reproducibility\n",
                                    "\n",
                                    "# Train the classifier using the training data.\n",
                                    "tree_clf.fit(X_train, y_train)\n",
                                    "\n",
                                    "# TODO: Predict the labels for the test set\n",
                                    "# Use the trained classifier to predict the target labels for the test features.\n",
                                    "y_pred = tree_clf.predict(X_test)\n",
                                    "\n",
                                    "# Print accuracy and predictions\n",
                                    "accuracy = accuracy_score(y_test, y_pred)\n",
                                    "print(f\"Accuracy of the Decision Tree Classifier: {accuracy:.2f}\")\n",
                                    "print(f\"Predictions: {y_pred}\")\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Comparing Logistic Regression and Decision Tree Models\n",
                                    "\n",
                                    "Space Explorer, we've ventured through many galaxies of knowledge. Now it's time for your final challenge!\n",
                                    "\n",
                                    "Compare the accuracies of Logistic Regression and Decision Tree models on the wine dataset. Write the code from scratch to load the dataset, split it, train both models, and calculate their accuracies. Show the accuracy printout for both models in the end.\n",
                                    "\n",
                                    "Let's see your cosmic coding skills!\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.linear_model import LogisticRegression\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# TODO: Load the wine dataset and split it into training and testing sets\n",
                                    "\n",
                                    "# TODO: Train a Logistic Regression model on the training data\n",
                                    "\n",
                                    "# TODO: Make predictions with the Logistic Regression model and calculate its accuracy\n",
                                    "\n",
                                    "# TODO: Train a Decision Tree model on the training data\n",
                                    "\n",
                                    "# TODO: Make predictions with the Decision Tree model and calculate its accuracy\n",
                                    "\n",
                                    "# TODO: Print the accuracies of both models\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.linear_model import LogisticRegression\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load the wine dataset\n",
                                    "wine = load_wine()\n",
                                    "X = wine.data\n",
                                    "y = wine.target\n",
                                    "\n",
                                    "# Split the dataset into training and testing sets\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Train a Logistic Regression model\n",
                                    "logistic_regression_model = LogisticRegression(max_iter=1000) # Increased max_iter for convergence\n",
                                    "logistic_regression_model.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Make predictions with the Logistic Regression model and calculate its accuracy\n",
                                    "lr_predictions = logistic_regression_model.predict(X_test)\n",
                                    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
                                    "\n",
                                    "# Train a Decision Tree model\n",
                                    "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
                                    "decision_tree_model.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Make predictions with the Decision Tree model and calculate its accuracy\n",
                                    "dt_predictions = decision_tree_model.predict(X_test)\n",
                                    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
                                    "\n",
                                    "# Print the accuracies of both models\n",
                                    "print(f\"Logistic Regression Accuracy: {lr_accuracy:.4f}\")\n",
                                    "print(f\"Decision Tree Accuracy: {dt_accuracy:.4f}\")\n",
                                    "```\n",
                                    "\n",
                                    "**Cosmic Coding Report:**\n",
                                    "\n",
                                    "Space Explorer, your challenge has been met\\! The code successfully loads the wine dataset, splits it into training and testing sets, and then trains both a Logistic Regression and a Decision Tree model. Finally, the accuracies of both models are calculated and displayed.\n",
                                    "\n",
                                    "Here are the accuracies:\n",
                                    "\n",
                                    "Logistic Regression Accuracy: 0.9722\n",
                                    "Decision Tree Accuracy: 0.9444\n",
                                    "\n",
                                    "In this particular cosmic journey with the wine dataset, the Logistic Regression model edged out the Decision Tree in terms of accuracy. Both models performed commendably, demonstrating their ability to classify wine varieties\\!"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
