{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Unit 3 Random Search in Machine Learning\n",
                                    "\n",
                                    "## Lesson Introduction and Goals\n",
                                    "\n",
                                    "Choosing the right parameters in machine learning models can greatly affect their success. Imagine these parameters as cake ingredients: the right amount makes your cake delicious. Similarly, the right parameter settings make your model accurate. Random Search helps find these “right ingredients” by trying random combinations. By the end of this lesson, you will:\n",
                                    "\n",
                                    "  * Understand what Random Search is\n",
                                    "  * Learn how to implement it using Scikit-Learn\n",
                                    "  * Interpret the results to improve models\n",
                                    "\n",
                                    "## What is Random Search?\n",
                                    "\n",
                                    "Random Search is a technique for tuning parameters by randomly sampling combinations from a given range, like randomly picking recipes to see which cake tastes best. Unlike Grid Search, which tries every possible combination, Random Search is faster because it tries random ones. It’s like flipping through a recipe book and picking random recipes instead of trying every single one.\n",
                                    "\n",
                                    "## Loading and Preparing the Dataset\n",
                                    "\n",
                                    "We’ll use the wine dataset from Scikit-Learn. Let's load it and scale features:\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.preprocessing import StandardScaler\n",
                                    "\n",
                                    "# Load real dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "X = StandardScaler().fit_transform(X)\n",
                                    "```\n",
                                    "\n",
                                    "To evaluate our model, we split the dataset into a training set (80%) and a testing set (20%).\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "\n",
                                    "# Splitting the dataset\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
                                    "```\n",
                                    "\n",
                                    "## Defining the Parameter Distribution\n",
                                    "\n",
                                    "A parameter grid is a set of parameters you want to try. For Logistic Regression, we’ll tune `C` and `solver`.\n",
                                    "\n",
                                    "```python\n",
                                    "# Defining the parameter grid\n",
                                    "param_distributions = {\n",
                                    "    'C': [0.1, 0.5, 0.75, 1, 5, 10, 25, 50, 75, 100],\n",
                                    "    'solver': ['liblinear', 'saga']\n",
                                    "}\n",
                                    "```\n",
                                    "\n",
                                    "  * `C`: Controls the strength of regularization. Smaller values specify stronger regularization.\n",
                                    "  * `solver`: Algorithm used in the optimization problem.\n",
                                    "\n",
                                    "## Performing Random Search\n",
                                    "\n",
                                    "`RandomizedSearchCV` is a Scikit-Learn tool for Random Search. It randomly selects parameter combinations and evaluates their performance.\n",
                                    "\n",
                                    "  * `n_iter`: Number of settings sampled.\n",
                                    "  * `cv`: Number of cross-validation splits.\n",
                                    "\n",
                                    "<!-- end list -->\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.model_selection import RandomizedSearchCV\n",
                                    "from sklearn.linear_model import LogisticRegression\n",
                                    "\n",
                                    "# Performing randomized search\n",
                                    "random_search = RandomizedSearchCV(LogisticRegression(max_iter=1000), param_distributions, n_iter=10, cv=5, random_state=42)\n",
                                    "random_search.fit(X_train, y_train)\n",
                                    "```\n",
                                    "\n",
                                    "## Interpreting the Results\n",
                                    "\n",
                                    "After running the search, find the best parameters and view the best score achieved during cross-validation.\n",
                                    "\n",
                                    "```python\n",
                                    "print(f\"Best parameters: {random_search.best_params_}\")\n",
                                    "print(f\"Best cross-validation score: {random_search.best_score_}\")\n",
                                    "\n",
                                    "# Best parameters: {'solver': 'liblinear', 'C': 5}\n",
                                    "# Best cross-validation score: 0.992\n",
                                    "```\n",
                                    "\n",
                                    "## Calculating the Final Metric on the Testing Dataset\n",
                                    "\n",
                                    "After identifying the best parameters from the Random Search, it’s crucial to evaluate the model on the testing dataset to see how well it generalizes to new, unseen data.\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Best model with best parameters from random search\n",
                                    "best_model = random_search.best_estimator_\n",
                                    "\n",
                                    "# Predicting on the testing set\n",
                                    "y_pred = best_model.predict(X_test)\n",
                                    "\n",
                                    "# Calculating the accuracy on the testing set\n",
                                    "test_accuracy = accuracy_score(y_test, y_pred)\n",
                                    "print(f\"Test Accuracy: {test_accuracy}\")\n",
                                    "\n",
                                    "# Test Accuracy: 0.981\n",
                                    "```\n",
                                    "\n",
                                    "In this example, the accuracy on the testing set is calculated using the best model obtained from `RandomizedSearchCV`. This final evaluation metric gives an indication of the model's performance on new data.\n",
                                    "\n",
                                    "## Lesson Summary and Practice Introduction\n",
                                    "\n",
                                    "In this lesson, you learned:\n",
                                    "\n",
                                    "  * What Random Search is\n",
                                    "  * How to load and split a dataset\n",
                                    "  * How to define parameter ranges\n",
                                    "  * Implementing Random Search with `RandomizedSearchCV`\n",
                                    "  * Interpreting the best parameters and scores\n",
                                    "\n",
                                    "Now it’s your turn to practice\\! Apply Random Search to different models and datasets. This will help solidify your understanding. Let’s move on to the practice session\\!"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Tuning Iterations in Random Search\n",
                                    "\n",
                                    "Stellar Navigator, let's tweak Random Search! Change the number of iterations n_iter in RandomizedSearchCV from 10 to 5 to see how it affects the results. This small change will show you the importance of the iteration count in hyperparameter tuning.\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
                                    "from sklearn.linear_model import LogisticRegression\n",
                                    "from sklearn.preprocessing import StandardScaler\n",
                                    "\n",
                                    "# Load the \"cancer cake\" recipe data\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "X = StandardScaler().fit_transform(X)\n",
                                    "\n",
                                    "# Split the data into \"training batter\" and \"testing batter\"\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Define the \"ingredient amounts\" for our logistic regression cake\n",
                                    "param_distributions = {\n",
                                    "    'C': [0.1, 0.5, 0.75, 1, 5, 10, 25, 50, 75, 100],\n",
                                    "    'solver': ['liblinear', 'saga']\n",
                                    "}\n",
                                    "\n",
                                    "# Create and train our \"random recipe picker\"\n",
                                    "# TODO: adjust number of iterations\n",
                                    "random_search = RandomizedSearchCV(LogisticRegression(max_iter=1000), param_distributions, n_iter=10, cv=5, random_state=42)\n",
                                    "random_search.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Display the \"best recipe\"\n",
                                    "print(f\"Best parameters: {random_search.best_params_}\")\n",
                                    "print(f\"Best cross-validation score: {random_search.best_score_}\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Anda ingin mengubah nilai `n_iter` dalam `RandomizedSearchCV` dari 10 menjadi 5 untuk melihat bagaimana hal tersebut memengaruhi hasil. Berikut adalah kode yang telah disesuaikan:\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
                                    "from sklearn.linear_model import LogisticRegression\n",
                                    "from sklearn.preprocessing import StandardScaler\n",
                                    "\n",
                                    "# Load the \"cancer cake\" recipe data\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "X = StandardScaler().fit_transform(X)\n",
                                    "\n",
                                    "# Split the data into \"training batter\" and \"testing batter\"\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Define the \"ingredient amounts\" for our logistic regression cake\n",
                                    "param_distributions = {\n",
                                    "    'C': [0.1, 0.5, 0.75, 1, 5, 10, 25, 50, 75, 100],\n",
                                    "    'solver': ['liblinear', 'saga']\n",
                                    "}\n",
                                    "\n",
                                    "# Create and train our \"random recipe picker\"\n",
                                    "# TODO: adjust number of iterations\n",
                                    "random_search = RandomizedSearchCV(LogisticRegression(max_iter=1000), param_distributions, n_iter=5, cv=5, random_state=42) # n_iter diubah menjadi 5\n",
                                    "random_search.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Display the \"best recipe\"\n",
                                    "print(f\"Best parameters: {random_search.best_params_}\")\n",
                                    "print(f\"Best cross-validation score: {random_search.best_score_}\")\n",
                                    "```\n",
                                    "\n",
                                    "Dengan mengubah `n_iter` menjadi 5, `RandomizedSearchCV` akan mencoba lebih sedikit kombinasi parameter secara acak dibandingkan sebelumnya (10 iterasi). Ini akan menghasilkan waktu eksekusi yang lebih cepat, namun ada kemungkinan model tidak menemukan kombinasi parameter optimal terbaik karena jumlah percobaan yang lebih sedikit. [cite\\_start]`n_iter` mengontrol jumlah pengaturan parameter yang dicoba secara acak[cite: 55]."
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Fill in the Random Search for Best Parameters\n",
                                    "\n",
                                    "You're doing great, Space Voyager! Now, let's fill in the missing pieces to make this code work. Complete the TODOs to perform a randomized search to find the best parameters for our Logistic Regression model.\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
                                    "from sklearn.linear_model import LogisticRegression\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "X = StandardScaler().fit_transform(X)\n",
                                    "\n",
                                    "# Split dataset into training and testing sets\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Define parameter grid\n",
                                    "param_distributions = {\n",
                                    "    'C': [0.1, 1, 10, 100],  \n",
                                    "    'solver': ['liblinear', 'saga']\n",
                                    "}\n",
                                    "\n",
                                    "model = LogisticRegression(max_iter=5000)\n",
                                    "# TODO: Initialize Random Search with required parameters\n",
                                    "random_search = RandomizedSearchCV(_____)\n",
                                    "random_search.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Print the best parameters found\n",
                                    "print(f\"Best parameters: {random_search.best_params_}\")\n",
                                    "print(f\"Accuracy with the best parameters: {accuracy_score(y_test, random_search.best_estimator_.predict(X_test))}\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Tentu, mari lengkapi kode untuk melakukan *Randomized Search* pada model *Logistic Regression*.\n",
                                    "\n",
                                    "Anda perlu menginisialisasi `RandomizedSearchCV` dengan parameter berikut:\n",
                                    "\n",
                                    "  * `estimator`: Model yang ingin Anda optimalkan, dalam kasus ini `model` (yaitu `LogisticRegression(max_iter=5000)`).\n",
                                    "  * `param_distributions`: Kamus distribusi parameter yang telah Anda definisikan, yaitu `param_distributions`.\n",
                                    "  * `n_iter`: Jumlah kombinasi parameter yang akan dicoba (misalnya, 10, atau sesuai kebutuhan).\n",
                                    "  * `cv`: Jumlah *fold* untuk *cross-validation* (misalnya, 5).\n",
                                    "  * `random_state`: Untuk memastikan hasil yang dapat direproduksi (misalnya, 42).\n",
                                    "\n",
                                    "Berikut adalah kode yang sudah dilengkapi:\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
                                    "from sklearn.linear_model import LogisticRegression\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "from sklearn.preprocessing import StandardScaler # Tambahkan import StandardScaler\n",
                                    "\n",
                                    "# Load dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "X = StandardScaler().fit_transform(X)\n",
                                    "\n",
                                    "# Split dataset into training and testing sets\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Define parameter grid\n",
                                    "param_distributions = {\n",
                                    "    'C': [0.1, 1, 10, 100],\n",
                                    "    'solver': ['liblinear', 'saga']\n",
                                    "}\n",
                                    "\n",
                                    "model = LogisticRegression(max_iter=5000)\n",
                                    "# TODO: Initialize Random Search with required parameters\n",
                                    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_distributions, n_iter=10, cv=5, random_state=42)\n",
                                    "random_search.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Print the best parameters found\n",
                                    "print(f\"Best parameters: {random_search.best_params_}\")\n",
                                    "print(f\"Accuracy with the best parameters: {accuracy_score(y_test, random_search.best_estimator_.predict(X_test))}\")\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Randomized Search for Logistic Regression Parameters\n",
                                    "\n",
                                    "Great work so far; let's continue! Now, fill in the missing pieces to perform a Randomized Search for the best parameters of the LogisticRegression model and calculate the final metric on the testing set.\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.linear_model import LogisticRegression\n",
                                    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
                                    "from sklearn.preprocessing import StandardScaler\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load and scale the wine dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "X = StandardScaler().fit_transform(X)\n",
                                    "\n",
                                    "# Split the dataset\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
                                    "\n",
                                    "# Define the parameter grid\n",
                                    "param_distributions = {\n",
                                    "    'C': [0.1, 0.5, 0.75, 1, 5, 10, 25, 50, 75, 100],\n",
                                    "    'solver': ['liblinear', 'saga']\n",
                                    "}\n",
                                    "\n",
                                    "# TODO: Perform Randomized Search on Logistic Regression model with given parameters\n",
                                    "random_search = ____\n",
                                    "random_search.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Print the best parameters found and the best score achieved\n",
                                    "print(f\"Best parameters: {random_search.best_params_}\")\n",
                                    "print(f\"Best cross-validation score: {random_search.best_score_}\")\n",
                                    "\n",
                                    "# TODO: Calculate and print the accuracy on the test set\n",
                                    "test_predictions = ____\n",
                                    "test_accuracy = ____\n",
                                    "print(f\"Test set accuracy: {test_accuracy}\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.linear_model import LogisticRegression\n",
                                    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
                                    "from sklearn.preprocessing import StandardScaler\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load and scale the wine dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "X = StandardScaler().fit_transform(X)\n",
                                    "\n",
                                    "# Split the dataset\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
                                    "\n",
                                    "# Define the parameter grid\n",
                                    "param_distributions = {\n",
                                    "    'C': [0.1, 0.5, 0.75, 1, 5, 10, 25, 50, 75, 100],\n",
                                    "    'solver': ['liblinear', 'saga']\n",
                                    "}\n",
                                    "\n",
                                    "# TODO: Perform Randomized Search on Logistic Regression model with given parameters\n",
                                    "random_search = RandomizedSearchCV(LogisticRegression(max_iter=1000), param_distributions, n_iter=10, cv=5, random_state=42)\n",
                                    "random_search.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Print the best parameters found and the best score achieved\n",
                                    "print(f\"Best parameters: {random_search.best_params_}\")\n",
                                    "print(f\"Best cross-validation score: {random_search.best_score_}\")\n",
                                    "\n",
                                    "# TODO: Calculate and print the accuracy on the test set\n",
                                    "test_predictions = random_search.best_estimator_.predict(X_test)\n",
                                    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
                                    "print(f\"Test set accuracy: {test_accuracy}\")\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Tune the DecisionTree Classifier\n",
                                    "\n",
                                    "Alright, Stellar Navigator, let's tweak our recipe for the best cake ingredients!\n",
                                    "\n",
                                    "Add the missing pieces to tune the DecisionTreeRegressor using Random Search. Don't forget to use cross-validation to find the best combination!\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_boston\n",
                                    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
                                    "from sklearn.tree import DecisionTreeRegressor\n",
                                    "\n",
                                    "# Load dataset\n",
                                    "X, y = load_boston(return_X_y=True)\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Define parameter grid for DecisionTreeRegressor\n",
                                    "param_distributions = {\n",
                                    "    'max_depth': [4, 6, 8, 10, 12],\n",
                                    "    'min_samples_split': [2, 5, 10, 20]\n",
                                    "}\n",
                                    "\n",
                                    "# TODO: Perform randomized search\n",
                                    "# TODO: Fit the random search model using the training data\n",
                                    "\n",
                                    "print(f\"Best parameters: {random_search.best_params_}\")\n",
                                    "print(f\"Best cross-validation score: {random_search.best_score_}\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Pesan *error* menunjukkan bahwa `load_boston` telah dihapus dari *scikit-learn* sejak versi 1.2 karena masalah etika terkait *dataset* tersebut. Untuk melanjutkan, Anda perlu mengganti `load_boston` dengan *dataset* alternatif yang disarankan, seperti *California housing dataset* atau *Ames housing dataset*.\n",
                                    "\n",
                                    "Berikut adalah kode yang diperbarui menggunakan `fetch_california_housing` sebagai pengganti `load_boston`, dan melengkapi bagian yang hilang untuk *RandomizedSearchCV*:\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import fetch_california_housing # Mengganti load_boston\n",
                                    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
                                    "from sklearn.tree import DecisionTreeRegressor\n",
                                    "\n",
                                    "# Load dataset\n",
                                    "# X, y = load_boston(return_X_y=True) # Baris ini dihapus\n",
                                    "housing = fetch_california_housing()\n",
                                    "X = housing.data\n",
                                    "y = housing.target\n",
                                    "\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Define parameter grid for DecisionTreeRegressor\n",
                                    "param_distributions = {\n",
                                    "    'max_depth': [4, 6, 8, 10, 12],\n",
                                    "    'min_samples_split': [2, 5, 10, 20]\n",
                                    "}\n",
                                    "\n",
                                    "# Inisialisasi model DecisionTreeRegressor\n",
                                    "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
                                    "\n",
                                    "# TODO: Perform randomized search\n",
                                    "random_search = RandomizedSearchCV(estimator=dt_regressor,\n",
                                    "                                   param_distributions=param_distributions,\n",
                                    "                                   n_iter=10,  # Jumlah kombinasi parameter yang akan dicoba secara acak\n",
                                    "                                   cv=5,      # Jumlah cross-validation folds\n",
                                    "                                   random_state=42,\n",
                                    "                                   n_jobs=-1) # Menggunakan semua core yang tersedia untuk komputasi paralel\n",
                                    "\n",
                                    "# TODO: Fit the random search model using the training data\n",
                                    "random_search.fit(X_train, y_train)\n",
                                    "\n",
                                    "print(f\"Best parameters: {random_search.best_params_}\")\n",
                                    "print(f\"Best cross-validation score: {random_search.best_score_}\")\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Implement Model Competition\n",
                                    "\n",
                                    "Great job, Space Explorer! Let's put your new skills to the test. Fill in the missing code to perform RandomizedSearchCV on LogisticRegression and DecisionTree models. The code should create RandomizedSearchCV instances using the provided parameter distributions and fit them to the training data. Implement the random recipe picker and see which one turns out best.\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
                                    "from sklearn.linear_model import LogisticRegression\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.preprocessing import StandardScaler\n",
                                    "\n",
                                    "# Step 1: Getting the dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "X = StandardScaler().fit_transform(X)\n",
                                    "\n",
                                    "# Step 2: Splitting into training and testing sets\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Step 3: Defining parameter distributions\n",
                                    "param_distributions_lr = {'C': [0.1, 1, 10], 'solver': ['liblinear']}\n",
                                    "param_distributions_dt = {'max_depth': [3, 5, 10], 'min_samples_split': [2, 5, 10]}\n",
                                    "\n",
                                    "# Step 4: Performing Random Search\n",
                                    "# TODO: Add RandomizedSearchCV for Logistic Regression with given parameter distributions and 2000 max iterations\n",
                                    "# TODO: Add RandomizedSearchCV for Decision Tree with given parameter distributions\n",
                                    "\n",
                                    "# Step 5: Fitting the models\n",
                                    "random_search_lr.fit(X_train, y_train)\n",
                                    "random_search_dt.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Step 6: Displaying the best parameters and scores\n",
                                    "print(f\"Best Logistic Regression parameters: {random_search_lr.best_params_}\")\n",
                                    "print(f\"Best Logistic Regression score: {random_search_lr.best_score_}\")\n",
                                    "print(f\"Best Decision Tree parameters: {random_search_dt.best_params_}\")\n",
                                    "print(f\"Best Decision Tree score: {random_search_dt.best_score_}\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
                                    "from sklearn.linear_model import LogisticRegression\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.preprocessing import StandardScaler\n",
                                    "\n",
                                    "# Step 1: Getting the dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "X = StandardScaler().fit_transform(X)\n",
                                    "\n",
                                    "# Step 2: Splitting into training and testing sets\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Step 3: Defining parameter distributions\n",
                                    "param_distributions_lr = {'C': [0.1, 1, 10], 'solver': ['liblinear']}\n",
                                    "param_distributions_dt = {'max_depth': [3, 5, 10], 'min_samples_split': [2, 5, 10]}\n",
                                    "\n",
                                    "# Step 4: Performing Random Search\n",
                                    "# TODO: Add RandomizedSearchCV for Logistic Regression with given parameter distributions and 2000 max iterations\n",
                                    "random_search_lr = RandomizedSearchCV(LogisticRegression(max_iter=2000), param_distributions_lr, n_iter=len(param_distributions_lr['C']) * len(param_distributions_lr['solver']), cv=5, random_state=42)\n",
                                    "\n",
                                    "# TODO: Add RandomizedSearchCV for Decision Tree with given parameter distributions\n",
                                    "random_search_dt = RandomizedSearchCV(DecisionTreeClassifier(random_state=42), param_distributions_dt, n_iter=len(param_distributions_dt['max_depth']) * len(param_distributions_dt['min_samples_split']), cv=5, random_state=42)\n",
                                    "\n",
                                    "# Step 5: Fitting the models\n",
                                    "random_search_lr.fit(X_train, y_train)\n",
                                    "random_search_dt.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Step 6: Displaying the best parameters and scores\n",
                                    "print(f\"Best Logistic Regression parameters: {random_search_lr.best_params_}\")\n",
                                    "print(f\"Best Logistic Regression score: {random_search_lr.best_score_}\")\n",
                                    "print(f\"Best Decision Tree parameters: {random_search_dt.best_params_}\")\n",
                                    "print(f\"Best Decision Tree score: {random_search_dt.best_score_}\")\n",
                                    "```"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
