{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Unit 5 Building Full Preprocessing Pipeline for the Titanic Dataset\n",
                                    "\n",
                                    "# Lesson Introduction\n",
                                    "\n",
                                    "Welcome\\! Today, we'll learn how to build a full **preprocessing pipeline** for the Titanic dataset. In real work, you're going to deal with big datasets with lots of features and rows.\n",
                                    "\n",
                                    "We aim to learn how to prepare real data for machine learning models by handling missing values, encoding categorical features, scaling numerical features, and splitting the data into training and test sets.\n",
                                    "\n",
                                    "Imagine you have a messy jigsaw puzzle. You need to organize the pieces, find the edges first, and then start assembling. Data preprocessing is like organizing the pieces before starting the puzzle.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## Load and Prepare the Data\n",
                                    "\n",
                                    "Let's start by loading the **Titanic dataset** using **Seaborn**, which has information about passengers like age, fare, and whether they survived. We'll drop some columns we won't use.\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "import seaborn as sns\n",
                                    "\n",
                                    "# Load the Titanic dataset\n",
                                    "df = sns.load_dataset('titanic')\n",
                                    "\n",
                                    "# Drop columns that won't be used\n",
                                    "df = df.drop(columns=['deck', 'embarked', 'alive'])\n",
                                    "\n",
                                    "print(df.head())\n",
                                    "```\n",
                                    "\n",
                                    "Expected output:\n",
                                    "\n",
                                    "```\n",
                                    "   survived  pclass     sex   age  sibsp  parch     fare  who  adult_male  \\\n",
                                    "0         0       3    male  22.0      1      0   7.2500  man        True   \n",
                                    "1         1       1  female  38.0      1      0  71.2833  woman      False   \n",
                                    "2         1       3  female  26.0      0      0   7.9250  woman      False   \n",
                                    "3         1       1  female  35.0      1      0  53.1000  woman      False   \n",
                                    "4         0       3    male  35.0      0      0   8.0500  man        True   \n",
                                    " \n",
                                    "     embark_town  alone  \n",
                                    "0  Southampton    False  \n",
                                    "1    Cherbourg    False  \n",
                                    "2  Southampton     True  \n",
                                    "3  Southampton    False  \n",
                                    "4  Southampton     True  \n",
                                    "```\n",
                                    "\n",
                                    "We loaded the dataset and dropped columns `deck`, `embarked`, and `alive` because they have too many missing values or aren't useful. For example, the `embarked` column shouldn't affect the passenger's survival rate, so it's questionable as a feature.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## Handle Missing Values\n",
                                    "\n",
                                    "Next, let's handle missing values using **SimpleImputer** from **SciKit Learn**.\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.impute import SimpleImputer\n",
                                    "\n",
                                    "# Handle missing values\n",
                                    "imputer_num = SimpleImputer(strategy='mean')\n",
                                    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
                                    "\n",
                                    "df['age'] = imputer_num.fit_transform(df[['age']])\n",
                                    "df['embark_town'] = imputer_cat.fit_transform(df[['embark_town']].values.reshape(-1, 1)).ravel()\n",
                                    "df['fare'] = imputer_num.fit_transform(df[['fare']])\n",
                                    "\n",
                                    "print(df.head())\n",
                                    "```\n",
                                    "\n",
                                    "As a reminder, `ravel()` is a method in NumPy that returns a contiguous flattened array. In this context, it's used to flatten the column vector returned by `fit_transform()` into a 1-dimensional array. This ensures that the `embark_town` column is reshaped back into a 1-D array that fits into the DataFrame correctly.\n",
                                    "\n",
                                    "Expected output:\n",
                                    "\n",
                                    "```\n",
                                    "   survived  pclass     sex   age  sibsp  parch     fare  who  adult_male  \\\n",
                                    "0         0       3    male  22.0      1      0   7.2500  man        True   \n",
                                    "1         1       1  female  38.0      1      0  71.2833  woman      False   \n",
                                    "2         1       3  female  26.0      0      0   7.9250  woman      False   \n",
                                    "3         1       1  female  35.0      1      0  53.1000  woman      False   \n",
                                    "4         0       3    male  35.0      0      0   8.0500  man        True   \n",
                                    " \n",
                                    "     embark_town  alone  \n",
                                    "0  Southampton    False  \n",
                                    "1    Cherbourg    False  \n",
                                    "2  Southampton     True  \n",
                                    "3  Southampton    False  \n",
                                    "4  Southampton     True  \n",
                                    "```\n",
                                    "\n",
                                    "We filled missing numerical data (`age`, `fare`) using the mean and categorical data (`embark_town`) using the most frequent value. This is like guessing a missing puzzle piece based on surrounding ones.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## Encode Categorical Features: Part 1\n",
                                    "\n",
                                    "Machine learning models need numerical data. So, we use **OneHotEncoder** to convert categorical features into numbers.\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.preprocessing import OneHotEncoder\n",
                                    "\n",
                                    "# Encode categorical features\n",
                                    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
                                    "encoded_columns = encoder.fit_transform(df[['sex', 'class', 'embark_town', 'who', 'adult_male', 'alone']])\n",
                                    "encoded_df = pd.DataFrame(encoded_columns, columns=encoder.get_feature_names_out(['sex', 'class', 'embark_town', 'who', 'adult_male', 'alone']))\n",
                                    "```\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## Encode Categorical Features: Part 2\n",
                                    "\n",
                                    "Next, we drop the original categorical columns and concatenate the new encoded columns with the DataFrame.\n",
                                    "\n",
                                    "```python\n",
                                    "# Drop and concatenate\n",
                                    "df = df.drop(columns=['sex', 'class', 'embark_town', 'who', 'adult_male', 'alone'])\n",
                                    "df = pd.concat([df.reset_index(drop=True), encoded_df], axis=1)\n",
                                    "\n",
                                    "print(df.head())\n",
                                    "```\n",
                                    "\n",
                                    "Expected output:\n",
                                    "\n",
                                    "```\n",
                                    "   survived  pclass   age  sibsp  parch     fare  alone  sex_male  \\\n",
                                    "0         0       3  22.0      1      0   7.2500  False       1.0   \n",
                                    "1         1       1  38.0      1      0  71.2833  False       0.0   \n",
                                    "2         1       3  26.0      0      0   7.9250   True       0.0   \n",
                                    "3         1       1  35.0      1      0  53.1000  False       0.0   \n",
                                    "4         0       3  35.0      0      0   8.0500   True       1.0   \n",
                                    " \n",
                                    "   class_2  class_3  embark_town_Queenstown  embark_town_Southampton  \\\n",
                                    "0      0.0      1.0                     0.0                      1.0   \n",
                                    "1      0.0      0.0                     0.0                      0.0   \n",
                                    "2      0.0      1.0                     0.0                      1.0   \n",
                                    "3      0.0      0.0                     0.0                      1.0   \n",
                                    "4      0.0      1.0                     0.0                      1.0   \n",
                                    " \n",
                                    "   who_man  who_woman  adult_male_True  \n",
                                    "0      1.0        0.0              1.0  \n",
                                    "1      0.0        1.0              0.0  \n",
                                    "2      0.0        1.0              0.0  \n",
                                    "3      0.0        1.0              0.0  \n",
                                    "4      1.0        0.0              1.0  \n",
                                    "```\n",
                                    "\n",
                                    "We converted the categorical columns into numerical ones, dropped the originals, and added the new encoded columns. It's like translating words into a secret code for a robot.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## Feature Scaling\n",
                                    "\n",
                                    "Feature scaling ensures all numerical values are on a similar scale. We use **StandardScaler** for this.\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.preprocessing import StandardScaler\n",
                                    "\n",
                                    "# Feature scaling\n",
                                    "scaler = StandardScaler()\n",
                                    "scaled_columns = scaler.fit_transform(df[['age', 'fare']])\n",
                                    "scaled_df = pd.DataFrame(scaled_columns, columns=['age', 'fare'])\n",
                                    "\n",
                                    "# Drop and concatenate\n",
                                    "df = df.drop(columns=['age', 'fare'])\n",
                                    "df = pd.concat([df.reset_index(drop=True), scaled_df], axis=1)\n",
                                    "\n",
                                    "print(df.head())\n",
                                    "```\n",
                                    "\n",
                                    "Expected output:\n",
                                    "\n",
                                    "```\n",
                                    "   survived  pclass  sibsp  parch  alone  sex_male  class_2  class_3  \\\n",
                                    "0         0       3      1      0  False       1.0      0.0      1.0   \n",
                                    "1         1       1      1      0  False       0.0      0.0      0.0   \n",
                                    "2         1       3      0      0   True       0.0      0.0      1.0   \n",
                                    "3         1       1      1      0  False       0.0      0.0      0.0   \n",
                                    "4         0       3      0      0   True       1.0      0.0      1.0   \n",
                                    " \n",
                                    "   embark_town_Queenstown  embark_town_Southampton  who_man  who_woman  \\\n",
                                    "0                     0.0                      1.0      1.0        0.0   \n",
                                    "1                     0.0                      0.0      0.0        1.0   \n",
                                    "2                     0.0                      1.0      0.0        1.0   \n",
                                    "3                     0.0                      1.0      0.0        1.0   \n",
                                    "4                     0.0                      1.0      1.0        0.0   \n",
                                    " \n",
                                    "   adult_male_True       age      fare  \n",
                                    "0              1.0 -0.530376 -0.502445  \n",
                                    "1              0.0  0.571829  0.788947  \n",
                                    "2              0.0 -0.254596 -0.488854  \n",
                                    "3              0.0  0.400810  0.420731  \n",
                                    "4              1.0  0.400810 -0.486337  \n",
                                    "```\n",
                                    "\n",
                                    "We scaled our numerical data (`age`, `fare`) to have a mean of 0 and a standard deviation of 1. This is like resizing puzzle pieces to fit perfectly.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## Separate Features and Target Variable\n",
                                    "\n",
                                    "Next, we separate our features (used for predictions) and the target variable (the outcome we predict).\n",
                                    "\n",
                                    "```python\n",
                                    "# Separate features and target variable\n",
                                    "X = df.drop(columns=['survived'])\n",
                                    "y = df['survived']\n",
                                    "\n",
                                    "print(\"X:\\n\", X.head())\n",
                                    "print(\"\\ny:\\n\", y.head())\n",
                                    "```\n",
                                    "\n",
                                    "Expected output:\n",
                                    "\n",
                                    "```\n",
                                    "X:\n",
                                    "    pclass  sibsp  parch  alone  sex_male  class_2  class_3  embark_town_Queenstown  \\\n",
                                    "0       3      1      0  False       1.0      0.0      1.0                     0.0   \n",
                                    "1       1      1      0  False       0.0      0.0      0.0                     0.0   \n",
                                    "2       3      0      0   True       0.0      0.0      1.0                     0.0   \n",
                                    "3       1      1      0  False       0.0      0.0      0.0                     0.0   \n",
                                    "4       3      0      0   True       1.0      0.0      1.0                     0.0   \n",
                                    " \n",
                                    "   embark_town_Southampton  who_man  who_woman  adult_male_True       age  \\\n",
                                    "0                      1.0      1.0        0.0              1.0 -0.530376   \n",
                                    "1                      0.0      0.0        1.0              0.0  0.571829   \n",
                                    "2                      1.0      0.0        1.0              0.0 -0.254596   \n",
                                    "3                      1.0      0.0        1.0              0.0  0.400810   \n",
                                    "4                      1.0      1.0        0.0              1.0  0.400810   \n",
                                    " \n",
                                    "       fare  \n",
                                    "0 -0.502445  \n",
                                    "1  0.788947  \n",
                                    "2 -0.488854  \n",
                                    "3  0.420731  \n",
                                    "4 -0.486337  \n",
                                    "\n",
                                    "y:\n",
                                    " 0    0\n",
                                    "1    1\n",
                                    "2    1\n",
                                    "3    1\n",
                                    "4    0\n",
                                    "Name: survived, dtype: int64\n",
                                    "```\n",
                                    "\n",
                                    "Here, `X` contains all features except `survived`, and `y` contains the `survived` column. This helps in training the model more efficiently.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## Train-Test Split\n",
                                    "\n",
                                    "Finally, we split the dataset into training and test sets using **train\\_test\\_split**. This lets us train the model on one part of the data and test it on another.\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "\n",
                                    "# Train-test split\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "print(f\"Training set size: {len(X_train)}, Test set size: {len(X_test)}\")\n",
                                    "```\n",
                                    "\n",
                                    "Expected output:\n",
                                    "\n",
                                    "```\n",
                                    "Training set size: 712, Test set size: 179\n",
                                    "```\n",
                                    "\n",
                                    "We split the data so 80% is used for training and 20% for testing. This step is like practicing with some pieces before trying the whole puzzle.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## Lesson Summary\n",
                                    "\n",
                                    "Today, we:\n",
                                    "\n",
                                    "  * **Loaded and prepared** the Titanic dataset.\n",
                                    "  * **Handled missing values**.\n",
                                    "  * **Encoded categorical features**.\n",
                                    "  * **Scaled numerical features**.\n",
                                    "  * **Separated features and the target variable**.\n",
                                    "  * **Split the dataset** into training and test sets.\n",
                                    "\n",
                                    "Now, you'll get to practice these steps hands-on. Happy learning\\!"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Drop Unwanted Titanic Columns\n",
                                    "\n",
                                    "Hey Space Navigator, let's continue our journey! We need to load the Titanic dataset and drop some columns we don't need. Fill in the missing lines to load the Titanic dataset using Seaborn and drop the specified columns. Let's ace this mission!\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "import seaborn as sns\n",
                                    "\n",
                                    "# Load the Titanic dataset\n",
                                    "df = sns.load_dataset('titanic')\n",
                                    "\n",
                                    "# TODO: Drop columns that won't be used: deck, embarked and alive\n",
                                    "\n",
                                    "# Display the modified dataset\n",
                                    "print(df.head())\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "import seaborn as sns\n",
                                    "\n",
                                    "# Load the Titanic dataset\n",
                                    "df = sns.load_dataset('titanic')\n",
                                    "\n",
                                    "# Drop columns that won't be used: deck, embarked and alive\n",
                                    "df = df.drop(columns=['deck', 'embarked', 'alive'])\n",
                                    "\n",
                                    "# Display the modified dataset\n",
                                    "print(df.head())\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Handle Missing Values in Titanic Dataset\n",
                                    "\n",
                                    "Great job so far, Galactic Pioneer! Let's handle some missing data before we move ahead. Fill in the TODOs to complete the code.\n",
                                    "\n",
                                    "Cleaning your dataset by filling in missing values helps ensure that the analysis is accurate and meaningful.\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "import seaborn as sns\n",
                                    "from sklearn.impute import SimpleImputer\n",
                                    "\n",
                                    "# Load the Titanic dataset\n",
                                    "df = sns.load_dataset('titanic')\n",
                                    "\n",
                                    "# Drop some columns for simplicity\n",
                                    "df = df.drop(columns=['deck', 'embarked', 'alive'])\n",
                                    "\n",
                                    "# TODO: Handle missing values in 'age' and 'fare' using mean\n",
                                    "\n",
                                    "print(df[['age', 'fare']].isna().sum())  # should be 0 if NaNs are handled!\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "import pandas as pd\n",
                                    "import seaborn as sns\n",
                                    "from sklearn.impute import SimpleImputer\n",
                                    "\n",
                                    "# Load the Titanic dataset\n",
                                    "df = sns.load_dataset('titanic')\n",
                                    "\n",
                                    "# Drop some columns for simplicity\n",
                                    "df = df.drop(columns=['deck', 'embarked', 'alive'])\n",
                                    "\n",
                                    "# Handle missing values in 'age' and 'fare' using mean\n",
                                    "imputer_num = SimpleImputer(strategy='mean')\n",
                                    "\n",
                                    "# Apply to 'age' column\n",
                                    "df['age'] = imputer_num.fit_transform(df[['age']])\n",
                                    "\n",
                                    "# Apply to 'fare' column\n",
                                    "# Note: While 'fare' has very few missing values (or sometimes none in the default dataset),\n",
                                    "# it's good practice to apply the imputer if you expect missing values in real-world scenarios.\n",
                                    "df['fare'] = imputer_num.fit_transform(df[['fare']])\n",
                                    "\n",
                                    "\n",
                                    "print(df[['age', 'fare']].isna().sum())\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Encode Categorical Features and Concatenate"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Handle Missing Values and Feature Scaling"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
