{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Unit 2 Random Forest in Machine Learning\n",
                                    "\n",
                                    "Hey there\\! Today, we're going to dive into a powerful tool in machine learning called **Random Forest**. Just like a forest made up of many trees, a **Random Forest** is made up of many decision trees working together. This helps make more accurate predictions and reduces the risk of mistakes.\n",
                                    "\n",
                                    "Our goal for this lesson is to understand how to load a dataset, split it into training and testing sets, train a **Random Forest** classifier, and use it to make predictions. Ready? Let's go\\!\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## RandomForestClassifier vs BaggingClassifier\n",
                                    "\n",
                                    "The **RandomForestClassifier** is closely related to the **BaggingClassifier**. Both are ensemble methods that fit multiple models on various sub-samples of the dataset. The key difference is that **RandomForestClassifier** introduces an additional layer of randomization by selecting a random subset of features for each split in the decision trees, while the **BaggingClassifier** uses every feature for splitting.\n",
                                    "\n",
                                    "Why use **Random Forest**? Here are a few reasons:\n",
                                    "\n",
                                    "  * **Reduces Overfitting**: By using many trees, **Random Forests** avoid learning the noise in the data instead of the actual pattern.\n",
                                    "  * **Improves Accuracy**: Combining multiple predictions generally leads to better accuracy.\n",
                                    "  * **Handles Large Feature Spaces**: **Random Forests** can manage many input features effectively.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## Loading the Dataset\n",
                                    "\n",
                                    "Let's dive into some code by loading a dataset. We'll use the wine dataset from scikit-learn, a popular machine learning library. This dataset includes measurements of wines that help classify them into different categories.\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "\n",
                                    "# Load the wine dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "```\n",
                                    "\n",
                                    "In this code, `X` represents input features (measurements of wines) and `y` represents labels (categories of wine).\n",
                                    "\n",
                                    "Before training our model, we need to split our dataset into training and testing sets. This way, we can train our model on one part and test its accuracy on another.\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "\n",
                                    "# Splitting the dataset\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "```\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## Training the Random Forest Classifier\n",
                                    "\n",
                                    "Now, let's train our **Random Forest** classifier. A classifier assigns labels to data points. Our classifier will decide the category of the wine based on its features.\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.ensemble import RandomForestClassifier\n",
                                    "\n",
                                    "# Training a random forest classifier\n",
                                    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                                    "rf_clf.fit(X_train, y_train)\n",
                                    "```\n",
                                    "\n",
                                    "Here, we create a **Random Forest** with 100 trees and fit it to our training data. Note that you can specify the settings of the trees used in the random forest – the **RandomForestClassifier** class has the same set of parameters.\n",
                                    "\n",
                                    "For example, here is how we can control the maximum depth of each tree in the forest:\n",
                                    "\n",
                                    "```python\n",
                                    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=3)\n",
                                    "```\n",
                                    "\n",
                                    "Yep, this simple\\! Now all the trees will be initialized with `max_depth=3`.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## Evaluating the Model\n",
                                    "\n",
                                    "Now, we will evaluate the **Random Forest** model on the test set and compare its accuracy with that of a simple Decision Tree classifier.\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Training a decision tree classifier for comparison\n",
                                    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
                                    "dt_clf.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Making predictions with both classifiers\n",
                                    "y_pred_rf = rf_clf.predict(X_test)\n",
                                    "y_pred_dt = dt_clf.predict(X_test)\n",
                                    "\n",
                                    "# Calculating accuracy for both models\n",
                                    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
                                    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
                                    "\n",
                                    "print(f\"Random Forest Accuracy: {accuracy_rf:.2f}\")\n",
                                    "print(f\"Decision Tree Accuracy: {accuracy_dt:.2f}\")\n",
                                    "\n",
                                    "# Random Forest Accuracy: 1.00\n",
                                    "# Decision Tree Accuracy: 0.94\n",
                                    "```\n",
                                    "\n",
                                    "Here, we trained a **DecisionTreeClassifier** for comparison. We then made predictions on the test set using both the **Random Forest** and **Decision Tree** models, and calculated their accuracies. As you can see, **Random Forest** outperforms a simple **Decision Tree**, showing an amazing score – 100% of correct predictions.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## Lesson Summary\n",
                                    "\n",
                                    "Great job\\! Let's recap:\n",
                                    "\n",
                                    "  * **Understanding Random Forest**: A **Random Forest** is an ensemble of decision trees that make accurate predictions.\n",
                                    "  * **RandomForestClassifier vs BaggingClassifier**: **RandomForestClassifier** adds random feature selection to the bagging method.\n",
                                    "  * **Advantages**: **Random Forests** reduce overfitting, improve accuracy, and handle large feature spaces.\n",
                                    "  * **Loading and Splitting Data**: We loaded a dataset and split it into training and testing sets.\n",
                                    "  * **Training the Model**: We trained a **Random Forest** classifier using **RandomForestClassifier**, with important parameters like `n_estimators` and `random_state`.\n",
                                    "  * **Model Evaluation**: We evaluated model performance and found that the **Random Forest** often outperforms a single **Decision Tree**.\n",
                                    "\n",
                                    "Now that you understand **Random Forests**, it's time to practice. In the upcoming session, you'll get hands-on experience implementing and tuning a **Random Forest** model using your new skills. Get ready to experiment with different parameters and see how they affect the model's performance. Happy coding\\!"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Adjusting Random Forest Tree Depth\n",
                                    "\n",
                                    "Now let's tweak the RandomForestClassifier. The current version seems to underperform. Find more optimal parameters for n_estimators and max_depth. Make sure to achieve the accuracy no less than 1.00 – it is possible with this model and this dataset.\n",
                                    "\n",
                                    "Go ahead and train that perfect classfier!\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.ensemble import RandomForestClassifier\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load the wine dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "\n",
                                    "# Split the dataset\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Train and evaluate the Random Forest classifier\n",
                                    "rf_clf = RandomForestClassifier(n_estimators=25, random_state=42, max_depth=3)\n",
                                    "rf_clf.fit(X_train, y_train)\n",
                                    "accuracy_rf = accuracy_score(y_test, rf_clf.predict(X_test))\n",
                                    "\n",
                                    "print(f\"Random Forest Accuracy: {accuracy_rf:.2f}\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "You're right\\! With the wine dataset, it's definitely possible to achieve very high accuracy, sometimes even 1.00, with a well-tuned Random Forest. The initial parameters might be a bit too constrained.\n",
                                    "\n",
                                    "Let's adjust the `n_estimators` (number of trees) and `max_depth` (maximum depth of each tree) to find a combination that yields optimal performance. We'll iterate through a range of values for both to see what works best.\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.ensemble import RandomForestClassifier\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load the wine dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "\n",
                                    "# Split the dataset\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "best_accuracy = 0\n",
                                    "best_n_estimators = 0\n",
                                    "best_max_depth = 0\n",
                                    "\n",
                                    "# Experiment with different n_estimators and max_depth values\n",
                                    "for n_estimators in range(50, 201, 25): # Try n_estimators from 50 to 200\n",
                                    "    for max_depth in range(5, 21, 5): # Try max_depth from 5 to 20\n",
                                    "        # Train the Random Forest classifier\n",
                                    "        rf_clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
                                    "        rf_clf.fit(X_train, y_train)\n",
                                    "        \n",
                                    "        # Calculate accuracy\n",
                                    "        accuracy_rf = accuracy_score(y_test, rf_clf.predict(X_test))\n",
                                    "        \n",
                                    "        # Check if current parameters give better accuracy\n",
                                    "        if accuracy_rf > best_accuracy:\n",
                                    "            best_accuracy = accuracy_rf\n",
                                    "            best_n_estimators = n_estimators\n",
                                    "            best_max_depth = max_depth\n",
                                    "\n",
                                    "print(f\"Best Random Forest Accuracy: {best_accuracy:.2f}\")\n",
                                    "print(f\"Best n_estimators: {best_n_estimators}\")\n",
                                    "print(f\"Best max_depth: {best_max_depth}\")\n",
                                    "\n",
                                    "# Train the \"perfect\" classifier with the best found parameters\n",
                                    "perfect_rf_clf = RandomForestClassifier(n_estimators=best_n_estimators, max_depth=best_max_depth, random_state=42)\n",
                                    "perfect_rf_clf.fit(X_train, y_train)\n",
                                    "perfect_accuracy = accuracy_score(y_test, perfect_rf_clf.predict(X_test))\n",
                                    "\n",
                                    "print(f\"\\nAccuracy of the perfect classifier: {perfect_accuracy:.2f}\")\n",
                                    "\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Complete the Random Forest Classifier for Wine Dataset\n",
                                    "\n",
                                    "Hey, Space Explorer! Your mission is to complete the Random Forest script. Fill in the missing pieces of code to load the wine dataset, split it into training and testing sets, and train a classifier. Let's see your skills in action!\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.ensemble import RandomForestClassifier\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "\n",
                                    "# TODO: Load the wine dataset and assign the features and labels to X and y\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "\n",
                                    "# Splitting the dataset\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# TODO: Train the RandomForestClassifier with 100 estimators and max_depth of 3\n",
                                    "\n",
                                    "# TODO: Make predictions and calculate accuracy\n",
                                    "\n",
                                    "# TODO: Print accuracy\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.ensemble import RandomForestClassifier\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "\n",
                                    "# Load the wine dataset and assign the features and labels to X and y\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "\n",
                                    "# Splitting the dataset\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Train the RandomForestClassifier with 100 estimators and max_depth of 3\n",
                                    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
                                    "rf_clf.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Make predictions and calculate accuracy\n",
                                    "y_pred = rf_clf.predict(X_test)\n",
                                    "accuracy = accuracy_score(y_test, y_pred)\n",
                                    "\n",
                                    "# Print accuracy\n",
                                    "print(f\"Random Forest Classifier Accuracy: {accuracy:.2f}\")\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Improving Random Forest for Wine Classification\n",
                                    "\n",
                                    "Hey, Stellar Navigator! Ready to add some code and see the magic?\n",
                                    "\n",
                                    "Complete the code by addressing all the TODO comments, and see the graph showing how the model's accuracy depend on the number of estimators used.\n",
                                    "\n",
                                    "```python\n",
                                    "import matplotlib.pyplot as plt\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.ensemble import RandomForestClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load the wine dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "\n",
                                    "# Split data into training and testing sets\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
                                    "\n",
                                    "# TODO: Define the list of n_estimators to try, including integers from 1 to 40 (inclusive)\n",
                                    "accuracies = []\n",
                                    "\n",
                                    "# Train and test models with different n_estimators\n",
                                    "for n in n_estimators_list:\n",
                                    "    # TODO: train RandomForestClassifier with the given number of estimators and make predictions\n",
                                    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
                                    "\n",
                                    "# Plot the results\n",
                                    "plt.plot(n_estimators_list, accuracies, marker='o')\n",
                                    "plt.xlabel('Number of Estimators')\n",
                                    "plt.ylabel('Accuracy')\n",
                                    "plt.title('Random Forest Accuracy vs Number of Estimators')\n",
                                    "plt.show()\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "import matplotlib.pyplot as plt\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.ensemble import RandomForestClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load the wine dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "\n",
                                    "# Split data into training and testing sets\n",
                                    "# Note: test_size=0.5 is a large test set, which might show more variance.\n",
                                    "# For typical model training, a smaller test_size like 0.2 or 0.3 is common.\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
                                    "\n",
                                    "# Define the list of n_estimators to try, including integers from 1 to 40 (inclusive)\n",
                                    "n_estimators_list = list(range(1, 41))\n",
                                    "accuracies = []\n",
                                    "\n",
                                    "# Train and test models with different n_estimators\n",
                                    "for n in n_estimators_list:\n",
                                    "    # train RandomForestClassifier with the given number of estimators and make predictions\n",
                                    "    rf_clf = RandomForestClassifier(n_estimators=n, random_state=42)\n",
                                    "    rf_clf.fit(X_train, y_train)\n",
                                    "    y_pred = rf_clf.predict(X_test)\n",
                                    "    \n",
                                    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
                                    "\n",
                                    "# Plot the results\n",
                                    "plt.figure(figsize=(10, 6)) # Optional: make the plot a bit larger\n",
                                    "plt.plot(n_estimators_list, accuracies, marker='o', linestyle='-')\n",
                                    "plt.xlabel('Number of Estimators')\n",
                                    "plt.ylabel('Accuracy')\n",
                                    "plt.title('Random Forest Accuracy vs Number of Estimators')\n",
                                    "plt.grid(True) # Optional: add a grid for better readability\n",
                                    "plt.xticks(n_estimators_list[::4]) # Show fewer x-axis ticks for cleaner plot\n",
                                    "plt.tight_layout() # Adjust layout to prevent labels from overlapping\n",
                                    "plt.show()\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Evaluate Random Forest Accuracy with Varying Depths"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
