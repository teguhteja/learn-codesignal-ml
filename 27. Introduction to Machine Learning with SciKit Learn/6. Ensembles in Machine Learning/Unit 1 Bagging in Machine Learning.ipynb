{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Unit 1 Bagging in Machine Learning\n",
                                    "\n",
                                    "Hello\\! In this lesson, we're diving into a powerful technique in machine learning called **Bagging**. Bagging stands for **Bootstrap Aggregating**. Imagine making important decisions by averaging the opinions of a large group rather than relying on just one individual. This collaborative approach generally leads to better and more stable decisions. The idea behind all ensemble methods is to combine predictions from multiple models to produce a single prediction. Our goal is to understand **Bagging**, how it works, and how to implement it using Python's **scikit-learn** library.\n",
                                    "\n",
                                    "Bagging is an ensemble method. It improves the stability and accuracy of machine learning models by training multiple copies of a dataset and combining their results. Think of it as working with a panel of experts rather than a single adviser.\n",
                                    "\n",
                                    "### How Bagging Works: An Example\n",
                                    "\n",
                                    "Let's break it down with a simple example:\n",
                                    "\n",
                                    "Suppose you have a dataset of different types of flowers and you want to classify them. Instead of training just one decision tree which might overfit to your training data, you can train multiple decision trees on different subsets of your data. Each subset is created by randomly selecting samples from the original dataset (with replacement) and has the same size as the original dataset. Then, you aggregate the predictions from all the trees. This process reduces overfitting and leads to a more robust model.\n",
                                    "\n",
                                    "It is important to note that a decision tree is just an example. You can use any model with bagging.\n",
                                    "\n",
                                    "### Loading a Dataset and Splitting the Data\n",
                                    "\n",
                                    "Let's start by loading a dataset. Think of it as a table of data where each row is an example we're learning from, and each column is a feature or quality about the examples. For today, we'll use a dataset about wine. This dataset comes with `scikit-learn`, so it's easy to load.\n",
                                    "\n",
                                    "Here's the code to load the dataset:\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "\n",
                                    "# Load dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "# Note: The output is a tuple of feature matrix X and target vector y\n",
                                    "```\n",
                                    "\n",
                                    "In this code, `X` represents the features of the dataset, and `y` represents the labels (the class of wine).\n",
                                    "\n",
                                    "To test our model properly, we split our data into training and testing parts, like studying for a test and then taking it. Use `train_test_split` from `scikit-learn` to do this:\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "\n",
                                    "# Split the dataset\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "# X_train, X_test, y_train, and y_test are arrays\n",
                                    "# For instance, len(X_train) would be 142, which is 80% of 178 samples\n",
                                    "```\n",
                                    "\n",
                                    "  * `test_size=0.2` uses 20% of the data for testing and 80% for training.\n",
                                    "  * `random_state=42` ensures the split is the same each time you run the code.\n",
                                    "\n",
                                    "### Building and Training a Single Decision Tree Classifier\n",
                                    "\n",
                                    "Before we dive into Bagging, let's first build a simple decision tree to see its performance:\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Train a single decision tree classifier\n",
                                    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
                                    "tree_clf.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Predict and calculate accuracy\n",
                                    "y_pred_tree = tree_clf.predict(X_test)\n",
                                    "tree_accuracy = accuracy_score(y_test, y_pred_tree)\n",
                                    "print(f\"Accuracy of single Decision Tree: {tree_accuracy:.2f}\")  # 0.94\n",
                                    "```\n",
                                    "\n",
                                    "### Building and Training a Bagging Classifier: Part 1\n",
                                    "\n",
                                    "Now let's create our Bagging classifier. We’ll start by defining the Bagging classifier and specifying its parameters:\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.ensemble import BaggingClassifier\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "\n",
                                    "# Train a bagging classifier\n",
                                    "bag_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
                                    "```\n",
                                    "\n",
                                    "In this code:\n",
                                    "\n",
                                    "  * We create a `BaggingClassifier`, our team captain organizing the mini-models.\n",
                                    "  * `estimator=DecisionTreeClassifier()` means each mini-model is a decision tree.\n",
                                    "  * `n_estimators=100` means we’ll have 100 mini-models (or decision trees) on our team.\n",
                                    "\n",
                                    "### Building and Training a Bagging Classifier: Part 2\n",
                                    "\n",
                                    "Let's continue by training the classifier with our training data:\n",
                                    "\n",
                                    "```python\n",
                                    "bag_clf.fit(X_train, y_train)\n",
                                    "```\n",
                                    "\n",
                                    "Finally, let's make predictions with our Bagging classifier and evaluate its performance:\n",
                                    "\n",
                                    "```python\n",
                                    "# Predict and calculate accuracy\n",
                                    "y_pred_bag = bag_clf.predict(X_test)\n",
                                    "bag_accuracy = accuracy_score(y_test, y_pred_bag)\n",
                                    "print(f\"Accuracy of Bagging Classifier: {bag_accuracy:.2f}\")  # 0.97\n",
                                    "```\n",
                                    "\n",
                                    "We see that using the bagging technique helped us to improve the resulting accuracy from 0.94 to 0.97.\n",
                                    "\n",
                                    "### Advantages and Disadvantages of Bagging\n",
                                    "\n",
                                    "While bagging offers numerous benefits, it also has some drawbacks:\n",
                                    "\n",
                                    "**Advantages:**\n",
                                    "\n",
                                    "  * **Reduced Overfitting:** By aggregating the results from multiple models, bagging helps to minimize overfitting.\n",
                                    "  * **Improved Accuracy:** The overall performance of the ensemble method is generally better than that of a single model.\n",
                                    "  * **Stability:** Bagging provides more stable predictions by reducing the variance in the model's output.\n",
                                    "\n",
                                    "**Disadvantages:**\n",
                                    "\n",
                                    "  * **Increased Computational Cost:** Training multiple models can be computationally expensive and time-consuming.\n",
                                    "  * **Complexity:** Combining multiple models can make the model more complex and harder to interpret.\n",
                                    "\n",
                                    "### Lesson Summary and Practice Introduction\n",
                                    "\n",
                                    "Well done\\! You've learned what **Bagging** is, why it's useful, and how it works through an example. You also learned how to load a dataset, split it, and build both a single Decision Tree and a Bagging classifier using `scikit-learn`. We've shown that the Bagging classifier typically performs better by combining the results of multiple decision trees.\n",
                                    "\n",
                                    "Now, it’s time for hands-on practice\\! Apply what you've learned by writing the code yourself. Ready? Let's get started\\!"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Adjust the Number of Estimators\n",
                                    "\n",
                                    "Hey Space Voyager!\n",
                                    "\n",
                                    "It's time to tweak our wine classifier a bit. Change the base estimator in the BaggingClassifier from DecisionTreeClassifier to KNeighborsClassifier to see how it impacts the accuracy.\n",
                                    "\n",
                                    "Let's code!\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.ensemble import BaggingClassifier\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.neighbors import KNeighborsClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "\n",
                                    "# Split the dataset\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Train a bagging classifier\n",
                                    "bag_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
                                    "bag_clf.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Predict and calculate accuracy\n",
                                    "y_pred_bag = bag_clf.predict(X_test)\n",
                                    "bag_accuracy = accuracy_score(y_test, y_pred_bag)\n",
                                    "\n",
                                    "print(f\"Bagging Classifier Accuracy with DecisionTreeClassifier: {bag_accuracy:.2f}\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.ensemble import BaggingClassifier\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.neighbors import KNeighborsClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load dataset\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "\n",
                                    "# Split the dataset\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Train a bagging classifier with DecisionTreeClassifier (original)\n",
                                    "bag_clf_dt = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
                                    "bag_clf_dt.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Predict and calculate accuracy for DecisionTreeClassifier\n",
                                    "y_pred_bag_dt = bag_clf_dt.predict(X_test)\n",
                                    "bag_accuracy_dt = accuracy_score(y_test, y_pred_bag_dt)\n",
                                    "\n",
                                    "print(f\"Bagging Classifier Accuracy with DecisionTreeClassifier: {bag_accuracy_dt:.2f}\")\n",
                                    "\n",
                                    "# Train a bagging classifier with KNeighborsClassifier\n",
                                    "bag_clf_knn = BaggingClassifier(estimator=KNeighborsClassifier(), n_estimators=100, random_state=42)\n",
                                    "bag_clf_knn.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Predict and calculate accuracy for KNeighborsClassifier\n",
                                    "y_pred_bag_knn = bag_clf_knn.predict(X_test)\n",
                                    "bag_accuracy_knn = accuracy_score(y_test, y_pred_bag_knn)\n",
                                    "\n",
                                    "print(f\"Bagging Classifier Accuracy with KNeighborsClassifier: {bag_accuracy_knn:.2f}\")\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Train and Evaluate Bagging Classifier\n",
                                    "\n",
                                    "Alright, young data scientist! It's time to add a missing piece. Train and evaluate a Bagging Classifier to classify wines based on their features. Make sure to use the DecisionTreeClassifier as a base model.\n",
                                    "\n",
                                    "Fill in the missing pieces, and let's see how high you can score!\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.ensemble import BaggingClassifier\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load dataset and split it\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# TODO: initialize and train the Bagging classifier, use `Decision Tree` as a base estimator\n",
                                    "\n",
                                    "# Predict and calculate accuracy on testing set\n",
                                    "y_pred = bag_clf.predict(X_test)\n",
                                    "accuracy = accuracy_score(y_test, y_pred)\n",
                                    "print(f\"Bagging Classifier Test Accuracy: {accuracy:.2f}\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.ensemble import BaggingClassifier\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load dataset and split it\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Initialize and train the Bagging classifier, use `Decision Tree` as a base estimator\n",
                                    "# Create an instance of DecisionTreeClassifier to be used as the base estimator\n",
                                    "base_estimator = DecisionTreeClassifier(random_state=42)\n",
                                    "\n",
                                    "# Initialize BaggingClassifier with the DecisionTreeClassifier as the estimator\n",
                                    "# n_estimators=100 is a common choice for the number of base estimators\n",
                                    "# random_state ensures reproducibility\n",
                                    "bag_clf = BaggingClassifier(estimator=base_estimator, n_estimators=100, random_state=42)\n",
                                    "\n",
                                    "# Train the Bagging classifier on the training data\n",
                                    "bag_clf.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Predict and calculate accuracy on testing set\n",
                                    "y_pred = bag_clf.predict(X_test)\n",
                                    "accuracy = accuracy_score(y_test, y_pred)\n",
                                    "print(f\"Bagging Classifier Test Accuracy: {accuracy:.2f}\")\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Optimize Bagging Classifier for Wine Classification\n",
                                    "\n",
                                    "Hey there, Space Wanderer!\n",
                                    "\n",
                                    "Let's optimize our Bagging classifier for classifying different types of wine. Use TODO comments to fill in the code for initializing and training the classifier, and evaluate its performance with varying numbers of decision trees n_estimators.\n",
                                    "\n",
                                    "May the celestial forces be with you!\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.ensemble import BaggingClassifier\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "best_accuracy = 0\n",
                                    "best_n_estimators = 0\n",
                                    "\n",
                                    "for n in range(10, 110, 10):\n",
                                    "    # TODO: Initialize a BaggingClassifier with DecisionTreeClassifier and given n_estimators (n) and put it into the bag_clf variable\n",
                                    "    # TODO: Fit the BaggingClassifier to the training data\n",
                                    "    \n",
                                    "    y_pred = bag_clf.predict(X_test)\n",
                                    "    accuracy = accuracy_score(y_test, y_pred)\n",
                                    "    if accuracy > best_accuracy:\n",
                                    "        best_accuracy = accuracy\n",
                                    "        best_n_estimators = n\n",
                                    "\n",
                                    "print(f\"Best n_estimators: {best_n_estimators}, Best Accuracy: {best_accuracy:.2f}\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.ensemble import BaggingClassifier\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "best_accuracy = 0\n",
                                    "best_n_estimators = 0\n",
                                    "\n",
                                    "for n in range(10, 110, 10):\n",
                                    "    # Initialize a BaggingClassifier with DecisionTreeClassifier and given n_estimators (n)\n",
                                    "    bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=n, random_state=42)\n",
                                    "    \n",
                                    "    # Fit the BaggingClassifier to the training data\n",
                                    "    bag_clf.fit(X_train, y_train)\n",
                                    "    \n",
                                    "    y_pred = bag_clf.predict(X_test)\n",
                                    "    accuracy = accuracy_score(y_test, y_pred)\n",
                                    "    if accuracy > best_accuracy:\n",
                                    "        best_accuracy = accuracy\n",
                                    "        best_n_estimators = n\n",
                                    "\n",
                                    "print(f\"Best n_estimators: {best_n_estimators}, Best Accuracy: {best_accuracy:.2f}\")\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Enhance Your Bagging Classifier\n",
                                    "\n",
                                    "Great job, Galactic Pioneer! Now, let's make it a bit more challenging. You'll need to fill in the missing pieces to complete our Bagging classifier code.\n",
                                    "\n",
                                    "Load the wine dataset.\n",
                                    "Split the dataset into training and test sets.\n",
                                    "Train a Bagging classifier with different numbers of estimators (50 to 150 with a step of 10) and different base models (DecisionTreeClassifier, KNeighborsClassifier and GaussianNB).\n",
                                    "Let's lock in those missing pieces!\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.neighbors import KNeighborsClassifier\n",
                                    "from sklearn.ensemble import BaggingClassifier\n",
                                    "from sklearn.naive_bayes import GaussianNB\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load dataset and split into training and testing sets\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Train a bagging classifier with different numbers of estimators and different base models\n",
                                    "best_accuracy = 0\n",
                                    "best_n_estimators = 0\n",
                                    "best_base_model = None\n",
                                    "base_models = [DecisionTreeClassifier(), KNeighborsClassifier(), GaussianNB()]\n",
                                    "\n",
                                    "for model in base_models:\n",
                                    "    for n in range(50, 151, 10):\n",
                                    "        # TODO: train bagging classifier with parameters estimator=model and n_estimators=n\n",
                                    "        # TODO: calculate the accuracy on the testing data and put it into the bag_accuracy variable\n",
                                    "        if bag_accuracy > best_accuracy:\n",
                                    "            best_accuracy = bag_accuracy\n",
                                    "            best_n_estimators = n\n",
                                    "            best_base_model = model.__class__.__name__\n",
                                    "\n",
                                    "print(f\"Best accuracy achieved: {best_accuracy:.2f} with {best_n_estimators} n_estimators and {best_base_model} as the base model\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_wine\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.neighbors import KNeighborsClassifier\n",
                                    "from sklearn.ensemble import BaggingClassifier\n",
                                    "from sklearn.naive_bayes import GaussianNB\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load dataset and split into training and testing sets\n",
                                    "X, y = load_wine(return_X_y=True)\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Train a bagging classifier with different numbers of estimators and different base models\n",
                                    "best_accuracy = 0\n",
                                    "best_n_estimators = 0\n",
                                    "best_base_model = None\n",
                                    "base_models = [DecisionTreeClassifier(), KNeighborsClassifier(), GaussianNB()]\n",
                                    "\n",
                                    "for model in base_models:\n",
                                    "    for n in range(50, 151, 10):\n",
                                    "        # train bagging classifier with parameters estimator=model and n_estimators=n\n",
                                    "        bag_clf = BaggingClassifier(estimator=model, n_estimators=n, random_state=42)\n",
                                    "        bag_clf.fit(X_train, y_train)\n",
                                    "        \n",
                                    "        # calculate the accuracy on the testing data and put it into the bag_accuracy variable\n",
                                    "        y_pred = bag_clf.predict(X_test)\n",
                                    "        bag_accuracy = accuracy_score(y_test, y_pred)\n",
                                    "        \n",
                                    "        if bag_accuracy > best_accuracy:\n",
                                    "            best_accuracy = bag_accuracy\n",
                                    "            best_n_estimators = n\n",
                                    "            best_base_model = model.__class__.__name__\n",
                                    "\n",
                                    "print(f\"Best accuracy achieved: {best_accuracy:.2f} with {best_n_estimators} n_estimators and {best_base_model} as the base model\")\n",
                                    "```"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
