{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Unit 5 Stacking in Machine Learning\n",
                                    "\n",
                                    "Hey there\\! ðŸ˜Š In this lesson, we'll explore an exciting machine learning technique called **\"Stacking.\"** You might wonder why weâ€™re learning about stacking and how it helps us make better predictions. Well, imagine asking several experts for their opinions and combining them to make a decision. By the end of this lesson, you'll know how to implement and use stacking to boost model performance\\!\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## Introduction to Stacking\n",
                                    "\n",
                                    "Let's dive into **stacking**. Stacking is an ensemble technique combining multiple models (**base models**) to produce a final prediction using another model (**meta-model**). Think of base models as chefs, and the meta-model as a food critic who tastes all the dishes and decides the final rating.\n",
                                    "\n",
                                    "### How Does Stacking Work?\n",
                                    "\n",
                                    "  * **Training Base Models:** Training multiple base models on the same dataset. Each model brings its unique strength to capture different aspects of the data.\n",
                                    "  * **Generating Meta-Data:** Using the base models' predictions, we generate a new dataset (**meta-data**). This dataset is composed of the predictions of all base models.\n",
                                    "  * **Training Meta-Model:** Training a meta-model on this new meta-data. The meta-model learns how to best combine the predictions of the base models to make the final prediction.\n",
                                    "\n",
                                    "### Why Stacking?\n",
                                    "\n",
                                    "  * **Improved Accuracy:** Combining different models captures various patterns and reduces errors.\n",
                                    "  * **Reduced Overfitting:** Multiple models balance biases and variances.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## Loading and Splitting the Dataset\n",
                                    "\n",
                                    "To get hands-on with stacking, we need data. We'll again use the `digit` dataset from `scikit-learn`. This dataset contains images of digits used to predict what digit each image represents.\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_digits\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "\n",
                                    "# Load digit dataset\n",
                                    "X, y = load_digits(return_X_y=True)\n",
                                    "\n",
                                    "# Splitting the dataset\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "```\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## Defining Base and Meta Models\n",
                                    "\n",
                                    "We define our base models (chefs) and meta-model (food critic). Base models do the heavy lifting, while the meta-model combines predictions for the final output. We use `RandomForestClassifier` and `GradientBoostingClassifier` as base models and `LogisticRegression` as our meta-model:\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
                                    "from sklearn.linear_model import LogisticRegression\n",
                                    "from sklearn.ensemble import StackingClassifier\n",
                                    "\n",
                                    "# Defining the base and meta models\n",
                                    "estimators = [\n",
                                    "    ('rf', RandomForestClassifier(n_estimators=20, random_state=42)),\n",
                                    "    ('gb', GradientBoostingClassifier(n_estimators=20, random_state=42))\n",
                                    "]\n",
                                    "\n",
                                    "stack_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
                                    "stack_clf.fit(X_train, y_train)\n",
                                    "```\n",
                                    "\n",
                                    "The `estimators` list has tuples with each base model's name and the actual model. `StackingClassifier` combines these estimators with the `final_estimator` (meta-model).\n",
                                    "\n",
                                    "For base models, avoid utilizing comparable models or models with similar hyperparameter settings, as this may not result in a significant performance gain.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## Calculating Accuracy on Testing Data\n",
                                    "\n",
                                    "After training, we can evaluate our model's performance by calculating the accuracy on the testing data:\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Predict and calculate accuracy\n",
                                    "y_pred = stack_clf.predict(X_test)\n",
                                    "accuracy = accuracy_score(y_test, y_pred)\n",
                                    "print(f\"Stacking Classifier Accuracy: {accuracy:.2f}\")\n",
                                    "# Stacking Classifier Accuracy: 0.97\n",
                                    "```\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## Comparison with GradientBoostingClassifier\n",
                                    "\n",
                                    "Finally, let's see how our stacking classifier stacks up against a single `GradientBoostingClassifier`:\n",
                                    "\n",
                                    "```python\n",
                                    "# Training GradientBoostingClassifier\n",
                                    "gb_clf = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
                                    "gb_clf.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Predict and calculate accuracy for GradientBoostingClassifier\n",
                                    "y_pred_gb = gb_clf.predict(X_test)\n",
                                    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
                                    "print(f\"GradientBoosting Classifier Accuracy: {accuracy_gb:.2f}\")\n",
                                    "# GradientBoosting Classifier Accuracy: 0.96\n",
                                    "```\n",
                                    "\n",
                                    "We see that the performance of the `GradientBoostingClassifier` is comparable to the performance of our new `StackingClassifier`. But how do we choose one in this case? Well, this is what the next course of this path is all about\\!\n",
                                    "\n",
                                    "However, let's answer here shortly:\n",
                                    "Firstly, we will try to find optimal models' hyperparameters and perhaps one of the models will outperform in this case.\n",
                                    "Secondly, we will implement a better validation technique than simple `train_test_split`.\n",
                                    "Finally, if two models still perform on the same level, we can consider other factors, like model's training time and interpretability.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## Lesson Summary\n",
                                    "\n",
                                    "Great job\\! ðŸŽ‰ Let's recap:\n",
                                    "\n",
                                    "  * **Stacking:** Combines multiple models (base models) using another model (meta-model) for a final prediction.\n",
                                    "  * **How It Works:** Includes training base models, generating meta-data, and training a meta-model.\n",
                                    "  * **Loading and Splitting Data:** Used the digit dataset and split it into training and testing sets.\n",
                                    "  * **Model Setup:** Defined base models (`RandomForestClassifier` and `GradientBoostingClassifier`) and a meta-model (`LogisticRegression`).\n",
                                    "  * **Training and Evaluating:** Implemented and trained the `StackingClassifier` and calculated its accuracy.\n",
                                    "  * **Comparison:** Compared the accuracy of the stacking classifier to that of a single `GradientBoostingClassifier`.\n",
                                    "\n",
                                    "Awesome, you made it\\! Now it's time to practice. In the upcoming session, youâ€™ll build, train, and evaluate stacking models. Let's get started\\! ðŸš€"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Change Meta-Model to Gradient Boosting\n",
                                    "\n",
                                    "Hey Space Voyager!\n",
                                    "\n",
                                    "Youâ€™ve learned how to set up stacking with different base models. Now, change the set of base models to see how a different ensemble performs. Replace KNeighborsClassifier and DecisionTreeClassifier with RandomForestClassifier and SVC respectively. Make sure to modify the estimators list accordingly in the stacking classifier.\n",
                                    "\n",
                                    "Let's code!\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_digits\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.linear_model import LogisticRegression\n",
                                    "from sklearn.svm import SVC\n",
                                    "from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load digit dataset\n",
                                    "X, y = load_digits(return_X_y=True)\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Defining base and meta models\n",
                                    "estimators = [\n",
                                    "    ('knn', KNeighborsClassifier()),\n",
                                    "    ('dt', DecisionTreeClassifier(random_state=42))\n",
                                    "]\n",
                                    "stack_clf = StackingClassifier(estimators=estimators, final_estimator=GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
                                    "stack_clf.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Predict and calculate accuracy\n",
                                    "y_pred = stack_clf.predict(X_test)\n",
                                    "accuracy = accuracy_score(y_test, y_pred)\n",
                                    "print(f\"Stacking Classifier Accuracy: {accuracy:.2f}\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Sure, I'll help you with that\\! You want to change the base models in your `StackingClassifier` from `KNeighborsClassifier` and `DecisionTreeClassifier` to `RandomForestClassifier` and `SVC`, respectively. Also, you want to ensure the meta-model remains `GradientBoostingClassifier`.\n",
                                    "\n",
                                    "Here's the modified code:\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_digits\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.linear_model import LogisticRegression # Not used for meta-model anymore, but good to keep if you might switch back\n",
                                    "from sklearn.svm import SVC\n",
                                    "from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load digit dataset\n",
                                    "X, y = load_digits(return_X_y=True)\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Defining base and meta models\n",
                                    "estimators = [\n",
                                    "    ('rf', RandomForestClassifier(n_estimators=50, random_state=42)), # Changed from KNeighborsClassifier\n",
                                    "    ('svc', SVC(random_state=42, probability=True)) # Changed from DecisionTreeClassifier, SVC needs probability=True for stacking\n",
                                    "]\n",
                                    "# The meta-model is already GradientBoostingClassifier as requested\n",
                                    "stack_clf = StackingClassifier(estimators=estimators, final_estimator=GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
                                    "stack_clf.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Predict and calculate accuracy\n",
                                    "y_pred = stack_clf.predict(X_test)\n",
                                    "accuracy = accuracy_score(y_test, y_pred)\n",
                                    "print(f\"Stacking Classifier Accuracy: {accuracy:.2f}\")\n",
                                    "\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Change the Meta-Model in Stacking Classifier\n",
                                    "\n",
                                    "Nice work so far, Space Wanderer! Now, let's change our meta-model. Modify the provided code to use LogisticRegression instead of KNeighborsClassifier as the meta-model in the stacking ensemble. This will provide a different approach to the decision-making process.\n",
                                    "\n",
                                    "Let's see if it improves the predictions!\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_digits\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.linear_model import LogisticRegression\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.neighbors import KNeighborsClassifier\n",
                                    "from sklearn.ensemble import StackingClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load digit dataset\n",
                                    "X, y = load_digits(return_X_y=True)\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Defining the base and meta models\n",
                                    "base_models = [\n",
                                    "    ('lr', LogisticRegression(max_iter=250, random_state=42)),\n",
                                    "    ('dt', DecisionTreeClassifier(random_state=42))\n",
                                    "]\n",
                                    "meta_model = KNeighborsClassifier()\n",
                                    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
                                    "stacking_model.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Predict and calculate accuracy\n",
                                    "predictions = stacking_model.predict(X_test)\n",
                                    "accuracy = accuracy_score(y_test, predictions)\n",
                                    "print(f\"Stacking Classifier Accuracy: {accuracy:.2f}\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Alright, Space Wanderer\\! Let's swap out that meta-model. You want to change the `final_estimator` (meta-model) of your `StackingClassifier` from `KNeighborsClassifier` to `LogisticRegression`.\n",
                                    "\n",
                                    "Here's the modified code:\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_digits\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.linear_model import LogisticRegression\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.neighbors import KNeighborsClassifier # Still imported, but no longer used for meta_model\n",
                                    "from sklearn.ensemble import StackingClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load digit dataset\n",
                                    "X, y = load_digits(return_X_y=True)\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# Defining the base and meta models\n",
                                    "base_models = [\n",
                                    "    ('lr', LogisticRegression(max_iter=250, random_state=42)),\n",
                                    "    ('dt', DecisionTreeClassifier(random_state=42))\n",
                                    "]\n",
                                    "# Change the meta_model to LogisticRegression\n",
                                    "meta_model = LogisticRegression(max_iter=250, random_state=42) # Using LogisticRegression as the meta-model\n",
                                    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
                                    "stacking_model.fit(X_train, y_train)\n",
                                    "\n",
                                    "# Predict and calculate accuracy\n",
                                    "predictions = stacking_model.predict(X_test)\n",
                                    "accuracy = accuracy_score(y_test, predictions)\n",
                                    "print(f\"Stacking Classifier Accuracy: {accuracy:.2f}\")\n",
                                    "\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Complete the Stacking Classifier\n",
                                    "\n",
                                    "Awesome work so far, Space Wanderer!\n",
                                    "\n",
                                    "Now let's see if you can fill in the missing pieces! Complete the code to define our base models using the RandomForestClassifier and GradientBoostingClassifier, then create the StackingClassifier with LogisticRegression as the meta-model. Each model has a unique strength. Finally, calculate the accuracy of the stacking model on the test set.\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_digits\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.linear_model import LogisticRegression\n",
                                    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load digit dataset\n",
                                    "X, y = load_digits(return_X_y=True)\n",
                                    "\n",
                                    "# Splitting the dataset\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# TODO: Define the RandomForest and GradientBoosting classifiers\n",
                                    "# Hint: use relatively small amount of estimators (e.g. 20) to make the code execution faster\n",
                                    "base_models = [\n",
                                    "    ('random_forest', ___),\n",
                                    "    ('gradient_boosting', ___)\n",
                                    "]\n",
                                    "meta_model = LogisticRegression()\n",
                                    "\n",
                                    "# TODO: Create the StackingClassifier using base models and LogisticRegression as the meta model\n",
                                    "\n",
                                    "# Training the Stacking Model\n",
                                    "stacking_model.fit(X_train, y_train)\n",
                                    "\n",
                                    "# TODO: Calculate the accuracy on the test set and print it\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Hey Space Wanderer\\! Let's get those missing pieces filled in and complete your Stacking Classifier.\n",
                                    "\n",
                                    "Here's the completed code:\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_digits\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.linear_model import LogisticRegression\n",
                                    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load digit dataset\n",
                                    "X, y = load_digits(return_X_y=True)\n",
                                    "\n",
                                    "# Splitting the dataset\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                    "\n",
                                    "# TODO: Define the RandomForest and GradientBoosting classifiers\n",
                                    "# Hint: use relatively small amount of estimators (e.g. 20) to make the code execution faster\n",
                                    "base_models = [\n",
                                    "    ('random_forest', RandomForestClassifier(n_estimators=20, random_state=42)), # Completed: RandomForestClassifier\n",
                                    "    ('gradient_boosting', GradientBoostingClassifier(n_estimators=20, random_state=42)) # Completed: GradientBoostingClassifier\n",
                                    "]\n",
                                    "meta_model = LogisticRegression(random_state=42) # Added random_state for reproducibility, though not strictly required by problem.\n",
                                    "\n",
                                    "# TODO: Create the StackingClassifier using base models and LogisticRegression as the meta model\n",
                                    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model) # Completed: StackingClassifier creation\n",
                                    "\n",
                                    "# Training the Stacking Model\n",
                                    "stacking_model.fit(X_train, y_train)\n",
                                    "\n",
                                    "# TODO: Calculate the accuracy on the test set and print it\n",
                                    "predictions = stacking_model.predict(X_test) # Completed: Make predictions\n",
                                    "accuracy = accuracy_score(y_test, predictions) # Completed: Calculate accuracy\n",
                                    "print(f\"Stacking Classifier Accuracy: {accuracy:.2f}\") # Completed: Print accuracy\n",
                                    "\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "id": "4814f784",
                           "metadata": {},
                           "source": [
                                    "Complete the code to iterate through possible meta models for the stacking classifier and print the accuracy for each one.\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_digits\n",
                                    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
                                    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load dataset and split it\n",
                                    "X, y = load_digits(return_X_y=True)\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
                                    "\n",
                                    "# Define the base models\n",
                                    "estimators = [\n",
                                    "    ('rf', RandomForestClassifier(n_estimators=12, random_state=42)),\n",
                                    "    ('gb', GradientBoostingClassifier(n_estimators=6, random_state=42))\n",
                                    "]\n",
                                    "\n",
                                    "# List of possible meta models\n",
                                    "meta_models = [\n",
                                    "    LogisticRegression(max_iter=100),\n",
                                    "    RidgeClassifier(),\n",
                                    "    DecisionTreeClassifier()\n",
                                    "]\n",
                                    "\n",
                                    "# Iterate through meta models and print accuracy\n",
                                    "for meta_model in meta_models:\n",
                                    "    # TODO: train StackingClassfier with estimators=estimators and final_estimator=meta_model\n",
                                    "    # TODO: make predictions and calculate the accuracy. Put the accuracy into the accuracy variable\n",
                                    "    print(f'Meta Model: {meta_model.__class__.__name__}, Accuracy: {accuracy:.2f}')\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "from sklearn.datasets import load_digits\n",
                                    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
                                    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "\n",
                                    "# Load dataset and split it\n",
                                    "X, y = load_digits(return_X_y=True)\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
                                    "\n",
                                    "# Define the base models\n",
                                    "estimators = [\n",
                                    "    ('rf', RandomForestClassifier(n_estimators=12, random_state=42)),\n",
                                    "    ('gb', GradientBoostingClassifier(n_estimators=6, random_state=42))\n",
                                    "]\n",
                                    "\n",
                                    "# List of possible meta models\n",
                                    "meta_models = [\n",
                                    "    LogisticRegression(max_iter=100, random_state=42), # Added random_state for reproducibility\n",
                                    "    RidgeClassifier(random_state=42), # Added random_state for reproducibility\n",
                                    "    DecisionTreeClassifier(random_state=42) # Added random_state for reproducibility\n",
                                    "]\n",
                                    "\n",
                                    "# Iterate through meta models and print accuracy\n",
                                    "for meta_model in meta_models:\n",
                                    "    # TODO: train StackingClassfier with estimators=estimators and final_estimator=meta_model\n",
                                    "    stacking_model = StackingClassifier(estimators=estimators, final_estimator=meta_model)\n",
                                    "    stacking_model.fit(X_train, y_train)\n",
                                    "\n",
                                    "    # TODO: make predictions and calculate the accuracy. Put the accuracy into the accuracy variable\n",
                                    "    predictions = stacking_model.predict(X_test)\n",
                                    "    accuracy = accuracy_score(y_test, predictions)\n",
                                    "    \n",
                                    "    print(f'Meta Model: {meta_model.__class__.__name__}, Accuracy: {accuracy:.2f}')\n",
                                    "\n",
                                    "```"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
