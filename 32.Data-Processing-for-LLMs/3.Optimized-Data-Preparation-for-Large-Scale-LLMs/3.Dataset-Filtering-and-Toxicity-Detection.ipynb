{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Unit 3"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Dataset Filtering and Toxicity Detection\n",
                "\n",
                "### Dataset Filtering and Toxicity Detection\n",
                "\n",
                "**Introduction and Context Setting**\n",
                "\n",
                "Welcome to the lesson on Dataset Filtering and Toxicity Detection. In the previous lessons, we explored efficient data storage and deduplication techniques for preparing datasets for large-scale language models (LLMs). Now, we will focus on filtering datasets to remove non-English and toxic content. This step is crucial to ensure the quality and safety of the data used to train LLMs. By the end of this lesson, you will be able to implement a function that filters out unwanted content from a dataset.\n",
                "\n",
                "### Language Detection with `langdetect`\n",
                "\n",
                "To filter out non-English content, we will use the `langdetect` library. This library helps identify the language of a given text.\n",
                "\n",
                "**Step-by-Step Explanation**\n",
                "\n",
                "1.  **Import the Library:** First, we need to import the `detect` function from the `langdetect` library.\n",
                "\n",
                "    ```python\n",
                "    from langdetect import detect\n",
                "    ```\n",
                "\n",
                "2.  **Detect Language:** Use the `detect` function to identify the language of a text. It returns a language code, such as \"en\" for English.\n",
                "\n",
                "    ```python\n",
                "    text = \"Je ne parle pas anglais.\"\n",
                "    language = detect(text)\n",
                "    print(\"Detected Language:\", language)\n",
                "    ```\n",
                "\n",
                "    Output:\n",
                "\n",
                "    ```\n",
                "    Detected Language: fr\n",
                "    ```\n",
                "\n",
                "    Here, the text is in French, so the detected language code is \"fr\".\n",
                "\n",
                "### Toxicity Detection with `Detoxify`\n",
                "\n",
                "Next, we will use the `Detoxify` library to detect toxic language in the text. This library provides a model that predicts toxicity scores.\n",
                "\n",
                "**Step-by-Step Explanation**\n",
                "\n",
                "1.  **Import the Library:** Import the `Detoxify` class from the `detoxify` library.\n",
                "\n",
                "    ```python\n",
                "    from detoxify import Detoxify\n",
                "    ```\n",
                "\n",
                "2.  **Predict Toxicity:** Use the `Detoxify` model to predict the toxicity score of a text. A higher score indicates more toxic content.\n",
                "\n",
                "    ```python\n",
                "    text = \"I hate this group of people!\"\n",
                "    toxicity_scores = Detoxify(\"original\").predict(text)\n",
                "    print(\"Toxicity Score:\", toxicity_scores[\"toxicity\"])\n",
                "    ```\n",
                "\n",
                "    Output:\n",
                "\n",
                "    ```\n",
                "    Toxicity Score: 0.85\n",
                "    ```\n",
                "\n",
                "    In this example, the text is considered highly toxic with a score of 0.85.\n",
                "\n",
                "### Implementing the Filtering Function\n",
                "\n",
                "Now, let's implement a function that combines language and toxicity detection to filter a dataset.\n",
                "\n",
                "**Step-by-Step Explanation**\n",
                "\n",
                "1.  **Define the Function:** Create a function `filter_text` that takes a text as input and returns `None` if the text is non-English or highly toxic.\n",
                "\n",
                "    ```python\n",
                "    def filter_text(text):\n",
                "        # Language Detection\n",
                "        if detect(text) != \"en\":\n",
                "            return None  # Remove non-English text\n",
                "        # Toxicity Detection\n",
                "        toxicity_scores = Detoxify(\"original\").predict(text)\n",
                "        if toxicity_scores[\"toxicity\"] > 0.7:\n",
                "            return None  # Remove highly toxic content\n",
                "        return text  # Keep clean text\n",
                "    ```\n",
                "\n",
                "    The function first checks if the text is in English. If not, it returns `None`. It then checks the toxicity score. If the score is above 0.7, it returns `None`. If the text passes both checks, it is returned as clean text.\n",
                "\n",
                "### Applying the Filtering Function to a Dataset\n",
                "\n",
                "Finally, we will apply the `filter_text` function to a list of texts using list comprehension.\n",
                "\n",
                "**Step-by-Step Explanation**\n",
                "\n",
                "1.  **Sample Dataset:** Define a list of sample texts.\n",
                "\n",
                "    ```python\n",
                "    texts = [\n",
                "        \"I hate this group of people!\",  # Toxic statement\n",
                "        \"This is a normal sentence.\",\n",
                "        \"Je ne parle pas anglais.\"  # Non-English\n",
                "    ]\n",
                "    ```\n",
                "\n",
                "2.  **Apply Filtering:** Use list comprehension to filter the dataset.\n",
                "\n",
                "    ```python\n",
                "    filtered_texts = [filter_text(text) for text in texts if filter_text(text)]\n",
                "    print(\"Filtered Dataset:\", filtered_texts)\n",
                "    ```\n",
                "\n",
                "    Output:\n",
                "\n",
                "    ```\n",
                "    Filtered Dataset: ['This is a normal sentence.']\n",
                "    ```\n",
                "\n",
                "    The list comprehension iterates over each text, applies the `filter_text` function, and includes only the texts that are not `None`.\n",
                "\n",
                "### Summary and Preparation for Practice\n",
                "\n",
                "In this lesson, you learned how to filter a dataset by removing non-English and toxic content using the `langdetect` and `Detoxify` libraries. We implemented a function that combines these checks and applied it to a sample dataset. This filtering process is essential for maintaining the quality and safety of data used in training large-scale language models.\n",
                "\n",
                "As you move on to the practice exercises, try experimenting with different datasets and filtering criteria. This hands-on practice will reinforce your understanding and help you apply these techniques to real-world scenarios. Congratulations on reaching this point in the course, and keep up the great work\\!\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Language Detection and Reporting\n",
                "\n",
                "Now that you've learned about the importance of filtering datasets for LLM training, let's put your knowledge into practice! In this exercise, you'll focus specifically on the language detection aspect we just covered.\n",
                "\n",
                "Your task is to complete the detect_languages function that processes a list of text samples and returns a list of tuples, each containing a text and its detected language. You'll use the langdetect library's detect function to identify each text's language.\n",
                "\n",
                "To complete this exercise:\n",
                "\n",
                "Implement the logic to detect the language of each text\n",
                "Return a list of tuples, each containing the text and its detected language\n",
                "This exercise builds a foundation for the more complex filtering we'll do later when we combine language detection with toxicity filtering. Successfully implementing this function will give you the skills needed for real-world dataset preparation tasks!\n",
                "\n",
                "```python\n",
                "from langdetect import detect\n",
                "\n",
                "# Sample dataset with texts in different languages\n",
                "texts = [\n",
                "    \"Hello, this is a sample text in English.\",  # English\n",
                "    \"Hola, este es un ejemplo de texto en español.\",  # Spanish\n",
                "    \"Bonjour, ceci est un exemple de texte en français.\",  # French\n",
                "    \"Hallo, dies ist ein Beispieltext auf Deutsch.\",  # German\n",
                "    \"This is another English text sample.\",  # English\n",
                "    \"Questo è un esempio di testo in italiano.\",  # Italian\n",
                "    \"The quick brown fox jumps over the lazy dog.\",  # English\n",
                "    \"私はあなたの言語を話せません。\",  # Japanese\n",
                "    \"English is a West Germanic language.\"  # English\n",
                "]\n",
                "\n",
                "def detect_languages(text_list):\n",
                "    \"\"\"\n",
                "    Detect the language of each text in the list and return the results.\n",
                "    \n",
                "    Args:\n",
                "        text_list (list): A list of text strings in various languages\n",
                "    \n",
                "    Returns:\n",
                "        list: A list of tuples containing each text and its detected language\n",
                "    \"\"\"\n",
                "    results = []\n",
                "    for text in text_list:\n",
                "        # TODO: Detect the language of the text\n",
                "        # TODO: Append the text and its detected language to the results list\n",
                "        pass\n",
                "    return results\n",
                "\n",
                "# Get the detection results\n",
                "detection_results = detect_languages(texts)\n",
                "\n",
                "# Print the results\n",
                "for text, language in detection_results:\n",
                "    print(f\"Text: {text} | Detected Language: {language}\")\n",
                "```\n",
                "\n",
                "```python\n",
                "from langdetect import detect\n",
                "\n",
                "# Sample dataset with texts in different languages\n",
                "texts = [\n",
                "    \"Hello, this is a sample text in English.\",  # English\n",
                "    \"Hola, este es un ejemplo de texto en español.\",  # Spanish\n",
                "    \"Bonjour, ceci est un exemple de texte en français.\",  # French\n",
                "    \"Hallo, dies ist ein Beispieltext auf Deutsch.\",  # German\n",
                "    \"This is another English text sample.\",  # English\n",
                "    \"Questo è un esempio di testo in italiano.\",  # Italian\n",
                "    \"The quick brown fox jumps over the lazy dog.\",  # English\n",
                "    \"私はあなたの言語を話せません。\",  # Japanese\n",
                "    \"English is a West Germanic language.\"  # English\n",
                "]\n",
                "\n",
                "def detect_languages(text_list):\n",
                "    \"\"\"\n",
                "    Detect the language of each text in the list and return the results.\n",
                "    \n",
                "    Args:\n",
                "        text_list (list): A list of text strings in various languages\n",
                "    \n",
                "    Returns:\n",
                "        list: A list of tuples containing each text and its detected language\n",
                "    \"\"\"\n",
                "    results = []\n",
                "    for text in text_list:\n",
                "        # TODO: Detect the language of the text\n",
                "        try:\n",
                "            language = detect(text)\n",
                "        except:\n",
                "            language = \"unknown\" # Handle cases where language cannot be detected\n",
                "        # TODO: Append the text and its detected language to the results list\n",
                "        results.append((text, language))\n",
                "    return results\n",
                "\n",
                "# Get the detection results\n",
                "detection_results = detect_languages(texts)\n",
                "\n",
                "# Print the results\n",
                "for text, language in detection_results:\n",
                "    print(f\"Text: {text} | Detected Language: {language}\")\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Filter English Texts with Langdetect"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Detect and Filter Toxic Texts"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Filter English and Non-Toxic Texts"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Filter English and Non-Toxic Texts"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
