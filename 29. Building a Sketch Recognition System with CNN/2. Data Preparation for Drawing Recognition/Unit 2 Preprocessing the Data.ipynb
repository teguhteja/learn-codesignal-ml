{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Unit 2 Preprocessing the Data\n",
                                    "\n",
                                    "# Introduction to Preprocessing the Data\n",
                                    "\n",
                                    "Welcome back\\! Now that you've learned how to load and understand the dataset for drawing recognition, it's time to move on to the next crucial step: **preprocessing the data**. Preprocessing is essential because it prepares your data for the machine learning model, ensuring that it can learn effectively. By the end of this lesson, you'll be equipped with the skills to clean and normalize your dataset, setting the stage for successful model training.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## What You'll Learn\n",
                                    "\n",
                                    "In this lesson, you will learn how to preprocess the dataset to make it suitable for training a drawing recognition model. We'll cover three main tasks: cleaning and normalizing the data. Here's a glimpse of the code you'll be working with:\n",
                                    "\n",
                                    "```python\n",
                                    "import numpy as np\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "\n",
                                    "# Load and prepare data\n",
                                    "data = []\n",
                                    "labels = []\n",
                                    "for idx, cat in enumerate(categories):\n",
                                    "    filepath = f'quickdraw_data/{cat}.npy'\n",
                                    "    imgs = np.load(filepath)[:15000]\n",
                                    "    if imgs.dtype != np.uint8:\n",
                                    "        imgs = imgs.astype(np.uint8)\n",
                                    "    data.append(imgs)\n",
                                    "    labels.append(np.full(imgs.shape[0], idx))\n",
                                    "\n",
                                    "data = np.concatenate(data, axis=0)\n",
                                    "labels = np.concatenate(labels, axis=0)\n",
                                    "\n",
                                    "# Shuffle data\n",
                                    "indices = np.arange(len(data))\n",
                                    "np.random.shuffle(indices)\n",
                                    "data, labels = data[indices], labels[indices]\n",
                                    "\n",
                                    "# Reshape and normalize\n",
                                    "data = data.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
                                    "\n",
                                    "# Split data into training and testing sets\n",
                                    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
                                    "```\n",
                                    "\n",
                                    "This code snippet demonstrates how to load, clean, and normalize the data, as well as how to split it into training and testing sets. You'll learn how to ensure your data is in the right format and ready for model training.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "## Why It Matters\n",
                                    "\n",
                                    "Preprocessing is a vital step in any machine learning project because it directly impacts the model's performance. By cleaning the data, you remove any inconsistencies or errors that could skew the results. Normalizing the data ensures that all input features are on a similar scale, which helps the model learn more effectively.\n",
                                    "\n",
                                    "Are you excited to dive in? Let's start the practice section and apply these preprocessing techniques to your dataset\\!"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Loading and Labeling Drawing Data\n",
                                    "\n",
                                    "Great job analyzing the dataset distribution! Now let's move on to the first step of preprocessing: loading and preparing the drawing data.\n",
                                    "\n",
                                    "When working with image datasets for machine learning, it's crucial to ensure all images have consistent dimensions and data types. Inconsistent data can lead to errors or poor model performance later on.\n",
                                    "\n",
                                    "In this practice, you'll load the drawing files, check their data types, and convert them if necessary. You'll also create label arrays for each category and combine everything into unified arrays.\n",
                                    "\n",
                                    "This foundational step ensures your data is properly formatted before moving on to more advanced preprocessing techniques like normalization and augmentation.\n",
                                    "\n",
                                    "```python\n",
                                    "import urllib.request\n",
                                    "import numpy as np\n",
                                    "import os\n",
                                    "\n",
                                    "# Ensure the data is downloaded\n",
                                    "categories = ['cat', 'house', 'airplane', 'apple', 'bicycle']\n",
                                    "base_url = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
                                    "\n",
                                    "os.makedirs('quickdraw_data', exist_ok=True)\n",
                                    "\n",
                                    "for category in categories:\n",
                                    "    file_path = f'quickdraw_data/{category}.npy'\n",
                                    "    if not os.path.exists(file_path):\n",
                                    "        print(f\"Downloading {category}...\")\n",
                                    "        urllib.request.urlretrieve(base_url + category + '.npy', file_path)\n",
                                    "    else:\n",
                                    "        print(f\"{category}.npy already exists.\")\n",
                                    "\n",
                                    "# Load and prepare data\n",
                                    "data = []\n",
                                    "labels = []\n",
                                    "\n",
                                    "# TODO: Load and prepare data for each category\n",
                                    "for idx, cat in enumerate(categories):\n",
                                    "    filepath = f'quickdraw_data/{cat}.npy'\n",
                                    "    # TODO: Load up to 15000 images from each category file\n",
                                    "    imgs = ________\n",
                                    "    \n",
                                    "    # TODO: Check if the data type is uint8, if not convert it\n",
                                    "    if imgs.dtype != np.uint8:\n",
                                    "        imgs = ________\n",
                                    "    \n",
                                    "    # TODO: Add the images to the data list\n",
                                    "    data.append(________) \n",
                                    "    \n",
                                    "    # TODO: Create labels for this category (use the category index)\n",
                                    "    # and add them to the labels list\n",
                                    "    labels.append(________) \n",
                                    "\n",
                                    "# TODO: Combine all data and labels into single arrays\n",
                                    "data = ________\n",
                                    "labels = ________\n",
                                    "\n",
                                    "# Print information about the loaded data\n",
                                    "print(f\"Total number of images: {len(data)}\")\n",
                                    "print(f\"Image data type: {data.dtype}\")\n",
                                    "print(f\"Image shape: {data[0].shape}\")\n",
                                    "print(f\"Label shape: {labels.shape}\")\n",
                                    "print(f\"First 5 labels: {labels[:5]}\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Of course\\! Here is the completed code for loading and preparing the drawing data.\n",
                                    "\n",
                                    "### Completed Code\n",
                                    "\n",
                                    "```python\n",
                                    "import urllib.request\n",
                                    "import numpy as np\n",
                                    "import os\n",
                                    "\n",
                                    "# Ensure the data is downloaded\n",
                                    "categories = ['cat', 'house', 'airplane', 'apple', 'bicycle']\n",
                                    "base_url = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
                                    "\n",
                                    "os.makedirs('quickdraw_data', exist_ok=True)\n",
                                    "\n",
                                    "for category in categories:\n",
                                    "    file_path = f'quickdraw_data/{category}.npy'\n",
                                    "    if not os.path.exists(file_path):\n",
                                    "        print(f\"Downloading {category}...\")\n",
                                    "        urllib.request.urlretrieve(base_url + category + '.npy', file_path)\n",
                                    "    else:\n",
                                    "        print(f\"{category}.npy already exists.\")\n",
                                    "\n",
                                    "# Load and prepare data\n",
                                    "data = []\n",
                                    "labels = []\n",
                                    "\n",
                                    "# Load and prepare data for each category\n",
                                    "for idx, cat in enumerate(categories):\n",
                                    "    filepath = f'quickdraw_data/{cat}.npy'\n",
                                    "    # Load up to 15000 images from each category file\n",
                                    "    imgs = np.load(filepath)[:15000]\n",
                                    "    \n",
                                    "    # Check if the data type is uint8, if not convert it\n",
                                    "    if imgs.dtype != np.uint8:\n",
                                    "        imgs = imgs.astype(np.uint8)\n",
                                    "    \n",
                                    "    # Add the images to the data list\n",
                                    "    data.append(imgs) \n",
                                    "    \n",
                                    "    # Create labels for this category (use the category index)\n",
                                    "    # and add them to the labels list\n",
                                    "    labels.append(np.full(imgs.shape[0], idx)) \n",
                                    "\n",
                                    "# Combine all data and labels into single arrays\n",
                                    "data = np.concatenate(data, axis=0)\n",
                                    "labels = np.concatenate(labels, axis=0)\n",
                                    "\n",
                                    "# Print information about the loaded data\n",
                                    "print(f\"Total number of images: {len(data)}\")\n",
                                    "print(f\"Image data type: {data.dtype}\")\n",
                                    "print(f\"Image shape: {data[0].shape}\")\n",
                                    "print(f\"Label shape: {labels.shape}\")\n",
                                    "print(f\"First 5 labels: {labels[:5]}\")\n",
                                    "```\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### Explanation 🧑‍🏫\n",
                                    "\n",
                                    "1.  **Load Images**: `np.load(filepath)[:15000]` loads the `.npy` file for a category and slices it to get the first **15,000 images**.\n",
                                    "2.  **Convert Data Type**: `imgs.astype(np.uint8)` converts the image data to `uint8` (unsigned 8-bit integer), a standard and memory-efficient format for grayscale images.\n",
                                    "3.  **Append Data**: `data.append(imgs)` adds the array of images for the current category to the `data` list.\n",
                                    "4.  **Create and Append Labels**: `np.full(imgs.shape[0], idx)` creates an array where every element is the category index (`idx`). The length of this array (`imgs.shape[0]`) matches the number of images loaded for that category. This label array is then added to the `labels` list.\n",
                                    "5.  **Concatenate Arrays**: `np.concatenate(...)` takes the lists of NumPy arrays (`data` and `labels`) and joins them into single, large NumPy arrays, which are necessary for feeding into a machine learning model."
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Shuffling and Normalizing Drawing Data\n",
                                    "\n",
                                    "Great job loading and labeling your drawing data! Now let's continue with essential preprocessing steps: shuffling and normalizing the data.\n",
                                    "\n",
                                    "Shuffling ensures your model doesn't learn patterns based on the order of samples. Normalizing (scaling pixel values from 0-255 to 0-1) helps your model converge faster during training.\n",
                                    "\n",
                                    "In this practice, you'll take your prepared data and:\n",
                                    "\n",
                                    "Shuffle the data and labels together.\n",
                                    "Reshape the images for CNN compatibility.\n",
                                    "Normalize the pixel values.\n",
                                    "These steps are critical for preparing your drawing dataset for effective model training.\n",
                                    "\n",
                                    "```python\n",
                                    "import urllib.request\n",
                                    "import numpy as np\n",
                                    "import os\n",
                                    "\n",
                                    "# Ensure the data is downloaded\n",
                                    "categories = ['cat', 'house', 'airplane', 'apple', 'bicycle']\n",
                                    "base_url = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
                                    "\n",
                                    "os.makedirs('quickdraw_data', exist_ok=True)\n",
                                    "\n",
                                    "for category in categories:\n",
                                    "    file_path = f'quickdraw_data/{category}.npy'\n",
                                    "    if not os.path.exists(file_path):\n",
                                    "        print(f\"Downloading {category}...\")\n",
                                    "        urllib.request.urlretrieve(base_url + category + '.npy', file_path)\n",
                                    "    else:\n",
                                    "        print(f\"{category}.npy already exists.\")\n",
                                    "\n",
                                    "# Load and prepare data\n",
                                    "data = []\n",
                                    "labels = []\n",
                                    "\n",
                                    "for idx, cat in enumerate(categories):\n",
                                    "    filepath = f'quickdraw_data/{cat}.npy'\n",
                                    "    imgs = np.load(filepath)[:15000]  # Load up to 15000 images per category\n",
                                    "    if imgs.dtype != np.uint8:\n",
                                    "        imgs = imgs.astype(np.uint8)\n",
                                    "    data.append(imgs)\n",
                                    "    labels.append(np.full(imgs.shape[0], idx))\n",
                                    "\n",
                                    "# Combine all data and labels\n",
                                    "data = np.concatenate(data, axis=0)\n",
                                    "labels = np.concatenate(labels, axis=0)\n",
                                    "\n",
                                    "# TODO: Create an array of indices for shuffling\n",
                                    "indices = ________\n",
                                    "\n",
                                    "# TODO: Shuffle the indices\n",
                                    "np.random.________\n",
                                    "\n",
                                    "# TODO: Use the shuffled indices to reorder both data and labels\n",
                                    "data, labels = ________, ________\n",
                                    "\n",
                                    "# TODO: Reshape the data to (samples, height, width, channels) and normalize to [0,1]\n",
                                    "data = data.reshape(________, ________, ________, ________).astype(________) / ________\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Of course\\! Here is the completed code for shuffling and normalizing the drawing data.\n",
                                    "\n",
                                    "### Completed Code\n",
                                    "\n",
                                    "```python\n",
                                    "import urllib.request\n",
                                    "import numpy as np\n",
                                    "import os\n",
                                    "\n",
                                    "# Ensure the data is downloaded\n",
                                    "categories = ['cat', 'house', 'airplane', 'apple', 'bicycle']\n",
                                    "base_url = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
                                    "\n",
                                    "os.makedirs('quickdraw_data', exist_ok=True)\n",
                                    "\n",
                                    "for category in categories:\n",
                                    "    file_path = f'quickdraw_data/{category}.npy'\n",
                                    "    if not os.path.exists(file_path):\n",
                                    "        print(f\"Downloading {category}...\")\n",
                                    "        urllib.request.urlretrieve(base_url + category + '.npy', file_path)\n",
                                    "    else:\n",
                                    "        print(f\"{category}.npy already exists.\")\n",
                                    "\n",
                                    "# Load and prepare data\n",
                                    "data = []\n",
                                    "labels = []\n",
                                    "\n",
                                    "for idx, cat in enumerate(categories):\n",
                                    "    filepath = f'quickdraw_data/{cat}.npy'\n",
                                    "    imgs = np.load(filepath)[:15000]  # Load up to 15000 images per category\n",
                                    "    if imgs.dtype != np.uint8:\n",
                                    "        imgs = imgs.astype(np.uint8)\n",
                                    "    data.append(imgs)\n",
                                    "    labels.append(np.full(imgs.shape[0], idx))\n",
                                    "\n",
                                    "# Combine all data and labels\n",
                                    "data = np.concatenate(data, axis=0)\n",
                                    "labels = np.concatenate(labels, axis=0)\n",
                                    "\n",
                                    "# Create an array of indices for shuffling\n",
                                    "indices = np.arange(len(data))\n",
                                    "\n",
                                    "# Shuffle the indices\n",
                                    "np.random.shuffle(indices)\n",
                                    "\n",
                                    "# Use the shuffled indices to reorder both data and labels\n",
                                    "data, labels = data[indices], labels[indices]\n",
                                    "\n",
                                    "# Reshape the data to (samples, height, width, channels) and normalize to [0,1]\n",
                                    "data = data.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
                                    "\n",
                                    "# Print information to verify the changes\n",
                                    "print(f\"Data shape after reshape: {data.shape}\")\n",
                                    "print(f\"Data type after normalization: {data.dtype}\")\n",
                                    "print(f\"Min and max pixel values: {data.min()}, {data.max()}\")\n",
                                    "print(f\"First 5 labels after shuffle: {labels[:5]}\")\n",
                                    "```\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### Explanation 🧑‍🏫\n",
                                    "\n",
                                    "1.  **Create Indices**: `np.arange(len(data))` generates an array of sequential integers from `0` to the total number of images. This creates a reference for the original order of the data.\n",
                                    "2.  **Shuffle Indices**: `np.random.shuffle(indices)` shuffles this array of indices in-place. This creates a new, random order.\n",
                                    "3.  **Apply Shuffled Order**: `data, labels = data[indices], labels[indices]` uses NumPy's advanced indexing to reorder both the `data` and `labels` arrays according to the `shuffled` indices. This is a critical step to ensure that each image remains correctly associated with its label.\n",
                                    "4.  **Reshape and Normalize**: `data.reshape(-1, 28, 28, 1).astype('float32') / 255.0` performs two operations in one line:\n",
                                    "      * `reshape(-1, 28, 28, 1)`: Changes the shape of the data array to be compatible with Convolutional Neural Networks (CNNs), which expect a 4D tensor: `(number_of_samples, height, width, color_channels)`. Here, `-1` tells NumPy to automatically calculate the number of samples.\n",
                                    "      * `.astype('float32') / 255.0`: First, it converts the data type from `uint8` to `float32`. Then, it divides every pixel value by `255.0`, scaling the range from `[0, 255]` down to `[0, 1]`. This normalization helps the model train more efficiently."
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Implementing Data Augmentation for Drawing Recognition\n",
                                    "\n",
                                    "Now that you've successfully shuffled and normalized your drawing data, let's split the data into training and test sets.\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "import urllib.request\n",
                                    "import numpy as np\n",
                                    "import os\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "\n",
                                    "# Ensure the data is downloaded\n",
                                    "categories = ['cat', 'house', 'airplane', 'apple', 'bicycle']\n",
                                    "base_url = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
                                    "\n",
                                    "os.makedirs('quickdraw_data', exist_ok=True)\n",
                                    "\n",
                                    "for category in categories:\n",
                                    "    file_path = f'quickdraw_data/{category}.npy'\n",
                                    "    if not os.path.exists(file_path):\n",
                                    "        print(f\"Downloading {category}...\")\n",
                                    "        urllib.request.urlretrieve(base_url + category + '.npy', file_path)\n",
                                    "    else:\n",
                                    "        print(f\"{category}.npy already exists.\")\n",
                                    "\n",
                                    "# Load and prepare data\n",
                                    "data = []\n",
                                    "labels = []\n",
                                    "\n",
                                    "for idx, cat in enumerate(categories):\n",
                                    "    filepath = f'quickdraw_data/{cat}.npy'\n",
                                    "    imgs = np.load(filepath)[:15000]  # Load up to 15000 images per category\n",
                                    "    if imgs.dtype != np.uint8:\n",
                                    "        imgs = imgs.astype(np.uint8)\n",
                                    "    data.append(imgs)\n",
                                    "    labels.append(np.full(imgs.shape[0], idx))\n",
                                    "\n",
                                    "# Combine all data and labels\n",
                                    "data = np.concatenate(data, axis=0)\n",
                                    "labels = np.concatenate(labels, axis=0)\n",
                                    "\n",
                                    "# Shuffle data\n",
                                    "indices = np.arange(len(data))\n",
                                    "np.random.shuffle(indices)\n",
                                    "data, labels = data[indices], labels[indices]\n",
                                    "\n",
                                    "# Reshape and normalize\n",
                                    "data = data.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
                                    "\n",
                                    "# TODO: Split data into training and testing sets and print shapes\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Of course. Here's the completed code to split your preprocessed data into training and test sets.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### Completed Code\n",
                                    "\n",
                                    "```python\n",
                                    "import urllib.request\n",
                                    "import numpy as np\n",
                                    "import os\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "\n",
                                    "# Ensure the data is downloaded\n",
                                    "categories = ['cat', 'house', 'airplane', 'apple', 'bicycle']\n",
                                    "base_url = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
                                    "\n",
                                    "os.makedirs('quickdraw_data', exist_ok=True)\n",
                                    "\n",
                                    "for category in categories:\n",
                                    "    file_path = f'quickdraw_data/{category}.npy'\n",
                                    "    if not os.path.exists(file_path):\n",
                                    "        print(f\"Downloading {category}...\")\n",
                                    "        urllib.request.urlretrieve(base_url + category + '.npy', file_path)\n",
                                    "    else:\n",
                                    "        print(f\"{category}.npy already exists.\")\n",
                                    "\n",
                                    "# Load and prepare data\n",
                                    "data = []\n",
                                    "labels = []\n",
                                    "\n",
                                    "for idx, cat in enumerate(categories):\n",
                                    "    filepath = f'quickdraw_data/{cat}.npy'\n",
                                    "    imgs = np.load(filepath)[:15000]\n",
                                    "    if imgs.dtype != np.uint8:\n",
                                    "        imgs = imgs.astype(np.uint8)\n",
                                    "    data.append(imgs)\n",
                                    "    labels.append(np.full(imgs.shape[0], idx))\n",
                                    "\n",
                                    "# Combine all data and labels\n",
                                    "data = np.concatenate(data, axis=0)\n",
                                    "labels = np.concatenate(labels, axis=0)\n",
                                    "\n",
                                    "# Shuffle data\n",
                                    "indices = np.arange(len(data))\n",
                                    "np.random.shuffle(indices)\n",
                                    "data, labels = data[indices], labels[indices]\n",
                                    "\n",
                                    "# Reshape and normalize\n",
                                    "data = data.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
                                    "\n",
                                    "# Split data into training and testing sets\n",
                                    "x_train, x_test, y_train, y_test = train_test_split(\n",
                                    "    data, labels, test_size=0.2, random_state=42, stratify=labels\n",
                                    ")\n",
                                    "\n",
                                    "# Print the shapes to verify the split\n",
                                    "print(\"Training data shape:\", x_train.shape)\n",
                                    "print(\"Testing data shape:\", x_test.shape)\n",
                                    "print(\"Training labels shape:\", y_train.shape)\n",
                                    "print(\"Testing labels shape:\", y_test.shape)\n",
                                    "```\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### Explanation 🧑‍🏫\n",
                                    "\n",
                                    "The final step in this preprocessing workflow is to partition the data. This is accomplished using Scikit-learn's `train_test_split` function.\n",
                                    "\n",
                                    "`x_train, x_test, y_train, y_test = train_test_split(...)`\n",
                                    "\n",
                                    "This single line splits both the image data (`data`) and the corresponding `labels` into four new arrays:\n",
                                    "\n",
                                    "  * **`x_train`**: The subset of images used for training the model (80% of the original data in this case).\n",
                                    "  * **`x_test`**: The subset of images used for evaluating the model's performance after training (the remaining 20%).\n",
                                    "  * **`y_train`**: The labels corresponding to the `x_train` images.\n",
                                    "  * **`y_test`**: The labels corresponding to the `x_test` images.\n",
                                    "\n",
                                    "The function's parameters are set as follows:\n",
                                    "\n",
                                    "  * `test_size=0.2`: Specifies that **20%** of the data should be allocated to the test set.\n",
                                    "  * `random_state=42`: Ensures that the split is **reproducible**. Anyone who runs this code with the same `random_state` will get the exact same split, which is crucial for consistent results.\n",
                                    "  * `stratify=labels`: This is an important parameter that ensures the proportion of each drawing category is the same in both the training and testing sets. It prevents a situation where, by random chance, one set has significantly more or fewer images of a certain category than the other."
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
