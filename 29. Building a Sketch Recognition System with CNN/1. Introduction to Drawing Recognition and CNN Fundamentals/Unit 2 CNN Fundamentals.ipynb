{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Unit 2 CNN Fundamentals\n",
                                    "\n",
                                    "Welcome to the next step in your journey of mastering drawing recognition using Convolutional Neural Networks (CNNs). In this lesson, we will delve into the fundamentals of CNNs, exploring what they are and how they work. This will build on your understanding of the drawing recognition problem and prepare you to create and train your own CNN models.\n",
                                    "\n",
                                    "### What You'll Learn\n",
                                    "\n",
                                    "Convolutional Neural Networks are a type of deep learning model specifically designed for processing structured grid data, like images. In this lesson, you will learn about the basic components of a CNN, including convolutional layers, pooling layers, and fully connected layers. We will also guide you through building a simple CNN using the MNIST dataset with Keras and TensorFlow.\n",
                                    "\n",
                                    "Here’s a breakdown of the main concepts you’ll encounter in the code:\n",
                                    "\n",
                                    "  * **Convolutional Layers:** These layers use filters (small matrices) that slide over the input image to detect features such as edges or patterns. The process of applying these filters is called convolution. Each filter helps the network learn different features from the image.\n",
                                    "  * **Activation Functions:** After each convolution, an activation function (like `relu`, which stands for Rectified Linear Unit) is applied. This introduces non-linearity, allowing the network to learn more complex patterns.\n",
                                    "  * **Pooling Layers:** These layers reduce the spatial size of the feature maps, making the computation more efficient and helping the model focus on the most important features. `Max pooling` is a common method, which takes the maximum value from a region of the feature map.\n",
                                    "  * **Fully Connected Layers:** After the convolutional and pooling layers, the data is flattened and passed through one or more fully connected (dense) layers. These layers combine the features learned by previous layers to make the final classification.\n",
                                    "  * **Optimizers:** The optimizer (like `adam` in the code) is an algorithm that adjusts the model’s parameters (weights) to minimize the loss during training.\n",
                                    "  * **Loss Function:** The loss function (like `categorical_crossentropy`) measures how well the model’s predictions match the actual labels. The optimizer tries to minimize this value.\n",
                                    "  * **Accuracy:** This is a metric that tells you the percentage of correct predictions made by the model. It’s a common way to evaluate how well your model is performing.\n",
                                    "\n",
                                    "Here’s a quick look at how you can build a simple CNN model:\n",
                                    "\n",
                                    "```python\n",
                                    "import tensorflow as tf\n",
                                    "from tensorflow.keras import layers, models\n",
                                    "\n",
                                    "def build_simple_cnn():\n",
                                    "    model = models.Sequential([\n",
                                    "        layers.Input(shape=(28, 28, 1)),\n",
                                    "        layers.Conv2D(32, (3, 3), activation='relu'),  # Convolutional layer with ReLU activation\n",
                                    "        layers.MaxPooling2D((2, 2)),                  # Pooling layer\n",
                                    "        layers.Conv2D(64, (3, 3), activation='relu'), # Another convolutional layer\n",
                                    "        layers.MaxPooling2D((2, 2)),                  # Another pooling layer\n",
                                    "        layers.Flatten(),                             # Flatten to 1D for dense layers\n",
                                    "        layers.Dense(64, activation='relu'),          # Fully connected (dense) layer\n",
                                    "        layers.Dense(10, activation='softmax')        # Output layer for 10 classes\n",
                                    "    ])\n",
                                    "    return model\n",
                                    "\n",
                                    "model = build_simple_cnn()\n",
                                    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
                                    "model.summary()\n",
                                    "```\n",
                                    "\n",
                                    "This code snippet demonstrates how to define a simple CNN model using Keras. The model consists of convolutional layers for feature extraction, pooling layers for down-sampling, and dense layers for classification. The optimizer, loss function, and accuracy metric are specified when compiling the model.\n",
                                    "\n",
                                    "`model.summary()` displays a table summarizing the structure of your CNN, including the types of layers, their output shapes, and the number of parameters in each layer. This helps you quickly understand the architecture and complexity of your model.\n",
                                    "\n",
                                    "### Training the Model\n",
                                    "\n",
                                    "Once you have defined your CNN model, the next step is to train it using a dataset. Training involves feeding the model with input data and adjusting its parameters to minimize the difference between the predicted and actual outputs. In this lesson, we will use the MNIST dataset to train our simple CNN model.\n",
                                    "\n",
                                    "Here's how you can train the model:\n",
                                    "\n",
                                    "```python\n",
                                    "# Train the model\n",
                                    "model.fit(train_images, train_labels, epochs=1, batch_size=64, validation_split=0.1)\n",
                                    "```\n",
                                    "\n",
                                    "In this snippet, `train_images` and `train_labels` represent the training data and their corresponding labels. The model is trained for one epoch with a batch size of 64, and 10% of the training data is used for validation. Adjusting these parameters can help improve the model's performance and generalization.\n",
                                    "\n",
                                    "### Making Predictions with the Model\n",
                                    "\n",
                                    "After training your CNN model, you can use it to make predictions on new data. This involves passing input data through the model to obtain the predicted output. Here's how you can use the trained model to make predictions:\n",
                                    "\n",
                                    "```python\n",
                                    "# Make predictions\n",
                                    "predictions = model.predict(test_images)\n",
                                    "\n",
                                    "# Example: Get the predicted class for the first test image\n",
                                    "predicted_class = predictions[0].argmax()\n",
                                    "```\n",
                                    "\n",
                                    "In this snippet, `test_images` represents the new data you want to classify. The `model.predict()` function returns an array of predictions, where each prediction is a probability distribution over the possible classes. You can use `argmax()` to find the class with the highest probability for each input, which is the model's predicted class. The `.argmax()` function returns the index of the highest value in the prediction array, which corresponds to the class with the highest predicted probability.\n",
                                    "\n",
                                    "### Evaluating the Model\n",
                                    "\n",
                                    "Once you've built and trained your CNN model, it's important to evaluate its performance to ensure it meets your expectations. Evaluating the model involves testing it on a separate dataset that it hasn't seen during training. This helps in assessing how well the model generalizes to new, unseen data.\n",
                                    "\n",
                                    "Here's how you can evaluate your CNN model using Keras:\n",
                                    "\n",
                                    "```python\n",
                                    "# Evaluate the model\n",
                                    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
                                    "print(f\"Test accuracy: {test_acc}\")\n",
                                    "```\n",
                                    "\n",
                                    "In this snippet, `model.evaluate()` is used to compute the loss and accuracy of the model on the test dataset. The `test_acc` provides a measure of how well the model performs on the test data, which is crucial for understanding its effectiveness in real-world applications.\n",
                                    "\n",
                                    "### Why It Matters\n",
                                    "\n",
                                    "Understanding CNN fundamentals is crucial because CNNs are the backbone of many modern computer vision applications. They are capable of automatically learning and extracting features from images, making them highly effective for tasks like drawing recognition. By mastering CNNs, you will be equipped with the skills to tackle a wide range of image processing challenges, from recognizing handwritten digits to more complex image classification tasks.\n",
                                    "\n",
                                    "Excited to see CNNs in action? Let's move on to the practice section and start building your own CNN models."
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Building Your First CNN Model\n",
                                    "\n",
                                    "Great job analyzing the digit distribution in the MNIST dataset! Now it's time to build a simple Convolutional Neural Network (CNN) to recognize these handwritten digits.\n",
                                    "\n",
                                    "CNNs excel at image recognition tasks because they can automatically learn spatial hierarchies of features. For handwritten digit recognition, the CNN will first learn to identify edges and simple patterns, then combine these features in later layers to recognize entire digits.\n",
                                    "\n",
                                    "In this practice, you'll complete the code to build a CNN model with convolutional layers for feature extraction, pooling layers for downsampling, and dense layers for classification. You'll also prepare the data correctly by reshaping and normalizing the images, which is a critical preprocessing step for CNNs.\n",
                                    "\n",
                                    "This model will serve as the foundation for our digit recognition system and demonstrate the core architecture used in many computer vision applications.\n",
                                    "\n",
                                    "```python\n",
                                    "import tensorflow as tf\n",
                                    "from tensorflow.keras import layers, models\n",
                                    "from tensorflow.keras.datasets import mnist\n",
                                    "from tensorflow.keras.utils import to_categorical\n",
                                    "\n",
                                    "# Load and preprocess a smaller sample of the MNIST dataset\n",
                                    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
                                    "TRAIN_SIZE = 3000\n",
                                    "TEST_SIZE = 1000\n",
                                    "train_images = train_images[:TRAIN_SIZE].reshape((________)).astype('float32') / ________\n",
                                    "test_images = test_images[:TEST_SIZE].reshape((________)).astype('float32') / ________\n",
                                    "train_labels = to_categorical(train_labels[:TRAIN_SIZE])\n",
                                    "test_labels = to_categorical(test_labels[:TEST_SIZE])\n",
                                    "\n",
                                    "# Simple CNN model using MNIST dataset\n",
                                    "def build_simple_cnn():\n",
                                    "    model = models.Sequential([\n",
                                    "        layers.Input(shape=(28, 28, 1)),\n",
                                    "        layers.Conv2D(32, (3, 3), activation='________'),\n",
                                    "        layers.MaxPooling2D((2, 2)),\n",
                                    "        layers.Conv2D(64, (3, 3), activation='________'),\n",
                                    "        layers.MaxPooling2D((2, 2)),\n",
                                    "        layers.Flatten(),\n",
                                    "        layers.Dense(64, activation='________'),\n",
                                    "        layers.Dense(10, activation='________')\n",
                                    "    ])\n",
                                    "    return model\n",
                                    "\n",
                                    "model = build_simple_cnn()\n",
                                    "model.compile(optimizer='________', loss='________', metrics=['________'])\n",
                                    "model.summary()\n",
                                    "\n",
                                    "# Train the model\n",
                                    "model.fit(train_images, train_labels, epochs=1, batch_size=64, validation_split=0.1)\n",
                                    "\n",
                                    "# Evaluate the model\n",
                                    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
                                    "print(f\"Test accuracy: {test_acc}\")\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "import tensorflow as tf\n",
                                    "from tensorflow.keras import layers, models\n",
                                    "from tensorflow.keras.datasets import mnist\n",
                                    "from tensorflow.keras.utils import to_categorical\n",
                                    "\n",
                                    "# Load and preprocess a smaller sample of the MNIST dataset\n",
                                    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
                                    "TRAIN_SIZE = 3000\n",
                                    "TEST_SIZE = 1000\n",
                                    "# Reshape images to include a channel dimension and normalize pixel values to [0, 1]\n",
                                    "train_images = train_images[:TRAIN_SIZE].reshape((TRAIN_SIZE, 28, 28, 1)).astype('float32') / 255\n",
                                    "test_images = test_images[:TEST_SIZE].reshape((TEST_SIZE, 28, 28, 1)).astype('float32') / 255\n",
                                    "# Convert integer labels to one-hot encoded vectors\n",
                                    "train_labels = to_categorical(train_labels[:TRAIN_SIZE])\n",
                                    "test_labels = to_categorical(test_labels[:TEST_SIZE])\n",
                                    "\n",
                                    "# Simple CNN model using MNIST dataset\n",
                                    "def build_simple_cnn():\n",
                                    "    model = models.Sequential([\n",
                                    "        # Input layer specifying the shape of the images (28x28 pixels, 1 channel for grayscale)\n",
                                    "        layers.Input(shape=(28, 28, 1)),\n",
                                    "        # First Convolutional Layer: 32 filters, 3x3 kernel, ReLU activation\n",
                                    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
                                    "        # First MaxPooling Layer: Reduces spatial dimensions by taking the maximum value over 2x2 windows\n",
                                    "        layers.MaxPooling2D((2, 2)),\n",
                                    "        # Second Convolutional Layer: 64 filters, 3x3 kernel, ReLU activation\n",
                                    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
                                    "        # Second MaxPooling Layer\n",
                                    "        layers.MaxPooling2D((2, 2)),\n",
                                    "        # Flatten layer: Converts the 2D feature maps into a 1D vector for the dense layers\n",
                                    "        layers.Flatten(),\n",
                                    "        # First Dense (Fully Connected) Layer: 64 units, ReLU activation\n",
                                    "        layers.Dense(64, activation='relu'),\n",
                                    "        # Output Dense Layer: 10 units (for 10 digits), Softmax activation for probability distribution\n",
                                    "        layers.Dense(10, activation='softmax')\n",
                                    "    ])\n",
                                    "    return model\n",
                                    "\n",
                                    "# Build the CNN model\n",
                                    "model = build_simple_cnn()\n",
                                    "# Compile the model:\n",
                                    "# optimizer: 'adam' is an efficient stochastic optimization algorithm\n",
                                    "# loss: 'categorical_crossentropy' is used for multi-class classification with one-hot encoded labels\n",
                                    "# metrics: 'accuracy' to monitor the proportion of correctly classified images\n",
                                    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
                                    "# Display a summary of the model's architecture\n",
                                    "model.summary()\n",
                                    "\n",
                                    "# Train the model:\n",
                                    "# train_images: The training data\n",
                                    "# train_labels: The corresponding labels for the training data\n",
                                    "# epochs: Number of times the model will iterate over the entire training dataset\n",
                                    "# batch_size: Number of samples per gradient update\n",
                                    "# validation_split: Fraction of the training data to be used as validation data\n",
                                    "model.fit(train_images, train_labels, epochs=1, batch_size=64, validation_split=0.1)\n",
                                    "\n",
                                    "# Evaluate the model on the test dataset:\n",
                                    "# test_images: The test data\n",
                                    "# test_labels: The corresponding labels for the test data\n",
                                    "# Returns the loss value and metrics values for the model in test mode\n",
                                    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
                                    "print(f\"Test accuracy: {test_acc}\")\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Training and Evaluating Your CNN Model\n",
                                    "\n",
                                    "Great job building your first CNN model! Now let's take the next step and train it on the MNIST dataset to recognize handwritten digits.\n",
                                    "\n",
                                    "Training a neural network involves feeding it batches of images and their labels, allowing the model to learn patterns through multiple iterations. After training, we need to evaluate how well the model performs on unseen data to measure its ability to generalize.\n",
                                    "\n",
                                    "In this practice, you'll complete the code to train the model and evaluate its accuracy on the test set. You'll specify the training data, configure training parameters, and implement the evaluation code to measure your model's performance.\n",
                                    "\n",
                                    "This step is crucial for understanding how well your CNN can recognize digits and will prepare you for more advanced techniques in future lessons.\n",
                                    "\n",
                                    "```python\n",
                                    "import tensorflow as tf\n",
                                    "from tensorflow.keras import layers, models\n",
                                    "from tensorflow.keras.datasets import mnist\n",
                                    "from tensorflow.keras.utils import to_categorical\n",
                                    "\n",
                                    "# Load and preprocess a smaller sample of the MNIST dataset\n",
                                    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
                                    "TRAIN_SIZE = 3000\n",
                                    "TEST_SIZE = 1000\n",
                                    "train_images = train_images[:TRAIN_SIZE].reshape((TRAIN_SIZE, 28, 28, 1)).astype('float32') / 255\n",
                                    "test_images = test_images[:TEST_SIZE].reshape((TEST_SIZE, 28, 28, 1)).astype('float32') / 255\n",
                                    "train_labels = to_categorical(train_labels[:TRAIN_SIZE])\n",
                                    "test_labels = to_categorical(test_labels[:TEST_SIZE])\n",
                                    "\n",
                                    "# Simple CNN model using MNIST dataset\n",
                                    "def build_simple_cnn():\n",
                                    "    model = models.Sequential([\n",
                                    "        layers.Input(shape=(28, 28, 1)),\n",
                                    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
                                    "        layers.MaxPooling2D((2, 2)),\n",
                                    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
                                    "        layers.MaxPooling2D((2, 2)),\n",
                                    "        layers.Flatten(),\n",
                                    "        layers.Dense(64, activation='relu'),\n",
                                    "        layers.Dense(10, activation='softmax')\n",
                                    "    ])\n",
                                    "    return model\n",
                                    "\n",
                                    "model = build_simple_cnn()\n",
                                    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
                                    "model.summary()\n",
                                    "\n",
                                    "# TODO: Train the model with 1 epoch, batch size of 64, and use 10% of training data for validation\n",
                                    "model.fit(_________, _________, epochs=_________, batch_size=_________, validation_split=_________)\n",
                                    "\n",
                                    "# TODO: Evaluate the model on test data and print the accuracy\n",
                                    "________, ________ = model.evaluate(_________, _________)\n",
                                    "print(f\"Test accuracy: {________}\")\n",
                                    "\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Building Enhanced CNN with Sequential API\n",
                                    "\n",
                                    "Now that you've successfully trained and evaluated your CNN model, let's enhance its architecture. In this practice, you'll build a more sophisticated CNN for digit recognition by implementing a different approach to model construction.\n",
                                    "\n",
                                    "You'll use the Sequential API's add() method instead of passing a list of layers. This approach gives you more flexibility when building complex models and is commonly used in professional deep learning projects.\n",
                                    "\n",
                                    "Your task is to complete the enhanced CNN architecture by adding the missing components according to the TODOs. This includes adding convolutional layers, pooling layers, flattening the output, and configuring the dense layers for classification.\n",
                                    "\n",
                                    "This enhanced architecture will help the model learn more complex features from the handwritten digits, potentially improving its recognition accuracy.\n",
                                    "\n",
                                    "```python\n",
                                    "import tensorflow as tf\n",
                                    "from tensorflow.keras import layers, models\n",
                                    "from tensorflow.keras.datasets import mnist\n",
                                    "from tensorflow.keras.utils import to_categorical\n",
                                    "\n",
                                    "# Load and preprocess a smaller sample of the MNIST dataset\n",
                                    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
                                    "TRAIN_SIZE = 3000\n",
                                    "TEST_SIZE = 1000\n",
                                    "train_images = train_images[:TRAIN_SIZE].reshape((TRAIN_SIZE, 28, 28, 1)).astype('float32') / 255\n",
                                    "test_images = test_images[:TEST_SIZE].reshape((TEST_SIZE, 28, 28, 1)).astype('float32') / 255\n",
                                    "train_labels = to_categorical(train_labels[:TRAIN_SIZE])\n",
                                    "test_labels = to_categorical(test_labels[:TEST_SIZE])\n",
                                    "\n",
                                    "# Enhanced CNN model for digit recognition\n",
                                    "def build_enhanced_cnn():\n",
                                    "    model = models.Sequential()\n",
                                    "    # Input layer\n",
                                    "    model.add(layers.Input(shape=(28, 28, 1)))\n",
                                    "    # First convolutional layer\n",
                                    "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
                                    "    model.add(layers.MaxPooling2D((2, 2)))\n",
                                    "    # TODO: Add second convolutional layer with 64 filters and ReLU activation\n",
                                    "    model.add(layers.Conv2D(_________, (3, 3), activation='_________'))\n",
                                    "    # TODO: Add another max pooling layer with 2x2 pool size\n",
                                    "    model.add(layers._________((2, 2)))\n",
                                    "    # TODO: Flatten the output\n",
                                    "    model.add(layers._________)\n",
                                    "    # TODO: Add a dense layer with 64 neurons and ReLU activation\n",
                                    "    model.add(layers.Dense(_________, activation='_________'))\n",
                                    "    # TODO: Add output layer with appropriate number of neurons and activation for digit classification\n",
                                    "    model.add(layers.Dense(_________, activation='_________'))\n",
                                    "    return model\n",
                                    "\n",
                                    "# Create the model\n",
                                    "model = build_enhanced_cnn()\n",
                                    "\n",
                                    "# TODO: Compile the model with appropriate optimizer, loss function, and metric\n",
                                    "model.compile(optimizer='_________', loss='_________', metrics=['_________'])\n",
                                    "\n",
                                    "# Display model summary\n",
                                    "model.summary()\n",
                                    "\n",
                                    "# Train the model\n",
                                    "model.fit(train_images, train_labels, epochs=1, batch_size=64, validation_split=0.1)\n",
                                    "\n",
                                    "# Evaluate the model\n",
                                    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
                                    "print(f\"Test accuracy: {test_acc}\")\n",
                                    "\n",
                                    "```\n",
                                    "Of course\\! Here is the completed Python script for building, compiling, and training the enhanced CNN model.\n",
                                    "\n",
                                    "The missing components have been filled in according to the instructions provided in the `TODO` comments.\n",
                                    "\n",
                                    "```python\n",
                                    "import tensorflow as tf\n",
                                    "from tensorflow.keras import layers, models\n",
                                    "from tensorflow.keras.datasets import mnist\n",
                                    "from tensorflow.keras.utils import to_categorical\n",
                                    "\n",
                                    "# Load and preprocess a smaller sample of the MNIST dataset\n",
                                    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
                                    "TRAIN_SIZE = 3000\n",
                                    "TEST_SIZE = 1000\n",
                                    "train_images = train_images[:TRAIN_SIZE].reshape((TRAIN_SIZE, 28, 28, 1)).astype('float32') / 255\n",
                                    "test_images = test_images[:TEST_SIZE].reshape((TEST_SIZE, 28, 28, 1)).astype('float32') / 255\n",
                                    "train_labels = to_categorical(train_labels[:TRAIN_SIZE])\n",
                                    "test_labels = to_categorical(test_labels[:TEST_SIZE])\n",
                                    "\n",
                                    "# Enhanced CNN model for digit recognition\n",
                                    "def build_enhanced_cnn():\n",
                                    "    model = models.Sequential()\n",
                                    "    # Input layer\n",
                                    "    model.add(layers.Input(shape=(28, 28, 1)))\n",
                                    "    # First convolutional layer\n",
                                    "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
                                    "    model.add(layers.MaxPooling2D((2, 2)))\n",
                                    "    # TODO: Add second convolutional layer with 64 filters and ReLU activation\n",
                                    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
                                    "    # TODO: Add another max pooling layer with 2x2 pool size\n",
                                    "    model.add(layers.MaxPooling2D((2, 2)))\n",
                                    "    # TODO: Flatten the output\n",
                                    "    model.add(layers.Flatten())\n",
                                    "    # TODO: Add a dense layer with 64 neurons and ReLU activation\n",
                                    "    model.add(layers.Dense(64, activation='relu'))\n",
                                    "    # TODO: Add output layer with appropriate number of neurons and activation for digit classification\n",
                                    "    model.add(layers.Dense(10, activation='softmax'))\n",
                                    "    return model\n",
                                    "\n",
                                    "# Create the model\n",
                                    "model = build_enhanced_cnn()\n",
                                    "\n",
                                    "# TODO: Compile the model with appropriate optimizer, loss function, and metric\n",
                                    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
                                    "\n",
                                    "# Display model summary\n",
                                    "model.summary()\n",
                                    "\n",
                                    "# Train the model\n",
                                    "model.fit(train_images, train_labels, epochs=1, batch_size=64, validation_split=0.1)\n",
                                    "\n",
                                    "# Evaluate the model\n",
                                    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
                                    "print(f\"Test accuracy: {test_acc}\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### **Explanation of Changes**\n",
                                    "\n",
                                    "  * **Second Convolutional Layer**: A `Conv2D` layer with **64** filters and a `'relu'` activation function was added to help the model learn more intricate patterns from the features detected by the first layer.\n",
                                    "  * **Second Pooling Layer**: A `MaxPooling2D` layer was added to downsample the feature maps, reducing computational complexity and making the learned features more robust.\n",
                                    "  * **Flatten Layer**: A `Flatten` layer was used to convert the 2D feature maps from the convolutional layers into a 1D vector, preparing the data for the fully connected (Dense) layers.\n",
                                    "  * **Dense & Output Layers**:\n",
                                    "      * A `Dense` layer with **64** neurons and a `'relu'` activation was added for high-level feature combination.\n",
                                    "      * The final `Dense` output layer has **10** neurons (one for each digit from 0 to 9) and a `'softmax'` activation function. Softmax is ideal for multi-class classification as it outputs a probability distribution across the classes.\n",
                                    "  * **Compilation**:\n",
                                    "      * **Optimizer**: `'adam'` is a popular and effective optimization algorithm that adapts the learning rate during training.\n",
                                    "      * **Loss Function**: `'categorical_crossentropy'` is the standard loss function for multi-class classification where labels are one-hot encoded.\n",
                                    "      * **Metric**: `['accuracy']` was chosen to monitor the model's performance by calculating the percentage of correctly classified digits."
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "id": "f2b820b3",
                           "metadata": {},
                           "source": [
                                    "Great job building your enhanced CNN model! Now let's put it to work by making actual predictions on handwritten digits. After all, the real value of a trained model is its ability to classify new data.\n",
                                    "\n",
                                    "In this practice, you'll implement code to generate predictions using your trained model on the test dataset. You'll convert the model's probability outputs into actual digit predictions and compare them with the true labels to assess performance.\n",
                                    "\n",
                                    "You'll also visualize some example predictions alongside the actual digits, which is an important step in understanding how your model performs on individual cases. This helps identify patterns in your model's successes and failures.\n",
                                    "\n",
                                    "This skill is essential for any machine learning project, as it bridges the gap between model training and practical application.\n",
                                    "\n",
                                    "```python\n",
                                    "import tensorflow as tf\n",
                                    "from tensorflow.keras import layers, models\n",
                                    "from tensorflow.keras.datasets import mnist\n",
                                    "from tensorflow.keras.utils import to_categorical\n",
                                    "import numpy as np\n",
                                    "import matplotlib.pyplot as plt\n",
                                    "\n",
                                    "# Load and preprocess a smaller sample of the MNIST dataset\n",
                                    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
                                    "TRAIN_SIZE = 3000\n",
                                    "TEST_SIZE = 1000\n",
                                    "train_images = train_images[:TRAIN_SIZE].reshape((TRAIN_SIZE, 28, 28, 1)).astype('float32') / 255\n",
                                    "test_images = test_images[:TEST_SIZE].reshape((TEST_SIZE, 28, 28, 1)).astype('float32') / 255\n",
                                    "train_labels = to_categorical(train_labels[:TRAIN_SIZE])\n",
                                    "test_labels = to_categorical(test_labels[:TEST_SIZE])\n",
                                    "\n",
                                    "# Enhanced CNN model for digit recognition\n",
                                    "def build_enhanced_cnn():\n",
                                    "    model = models.Sequential()\n",
                                    "    # Input layer\n",
                                    "    model.add(layers.Input(shape=(28, 28, 1)))\n",
                                    "    # First convolutional layer\n",
                                    "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
                                    "    model.add(layers.MaxPooling2D((2, 2)))\n",
                                    "    # Second convolutional layer\n",
                                    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
                                    "    model.add(layers.MaxPooling2D((2, 2)))\n",
                                    "    # Flatten layer\n",
                                    "    model.add(layers.Flatten())\n",
                                    "    # Dense hidden layer\n",
                                    "    model.add(layers.Dense(64, activation='relu'))\n",
                                    "    # Output layer\n",
                                    "    model.add(layers.Dense(10, activation='softmax'))\n",
                                    "    return model\n",
                                    "\n",
                                    "# Create the model\n",
                                    "model = build_enhanced_cnn()\n",
                                    "\n",
                                    "# Compile the model\n",
                                    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
                                    "\n",
                                    "# Train the model\n",
                                    "model.fit(train_images, train_labels, epochs=1, batch_size=64, validation_split=0.1)\n",
                                    "\n",
                                    "# TODO: Generate predictions on test data\n",
                                    "predictions = model._________(__________)\n",
                                    "\n",
                                    "# TODO: Convert prediction probabilities to class labels\n",
                                    "predicted_classes = np._________(predictions, axis=_________)\n",
                                    "\n",
                                    "# TODO: Convert one-hot encoded test labels back to class labels\n",
                                    "actual_classes = np._________(__________, axis=_________)\n",
                                    "\n",
                                    "# TODO: Calculate accuracy manually\n",
                                    "correct_predictions = np._________(predicted_classes == actual_classes)\n",
                                    "accuracy = correct_predictions / _________\n",
                                    "print(f\"Manual accuracy calculation: {accuracy:.4f}\")\n",
                                    "\n",
                                    "# Display some example predictions\n",
                                    "num_examples = 5\n",
                                    "plt.figure(figsize=(15, 3))\n",
                                    "for i in range(num_examples):\n",
                                    "    plt.subplot(1, num_examples, i+1)\n",
                                    "    plt.imshow(test_images[i].reshape(28, 28), cmap='gray')\n",
                                    "    # TODO: Complete the title to show actual and predicted classes\n",
                                    "    plt.title(f\"Actual: {_________}\\nPredicted: {_________}\")\n",
                                    "    plt.axis('off')\n",
                                    "plt.tight_layout()\n",
                                    "plt.savefig('static/images/plot.png')\n",
                                    "\n",
                                    "```\n",
                                    "Of course\\! Here is the completed script for making predictions with your trained model.\n",
                                    "\n",
                                    "The missing lines have been filled in to generate predictions, convert probabilities to class labels, calculate accuracy, and visualize the results.\n",
                                    "\n",
                                    "```python\n",
                                    "import tensorflow as tf\n",
                                    "from tensorflow.keras import layers, models\n",
                                    "from tensorflow.keras.datasets import mnist\n",
                                    "from tensorflow.keras.utils import to_categorical\n",
                                    "import numpy as np\n",
                                    "import matplotlib.pyplot as plt\n",
                                    "\n",
                                    "# Load and preprocess a smaller sample of the MNIST dataset\n",
                                    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
                                    "TRAIN_SIZE = 3000\n",
                                    "TEST_SIZE = 1000\n",
                                    "train_images = train_images[:TRAIN_SIZE].reshape((TRAIN_SIZE, 28, 28, 1)).astype('float32') / 255\n",
                                    "test_images = test_images[:TEST_SIZE].reshape((TEST_SIZE, 28, 28, 1)).astype('float32') / 255\n",
                                    "train_labels = to_categorical(train_labels[:TRAIN_SIZE])\n",
                                    "test_labels = to_categorical(test_labels[:TEST_SIZE])\n",
                                    "\n",
                                    "# Enhanced CNN model for digit recognition\n",
                                    "def build_enhanced_cnn():\n",
                                    "    model = models.Sequential()\n",
                                    "    # Input layer\n",
                                    "    model.add(layers.Input(shape=(28, 28, 1)))\n",
                                    "    # First convolutional layer\n",
                                    "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
                                    "    model.add(layers.MaxPooling2D((2, 2)))\n",
                                    "    # Second convolutional layer\n",
                                    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
                                    "    model.add(layers.MaxPooling2D((2, 2)))\n",
                                    "    # Flatten layer\n",
                                    "    model.add(layers.Flatten())\n",
                                    "    # Dense hidden layer\n",
                                    "    model.add(layers.Dense(64, activation='relu'))\n",
                                    "    # Output layer\n",
                                    "    model.add(layers.Dense(10, activation='softmax'))\n",
                                    "    return model\n",
                                    "\n",
                                    "# Create the model\n",
                                    "model = build_enhanced_cnn()\n",
                                    "\n",
                                    "# Compile the model\n",
                                    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
                                    "\n",
                                    "# Train the model\n",
                                    "model.fit(train_images, train_labels, epochs=1, batch_size=64, validation_split=0.1)\n",
                                    "\n",
                                    "# TODO: Generate predictions on test data\n",
                                    "predictions = model.predict(test_images)\n",
                                    "\n",
                                    "# TODO: Convert prediction probabilities to class labels\n",
                                    "predicted_classes = np.argmax(predictions, axis=1)\n",
                                    "\n",
                                    "# TODO: Convert one-hot encoded test labels back to class labels\n",
                                    "actual_classes = np.argmax(test_labels, axis=1)\n",
                                    "\n",
                                    "# TODO: Calculate accuracy manually\n",
                                    "correct_predictions = np.sum(predicted_classes == actual_classes)\n",
                                    "accuracy = correct_predictions / len(actual_classes)\n",
                                    "print(f\"Manual accuracy calculation: {accuracy:.4f}\")\n",
                                    "\n",
                                    "# Display some example predictions\n",
                                    "num_examples = 5\n",
                                    "plt.figure(figsize=(15, 3))\n",
                                    "for i in range(num_examples):\n",
                                    "    plt.subplot(1, num_examples, i+1)\n",
                                    "    plt.imshow(test_images[i].reshape(28, 28), cmap='gray')\n",
                                    "    # TODO: Complete the title to show actual and predicted classes\n",
                                    "    plt.title(f\"Actual: {actual_classes[i]}\\nPredicted: {predicted_classes[i]}\")\n",
                                    "    plt.axis('off')\n",
                                    "plt.tight_layout()\n",
                                    "plt.savefig('static/images/plot.png')\n",
                                    "```\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### **Explanation of Changes**\n",
                                    "\n",
                                    "  * **Generate Predictions**: The `model.predict()` method is called on the `test_images` to generate an array of predictions. Each prediction is a list of 10 probabilities corresponding to the 10 possible digits.\n",
                                    "  * **Convert Probabilities**: `np.argmax(predictions, axis=1)` finds the index of the highest probability for each prediction. Since the indices correspond to the digits (0-9), this effectively converts the probability arrays into single-digit predictions (e.g., `[0.1, 0.2, 0.7]` becomes `2`).\n",
                                    "  * **Convert Labels**: Similarly, `np.argmax(test_labels, axis=1)` is used to convert the one-hot encoded `test_labels` back into single-digit labels for easy comparison.\n",
                                    "  * **Calculate Accuracy**:\n",
                                    "      * `np.sum(predicted_classes == actual_classes)` compares the predicted and actual labels element-wise, creating a boolean array (`True` for correct, `False` for incorrect). `np.sum()` then counts the `True` values.\n",
                                    "      * This count is divided by the total number of test samples (`len(actual_classes)`) to get the accuracy score.\n",
                                    "  * **Visualize Results**: The `matplotlib` code now correctly fetches the `i`-th actual label and predicted label from the `actual_classes` and `predicted_classes` arrays to display in the title of each example plot."
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
