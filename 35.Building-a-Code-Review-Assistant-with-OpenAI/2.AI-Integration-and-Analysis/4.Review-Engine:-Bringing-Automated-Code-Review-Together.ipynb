{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Unit 4"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Review Engine: Bringing Automated Code Review Together\n",
                "\n",
                "# Welcome to this Lesson on Building a **Review Engine**\\!\n",
                "\n",
                "So far, you have learned how to set up an **AI client**, parse code changes, and gather useful context for code review. Now, you will see how these pieces come together in a **Review Engine** â€” a tool that automates the process of reviewing code changes using AI.\n",
                "\n",
                "A Review Engine is a program that takes a set of code changes (called a \"**changeset**\"), gathers all the important information about those changes, and then asks an AI model to review them. This helps developers catch mistakes, improve code quality, and save time.\n",
                "\n",
                "By the end of this lesson, you will understand how to build a Review Engine that can review both individual files and entire changesets, using all the tools you have learned so far.\n",
                "\n",
                "-----\n",
                "\n",
                "## Recall: Connecting the Pieces\n",
                "\n",
                "Before we dive in, let's quickly remind ourselves how the main parts work together:\n",
                "\n",
                "  * **OpenAI Client:** This is the tool that sends code and context to the AI model and gets back a review.\n",
                "  * **Diff Parser:** This breaks down the code changes into a format that is easy to work with.\n",
                "  * **Context Generator:** This gathers extra information about the code, like recent changes and related files, to help the AI give better feedback.\n",
                "\n",
                "In this lesson, you will see how the Review Engine uses all these parts to review code changes automatically.\n",
                "\n",
                "-----\n",
                "\n",
                "## Reviewing a Single File in a Changeset\n",
                "\n",
                "Let's start by looking at how the Review Engine reviews one file at a time. This is the basic building block for reviewing larger sets of changes.\n",
                "\n",
                "### Step 1: Parsing the Diff\n",
                "\n",
                "The first thing the Review Engine does is parse the diff for the file. The diff shows what has changed in the code.\n",
                "\n",
                "```python\n",
                "import logging\n",
                "import time\n",
                "\n",
                "logger = logging.getLogger(__name__)\n",
                "\n",
                "def review_changeset_file(self, session, changeset_file):\n",
                "    start_time = time.time()\n",
                "    file_path = changeset_file.file_path\n",
                "    \n",
                "    logger.info(f\"Starting review for file: {file_path}\")\n",
                "    try:\n",
                "        diff = parse_unified_diff(changeset_file.diff_content)\n",
                "```\n",
                "\n",
                "Here, `parse_unified_diff` is a function that takes the raw diff text and turns it into a structured object. This makes it easier to work with the changes.\n",
                "\n",
                "  * `changeset_file.diff_content` is the text showing the changes for this file.\n",
                "  * `diff` will now hold information like the file path and the specific lines that changed.\n",
                "\n",
                "### Step 2: Gathering Context\n",
                "\n",
                "Next, the Review Engine gathers extra information about the file. This helps the AI understand the code better.\n",
                "\n",
                "```python\n",
                "        file_context = get_file_context(session, diff.file_path)\n",
                "        recent_changes = get_recent_changes(session, diff.file_path)\n",
                "        related_files = find_related_files(session, diff.file_path)\n",
                "        \n",
                "        logger.debug(f\"Gathered context for {file_path}: {len(recent_changes)} recent changes, {len(related_files)} related files\")\n",
                "```\n",
                "\n",
                "  * `get_file_context` gets the current content of the file.\n",
                "  * `get_recent_changes` finds recent changes made to this file.\n",
                "  * `find_related_files` lists other files that are related to this one.\n",
                "\n",
                "### Step 3: Building the Context Summary\n",
                "\n",
                "The Review Engine then combines this information into a summary that will be sent to the AI.\n",
                "\n",
                "```python\n",
                "        context_parts = []\n",
                "        if recent_changes:\n",
                "            recent_summary = \"; \".join([\n",
                "                f\"{change['hash']}: {change['message']}\" \n",
                "                for change in recent_changes[:2]\n",
                "            ])\n",
                "            context_parts.append(f\"Recent changes: {recent_summary}\")\n",
                "            \n",
                "        if related_files:\n",
                "            context_parts.append(f\"Related files: {', '.join(related_files)}\")\n",
                "            \n",
                "        context = \" | \".join(context_parts)\n",
                "```\n",
                "\n",
                "This code creates a list called `context_parts`.\n",
                "\n",
                "  * If there are recent changes, it adds a summary of the last two changes.\n",
                "  * If there are related files, it adds their names.\n",
                "  * Finally, it joins everything into a single string called `context`.\n",
                "\n",
                "### Step 4: Generating the Review\n",
                "\n",
                "Now, the Review Engine asks the AI to review the changes, using the context we just built.\n",
                "\n",
                "```python\n",
                "        review = self.llm_client.analyze_changeset(\n",
                "            file_path=diff.file_path,\n",
                "            diff=changeset_file.diff_content,\n",
                "            context=context\n",
                "        )\n",
                "        \n",
                "        duration = time.time() - start_time\n",
                "        logger.info(f\"Successfully reviewed {file_path} in {duration:.2f} seconds\")\n",
                "        \n",
                "        return review\n",
                "        \n",
                "    except Exception as e:\n",
                "        duration = time.time() - start_time\n",
                "        logger.error(f\"Failed to review {file_path} after {duration:.2f} seconds: {str(e)}\")\n",
                "        raise\n",
                "```\n",
                "\n",
                "  * `analyze_changeset` is a method that sends the file path, the diff, and the context to the AI.\n",
                "  * The AI returns a review, which is stored in the `review` variable.\n",
                "  * The engine logs both successful reviews and failures, including timing information.\n",
                "\n",
                "**Example Output:**\n",
                "\n",
                "```\n",
                "INFO: Starting review for file: example.py\n",
                "DEBUG: Gathered context for example.py: 2 recent changes, 2 related files\n",
                "INFO: Successfully reviewed example.py in 3.42 seconds\n",
                "```\n",
                "\n",
                "Review for `example.py` with context: `Recent changes: abc12345: Initial commit; def67890: Refactor code | Related files: utils.py, helpers.py`\n",
                "\n",
                "This output shows that the AI has reviewed the file and included the context we provided, along with logging information about the process.\n",
                "\n",
                "-----\n",
                "\n",
                "## Reviewing an Entire Changeset\n",
                "\n",
                "Now that you know how to review a single file, let's see how the Review Engine reviews all files in a changeset.\n",
                "\n",
                "### Step 1: Looping Through Files\n",
                "\n",
                "The Review Engine goes through each file in the changeset and reviews them one by one.\n",
                "\n",
                "```python\n",
                "def review_changeset(self, session, changeset):\n",
                "    changeset_start_time = time.time()\n",
                "    total_files = len(changeset.files)\n",
                "    \n",
                "    logger.info(f\"Starting changeset review for {total_files} files\")\n",
                "    \n",
                "    reviews = {}\n",
                "    successful_reviews = 0\n",
                "    failed_reviews = 0\n",
                "    \n",
                "    for changeset_file in changeset.files:\n",
                "        try:\n",
                "            review = self.review_changeset_file(session, changeset_file)\n",
                "            reviews[changeset_file.file_path] = review\n",
                "            successful_reviews += 1\n",
                "        except Exception as e:\n",
                "            logger.warning(f\"Skipping file {changeset_file.file_path} due to error: {str(e)}\")\n",
                "            failed_reviews += 1\n",
                "            \n",
                "    total_duration = time.time() - changeset_start_time\n",
                "    logger.info(f\"Changeset review completed in {total_duration:.2f} seconds. \"\n",
                "               f\"Success: {successful_reviews}, Failed: {failed_reviews}\")\n",
                "```\n",
                "\n",
                "  * `changeset.files` is a list of all the files that were changed.\n",
                "  * For each file, the engine calls `review_changeset_file`, which does everything we just covered.\n",
                "  * The results are stored in a dictionary called `reviews`, with the file path as the key.\n",
                "  * The engine tracks and logs success/failure statistics for the entire changeset.\n",
                "\n",
                "### Step 2: Returning All Reviews\n",
                "\n",
                "After all files are reviewed, the engine returns the results.\n",
                "\n",
                "```python\n",
                "    return reviews\n",
                "```\n",
                "\n",
                "**Example Output:**\n",
                "\n",
                "```\n",
                "INFO: Starting changeset review for 2 files\n",
                "INFO: Starting review for file: example.py\n",
                "DEBUG: Gathered context for example.py: 2 recent changes, 2 related files\n",
                "INFO: Successfully reviewed example.py in 3.42 seconds\n",
                "INFO: Starting review for file: utils.py\n",
                "DEBUG: Gathered context for utils.py: 1 recent changes, 1 related files\n",
                "INFO: Successfully reviewed utils.py in 2.15 seconds\n",
                "INFO: Changeset review completed in 5.73 seconds. Success: 2, Failed: 0\n",
                "```\n",
                "\n",
                "Review for `example.py`:\n",
                "`Review for example.py with context: Recent changes: abc12345: Initial commit; def67890: Refactor code | Related files: utils.py, helpers.py`\n",
                "\n",
                "Review for `utils.py`:\n",
                "`Review for utils.py with context: Recent changes: abc12345: Initial commit | Related files: example.py`\n",
                "\n",
                "This shows that each file in the changeset has been reviewed, the results are organized by file, and comprehensive logging tracks the entire process.\n",
                "\n",
                "-----\n",
                "\n",
                "## Optimizing for Large Changesets: Batching and Parallelization\n",
                "\n",
                "The sequential approach shown above works well for small changesets, but for large changesets with many files, reviewing them one by one can be slow. Here are strategies to improve performance:\n",
                "\n",
                "### Batching Strategy\n",
                "\n",
                "Instead of reviewing files individually, you can group them into **batches** and send multiple files to the AI in a single request:\n",
                "\n",
                "```python\n",
                "def review_changeset_batch(self, session, changeset, batch_size=5):\n",
                "    files = changeset.files\n",
                "    reviews = {}\n",
                "    \n",
                "    # Group files into batches\n",
                "    for i in range(0, len(files), batch_size):\n",
                "        batch = files[i:i + batch_size]\n",
                "        batch_contexts = []\n",
                "        \n",
                "        for changeset_file in batch:\n",
                "            # Gather context for each file in the batch\n",
                "            diff = parse_unified_diff(changeset_file.diff_content)\n",
                "            context = self.build_file_context(session, diff.file_path)\n",
                "            \n",
                "            batch_contexts.append({\n",
                "                'file_path': diff.file_path,\n",
                "                'diff': changeset_file.diff_content,\n",
                "                'context': context\n",
                "            })\n",
                "            \n",
                "        # Send entire batch to AI for review\n",
                "        batch_reviews = self.llm_client.analyze_changeset_batch(batch_contexts)\n",
                "        \n",
                "        # Add batch results to overall reviews\n",
                "        for file_review in batch_reviews:\n",
                "            reviews[file_review['file_path']] = file_review['review']\n",
                "            \n",
                "    return reviews\n",
                "```\n",
                "\n",
                "### Parallelization Strategy\n",
                "\n",
                "For even better performance, you can review multiple files or batches concurrently:\n",
                "\n",
                "```python\n",
                "import concurrent.futures\n",
                "import threading\n",
                "\n",
                "def review_changeset_parallel(self, session, changeset, max_workers=3):\n",
                "    reviews = {}\n",
                "    reviews_lock = threading.Lock()\n",
                "    \n",
                "    def review_single_file(changeset_file):\n",
                "        try:\n",
                "            review = self.review_changeset_file(session, changeset_file)\n",
                "            with reviews_lock:\n",
                "                reviews[changeset_file.file_path] = review\n",
                "            return True\n",
                "        except Exception as e:\n",
                "            logger.warning(f\"Failed to review {changeset_file.file_path}: {str(e)}\")\n",
                "            return False\n",
                "            \n",
                "    # Process files in parallel\n",
                "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
                "        futures = [executor.submit(review_single_file, f) for f in changeset.files]\n",
                "        \n",
                "        # Wait for all reviews to complete\n",
                "        concurrent.futures.wait(futures)\n",
                "        \n",
                "    return reviews\n",
                "```\n",
                "\n",
                "### Trade-offs and Considerations\n",
                "\n",
                "| Strategy | Benefit | Drawback / Consideration |\n",
                "| :--- | :--- | :--- |\n",
                "| **Batching** | Reduces API calls. | May hit **token limits** with very large batches. |\n",
                "| **Parallelization** | Faster processing. | Consumes more **API rate limits** simultaneously. |\n",
                "| **Sequential** | Simplest for debugging. | Slow for large changesets. |\n",
                "| **General** | | Large changesets require more **memory** to store all reviews. |\n",
                "| **General** | | Parallel processing makes **error handling** more complex. |\n",
                "\n",
                "**When to use each approach:**\n",
                "\n",
                "  * **Sequential:** Small changesets (\\< 10 files) or when debugging.\n",
                "  * **Batching:** Medium changesets (10-50 files) with token limit considerations.\n",
                "  * **Parallel:** Large changesets (\\> 50 files) when speed is critical and rate limits allow.\n",
                "\n",
                "-----\n",
                "\n",
                "## Production Logging Best Practices\n",
                "\n",
                "In a production Review Engine, proper logging is essential for monitoring, debugging, and performance optimization. Here are the key logging practices demonstrated above:\n",
                "\n",
                "### Log Levels and What to Include\n",
                "\n",
                "| Log Level | Purpose | What to Include |\n",
                "| :--- | :--- | :--- |\n",
                "| **INFO** | General process tracking. | Start/completion of reviews, timing, and success summaries. |\n",
                "| **DEBUG** | Detailed step-by-step information. | Detailed context information that helps with troubleshooting. |\n",
                "| **WARNING** | Non-fatal issues. | Non-fatal errors that allow the process to continue. |\n",
                "| **ERROR** | Critical failures. | Fatal errors that prevent a file from being reviewed. |\n",
                "\n",
                "### Key Metrics to Track\n",
                "\n",
                "  * **File path:** Always log which file is being processed.\n",
                "  * **Success/failure status:** Track whether each review completed successfully.\n",
                "  * **Timing:** Measure how long each operation takes.\n",
                "  * **Context statistics:** Log how much context was gathered (number of changes, related files).\n",
                "\n",
                "### Example Log Configuration\n",
                "\n",
                "```python\n",
                "import logging\n",
                "\n",
                "logging.basicConfig(\n",
                "    level=logging.INFO,\n",
                "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
                "    handlers=[\n",
                "        logging.FileHandler('review_engine.log'),\n",
                "        logging.StreamHandler()\n",
                "    ]\n",
                ")\n",
                "```\n",
                "\n",
                "This configuration ensures that all review activities are logged both to a file and to the console, making it easy to monitor the Review Engine in production.\n",
                "\n",
                "-----\n",
                "\n",
                "## Building and Using Context for Better Reviews\n",
                "\n",
                "The quality of the AI's review depends on the **context** you provide. Let's look at how the Review Engine builds and uses this context.\n",
                "\n",
                "### Example: Summarizing Recent Changes and Related Files\n",
                "\n",
                "Suppose you have a file called `example.py` that was recently changed. The Review Engine gathers:\n",
                "\n",
                "  * **The last two changes:**\n",
                "      * `abc12345`: Initial commit\n",
                "      * `def67890`: Refactor code\n",
                "  * **Related files:**\n",
                "      * `utils.py`\n",
                "      * `helpers.py`\n",
                "\n",
                "It combines this information into a single string:\n",
                "\n",
                "```python\n",
                "context = \"Recent changes: abc12345: Initial commit; def67890: Refactor code | Related files: utils.py, helpers.py\"\n",
                "```\n",
                "\n",
                "This context is then sent to the AI, helping it understand not just the current change, but also the history and connections to other files.\n",
                "\n",
                "**Why is this important?**\n",
                "By giving the AI more information, you help it make better suggestions and catch issues that might be missed if it only saw the code change by itself.\n",
                "\n",
                "-----\n",
                "\n",
                "## Summary and Practice Preview\n",
                "\n",
                "In this lesson, you learned how to build a Review Engine that brings together the OpenAI client, diff parser, and context generator to review code changes automatically. You saw how to:\n",
                "\n",
                "  * **Review a single file** by parsing its diff, gathering context, and generating a review.\n",
                "  * **Review an entire changeset** by looping through all changed files.\n",
                "  * **Build and use context summaries** to help the AI give better feedback.\n",
                "  * **Implement production-ready logging** to track file paths, success/failure status, and timing.\n",
                "  * **Optimize for large changesets** using batching and parallelization strategies.\n",
                "\n",
                "Next, you will get a chance to practice these ideas by working with code that reviews changesets using the Review Engine. This hands-on practice will help you solidify your understanding and prepare you to use AI-powered code review in real projects."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Building Context for Better Reviews\n",
                "\n",
                "Cosmo\n",
                "Just now\n",
                "Read message aloud\n",
                "Now that you've learned about the Review Engine's structure, let's put that knowledge into practice! In this exercise, you'll implement the context-building logic that helps the AI better understand code changes.\n",
                "\n",
                "You'll be working on the review_changeset_file method, which is a key part of providing useful context to the AI reviewer. The method already handles parsing diffs and gathering raw context data, but it needs your help to format this information properly.\n",
                "\n",
                "Your task is to complete the context-building section by:\n",
                "\n",
                "Creating a list to store different parts of the context\n",
                "Formatting recent changes into a readable summary with semicolon separators\n",
                "Adding related files as a comma-separated list\n",
                "Joining all context parts with a pipe separator\n",
                "This context-building is crucial because it helps the AI understand not just the current code changes, but also their history and relationships to other files, resulting in more accurate and helpful reviews.\n",
                "\n",
                "```python\n",
                "from typing import Dict\n",
                "from sqlalchemy.orm import Session\n",
                "\n",
                "# Dummy imports for demonstration; in a real course, these would be actual modules.\n",
                "# from llm_client import LLMClient\n",
                "# from diff_parser import parse_unified_diff\n",
                "# from context_generator import get_file_context, get_recent_changes, find_related_files\n",
                "# from models import ChangesetFile\n",
                "\n",
                "# Minimal stubs for demonstration and to make the code runnable\n",
                "class LLMClient:\n",
                "    def analyze_changeset(self, file_path: str, diff: str, context: str = \"\") -> str:\n",
                "        return f\"Review for {file_path} with context: {context}\"\n",
                "\n",
                "def parse_unified_diff(diff_content: str):\n",
                "    class DummyDiff:\n",
                "        file_path = \"example.py\"\n",
                "    return DummyDiff()\n",
                "\n",
                "def get_file_context(session, file_path):\n",
                "    return \"def foo():\\n    pass\"\n",
                "\n",
                "def get_recent_changes(session, file_path):\n",
                "    return [\n",
                "        {'hash': 'abc12345', 'message': 'Initial commit', 'author': 'Alice', 'date': '2024-06-01'},\n",
                "        {'hash': 'def67890', 'message': 'Refactor code', 'author': 'Bob', 'date': '2024-06-02'}\n",
                "    ]\n",
                "\n",
                "def find_related_files(session, file_path):\n",
                "    return [\"utils.py\", \"helpers.py\"]\n",
                "\n",
                "class ChangesetFile:\n",
                "    def __init__(self, diff_content, file_path=\"example.py\"):\n",
                "        self.diff_content = diff_content\n",
                "        self.file_path = file_path\n",
                "\n",
                "class Changeset:\n",
                "    def __init__(self, files):\n",
                "        self.files = files\n",
                "\n",
                "class ReviewEngine:\n",
                "    def __init__(self):\n",
                "        self.llm_client = LLMClient()\n",
                "    \n",
                "    def review_changeset_file(self, session: Session, changeset_file: ChangesetFile) -> str:\n",
                "        \"\"\"Review a single file in a changeset\"\"\"\n",
                "        # Parse the diff\n",
                "        diff = parse_unified_diff(changeset_file.diff_content)\n",
                "        \n",
                "        # Gather context\n",
                "        file_context = get_file_context(session, diff.file_path)\n",
                "        recent_changes = get_recent_changes(session, diff.file_path)\n",
                "        related_files = find_related_files(session, diff.file_path)\n",
                "        \n",
                "        # Build context summary\n",
                "        # TODO: Create an empty list to store context parts\n",
                "        \n",
                "        if recent_changes:\n",
                "            # TODO: Create a string that joins the hash and message of each recent change \n",
                "            # with a semicolon separator (limit to first 2 changes)\n",
                "            \n",
                "            # TODO: Add the recent changes summary to context_parts with \"Recent changes: \" prefix\n",
                "        \n",
                "        if related_files:\n",
                "            # TODO: Add related files as a comma-separated list to context_parts\n",
                "            # with \"Related files: \" prefix\n",
                "        \n",
                "        # TODO: Join all context parts with \" | \" separator\n",
                "        \n",
                "        # Generate review\n",
                "        return self.llm_client.analyze_changeset(\n",
                "            file_path=diff.file_path,\n",
                "            diff=changeset_file.diff_content,\n",
                "            context=context\n",
                "        )\n",
                "    \n",
                "    def review_full_changeset(self, session: Session, changeset_id: int) -> Dict[str, str]:\n",
                "        \"\"\"Review all files in a changeset\"\"\"\n",
                "        # from models import Changeset\n",
                "        # For demonstration, we'll create a dummy changeset\n",
                "        changeset = Changeset([\n",
                "            ChangesetFile(\"diff --git a/example.py b/example.py\\n@@ -1 +1,2 @@\\n+print('Hello')\", \"example.py\"),\n",
                "            ChangesetFile(\"diff --git a/utils.py b/utils.py\\n@@ -1 +1,2 @@\\n+def util(): pass\", \"utils.py\")\n",
                "        ])\n",
                "        \n",
                "        reviews = {}\n",
                "        for changeset_file in changeset.files:\n",
                "            review = self.review_changeset_file(session, changeset_file)\n",
                "            reviews[changeset_file.file_path] = review\n",
                "        \n",
                "        return reviews\n",
                "\n",
                "# Example usage (for demonstration purposes)\n",
                "if __name__ == \"__main__\":\n",
                "    engine = ReviewEngine()\n",
                "    # session would be a SQLAlchemy session in a real app; here we use None\n",
                "    reviews = engine.review_full_changeset(None, 1)\n",
                "    for file, review in reviews.items():\n",
                "        print(f\"Review for {file}:\\n{review}\\n\")\n",
                "```\n",
                "\n",
                "That's a great exercise\\! Implementing the context-building logic is key to getting high-quality reviews from the AI.\n",
                "\n",
                "Here is the completed `review_changeset_file` method with the context-building logic filled in:\n",
                "\n",
                "```python\n",
                "from typing import Dict\n",
                "from sqlalchemy.orm import Session\n",
                "\n",
                "# Dummy imports for demonstration; in a real course, these would be actual modules.\n",
                "# from llm_client import LLMClient\n",
                "# from diff_parser import parse_unified_diff\n",
                "# from context_generator import get_file_context, get_recent_changes, find_related_files\n",
                "# from models import ChangesetFile\n",
                "\n",
                "# Minimal stubs for demonstration and to make the code runnable\n",
                "class LLMClient:\n",
                "    def analyze_changeset(self, file_path: str, diff: str, context: str = \"\") -> str:\n",
                "        return f\"Review for {file_path} with context: {context}\"\n",
                "\n",
                "def parse_unified_diff(diff_content: str):\n",
                "    class DummyDiff:\n",
                "        file_path = \"example.py\"\n",
                "    return DummyDiff()\n",
                "\n",
                "def get_file_context(session, file_path):\n",
                "    return \"def foo():\\n    pass\"\n",
                "\n",
                "def get_recent_changes(session, file_path):\n",
                "    return [\n",
                "        {'hash': 'abc12345', 'message': 'Initial commit', 'author': 'Alice', 'date': '2024-06-01'},\n",
                "        {'hash': 'def67890', 'message': 'Refactor code', 'author': 'Bob', 'date': '2024-06-02'}\n",
                "    ]\n",
                "\n",
                "def find_related_files(session, file_path):\n",
                "    return [\"utils.py\", \"helpers.py\"]\n",
                "\n",
                "class ChangesetFile:\n",
                "    def __init__(self, diff_content, file_path=\"example.py\"):\n",
                "        self.diff_content = diff_content\n",
                "        self.file_path = file_path\n",
                "\n",
                "class Changeset:\n",
                "    def __init__(self, files):\n",
                "        self.files = files\n",
                "\n",
                "class ReviewEngine:\n",
                "    def __init__(self):\n",
                "        self.llm_client = LLMClient()\n",
                "    \n",
                "    def review_changeset_file(self, session: Session, changeset_file: ChangesetFile) -> str:\n",
                "        \"\"\"Review a single file in a changeset\"\"\"\n",
                "        # Parse the diff\n",
                "        diff = parse_unified_diff(changeset_file.diff_content)\n",
                "        \n",
                "        # Gather context\n",
                "        file_context = get_file_context(session, diff.file_path)\n",
                "        recent_changes = get_recent_changes(session, diff.file_path)\n",
                "        related_files = find_related_files(session, diff.file_path)\n",
                "        \n",
                "        # Build context summary\n",
                "        context_parts = []  # TODO: Create an empty list to store context parts\n",
                "        \n",
                "        if recent_changes:\n",
                "            # TODO: Create a string that joins the hash and message of each recent change \n",
                "            # with a semicolon separator (limit to first 2 changes)\n",
                "            recent_summary = \"; \".join([\n",
                "                f\"{change['hash']}: {change['message']}\" \n",
                "                for change in recent_changes[:2]\n",
                "            ])\n",
                "            \n",
                "            # TODO: Add the recent changes summary to context_parts with \"Recent changes: \" prefix\n",
                "            context_parts.append(f\"Recent changes: {recent_summary}\")\n",
                "        \n",
                "        if related_files:\n",
                "            # TODO: Add related files as a comma-separated list to context_parts\n",
                "            # with \"Related files: \" prefix\n",
                "            related_summary = \", \".join(related_files)\n",
                "            context_parts.append(f\"Related files: {related_summary}\")\n",
                "        \n",
                "        # TODO: Join all context parts with \" | \" separator\n",
                "        context = \" | \".join(context_parts)\n",
                "        \n",
                "        # Generate review\n",
                "        return self.llm_client.analyze_changeset(\n",
                "            file_path=diff.file_path,\n",
                "            diff=changeset_file.diff_content,\n",
                "            context=context\n",
                "        )\n",
                "    \n",
                "    def review_full_changeset(self, session: Session, changeset_id: int) -> Dict[str, str]:\n",
                "        \"\"\"Review all files in a changeset\"\"\"\n",
                "        # from models import Changeset\n",
                "        # For demonstration, we'll create a dummy changeset\n",
                "        changeset = Changeset([\n",
                "            ChangesetFile(\"diff --git a/example.py b/example.py\\n@@ -1 +1,2 @@\\n+print('Hello')\", \"example.py\"),\n",
                "            ChangesetFile(\"diff --git a/utils.py b/utils.py\\n@@ -1 +1,2 @@\\n+def util(): pass\", \"utils.py\")\n",
                "        ])\n",
                "        \n",
                "        reviews = {}\n",
                "        for changeset_file in changeset.files:\n",
                "            review = self.review_changeset_file(session, changeset_file)\n",
                "            reviews[changeset_file.file_path] = review\n",
                "        \n",
                "        return reviews\n",
                "\n",
                "# Example usage (for demonstration purposes)\n",
                "if __name__ == \"__main__\":\n",
                "    engine = ReviewEngine()\n",
                "    # session would be a SQLAlchemy session in a real app; here we use None\n",
                "    reviews = engine.review_full_changeset(None, 1)\n",
                "    for file, review in reviews.items():\n",
                "        print(f\"Review for {file}:\\n{review}\\n\")\n",
                "\n",
                "```\n",
                "\n",
                "### Example Output\n",
                "\n",
                "The output for `example.py` now shows the structured context:\n",
                "\n",
                "```\n",
                "Review for example.py:\n",
                "Review for example.py with context: Recent changes: abc12345: Initial commit; def67890: Refactor code | Related files: utils.py, helpers.py\n",
                "\n",
                "Review for utils.py:\n",
                "Review for utils.py with context: Recent changes: abc12345: Initial commit; def67890: Refactor code | Related files: utils.py, helpers.py\n",
                "```\n",
                "\n",
                "***Note:** Since the dummy functions `get_recent_changes` and `find_related_files` return the same data regardless of the file path, the context for both `example.py` and `utils.py` is identical in this demonstration.*\n",
                "\n",
                "### Explanation of Context Logic\n",
                "\n",
                "1.  **`context_parts = []`**: Initializes an empty list to conditionally build the context string.\n",
                "2.  **Recent Changes Formatting**:\n",
                "    ```python\n",
                "    recent_summary = \"; \".join([\n",
                "        f\"{change['hash']}: {change['message']}\" \n",
                "        for change in recent_changes[:2] # Limits to the first two changes\n",
                "    ])\n",
                "    context_parts.append(f\"Recent changes: {recent_summary}\")\n",
                "    ```\n",
                "    This uses a **list comprehension** to iterate over the first two recent changes (`[:2]`), formats each one as `hash: message`, and then joins them with a **semicolon and space (` ;  `)**.\n",
                "3.  **Related Files Formatting**:\n",
                "    ```python\n",
                "    related_summary = \", \".join(related_files)\n",
                "    context_parts.append(f\"Related files: {related_summary}\")\n",
                "    ```\n",
                "    This simply joins the list of file names with a **comma and space (` ,  `)**.\n",
                "4.  **Final Join**:\n",
                "    ```python\n",
                "    context = \" | \".join(context_parts)\n",
                "    ```\n",
                "    All collected context strings are combined with the **pipe separator (`|`)**, creating a clear, single string for the AI model."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Building Context for Better Reviews\n",
                "\n",
                "You've just learned how the Review Engine connects all the pieces we've studied so far! Now it's time to implement a key part of this system â€” the context-building logic that makes AI reviews more accurate.\n",
                "\n",
                "In this exercise, you'll complete the review_changeset_file method by adding code that formats context information in a way the AI can use effectively. The method already handles parsing diffs and gathering raw data but needs your help with the formatting.\n",
                "\n",
                "Your task is to:\n",
                "\n",
                "Create a list to store different parts of the context\n",
                "Format recent changes into a readable summary with semicolon separators\n",
                "Add related files as a comma-separated list\n",
                "Join all context parts with a pipe separator\n",
                "This context-building step is vital because it transforms raw data into structured information that helps the AI understand both the code changes and their broader context, leading to more insightful and helpful reviews.\n",
                "\n",
                "```python\n",
                "from typing import Dict\n",
                "from sqlalchemy.orm import Session\n",
                "\n",
                "# Dummy imports for demonstration; in a real course, these would be actual modules.\n",
                "# from llm_client import LLMClient\n",
                "# from diff_parser import parse_unified_diff\n",
                "# from context_generator import get_file_context, get_recent_changes, find_related_files\n",
                "# from models import ChangesetFile\n",
                "\n",
                "# Minimal stubs for demonstration and to make the code runnable\n",
                "class LLMClient:\n",
                "    def analyze_changeset(self, file_path: str, diff: str, context: str = \"\") -> str:\n",
                "        return f\"Review for {file_path} with context: {context}\"\n",
                "\n",
                "def parse_unified_diff(diff_content: str):\n",
                "    class DummyDiff:\n",
                "        file_path = \"example.py\"\n",
                "    return DummyDiff()\n",
                "\n",
                "def get_file_context(session, file_path):\n",
                "    return \"def foo():\\n    pass\"\n",
                "\n",
                "def get_recent_changes(session, file_path):\n",
                "    return [\n",
                "        {'hash': 'abc12345', 'message': 'Initial commit', 'author': 'Alice', 'date': '2024-06-01'},\n",
                "        {'hash': 'def67890', 'message': 'Refactor code', 'author': 'Bob', 'date': '2024-06-02'}\n",
                "    ]\n",
                "\n",
                "def find_related_files(session, file_path):\n",
                "    return [\"utils.py\", \"helpers.py\"]\n",
                "\n",
                "class ChangesetFile:\n",
                "    def __init__(self, diff_content, file_path=\"example.py\"):\n",
                "        self.diff_content = diff_content\n",
                "        self.file_path = file_path\n",
                "\n",
                "class Changeset:\n",
                "    def __init__(self, files):\n",
                "        self.files = files\n",
                "\n",
                "class ReviewEngine:\n",
                "    def __init__(self):\n",
                "        self.llm_client = LLMClient()\n",
                "    \n",
                "    def review_changeset_file(self, session: Session, changeset_file: ChangesetFile) -> str:\n",
                "        \"\"\"Review a single file in a changeset\"\"\"\n",
                "        # Parse the diff\n",
                "        diff = parse_unified_diff(changeset_file.diff_content)\n",
                "        \n",
                "        # Gather context\n",
                "        file_context = get_file_context(session, diff.file_path)\n",
                "        recent_changes = get_recent_changes(session, diff.file_path)\n",
                "        related_files = find_related_files(session, diff.file_path)\n",
                "        \n",
                "        # Build context summary\n",
                "        # TODO: Create an empty list to store context parts\n",
                "        \n",
                "        if recent_changes:\n",
                "            # TODO: Create a string that joins the hash and message of each recent change \n",
                "            # with a semicolon separator (limit to first 2 changes)\n",
                "            \n",
                "            # TODO: Add the recent changes summary to context_parts with \"Recent changes: \" prefix\n",
                "        \n",
                "        if related_files:\n",
                "            # TODO: Add related files as a comma-separated list to context_parts\n",
                "            # with \"Related files: \" prefix\n",
                "        \n",
                "        # TODO: Join all context parts with \" | \" separator\n",
                "        \n",
                "        # Generate review\n",
                "        return self.llm_client.analyze_changeset(\n",
                "            file_path=diff.file_path,\n",
                "            diff=changeset_file.diff_content,\n",
                "            context=context\n",
                "        )\n",
                "    \n",
                "    def review_full_changeset(self, session: Session, changeset_id: int) -> Dict[str, str]:\n",
                "        \"\"\"Review all files in a changeset\"\"\"\n",
                "        # from models import Changeset\n",
                "        # For demonstration, we'll create a dummy changeset\n",
                "        changeset = Changeset([\n",
                "            ChangesetFile(\"diff --git a/example.py b/example.py\\n@@ -1 +1,2 @@\\n+print('Hello')\", \"example.py\"),\n",
                "            ChangesetFile(\"diff --git a/utils.py b/utils.py\\n@@ -1 +1,2 @@\\n+def util(): pass\", \"utils.py\")\n",
                "        ])\n",
                "        \n",
                "        reviews = {}\n",
                "        for changeset_file in changeset.files:\n",
                "            review = self.review_changeset_file(session, changeset_file)\n",
                "            reviews[changeset_file.file_path] = review\n",
                "        \n",
                "        return reviews\n",
                "\n",
                "# Example usage (for demonstration purposes)\n",
                "if __name__ == \"__main__\":\n",
                "    engine = ReviewEngine()\n",
                "    # session would be a SQLAlchemy session in a real app; here we use None\n",
                "    reviews = engine.review_full_changeset(None, 1)\n",
                "    for file, review in reviews.items():\n",
                "        print(f\"Review for {file}:\\n{review}\\n\")\n",
                "\n",
                "```\n",
                "\n",
                "That's an excellent task\\! Getting the context formatting right is what transforms raw data into **actionable insights** for the AI.\n",
                "\n",
                "Here is the completed `review_changeset_file` method with the context-building logic implemented according to your requirements:\n",
                "\n",
                "```python\n",
                "from typing import Dict\n",
                "from sqlalchemy.orm import Session\n",
                "\n",
                "# Dummy imports for demonstration; in a real course, these would be actual modules.\n",
                "# from llm_client import LLMClient\n",
                "# from diff_parser import parse_unified_diff\n",
                "# from context_generator import get_file_context, get_recent_changes, find_related_files\n",
                "# from models import ChangesetFile\n",
                "\n",
                "# Minimal stubs for demonstration and to make the code runnable\n",
                "class LLMClient:\n",
                "    def analyze_changeset(self, file_path: str, diff: str, context: str = \"\") -> str:\n",
                "        return f\"Review for {file_path} with context: {context}\"\n",
                "\n",
                "def parse_unified_diff(diff_content: str):\n",
                "    class DummyDiff:\n",
                "        file_path = \"example.py\"\n",
                "    return DummyDiff()\n",
                "\n",
                "def get_file_context(session, file_path):\n",
                "    return \"def foo():\\n    pass\"\n",
                "\n",
                "def get_recent_changes(session, file_path):\n",
                "    return [\n",
                "        {'hash': 'abc12345', 'message': 'Initial commit', 'author': 'Alice', 'date': '2024-06-01'},\n",
                "        {'hash': 'def67890', 'message': 'Refactor code', 'author': 'Bob', 'date': '2024-06-02'}\n",
                "    ]\n",
                "\n",
                "def find_related_files(session, file_path):\n",
                "    return [\"utils.py\", \"helpers.py\"]\n",
                "\n",
                "class ChangesetFile:\n",
                "    def __init__(self, diff_content, file_path=\"example.py\"):\n",
                "        self.diff_content = diff_content\n",
                "        self.file_path = file_path\n",
                "\n",
                "class Changeset:\n",
                "    def __init__(self, files):\n",
                "        self.files = files\n",
                "\n",
                "class ReviewEngine:\n",
                "    def __init__(self):\n",
                "        self.llm_client = LLMClient()\n",
                "    \n",
                "    def review_changeset_file(self, session: Session, changeset_file: ChangesetFile) -> str:\n",
                "        \"\"\"Review a single file in a changeset\"\"\"\n",
                "        # Parse the diff\n",
                "        diff = parse_unified_diff(changeset_file.diff_content)\n",
                "        \n",
                "        # Gather context\n",
                "        file_context = get_file_context(session, diff.file_path)\n",
                "        recent_changes = get_recent_changes(session, diff.file_path)\n",
                "        related_files = find_related_files(session, diff.file_path)\n",
                "        \n",
                "        # Build context summary\n",
                "        context_parts = []  # Create an empty list to store context parts\n",
                "        \n",
                "        if recent_changes:\n",
                "            # Create a string that joins the hash and message of each recent change \n",
                "            # with a semicolon separator (limit to first 2 changes)\n",
                "            recent_summary = \"; \".join([\n",
                "                f\"{change['hash']}: {change['message']}\" \n",
                "                for change in recent_changes[:2]\n",
                "            ])\n",
                "            \n",
                "            # Add the recent changes summary to context_parts with \"Recent changes: \" prefix\n",
                "            context_parts.append(f\"Recent changes: {recent_summary}\")\n",
                "        \n",
                "        if related_files:\n",
                "            # Add related files as a comma-separated list to context_parts\n",
                "            # with \"Related files: \" prefix\n",
                "            related_summary = \", \".join(related_files)\n",
                "            context_parts.append(f\"Related files: {related_summary}\")\n",
                "        \n",
                "        # Join all context parts with \" | \" separator\n",
                "        context = \" | \".join(context_parts)\n",
                "        \n",
                "        # Generate review\n",
                "        return self.llm_client.analyze_changeset(\n",
                "            file_path=diff.file_path,\n",
                "            diff=changeset_file.diff_content,\n",
                "            context=context\n",
                "        )\n",
                "    \n",
                "    def review_full_changeset(self, session: Session, changeset_id: int) -> Dict[str, str]:\n",
                "        \"\"\"Review all files in a changeset\"\"\"\n",
                "        # from models import Changeset\n",
                "        # For demonstration, we'll create a dummy changeset\n",
                "        changeset = Changeset([\n",
                "            ChangesetFile(\"diff --git a/example.py b/example.py\\n@@ -1 +1,2 @@\\n+print('Hello')\", \"example.py\"),\n",
                "            ChangesetFile(\"diff --git a/utils.py b/utils.py\\n@@ -1 +1,2 @@\\n+def util(): pass\", \"utils.py\")\n",
                "        ])\n",
                "        \n",
                "        reviews = {}\n",
                "        for changeset_file in changeset.files:\n",
                "            review = self.review_changeset_file(session, changeset_file)\n",
                "            reviews[changeset_file.file_path] = review\n",
                "        \n",
                "        return reviews\n",
                "\n",
                "# Example usage (for demonstration purposes)\n",
                "if __name__ == \"__main__\":\n",
                "    engine = ReviewEngine()\n",
                "    # session would be a SQLAlchemy session in a real app; here we use None\n",
                "    reviews = engine.review_full_changeset(None, 1)\n",
                "    for file, review in reviews.items():\n",
                "        print(f\"Review for {file}:\\n{review}\\n\")\n",
                "```\n",
                "\n",
                "### Explanation of Implemented Logic\n",
                "\n",
                "1.  **Initialization:** `context_parts = []` creates the dynamic list to store parts of the context only if the relevant data exists.\n",
                "2.  **Recent Changes:**\n",
                "      * A **list comprehension** `[... for change in recent_changes[:2]]` is used to efficiently iterate over, format, and limit the history to the last two changes.\n",
                "      * `\"; \".join(...)` combines the hashes and messages into a clean summary using the required semicolon separator.\n",
                "3.  **Related Files:**\n",
                "      * `\", \".join(related_files)` quickly converts the list of file names into a comma-separated string.\n",
                "4.  **Final Assembly:** `context = \" | \".join(context_parts)` brings all the separate, prefixed parts together using the **pipe separator** (`|`), producing a concise and structured string that the AI model can easily parse and utilize.\n",
                "\n",
                "This structure successfully translates the raw context data into the high-quality input needed for the AI reviewer."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Fixing Context Format for Better Reviews\n",
                "\n",
                "Now that you've seen how the Review Engine connects all the pieces together, let's put your debugging skills to the test! In this exercise, you'll fix a broken implementation of the context-building logic in our Review Engine.\n",
                "\n",
                "The review_changeset_file method is supposed to format context information properly, but it contains several formatting bugs that could confuse the AI reviewer. Your job is to find and fix these issues.\n",
                "\n",
                "Look for three specific problems:\n",
                "\n",
                "Missing colons between commit hashes and messages\n",
                "An incorrect separator for the related files list\n",
                "The wrong separator for joining the final context parts\n",
                "These small formatting details might seem minor, but they significantly impact how well the AI understands the context of code changes. Fixing these issues will ensure our Review Engine provides the most helpful and accurate feedback possible.\n",
                "\n",
                "```python\n",
                "from typing import Dict\n",
                "from sqlalchemy.orm import Session\n",
                "\n",
                "# Dummy imports for demonstration; in a real course, these would be actual modules.\n",
                "# from llm_client import LLMClient\n",
                "# from diff_parser import parse_unified_diff\n",
                "# from context_generator import get_file_context, get_recent_changes, find_related_files\n",
                "# from models import ChangesetFile\n",
                "\n",
                "# Minimal stubs for demonstration and to make the code runnable\n",
                "class LLMClient:\n",
                "    def analyze_changeset(self, file_path: str, diff: str, context: str = \"\") -> str:\n",
                "        return f\"Review for {file_path} with context: {context}\"\n",
                "\n",
                "def parse_unified_diff(diff_content: str):\n",
                "    class DummyDiff:\n",
                "        file_path = \"example.py\"\n",
                "    return DummyDiff()\n",
                "\n",
                "def get_file_context(session, file_path):\n",
                "    return \"def foo():\\n    pass\"\n",
                "\n",
                "def get_recent_changes(session, file_path):\n",
                "    return [\n",
                "        {'hash': 'abc12345', 'message': 'Initial commit', 'author': 'Alice', 'date': '2024-06-01'},\n",
                "        {'hash': 'def67890', 'message': 'Refactor code', 'author': 'Bob', 'date': '2024-06-02'}\n",
                "    ]\n",
                "\n",
                "def find_related_files(session, file_path):\n",
                "    return [\"utils.py\", \"helpers.py\"]\n",
                "\n",
                "class ChangesetFile:\n",
                "    def __init__(self, diff_content, file_path=\"example.py\"):\n",
                "        self.diff_content = diff_content\n",
                "        self.file_path = file_path\n",
                "\n",
                "class Changeset:\n",
                "    def __init__(self, files):\n",
                "        self.files = files\n",
                "\n",
                "class ReviewEngine:\n",
                "    def __init__(self):\n",
                "        self.llm_client = LLMClient()\n",
                "    \n",
                "    def review_changeset_file(self, session: Session, changeset_file: ChangesetFile) -> str:\n",
                "        \"\"\"Review a single file in a changeset\"\"\"\n",
                "        # Parse the diff\n",
                "        diff = parse_unified_diff(changeset_file.diff_content)\n",
                "        \n",
                "        # Gather context\n",
                "        file_context = get_file_context(session, diff.file_path)\n",
                "        recent_changes = get_recent_changes(session, diff.file_path)\n",
                "        related_files = find_related_files(session, diff.file_path)\n",
                "        \n",
                "        # Build context summary\n",
                "        context_parts = []\n",
                "        \n",
                "        if recent_changes:\n",
                "            recent_summary = \"; \".join([\n",
                "                f\"{change['hash']} {change['message']}\" \n",
                "                for change in recent_changes[:2]\n",
                "            ])\n",
                "            context_parts.append(f\"Recent changes: {recent_summary}\")\n",
                "        \n",
                "        if related_files:\n",
                "            context_parts.append(f\"Related files: {'; '.join(related_files)}\")\n",
                "        \n",
                "        context = \", \".join(context_parts)\n",
                "        \n",
                "        # Generate review\n",
                "        return self.llm_client.analyze_changeset(\n",
                "            file_path=diff.file_path,\n",
                "            diff=changeset_file.diff_content,\n",
                "            context=context\n",
                "        )\n",
                "    \n",
                "    def review_full_changeset(self, session: Session, changeset_id: int) -> Dict[str, str]:\n",
                "        \"\"\"Review all files in a changeset\"\"\"\n",
                "        # from models import Changeset\n",
                "        # For demonstration, we'll create a dummy changeset\n",
                "        changeset = Changeset([\n",
                "            ChangesetFile(\"diff --git a/example.py b/example.py\\n@@ -1 +1,2 @@\\n+print('Hello')\", \"example.py\"),\n",
                "            ChangesetFile(\"diff --git a/utils.py b/utils.py\\n@@ -1 +1,2 @@\\n+def util(): pass\", \"utils.py\")\n",
                "        ])\n",
                "        \n",
                "        reviews = {}\n",
                "        for changeset_file in changeset.files:\n",
                "            review = self.review_changeset_file(session, changeset_file)\n",
                "            reviews[changeset_file.file_path] = review\n",
                "        \n",
                "        return reviews\n",
                "\n",
                "# Example usage (for demonstration purposes)\n",
                "if __name__ == \"__main__\":\n",
                "    engine = ReviewEngine()\n",
                "    # session would be a SQLAlchemy session in a real app; here we use None\n",
                "    reviews = engine.review_full_changeset(None, 1)\n",
                "    for file, review in reviews.items():\n",
                "        print(f\"Review for {file}:\\n{review}\\n\")\n",
                "\n",
                "```\n",
                "\n",
                "That's a great task\\! Fixing small formatting bugs like these is crucial for maintaining effective communication with the AI.\n",
                "\n",
                "I've located and fixed the three specified issues in the `review_changeset_file` method.\n",
                "\n",
                "### Fixed Code\n",
                "\n",
                "```python\n",
                "from typing import Dict\n",
                "from sqlalchemy.orm import Session\n",
                "\n",
                "# Dummy imports for demonstration; in a real course, these would be actual modules.\n",
                "# from llm_client import LLMClient\n",
                "# from diff_parser import parse_unified_diff\n",
                "# from context_generator import get_file_context, get_recent_changes, find_related_files\n",
                "# from models import ChangesetFile\n",
                "\n",
                "# Minimal stubs for demonstration and to make the code runnable\n",
                "class LLMClient:\n",
                "    def analyze_changeset(self, file_path: str, diff: str, context: str = \"\") -> str:\n",
                "        return f\"Review for {file_path} with context: {context}\"\n",
                "\n",
                "def parse_unified_diff(diff_content: str):\n",
                "    class DummyDiff:\n",
                "        file_path = \"example.py\"\n",
                "    return DummyDiff()\n",
                "\n",
                "def get_file_context(session, file_path):\n",
                "    return \"def foo():\\n    pass\"\n",
                "\n",
                "def get_recent_changes(session, file_path):\n",
                "    return [\n",
                "        {'hash': 'abc12345', 'message': 'Initial commit', 'author': 'Alice', 'date': '2024-06-01'},\n",
                "        {'hash': 'def67890', 'message': 'Refactor code', 'author': 'Bob', 'date': '2024-06-02'}\n",
                "    ]\n",
                "\n",
                "def find_related_files(session, file_path):\n",
                "    return [\"utils.py\", \"helpers.py\"]\n",
                "\n",
                "class ChangesetFile:\n",
                "    def __init__(self, diff_content, file_path=\"example.py\"):\n",
                "        self.diff_content = diff_content\n",
                "        self.file_path = file_path\n",
                "\n",
                "class Changeset:\n",
                "    def __init__(self, files):\n",
                "        self.files = files\n",
                "\n",
                "class ReviewEngine:\n",
                "    def __init__(self):\n",
                "        self.llm_client = LLMClient()\n",
                "    \n",
                "    def review_changeset_file(self, session: Session, changeset_file: ChangesetFile) -> str:\n",
                "        \"\"\"Review a single file in a changeset\"\"\"\n",
                "        # Parse the diff\n",
                "        diff = parse_unified_diff(changeset_file.diff_content)\n",
                "        \n",
                "        # Gather context\n",
                "        file_context = get_file_context(session, diff.file_path)\n",
                "        recent_changes = get_recent_changes(session, diff.file_path)\n",
                "        related_files = find_related_files(session, diff.file_path)\n",
                "        \n",
                "        # Build context summary\n",
                "        context_parts = []\n",
                "        \n",
                "        if recent_changes:\n",
                "            # FIX 1: Added ':' between hash and message\n",
                "            recent_summary = \"; \".join([\n",
                "                f\"{change['hash']}: {change['message']}\" \n",
                "                for change in recent_changes[:2]\n",
                "            ])\n",
                "            context_parts.append(f\"Recent changes: {recent_summary}\")\n",
                "        \n",
                "        if related_files:\n",
                "            # FIX 2: Changed separator from '; ' to ', ' for related files list\n",
                "            context_parts.append(f\"Related files: {', '.join(related_files)}\")\n",
                "        \n",
                "        # FIX 3: Changed separator from ', ' to ' | ' for joining final context parts\n",
                "        context = \" | \".join(context_parts)\n",
                "        \n",
                "        # Generate review\n",
                "        return self.llm_client.analyze_changeset(\n",
                "            file_path=diff.file_path,\n",
                "            diff=changeset_file.diff_content,\n",
                "            context=context\n",
                "        )\n",
                "    \n",
                "    def review_full_changeset(self, session: Session, changeset_id: int) -> Dict[str, str]:\n",
                "        \"\"\"Review all files in a changeset\"\"\"\n",
                "        # from models import Changeset\n",
                "        # For demonstration, we'll create a dummy changeset\n",
                "        changeset = Changeset([\n",
                "            ChangesetFile(\"diff --git a/example.py b/example.py\\n@@ -1 +1,2 @@\\n+print('Hello')\", \"example.py\"),\n",
                "            ChangesetFile(\"diff --git a/utils.py b/utils.py\\n@@ -1 +1,2 @@\\n+def util(): pass\", \"utils.py\")\n",
                "        ])\n",
                "        \n",
                "        reviews = {}\n",
                "        for changeset_file in changeset.files:\n",
                "            review = self.review_changeset_file(session, changeset_file)\n",
                "            reviews[changeset_file.file_path] = review\n",
                "        \n",
                "        return reviews\n",
                "\n",
                "# Example usage (for demonstration purposes)\n",
                "if __name__ == \"__main__\":\n",
                "    engine = ReviewEngine()\n",
                "    # session would be a SQLAlchemy session in a real app; here we use None\n",
                "    reviews = engine.review_full_changeset(None, 1)\n",
                "    for file, review in reviews.items():\n",
                "        print(f\"Review for {file}:\\n{review}\\n\")\n",
                "```\n",
                "\n",
                "-----\n",
                "\n",
                "## Summary of Fixes\n",
                "\n",
                "The formatting issues were resolved as follows:\n",
                "\n",
                "1.  **Missing Colons in Recent Changes (Fix 1):**\n",
                "\n",
                "      * **Old Code:** `f\"{change['hash']} {change['message']}\"` (Output: `abc12345 Initial commit`)\n",
                "      * **New Code:** `f\"{change['hash']}: {change['message']}\"` (Output: `abc12345: Initial commit`)\n",
                "      * **Rationale:** The colon is a standard delimiter that clearly separates the commit ID from the message, making the context easier for the AI to parse.\n",
                "\n",
                "2.  **Incorrect Separator for Related Files (Fix 2):**\n",
                "\n",
                "      * **Old Code:** `'; '.join(related_files)` (Output: `utils.py; helpers.py`)\n",
                "      * **New Code:** `', '.join(related_files)` (Output: `utils.py, helpers.py`)\n",
                "      * **Rationale:** Related files are typically presented as a **comma-separated list** for readability, distinguishing them from the semicolon-separated commit summaries.\n",
                "\n",
                "3.  **Wrong Final Context Separator (Fix 3):**\n",
                "\n",
                "      * **Old Code:** `context = \", \".join(context_parts)` (Output: `Recent changes:... , Related files:...`)\n",
                "      * **New Code:** `context = \" | \".join(context_parts)` (Output: `Recent changes:... | Related files:...`)\n",
                "      * **Rationale:** Using the **pipe separator (`|`)** provides a strong, clear break between the main context categories (`Recent changes` and `Related files`), ensuring the AI doesn't mistake them for a single sentence.\n",
                "\n",
                "The final, corrected context format is now:\n",
                "`Recent changes: abc12345: Initial commit; def67890: Refactor code | Related files: utils.py, helpers.py`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Scaling Up The Review Engine\n",
                "\n",
                "Now that you've mastered the context-building part of our Review Engine, let's scale things up! In this exercise, you'll implement the review_full_changeset method, which processes an entire set of code changes at once.\n",
                "\n",
                "You've already seen how the Review Engine handles individual files. Your job now is to write the code that orchestrates the review of multiple files in a changeset. The method signature and changeset creation are already set up for you.\n",
                "\n",
                "Your task is to:\n",
                "\n",
                "Initialize an empty dictionary to store review results\n",
                "Loop through each file in the changeset\n",
                "Call the review_changeset_file method for each file\n",
                "Store each review result in the dictionary using the file path as the key\n",
                "Return the completed dictionary\n",
                "This orchestration logic is what makes a Review Engine truly powerful â€” allowing it to analyze complex changesets with multiple files and provide organized feedback. Implementing this feature will complete your understanding of how all the pieces work together in a full code review system.\n",
                "\n",
                "```python\n",
                "from typing import Dict\n",
                "from sqlalchemy.orm import Session\n",
                "\n",
                "# Dummy imports for demonstration; in a real course, these would be actual modules.\n",
                "# from llm_client import LLMClient\n",
                "# from diff_parser import parse_unified_diff\n",
                "# from context_generator import get_file_context, get_recent_changes, find_related_files\n",
                "# from models import ChangesetFile\n",
                "\n",
                "# Minimal stubs for demonstration and to make the code runnable\n",
                "class LLMClient:\n",
                "    def analyze_changeset(self, file_path: str, diff: str, context: str = \"\") -> str:\n",
                "        return f\"Review for {file_path} with context: {context}\"\n",
                "\n",
                "def parse_unified_diff(diff_content: str):\n",
                "    class DummyDiff:\n",
                "        file_path = \"example.py\"\n",
                "    return DummyDiff()\n",
                "\n",
                "def get_file_context(session, file_path):\n",
                "    return \"def foo():\\n    pass\"\n",
                "\n",
                "def get_recent_changes(session, file_path):\n",
                "    return [\n",
                "        {'hash': 'abc12345', 'message': 'Initial commit', 'author': 'Alice', 'date': '2024-06-01'},\n",
                "        {'hash': 'def67890', 'message': 'Refactor code', 'author': 'Bob', 'date': '2024-06-02'}\n",
                "    ]\n",
                "\n",
                "def find_related_files(session, file_path):\n",
                "    return [\"utils.py\", \"helpers.py\"]\n",
                "\n",
                "class ChangesetFile:\n",
                "    def __init__(self, diff_content, file_path=\"example.py\"):\n",
                "        self.diff_content = diff_content\n",
                "        self.file_path = file_path\n",
                "\n",
                "class Changeset:\n",
                "    def __init__(self, files):\n",
                "        self.files = files\n",
                "\n",
                "class ReviewEngine:\n",
                "    def __init__(self):\n",
                "        self.llm_client = LLMClient()\n",
                "    \n",
                "    def review_changeset_file(self, session: Session, changeset_file: ChangesetFile) -> str:\n",
                "        \"\"\"Review a single file in a changeset\"\"\"\n",
                "        # Parse the diff\n",
                "        diff = parse_unified_diff(changeset_file.diff_content)\n",
                "        \n",
                "        # Gather context\n",
                "        file_context = get_file_context(session, diff.file_path)\n",
                "        recent_changes = get_recent_changes(session, diff.file_path)\n",
                "        related_files = find_related_files(session, diff.file_path)\n",
                "        \n",
                "        # Build context summary\n",
                "        context_parts = []\n",
                "        \n",
                "        if recent_changes:\n",
                "            recent_summary = \"; \".join([\n",
                "                f\"{change['hash']}: {change['message']}\" \n",
                "                for change in recent_changes[:2]\n",
                "            ])\n",
                "            context_parts.append(f\"Recent changes: {recent_summary}\")\n",
                "        \n",
                "        if related_files:\n",
                "            context_parts.append(f\"Related files: {', '.join(related_files)}\")\n",
                "        \n",
                "        context = \" | \".join(context_parts)\n",
                "        \n",
                "        # Generate review\n",
                "        return self.llm_client.analyze_changeset(\n",
                "            file_path=diff.file_path,\n",
                "            diff=changeset_file.diff_content,\n",
                "            context=context\n",
                "        )\n",
                "    \n",
                "    def review_full_changeset(self, session: Session, changeset_id: int) -> Dict[str, str]:\n",
                "        \"\"\"Review all files in a changeset\"\"\"\n",
                "        # from models import Changeset\n",
                "        # For demonstration, we'll create a dummy changeset\n",
                "        changeset = Changeset([\n",
                "            ChangesetFile(\"diff --git a/example.py b/example.py\\n@@ -1 +1,2 @@\\n+print('Hello')\", \"example.py\"),\n",
                "            ChangesetFile(\"diff --git a/utils.py b/utils.py\\n@@ -1 +1,2 @@\\n+def util(): pass\", \"utils.py\")\n",
                "        ])\n",
                "        \n",
                "        # TODO: Initialize an empty dictionary to store review results\n",
                "        \n",
                "        # TODO: Loop through each file in the changeset\n",
                "        \n",
                "            # TODO: Call review_changeset_file for each file and store the result\n",
                "        \n",
                "        # TODO: Return the completed reviews dictionary\n",
                "\n",
                "# Example usage (for demonstration purposes)\n",
                "if __name__ == \"__main__\":\n",
                "    engine = ReviewEngine()\n",
                "    # session would be a SQLAlchemy session in a real app; here we use None\n",
                "    reviews = engine.review_full_changeset(None, 1)\n",
                "    for file, review in reviews.items():\n",
                "        print(f\"Review for {file}:\\n{review}\\n\")\n",
                "```\n",
                "\n",
                "That's the final piece of the sequential Review Engine puzzle\\! Orchestrating the file-by-file review is exactly how you scale up from a single change to a full changeset analysis.\n",
                "\n",
                "Here is the completed `review_full_changeset` method:\n",
                "\n",
                "```python\n",
                "from typing import Dict\n",
                "from sqlalchemy.orm import Session\n",
                "\n",
                "# Dummy imports for demonstration; in a real course, these would be actual modules.\n",
                "# from llm_client import LLMClient\n",
                "# from diff_parser import parse_unified_diff\n",
                "# from context_generator import get_file_context, get_recent_changes, find_related_files\n",
                "# from models import ChangesetFile\n",
                "\n",
                "# Minimal stubs for demonstration and to make the code runnable\n",
                "class LLMClient:\n",
                "    def analyze_changeset(self, file_path: str, diff: str, context: str = \"\") -> str:\n",
                "        return f\"Review for {file_path} with context: {context}\"\n",
                "\n",
                "def parse_unified_diff(diff_content: str):\n",
                "    class DummyDiff:\n",
                "        file_path = \"example.py\"\n",
                "    return DummyDiff()\n",
                "\n",
                "def get_file_context(session, file_path):\n",
                "    return \"def foo():\\n    pass\"\n",
                "\n",
                "def get_recent_changes(session, file_path):\n",
                "    return [\n",
                "        {'hash': 'abc12345', 'message': 'Initial commit', 'author': 'Alice', 'date': '2024-06-01'},\n",
                "        {'hash': 'def67890', 'message': 'Refactor code', 'author': 'Bob', 'date': '2024-06-02'}\n",
                "    ]\n",
                "\n",
                "def find_related_files(session, file_path):\n",
                "    return [\"utils.py\", \"helpers.py\"]\n",
                "\n",
                "class ChangesetFile:\n",
                "    def __init__(self, diff_content, file_path=\"example.py\"):\n",
                "        self.diff_content = diff_content\n",
                "        self.file_path = file_path\n",
                "\n",
                "class Changeset:\n",
                "    def __init__(self, files):\n",
                "        self.files = files\n",
                "\n",
                "class ReviewEngine:\n",
                "    def __init__(self):\n",
                "        self.llm_client = LLMClient()\n",
                "    \n",
                "    def review_changeset_file(self, session: Session, changeset_file: ChangesetFile) -> str:\n",
                "        \"\"\"Review a single file in a changeset\"\"\"\n",
                "        # Parse the diff\n",
                "        diff = parse_unified_diff(changeset_file.diff_content)\n",
                "        \n",
                "        # Gather context\n",
                "        file_context = get_file_context(session, diff.file_path)\n",
                "        recent_changes = get_recent_changes(session, diff.file_path)\n",
                "        related_files = find_related_files(session, diff.file_path)\n",
                "        \n",
                "        # Build context summary\n",
                "        context_parts = []\n",
                "        \n",
                "        if recent_changes:\n",
                "            recent_summary = \"; \".join([\n",
                "                f\"{change['hash']}: {change['message']}\" \n",
                "                for change in recent_changes[:2]\n",
                "            ])\n",
                "            context_parts.append(f\"Recent changes: {recent_summary}\")\n",
                "        \n",
                "        if related_files:\n",
                "            context_parts.append(f\"Related files: {', '.join(related_files)}\")\n",
                "        \n",
                "        context = \" | \".join(context_parts)\n",
                "        \n",
                "        # Generate review\n",
                "        return self.llm_client.analyze_changeset(\n",
                "            file_path=diff.file_path,\n",
                "            diff=changeset_file.diff_content,\n",
                "            context=context\n",
                "        )\n",
                "    \n",
                "    def review_full_changeset(self, session: Session, changeset_id: int) -> Dict[str, str]:\n",
                "        \"\"\"Review all files in a changeset\"\"\"\n",
                "        # from models import Changeset\n",
                "        # For demonstration, we'll create a dummy changeset\n",
                "        changeset = Changeset([\n",
                "            ChangesetFile(\"diff --git a/example.py b/example.py\\n@@ -1 +1,2 @@\\n+print('Hello')\", \"example.py\"),\n",
                "            ChangesetFile(\"diff --git a/utils.py b/utils.py\\n@@ -1 +1,2 @@\\n+def util(): pass\", \"utils.py\")\n",
                "        ])\n",
                "        \n",
                "        reviews = {} # Initialize an empty dictionary to store review results\n",
                "        \n",
                "        for changeset_file in changeset.files: # Loop through each file in the changeset\n",
                "            # Call review_changeset_file for each file and store the result\n",
                "            review = self.review_changeset_file(session, changeset_file)\n",
                "            reviews[changeset_file.file_path] = review\n",
                "        \n",
                "        return reviews # Return the completed reviews dictionary\n",
                "\n",
                "# Example usage (for demonstration purposes)\n",
                "if __name__ == \"__main__\":\n",
                "    engine = ReviewEngine()\n",
                "    # session would be a SQLAlchemy session in a real app; here we use None\n",
                "    reviews = engine.review_full_changeset(None, 1)\n",
                "    for file, review in reviews.items():\n",
                "        print(f\"Review for {file}:\\n{review}\\n\")\n",
                "```\n",
                "\n",
                "### Example Output\n",
                "\n",
                "The output now shows a review for **both** files in the dummy changeset, proving the orchestration logic works:\n",
                "\n",
                "```\n",
                "Review for example.py:\n",
                "Review for example.py with context: Recent changes: abc12345: Initial commit; def67890: Refactor code | Related files: utils.py, helpers.py\n",
                "\n",
                "Review for utils.py:\n",
                "Review for utils.py with context: Recent changes: abc12345: Initial commit; def67890: Refactor code | Related files: utils.py, helpers.py\n",
                "```\n",
                "\n",
                "That's the final piece of the sequential Review Engine puzzle\\! Orchestrating the file-by-file review is exactly how you scale up from a single change to a full changeset analysis.\n",
                "\n",
                "Here is the completed `review_full_changeset` method:\n",
                "\n",
                "```python\n",
                "from typing import Dict\n",
                "from sqlalchemy.orm import Session\n",
                "\n",
                "# Dummy imports for demonstration; in a real course, these would be actual modules.\n",
                "# from llm_client import LLMClient\n",
                "# from diff_parser import parse_unified_diff\n",
                "# from context_generator import get_file_context, get_recent_changes, find_related_files\n",
                "# from models import ChangesetFile\n",
                "\n",
                "# Minimal stubs for demonstration and to make the code runnable\n",
                "class LLMClient:\n",
                "    def analyze_changeset(self, file_path: str, diff: str, context: str = \"\") -> str:\n",
                "        return f\"Review for {file_path} with context: {context}\"\n",
                "\n",
                "def parse_unified_diff(diff_content: str):\n",
                "    class DummyDiff:\n",
                "        file_path = \"example.py\"\n",
                "    return DummyDiff()\n",
                "\n",
                "def get_file_context(session, file_path):\n",
                "    return \"def foo():\\n    pass\"\n",
                "\n",
                "def get_recent_changes(session, file_path):\n",
                "    return [\n",
                "        {'hash': 'abc12345', 'message': 'Initial commit', 'author': 'Alice', 'date': '2024-06-01'},\n",
                "        {'hash': 'def67890', 'message': 'Refactor code', 'author': 'Bob', 'date': '2024-06-02'}\n",
                "    ]\n",
                "\n",
                "def find_related_files(session, file_path):\n",
                "    return [\"utils.py\", \"helpers.py\"]\n",
                "\n",
                "class ChangesetFile:\n",
                "    def __init__(self, diff_content, file_path=\"example.py\"):\n",
                "        self.diff_content = diff_content\n",
                "        self.file_path = file_path\n",
                "\n",
                "class Changeset:\n",
                "    def __init__(self, files):\n",
                "        self.files = files\n",
                "\n",
                "class ReviewEngine:\n",
                "    def __init__(self):\n",
                "        self.llm_client = LLMClient()\n",
                "    \n",
                "    def review_changeset_file(self, session: Session, changeset_file: ChangesetFile) -> str:\n",
                "        \"\"\"Review a single file in a changeset\"\"\"\n",
                "        # Parse the diff\n",
                "        diff = parse_unified_diff(changeset_file.diff_content)\n",
                "        \n",
                "        # Gather context\n",
                "        file_context = get_file_context(session, diff.file_path)\n",
                "        recent_changes = get_recent_changes(session, diff.file_path)\n",
                "        related_files = find_related_files(session, diff.file_path)\n",
                "        \n",
                "        # Build context summary\n",
                "        context_parts = []\n",
                "        \n",
                "        if recent_changes:\n",
                "            recent_summary = \"; \".join([\n",
                "                f\"{change['hash']}: {change['message']}\" \n",
                "                for change in recent_changes[:2]\n",
                "            ])\n",
                "            context_parts.append(f\"Recent changes: {recent_summary}\")\n",
                "        \n",
                "        if related_files:\n",
                "            context_parts.append(f\"Related files: {', '.join(related_files)}\")\n",
                "        \n",
                "        context = \" | \".join(context_parts)\n",
                "        \n",
                "        # Generate review\n",
                "        return self.llm_client.analyze_changeset(\n",
                "            file_path=diff.file_path,\n",
                "            diff=changeset_file.diff_content,\n",
                "            context=context\n",
                "        )\n",
                "    \n",
                "    def review_full_changeset(self, session: Session, changeset_id: int) -> Dict[str, str]:\n",
                "        \"\"\"Review all files in a changeset\"\"\"\n",
                "        # from models import Changeset\n",
                "        # For demonstration, we'll create a dummy changeset\n",
                "        changeset = Changeset([\n",
                "            ChangesetFile(\"diff --git a/example.py b/example.py\\n@@ -1 +1,2 @@\\n+print('Hello')\", \"example.py\"),\n",
                "            ChangesetFile(\"diff --git a/utils.py b/utils.py\\n@@ -1 +1,2 @@\\n+def util(): pass\", \"utils.py\")\n",
                "        ])\n",
                "        \n",
                "        reviews = {} # Initialize an empty dictionary to store review results\n",
                "        \n",
                "        for changeset_file in changeset.files: # Loop through each file in the changeset\n",
                "            # Call review_changeset_file for each file and store the result\n",
                "            review = self.review_changeset_file(session, changeset_file)\n",
                "            reviews[changeset_file.file_path] = review\n",
                "        \n",
                "        return reviews # Return the completed reviews dictionary\n",
                "\n",
                "# Example usage (for demonstration purposes)\n",
                "if __name__ == \"__main__\":\n",
                "    engine = ReviewEngine()\n",
                "    # session would be a SQLAlchemy session in a real app; here we use None\n",
                "    reviews = engine.review_full_changeset(None, 1)\n",
                "    for file, review in reviews.items():\n",
                "        print(f\"Review for {file}:\\n{review}\\n\")\n",
                "```\n",
                "\n",
                "### Example Output\n",
                "\n",
                "The output now shows a review for **both** files in the dummy changeset, proving the orchestration logic works:\n",
                "\n",
                "```\n",
                "Review for example.py:\n",
                "Review for example.py with context: Recent changes: abc12345: Initial commit; def67890: Refactor code | Related files: utils.py, helpers.py\n",
                "\n",
                "Review for utils.py:\n",
                "Review for utils.py with context: Recent changes: abc12345: Initial commit; def67890: Refactor code | Related files: utils.py, helpers.py\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Error Proofing Your Review Engine\n",
                "\n",
                "You've built a solid foundation with context building and learned how to review individual files. Now, let's make our Review Engine more robust! In this exercise, you'll add comprehensive error handling to ensure the system works reliably, even when things go wrong.\n",
                "\n",
                "Real-world code review systems need to handle unexpected situations gracefully â€” malformed diffs, missing context, or AI service outages shouldn't crash your entire review process.\n",
                "\n",
                "Your task is to enhance the review_changeset_file method with proper error handling:\n",
                "\n",
                "Add try-except blocks around diff parsing to handle parsing failures\n",
                "Implement error handling for context-gathering functions\n",
                "Add defensive programming to the context-building section\n",
                "Wrap the LLM client call with error handling to provide fallback messages\n",
                "This error handling is essential because it transforms a fragile prototype into a dependable tool that can handle the messy realities of software development. By completing this exercise, you'll create a Review Engine that not only provides helpful feedback but also remains stable when facing unexpected challenges.\n",
                "\n",
                "```python\n",
                "from typing import Dict\n",
                "from sqlalchemy.orm import Session\n",
                "\n",
                "# Dummy imports for demonstration; in a real course, these would be actual modules.\n",
                "# from llm_client import LLMClient\n",
                "# from diff_parser import parse_unified_diff\n",
                "# from context_generator import get_file_context, get_recent_changes, find_related_files\n",
                "# from models import ChangesetFile\n",
                "\n",
                "# Minimal stubs for demonstration and to make the code runnable\n",
                "class LLMClient:\n",
                "    def analyze_changeset(self, file_path: str, diff: str, context: str = \"\") -> str:\n",
                "        # Simulating potential API errors\n",
                "        if \"error\" in diff.lower():\n",
                "            raise Exception(\"LLM API error: Service unavailable\")\n",
                "        return f\"Review for {file_path} with context: {context}\"\n",
                "\n",
                "class DiffParsingError(Exception):\n",
                "    \"\"\"Exception raised when diff parsing fails.\"\"\"\n",
                "    pass\n",
                "\n",
                "def parse_unified_diff(diff_content: str):\n",
                "    # Simulating potential parsing errors\n",
                "    if \"invalid\" in diff_content.lower():\n",
                "        raise DiffParsingError(\"Invalid diff format\")\n",
                "    \n",
                "    class DummyDiff:\n",
                "        file_path = \"example.py\"\n",
                "    return DummyDiff()\n",
                "\n",
                "def get_file_context(session, file_path):\n",
                "    # Simulating potential errors\n",
                "    if \"missing\" in file_path:\n",
                "        return None\n",
                "    return \"def foo():\\n    pass\"\n",
                "\n",
                "def get_recent_changes(session, file_path):\n",
                "    # Simulating potential errors\n",
                "    if \"no_history\" in file_path:\n",
                "        return None\n",
                "    return [\n",
                "        {'hash': 'abc12345', 'message': 'Initial commit', 'author': 'Alice', 'date': '2024-06-01'},\n",
                "        {'hash': 'def67890', 'message': 'Refactor code', 'author': 'Bob', 'date': '2024-06-02'}\n",
                "    ]\n",
                "\n",
                "def find_related_files(session, file_path):\n",
                "    # Simulating potential errors\n",
                "    if \"isolated\" in file_path:\n",
                "        return None\n",
                "    return [\"utils.py\", \"helpers.py\"]\n",
                "\n",
                "class ChangesetFile:\n",
                "    def __init__(self, diff_content, file_path=\"example.py\"):\n",
                "        self.diff_content = diff_content\n",
                "        self.file_path = file_path\n",
                "\n",
                "class Changeset:\n",
                "    def __init__(self, files):\n",
                "        self.files = files\n",
                "\n",
                "class ReviewEngine:\n",
                "    def __init__(self):\n",
                "        self.llm_client = LLMClient()\n",
                "    \n",
                "    def review_changeset_file(self, session: Session, changeset_file: ChangesetFile) -> str:\n",
                "        \"\"\"Review a single file in a changeset with error handling\"\"\"\n",
                "        # TODO: Get file_path safely using getattr with a default value in case file_path is missing\n",
                "        \n",
                "        # Parse the diff with error handling\n",
                "        # TODO: Add try-except block around diff parsing to handle DiffParsingError and general exceptions\n",
                "        diff = parse_unified_diff(changeset_file.diff_content)\n",
                "        \n",
                "        # Gather context with error handling\n",
                "        # TODO: Add try-except block around file_context retrieval\n",
                "        file_context = get_file_context(session, diff.file_path)\n",
                "        \n",
                "        # TODO: Add try-except block around recent_changes retrieval\n",
                "        recent_changes = get_recent_changes(session, diff.file_path)\n",
                "        \n",
                "        # TODO: Add try-except block around related_files retrieval\n",
                "        related_files = find_related_files(session, diff.file_path)\n",
                "        \n",
                "        # Build context summary with defensive programming\n",
                "        context_parts = []\n",
                "        \n",
                "        if recent_changes:\n",
                "            # TODO: Add try-except block around recent changes formatting\n",
                "            # TODO: Use dict.get() with default values for safer dictionary access\n",
                "            recent_summary = \"; \".join([\n",
                "                f\"{change['hash']}: {change['message']}\" \n",
                "                for change in recent_changes[:2]\n",
                "            ])\n",
                "            context_parts.append(f\"Recent changes: {recent_summary}\")\n",
                "        \n",
                "        if related_files:\n",
                "            # TODO: Add try-except block around related files formatting\n",
                "            context_parts.append(f\"Related files: {', '.join(related_files)}\")\n",
                "        \n",
                "        # TODO: Add a fallback for empty context_parts\n",
                "        context = \" | \".join(context_parts)\n",
                "        \n",
                "        # Generate review with error handling\n",
                "        # TODO: Add try-except block around LLM client call with a helpful fallback message\n",
                "        return self.llm_client.analyze_changeset(\n",
                "            file_path=diff.file_path,\n",
                "            diff=changeset_file.diff_content,\n",
                "            context=context\n",
                "        )\n",
                "    \n",
                "    def review_full_changeset(self, session: Session, changeset_id: int) -> Dict[str, str]:\n",
                "        \"\"\"Review all files in a changeset with error handling\"\"\"\n",
                "        # from models import Changeset\n",
                "        # For demonstration, we'll create a dummy changeset\n",
                "        changeset = Changeset([\n",
                "            ChangesetFile(\"diff --git a/example.py b/example.py\\n@@ -1 +1,2 @@\\n+print('Hello')\", \"example.py\"),\n",
                "            ChangesetFile(\"diff --git a/utils.py b/utils.py\\n@@ -1 +1,2 @@\\n+def util(): pass\", \"utils.py\"),\n",
                "            ChangesetFile(\"invalid diff content\", \"invalid.py\"),\n",
                "            ChangesetFile(\"diff with error\", \"error.py\")\n",
                "        ])\n",
                "        \n",
                "        reviews = {}\n",
                "        # TODO: Add try-except block around each file review to handle any unexpected errors\n",
                "        for changeset_file in changeset.files:\n",
                "            review = self.review_changeset_file(session, changeset_file)\n",
                "            reviews[changeset_file.file_path] = review\n",
                "        \n",
                "        return reviews\n",
                "\n",
                "# Example usage (for demonstration purposes)\n",
                "if __name__ == \"__main__\":\n",
                "    engine = ReviewEngine()\n",
                "    # session would be a SQLAlchemy session in a real app; here we use None\n",
                "    reviews = engine.review_full_changeset(None, 1)\n",
                "    for file, review in reviews.items():\n",
                "        print(f\"Review for {file}:\\n{review}\\n\")\n",
                "\n",
                "```\n",
                "\n",
                "Enhancing the `ReviewEngine` with comprehensive error handling makes it much more resilient. The updated code below includes **try-except blocks** for parsing, context gathering, and the LLM call, along with **defensive programming** practices like using `getattr` and `dict.get()`.\n",
                "\n",
                "```python\n",
                "from typing import Dict\n",
                "from sqlalchemy.orm import Session\n",
                "import logging\n",
                "\n",
                "# Configure basic logging to see error messages\n",
                "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
                "\n",
                "# Minimal stubs for demonstration and to make the code runnable\n",
                "class LLMClient:\n",
                "    def analyze_changeset(self, file_path: str, diff: str, context: str = \"\") -> str:\n",
                "        # Simulating potential API errors\n",
                "        if \"error\" in diff.lower():\n",
                "            raise Exception(\"LLM API error: Service unavailable\")\n",
                "        return f\"Review for {file_path} (Context: {context[:30]}...)\"\n",
                "\n",
                "class DiffParsingError(Exception):\n",
                "    \"\"\"Exception raised when diff parsing fails.\"\"\"\n",
                "    pass\n",
                "\n",
                "def parse_unified_diff(diff_content: str):\n",
                "    # Simulating potential parsing errors\n",
                "    if \"invalid\" in diff_content.lower():\n",
                "        raise DiffParsingError(\"Invalid diff format\")\n",
                "    \n",
                "    class DummyDiff:\n",
                "        # In a real parser, this would extract the file path from the diff content\n",
                "        file_path = \"example.py\" if \"example\" in diff_content else \"utils.py\" if \"util\" in diff_content else \"default_file.py\"\n",
                "    return DummyDiff()\n",
                "\n",
                "def get_file_context(session, file_path):\n",
                "    # Simulating potential errors\n",
                "    if \"missing\" in file_path:\n",
                "        return None\n",
                "    return \"def foo():\\n    pass\"\n",
                "\n",
                "def get_recent_changes(session, file_path):\n",
                "    # Simulating potential errors\n",
                "    if \"no_history\" in file_path:\n",
                "        return None\n",
                "    return [\n",
                "        {'hash': 'abc12345', 'message': 'Initial commit', 'author': 'Alice', 'date': '2024-06-01'},\n",
                "        {'hash': 'def67890', 'message': 'Refactor code', 'author': 'Bob', 'date': '2024-06-02'}\n",
                "    ]\n",
                "\n",
                "def find_related_files(session, file_path):\n",
                "    # Simulating potential errors\n",
                "    if \"isolated\" in file_path:\n",
                "        return None\n",
                "    return [\"utils.py\", \"helpers.py\"]\n",
                "\n",
                "class ChangesetFile:\n",
                "    def __init__(self, diff_content, file_path=\"example.py\"):\n",
                "        self.diff_content = diff_content\n",
                "        self.file_path = file_path\n",
                "\n",
                "class Changeset:\n",
                "    def __init__(self, files):\n",
                "        self.files = files\n",
                "\n",
                "class ReviewEngine:\n",
                "    def __init__(self):\n",
                "        self.llm_client = LLMClient()\n",
                "    \n",
                "    def review_changeset_file(self, session: Session, changeset_file: ChangesetFile) -> str:\n",
                "        \"\"\"Review a single file in a changeset with error handling\"\"\"\n",
                "        \n",
                "        # Defensive programming: Safely get file_path, falling back to a dummy if missing\n",
                "        file_path = getattr(changeset_file, 'file_path', 'unknown_file')\n",
                "        diff_content = changeset_file.diff_content\n",
                "        \n",
                "        # --- Diff Parsing with Error Handling ---\n",
                "        try:\n",
                "            diff_object = parse_unified_diff(diff_content)\n",
                "            file_path = diff_object.file_path # Update file_path from the parsed diff if successful\n",
                "        except DiffParsingError as e:\n",
                "            error_msg = f\"Failed to parse diff for file '{file_path}': {e}\"\n",
                "            logging.error(error_msg)\n",
                "            return f\"Review Error (Parsing): {error_msg}. Cannot proceed with review.\"\n",
                "        except Exception as e:\n",
                "            error_msg = f\"An unexpected error occurred during diff parsing for file '{file_path}': {e}\"\n",
                "            logging.error(error_msg)\n",
                "            return f\"Review Error (Parsing): {error_msg}. Cannot proceed with review.\"\n",
                "        \n",
                "        # --- Gather Context with Error Handling ---\n",
                "        \n",
                "        # Context 1: File Content\n",
                "        file_context = None\n",
                "        try:\n",
                "            file_context = get_file_context(session, file_path)\n",
                "        except Exception as e:\n",
                "            logging.warning(f\"Could not get file context for '{file_path}': {e}\")\n",
                "\n",
                "        # Context 2: Recent Changes\n",
                "        recent_changes = None\n",
                "        try:\n",
                "            recent_changes = get_recent_changes(session, file_path)\n",
                "        except Exception as e:\n",
                "            logging.warning(f\"Could not get recent changes for '{file_path}': {e}\")\n",
                "        \n",
                "        # Context 3: Related Files\n",
                "        related_files = None\n",
                "        try:\n",
                "            related_files = find_related_files(session, file_path)\n",
                "        except Exception as e:\n",
                "            logging.warning(f\"Could not get related files for '{file_path}': {e}\")\n",
                "        \n",
                "        # --- Build Context Summary with Defensive Programming ---\n",
                "        context_parts = []\n",
                "        \n",
                "        if file_context:\n",
                "            context_parts.append(f\"File Context (Snippet):\\n{file_context[:50]}...\")\n",
                "        \n",
                "        if recent_changes:\n",
                "            try:\n",
                "                # Defensive programming: Safely access dict keys using .get()\n",
                "                recent_summary = \"; \".join([\n",
                "                    f\"{change.get('hash', 'N/A')[:7]}: {change.get('message', 'No message')}\" \n",
                "                    for change in recent_changes[:2]\n",
                "                ])\n",
                "                context_parts.append(f\"Recent changes: {recent_summary}\")\n",
                "            except Exception as e:\n",
                "                logging.warning(f\"Error formatting recent changes for '{file_path}': {e}\")\n",
                "        \n",
                "        if related_files:\n",
                "            try:\n",
                "                context_parts.append(f\"Related files: {', '.join(related_files)}\")\n",
                "            except Exception as e:\n",
                "                logging.warning(f\"Error formatting related files for '{file_path}': {e}\")\n",
                "        \n",
                "        # Fallback for empty context\n",
                "        context = \" | \".join(context_parts)\n",
                "        if not context:\n",
                "            context = \"No context available.\"\n",
                "        \n",
                "        # --- Generate Review with Error Handling (LLM Call) ---\n",
                "        try:\n",
                "            return self.llm_client.analyze_changeset(\n",
                "                file_path=file_path,\n",
                "                diff=diff_content,\n",
                "                context=context\n",
                "            )\n",
                "        except Exception as e:\n",
                "            error_msg = f\"LLM client failed to review file '{file_path}': {e}\"\n",
                "            logging.error(error_msg)\n",
                "            # Provide a helpful fallback message\n",
                "            return f\"Review Error (AI Service): {error_msg}. The LLM service is currently unavailable or returned an error. Please try again later.\"\n",
                "    \n",
                "    def review_full_changeset(self, session: Session, changeset_id: int) -> Dict[str, str]:\n",
                "        \"\"\"Review all files in a changeset with error handling\"\"\"\n",
                "        \n",
                "        changeset = Changeset([\n",
                "            ChangesetFile(\"diff --git a/example.py b/example.py\\n@@ -1 +1,2 @@\\n+print('Hello')\", \"example.py\"),\n",
                "            ChangesetFile(\"diff --git a/utils.py b/utils.py\\n@@ -1 +1,2 @@\\n+def util(): pass\", \"utils.py\"),\n",
                "            ChangesetFile(\"invalid diff content\", \"invalid.py\"), # Should fail parsing\n",
                "            ChangesetFile(\"diff with error\", \"error.py\") # Should fail LLM call\n",
                "        ])\n",
                "        \n",
                "        reviews = {}\n",
                "        for changeset_file in changeset.files:\n",
                "            # --- Try-except block for each file review to prevent a full crash ---\n",
                "            file_path = getattr(changeset_file, 'file_path', 'unknown_file')\n",
                "            try:\n",
                "                review = self.review_changeset_file(session, changeset_file)\n",
                "            except Exception as e:\n",
                "                review = f\"Fatal Error: Review Engine crashed while processing this file. {e}\"\n",
                "                logging.critical(f\"A critical error occurred for file '{file_path}': {e}\")\n",
                "            \n",
                "            reviews[file_path] = review\n",
                "        \n",
                "        return reviews\n",
                "\n",
                "# Example usage (for demonstration purposes)\n",
                "if __name__ == \"__main__\":\n",
                "    print(\"--- Starting Review Engine with Error Proofing ---\\n\")\n",
                "    engine = ReviewEngine()\n",
                "    # session would be a SQLAlchemy session in a real app; here we use None\n",
                "    reviews = engine.review_full_changeset(None, 1)\n",
                "    \n",
                "    print(\"\\n--- Final Reviews ---\\n\")\n",
                "    for file, review in reviews.items():\n",
                "        print(f\"Review for **{file}**:\\n{review}\\n\")\n",
                "```\n",
                "\n",
                "-----\n",
                "\n",
                "### Key Error Handling Implementations\n",
                "\n",
                "1.  **Diff Parsing:**\n",
                "\n",
                "      * A `try...except DiffParsingError` block is used to catch expected parsing issues (e.g., malformed diffs).\n",
                "      * A generic `except Exception` catches any other unforeseen errors during parsing.\n",
                "      * If parsing fails, the method immediately returns a helpful error message, preventing subsequent code from crashing due to a missing `diff_object`.\n",
                "\n",
                "2.  **Defensive Context Gathering:**\n",
                "\n",
                "      * `getattr(changeset_file, 'file_path', 'unknown_file')` is used to safely get the file path, providing a **default value** if the attribute is missing.\n",
                "      * **Context functions** (`get_file_context`, `get_recent_changes`, `find_related_files`) are wrapped in individual `try...except` blocks. If one context function fails, it only logs a warning and sets that variable to `None`, allowing the rest of the review process to continue with partial context.\n",
                "\n",
                "3.  **Defensive Context Building:**\n",
                "\n",
                "      * The code uses `dict.get('key', 'default_value')` within the list comprehension for `recent_changes`. This ensures that if a change dictionary is missing a key (like `'hash'` or `'message'`), the code won't crash and will instead use a safe fallback value (`'N/A'` or `'No message'`).\n",
                "\n",
                "4.  **LLM Client Call:**\n",
                "\n",
                "      * The call to `self.llm_client.analyze_changeset` is wrapped in a final `try...except` block.\n",
                "      * If the LLM service fails (simulated by the `error` keyword in the diff), it catches the exception, logs the error, and returns a **graceful fallback message**, ensuring the user knows the AI service is the problem, not the engine itself.\n",
                "\n",
                "5.  **Full Changeset Review:**\n",
                "\n",
                "      * The `review_full_changeset` method adds a `try...except` block *around the loop call* to `review_changeset_file`. This ensures that even a catastrophic, unexpected crash during the processing of a single file will only cause that file's review to fail, but the engine will continue processing all other files in the changeset."
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
