{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Unit 1 Handling Pagination in Web Scraping with Python and Beautiful Soup\n",
                                    "\n",
                                    "# Introduction to Pagination with BeautifulSoup\n",
                                    "\n",
                                    "Hello and welcome\\! In this lesson, we will focus on handling **pagination** in web scraping using Python and Beautiful Soup. Pagination is essential when scraping large datasets from websites that display their content over multiple pages. By the end of this lesson, you will be equipped with the skills to navigate multiple web pages, extract necessary data, and handle pagination effectively.\n",
                                    "\n",
                                    "### What is Pagination?\n",
                                    "\n",
                                    "Pagination is a web design technique used to divide extensive content into multiple pages, commonly seen in search results, blogs, and forums. Each page shows a subset of the total data, and navigation links (typically labeled \"Next\", \"Previous\", or page numbers) let users move through the data.\n",
                                    "\n",
                                    "**Challenges:**\n",
                                    "\n",
                                    "  * Identifying and following \"Next\" buttons programmatically.\n",
                                    "  * Constructing URLs dynamically to request subsequent pages.\n",
                                    "  * Ensuring consistent data extraction amidst varying page layouts.\n",
                                    "\n",
                                    "Understanding pagination is essential for effective web scraping since it allows you to gather comprehensive datasets.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### Implementing Pagination in Web Scraping\n",
                                    "\n",
                                    "Let's consider a scenario where we scrape quotes from a website that paginates its content. The website displays quotes on multiple pages, with a \"Next\" button to navigate to the next page. The following code demonstrates how to scrape quotes from multiple pages:\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "next_url = '/page/1/'\n",
                                    "\n",
                                    "while next_url:\n",
                                    "    response = requests.get(f\"{base_url}{next_url}\")\n",
                                    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                                    "    quotes = soup.find_all(\"div\", class_=\"quote\")\n",
                                    "\n",
                                    "    for quote in quotes:\n",
                                    "        print(quote.find(\"span\", class_=\"text\").text)\n",
                                    "\n",
                                    "    next_button = soup.find(\"li\", class_=\"next\")\n",
                                    "    next_url = next_button.find(\"a\")[\"href\"] if next_button else None\n",
                                    "```\n",
                                    "\n",
                                    "The code iterates through multiple pages of the website and extracts quotes using Beautiful Soup.\n",
                                    "The `while` loop continues as long as the `next_url` is available, extracting the next URL dynamically from the \"Next\" button link. This code elegantly handles pagination by recursively following \"Next\" links until no more pages are available.\n",
                                    "\n",
                                    "We use `soup.find_all` to locate all `div` tags with class `quote`. Within each `quote` `div`, we find the `span` with the class `text` to extract the quote text.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "### Lesson Summary\n",
                                    "\n",
                                    "In this lesson, we explored how to handle pagination while scraping web data using Python and Beautiful Soup. We started with the concept of pagination, broke down the example code, and implemented a full pagination logic to scrape multiple pages.\n",
                                    "\n",
                                    "Let's practice and reinforce the concepts we learned. Happy scraping\\!"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Scraping Quotes with Pagination\n",
                                    "\n",
                                    "Great job on understanding the lesson! Let's now run the example code to see pagination in action.\n",
                                    "\n",
                                    "Run the code to observe how it scrapes quotes from multiple pages.\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "next_url = '/page/1/'\n",
                                    "while next_url:\n",
                                    "    response = requests.get(f\"{base_url}{next_url}\")\n",
                                    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                                    "\n",
                                    "    quotes = soup.find_all(\"div\", class_=\"quote\")\n",
                                    "    for quote in quotes:\n",
                                    "        print(quote.find(\"span\", class_=\"text\").text)\n",
                                    "\n",
                                    "    next_button = soup.find(\"li\", class_=\"next\")\n",
                                    "    next_url = next_button.find(\"a\")[\"href\"] if next_button else None\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Enhance Quote Scraping Script\n",
                                    "\n",
                                    "Great job so far! Now, let's take one step further and modify our existing code.\n",
                                    "\n",
                                    "Currently, the code prints only the text of the quotes. Change the code to also print the author of each quote.\n",
                                    "\n",
                                    "Remember, analyzing the structure of the page is crucial in web scraping. So, if you are not sure where to find the author's name, you can open the URL in another tab and inspect the page.\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "next_url = '/page/1/'\n",
                                    "while next_url:\n",
                                    "    response = requests.get(f\"{base_url}{next_url}\")\n",
                                    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                                    "\n",
                                    "    quotes = soup.find_all(\"div\", class_=\"quote\")\n",
                                    "\n",
                                    "    # TODO: Modify the code to print the author of each quote along with the text\n",
                                    "    for quote in quotes:\n",
                                    "        print(quote.find(\"span\", class_=\"text\").text)\n",
                                    "\n",
                                    "    next_button = soup.find(\"li\", class_=\"next\")\n",
                                    "    next_url = next_button.find(\"a\")[\"href\"] if next_button else None\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "next_url = '/page/1/'\n",
                                    "while next_url:\n",
                                    "    response = requests.get(f\"{base_url}{next_url}\")\n",
                                    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                                    "\n",
                                    "    quotes = soup.find_all(\"div\", class_=\"quote\")\n",
                                    "    \n",
                                    "    # TODO: Modify the code to print the author of each quote along with the text\n",
                                    "    for quote in quotes:\n",
                                    "        text = quote.find(\"span\", class_=\"text\").text\n",
                                    "        author = quote.find(\"small\", class_=\"author\").text\n",
                                    "        print(f'\"{text}\" - {author}')\n",
                                    "\n",
                                    "    next_button = soup.find(\"li\", class_=\"next\")\n",
                                    "    next_url = next_button.find(\"a\")[\"href\"] if next_button else None\n",
                                    "```\n",
                                    "\n",
                                    "**Penjelasan Modifikasi:**\n",
                                    "\n",
                                    "1.  **Mencari Elemen Penulis**: Saya menganalisis struktur HTML dari halaman `quotes.toscrape.com` dan menemukan bahwa nama penulis berada di dalam tag `<small>` dengan `class=\"author\"`.\n",
                                    "2.  **Menyimpan Teks dan Penulis**: Di dalam loop `for`, saya sekarang mengambil teks kutipan dan nama penulis secara terpisah dan menyimpannya ke dalam variabel `text` dan `author`.\n",
                                    "3.  **Mencetak Format Baru**: Saya menggunakan f-string (`f'\"{text}\" - {author}'`) untuk menggabungkan teks kutipan dan nama penulis ke dalam satu baris output yang mudah dibaca."
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Enhance Pagination Handling Script\n",
                                    "\n",
                                    "Great job so far! Let's take our pagination handling skills one step further.\n",
                                    "\n",
                                    "The current code prints the quotes on 10 pages navigated by the \"Next\" button. Let's modify the code to fetch only the first 5 pages of quotes.\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "next_url = '/page/1/'\n",
                                    "# TODO: Fetch only the first 5 pages of quotes\n",
                                    "while next_url:\n",
                                    "    response = requests.get(f\"{base_url}{next_url}\")\n",
                                    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                                    "\n",
                                    "    quotes = soup.find_all(\"div\", class_=\"quote\")\n",
                                    "    for quote in quotes:\n",
                                    "        print(quote.find(\"span\", class_=\"text\").text)\n",
                                    "\n",
                                    "    next_button = soup.find(\"li\", class_=\"next\")\n",
                                    "    next_url = next_button.find(\"a\")[\"href\"] if next_button else None\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "next_url = '/page/1/'\n",
                                    "# TODO: Fetch only the first 5 pages of quotes\n",
                                    "page_count = 0\n",
                                    "while next_url and page_count < 5:\n",
                                    "    response = requests.get(f\"{base_url}{next_url}\")\n",
                                    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                                    "\n",
                                    "    quotes = soup.find_all(\"div\", class_=\"quote\")\n",
                                    "    for quote in quotes:\n",
                                    "        print(quote.find(\"span\", class_=\"text\").text)\n",
                                    "\n",
                                    "    next_button = soup.find(\"li\", class_=\"next\")\n",
                                    "    next_url = next_button.find(\"a\")[\"href\"] if next_button else None\n",
                                    "    page_count += 1\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Handle Next Button\n",
                                    "\n",
                                    "Great progress so far!\n",
                                    "\n",
                                    "Now, let's add the missing piece to our web scraping script. We need to get the URL of the next page from the \"Next\" button on the page.\n",
                                    "\n",
                                    "Follow the TODO in the starter code to complete the task.\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "next_url = '/page/1/'\n",
                                    "while next_url:\n",
                                    "    response = requests.get(f\"{base_url}{next_url}\")\n",
                                    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                                    "\n",
                                    "    quotes = soup.find_all(\"div\", class_=\"quote\")\n",
                                    "    for quote in quotes:\n",
                                    "        text = quote.find(\"span\", class_=\"text\").text\n",
                                    "        author = quote.find(\"small\", class_=\"author\").text\n",
                                    "        print(f\"{text} by {author}\")\n",
                                    "\n",
                                    "    # TODO: Add code to get the button that leads to the next page. It is a list item with the class \"next\"\n",
                                    "    \n",
                                    "    next_url = next_button.find(\"a\")[\"href\"] if next_button else None\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "next_url = '/page/1/'\n",
                                    "while next_url:\n",
                                    "    response = requests.get(f\"{base_url}{next_url}\")\n",
                                    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                                    "\n",
                                    "    quotes = soup.find_all(\"div\", class_=\"quote\")\n",
                                    "    for quote in quotes:\n",
                                    "        text = quote.find(\"span\", class_=\"text\").text\n",
                                    "        author = quote.find(\"small\", class_=\"author\").text\n",
                                    "        print(f\"{text} by {author}\")\n",
                                    "\n",
                                    "    # TODO: Add code to get the button that leads to the next page. It is a list item with the class \"next\"\n",
                                    "    next_button = soup.find(\"li\", class_=\"next\")\n",
                                    "    \n",
                                    "    next_url = next_button.find(\"a\")[\"href\"] if next_button else None\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Handle Pagination in Web Scraping\n",
                                    "\n",
                                    "Great progress so far! Now, let's ensure your understanding of pagination handling is solid.\n",
                                    "\n",
                                    "In this task, you will complete the pagination handling code for scraping quotes from a website. Fill in the missing part in the provided code to extract quotes and handle the \"Next\" button to navigate through all available pages.\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "next_url = '/page/1/'\n",
                                    "while next_url:\n",
                                    "    response = requests.get(f\"{base_url}{next_url}\")\n",
                                    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                                    "\n",
                                    "    quotes = soup.find_all(\"div\", class_=\"quote\")\n",
                                    "    for quote in quotes:\n",
                                    "        text = quote.find(\"span\", class_=\"text\").text\n",
                                    "        author = quote.find(\"small\", class_=\"author\").text\n",
                                    "        print(f\"{text} by {author}\")\n",
                                    "\n",
                                    "    # TODO: Add code to get the button that leads to the next page. It is a list item with the class \"next\"\n",
                                    "    next_button = soup.find(\"li\", class_=\"next\")\n",
                                    "    \n",
                                    "    next_url = next_button.find(\"a\")[\"href\"] if next_button else None\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "next_url = '/page/1/'\n",
                                    "while next_url:\n",
                                    "    response = requests.get(f\"{base_url}{next_url}\")\n",
                                    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                                    "\n",
                                    "    quotes = soup.find_all(\"div\", class_=\"quote\")\n",
                                    "    for quote in quotes:\n",
                                    "        text = quote.find(\"span\", class_=\"text\").text\n",
                                    "        author = quote.find(\"small\", class_=\"author\").text\n",
                                    "        print(f\"{text} by {author}\")\n",
                                    "\n",
                                    "    # TODO: Add code to get the button that leads to the next page. It is a list item with the class \"next\"\n",
                                    "    next_button = soup.find(\"li\", class_=\"next\")\n",
                                    "    \n",
                                    "    next_url = next_button.find(\"a\")[\"href\"] if next_button else None\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Creating a Pagination Scraper\n",
                                    "\n",
                                    "Great job on reaching this final practice! Now it's time to put your knowledge to the test and show that you've mastered handling pagination in web scraping.\n",
                                    "\n",
                                    "Your task is to write a Python script that scrapes quotes from a website spread across multiple pages.\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "next_url = '/page/1/'\n",
                                    "\n",
                                    "# TODO: Create a while loop that continues as long as next_url is not None\n",
                                    "\n",
                                    "    # TODO: Make a request to the current page and get its content\n",
                                    "\n",
                                    "    # TODO: Parse the page content using BeautifulSoup\n",
                                    "\n",
                                    "    # TODO: Find all quotes on the page and print each quote's text - Quotes are inside a div with class \"quote\"\n",
                                    "\n",
                                    "    # TODO: Find the \"Next\" button and get the URL for the next page - The \"Next\" button is inside a li with class \"next\"\n",
                                    "    #       If there is no \"Next\" button, set next_url to None\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "next_url = '/'\n",
                                    "\n",
                                    "# List to store all scraped quotes\n",
                                    "all_quotes = []\n",
                                    "\n",
                                    "while next_url:\n",
                                    "    # Construct the full URL for the current page\n",
                                    "    full_url = f'{base_url}{next_url}'\n",
                                    "\n",
                                    "    # Make a request to the current page and get its content\n",
                                    "    try:\n",
                                    "        response = requests.get(full_url)\n",
                                    "        response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)\n",
                                    "    except requests.exceptions.RequestException as e:\n",
                                    "        print(f\"Error fetching {full_url}: {e}\")\n",
                                    "        break\n",
                                    "\n",
                                    "    # Parse the page content using BeautifulSoup\n",
                                    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                                    "\n",
                                    "    # Find all quotes on the page and print each quote's text\n",
                                    "    quotes = soup.find_all('div', class_='quote')\n",
                                    "    for quote in quotes:\n",
                                    "        text = quote.find('span', class_='text').text\n",
                                    "        author = quote.find('small', class_='author').text\n",
                                    "        print(f'\"{text}\" - {author}')\n",
                                    "        all_quotes.append({'text': text, 'author': author})\n",
                                    "\n",
                                    "    # Find the \"Next\" button and get the URL for the next page\n",
                                    "    next_button = soup.find('li', class_='next')\n",
                                    "    if next_button:\n",
                                    "        next_url = next_button.find('a')['href']\n",
                                    "    else:\n",
                                    "        # If there is no \"Next\" button, set next_url to None to break the loop\n",
                                    "        next_url = None\n",
                                    "```"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
