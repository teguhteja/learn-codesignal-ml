{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Unit 2 Advanced Link Navigation and URL Management in Web Scraping\n",
                                    "\n",
                                    "# Topic Overview\n",
                                    "\n",
                                    "Welcome\\! In this lesson, we'll delve into advanced link navigation and URL management within the realm of web scraping using Python and BeautifulSoup. Our goal is to ensure that you can navigate between linked web pages and manage URLs effectively for scalable web scraping.\n",
                                    "\n",
                                    "## Navigating Author Details\n",
                                    "\n",
                                    "To solidify your understanding of link navigation, we'll focus on a scenario where you scrape quotes from a website and navigate to author pages to extract additional information. This process involves extracting links from the main page, navigating to the linked pages, and scraping data from those pages. The following code scrapes quote from the main page and navigate to the author pages for more information:\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "def scrape_quotes(base_url):\n",
                                    "    response = requests.get(base_url)\n",
                                    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                                    "    quotes = soup.select('.quote')\n",
                                    "    for quote in quotes:\n",
                                    "        text = quote.select_one('.text').get_text()\n",
                                    "        author = quote.select_one('.author').get_text()\n",
                                    "        print(f'{text} - {author}')\n",
                                    "        endpoint_to_about_page = quote.select_one('span a')['href']\n",
                                    "        url_to_about_page = base_url + endpoint_to_about_page\n",
                                    "\n",
                                    "        response = requests.get(url_to_about_page)\n",
                                    "        soup_about = BeautifulSoup(response.text, 'html.parser')\n",
                                    "        born_date = soup_about.select_one('.author-born-date').get_text()\n",
                                    "        born_location = soup_about.select_one('.author-born-location').get_text()\n",
                                    "        print(f'{author} was born on {born_date} in {born_location}\\n')\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "scrape_quotes(base_url)\n",
                                    "```\n",
                                    "\n",
                                    "First, we import the necessary libraries and define a soup object for the main page.\n",
                                    "\n",
                                    "Then, we extract quotes from the main page and iterate over each quote to extract text and author information.\n",
                                    "\n",
                                    "After that, we extract the endpoint to the author's page and construct the full URL:\n",
                                    "\n",
                                    "```python\n",
                                    "endpoint_to_about_page = quote.select_one('span a')['href']\n",
                                    "url_to_about_page = base_url + endpoint_to_about_page\n",
                                    "```\n",
                                    "\n",
                                    "Remember that `select_one()` returns the first matching element, and we use the `['href']` attribute to extract the endpoint.\n",
                                    "\n",
                                    "Once we have the full URL, we send a request to the author's page and create a new soup object to extract additional information:\n",
                                    "\n",
                                    "```python\n",
                                    "response = requests.get(url_to_about_page)\n",
                                    "soup_about = BeautifulSoup(response.text, 'html.parser')\n",
                                    "born_date = soup_about.select_one('.author-born-date').get_text()\n",
                                    "born_location = soup_about.select_one('.author-born-location').get_text()\n",
                                    "print(f'{author} was born on {born_date} in {born_location}\\n')\n",
                                    "```\n",
                                    "\n",
                                    "Notice, that in this snippet as well, we use `select_one()` to extract the birth date and location of the author.\n",
                                    "\n",
                                    "The output of the code will be the following:\n",
                                    "\n",
                                    "```\n",
                                    "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.” - Albert Einstein\n",
                                    "Albert Einstein was born on March 14, 1879 in in Ulm, Germany\n",
                                    "\n",
                                    "“It is our choices, Harry, that show what we truly are, far more than our abilities.” - J.K. Rowling\n",
                                    "J.K. Rowling was born on July 31, 1965 in in Yate, South Gloucestershire, England, The United Kingdom\n",
                                    "\n",
                                    "“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.” - Albert Einstein\n",
                                    "Albert Einstein was born on March 14, 1879 in in Ulm, Germany\n",
                                    "\n",
                                    "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.” - Jane Austen\n",
                                    "Jane Austen was born on December 16, 1775 in in Steventon Rectory, Hampshire, The United Kingdom\n",
                                    "...\n",
                                    "```\n",
                                    "\n",
                                    "## Lesson Summary and Practice\n",
                                    "\n",
                                    "In this lesson, we've covered advanced link navigation and URL management in web scraping using Python and BeautifulSoup. We examined and extracted links, navigated between pages, handled relative and absolute URLs, and applied these concepts in a detailed code example. These skills will enable you to handle more complex web scraping tasks effectively.\n",
                                    "\n",
                                    "These exercises will help you practice and deepen your understanding of link navigation and URL management in web scraping, enhancing your proficiency in scalable scraping projects. Happy Scraping\\!"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Navigate and Scrape with Python\n",
                                    "\n",
                                    "Great work on the lesson! Now, let's run the code provided in the lesson to see how it works in action.\n",
                                    "\n",
                                    "By running this code, you will be able to observe how it fetches quotes, authors, and navigates to author pages to extract additional information like birth dates and locations.\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "def scrape_quotes(base_url):\n",
                                    "    response = requests.get(base_url)\n",
                                    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                                    "\n",
                                    "    quotes = soup.select('.quote')\n",
                                    "\n",
                                    "    for quote in quotes:\n",
                                    "        text = quote.select_one('.text').get_text()\n",
                                    "        author = quote.select_one('.author').get_text()\n",
                                    "        print(f'{text} - {author}')\n",
                                    "\n",
                                    "        endpoint_to_about_page = quote.select_one('span a')['href']\n",
                                    "        url_to_about_page = base_url + endpoint_to_about_page\n",
                                    "\n",
                                    "        response = requests.get(url_to_about_page)\n",
                                    "        soup_about = BeautifulSoup(response.text, 'html.parser')\n",
                                    "        born_date = soup_about.select_one('.author-born-date').get_text()\n",
                                    "        born_location = soup_about.select_one('.author-born-location').get_text()\n",
                                    "\n",
                                    "        # Remove leading \"in \" from born_location if present\n",
                                    "        if born_location.startswith(\"in \"):\n",
                                    "            born_location = born_location[3:]\n",
                                    "\n",
                                    "        print(f'{author} was born on {born_date} in {born_location}\\n')\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "scrape_quotes(base_url)\n",
                                    "\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Adding Quote Tags for More Detail\n",
                                    "\n",
                                    "Great progress so far!\n",
                                    "\n",
                                    "Now, let's update the code the retrieve and print the author description as well along with born date and location. Follow the TODO instructions to complete the task.\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "def scrape_quotes(base_url):\n",
                                    "    response = requests.get(base_url)\n",
                                    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                                    "\n",
                                    "    quotes = soup.select('.quote')[:2]\n",
                                    "\n",
                                    "    for quote in quotes:\n",
                                    "        text = quote.select_one('.text').get_text()\n",
                                    "        author = quote.select_one('.author').get_text()\n",
                                    "        print(f'{text} - {author}')\n",
                                    "\n",
                                    "        endpoint_to_about_page = quote.select_one('span a')['href']\n",
                                    "        url_to_about_page = base_url + endpoint_to_about_page\n",
                                    "\n",
                                    "        response = requests.get(url_to_about_page)\n",
                                    "        soup_about = BeautifulSoup(response.text, 'html.parser')\n",
                                    "        born_date = soup_about.select_one('.author-born-date').get_text()\n",
                                    "        born_location = soup_about.select_one('.author-born-location').get_text()\n",
                                    "        print(f'{author} was born on {born_date} in {born_location}\\n')\n",
                                    "\n",
                                    "        # TODO: Add another line to retrieve the author description from the nested URL\n",
                                    "\n",
                                    "        # TODO: Print the author description. Hint: You can use the element with class 'author-description'\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "scrape_quotes(base_url)\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "def scrape_quotes(base_url):\n",
                                    "    response = requests.get(base_url)\n",
                                    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                                    "\n",
                                    "    quotes = soup.select('.quote')[:2]\n",
                                    "\n",
                                    "    for quote in quotes:\n",
                                    "        text = quote.select_one('.text').get_text()\n",
                                    "        author = quote.select_one('.author').get_text()\n",
                                    "        print(f'{text} - {author}')\n",
                                    "\n",
                                    "        endpoint_to_about_page = quote.select_one('span a')['href']\n",
                                    "        url_to_about_page = base_url + endpoint_to_about_page\n",
                                    "\n",
                                    "        response = requests.get(url_to_about_page)\n",
                                    "        soup_about = BeautifulSoup(response.text, 'html.parser')\n",
                                    "        born_date = soup_about.select_one('.author-born-date').get_text()\n",
                                    "        born_location = soup_about.select_one('.author-born-location').get_text()\n",
                                    "        print(f'{author} was born on {born_date} in {born_location}\\n')\n",
                                    "\n",
                                    "        # TODO: Add another line to retrieve the author description from the nested URL\n",
                                    "        author_description = soup_about.select_one('.author-description').get_text()\n",
                                    "\n",
                                    "        # TODO: Print the author description. Hint: You can use the element with class 'author-description'\n",
                                    "        print(f'Description: {author_description}\\n')\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "scrape_quotes(base_url)\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Navigating Linked Author Pages\n",
                                    "\n",
                                    "You've done well navigating through links and extracting data.\n",
                                    "\n",
                                    "Now, let's practice filling in missing parts of a Python script to scrape quotes and additional author information. Complete the script so that it navigates to author pages to extract their birth dates and locations.\n",
                                    "\n",
                                    "You need to fill in the missing parts of the script.\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "def scrape_quotes(base_url):\n",
                                    "    # Send a request to get the main page content\n",
                                    "    response = requests.get(base_url)\n",
                                    "    # Create a BeautifulSoup object from the response text\n",
                                    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                                    "\n",
                                    "    # Select all quotes on the main page\n",
                                    "    quotes = soup.select('.quote')\n",
                                    "\n",
                                    "    for quote in quotes:\n",
                                    "        # Extract the text of the quote\n",
                                    "        text = quote.select_one('.text').get_text()\n",
                                    "        # Extract the author's name\n",
                                    "        author = quote.select_one('.author').get_text()\n",
                                    "        print(f'{text} - {author}')\n",
                                    "\n",
                                    "        # Extract the relative URL to the author's page\n",
                                    "        endpoint_to_about_page = quote.select_one('span a')['href']\n",
                                    "\n",
                                    "        # Generate the full URL\n",
                                    "        url_to_about_page = base_url + endpoint_to_about_page\n",
                                    "\n",
                                    "        # Send a request to get the author's page content\n",
                                    "        response = requests.get(url_to_about_page)\n",
                                    "\n",
                                    "        # Create a BeautifulSoup object from the author's page\n",
                                    "        soup_about = BeautifulSoup(response.text, 'html.parser')\n",
                                    "\n",
                                    "        # TODO: Extract the author's birth date from the linked page using CSS selector and get it's text\n",
                                    "        # Hint: The class name of the necessary elemenet is 'author-born-date'\n",
                                    "\n",
                                    "        # TODO: Extract the author's birth location from the linked page using CSS selector and get it's text\n",
                                    "        # Hint: The class name of the necessary elemenet is 'author-born-location'\n",
                                    "\n",
                                    "        print(f'{author} was born on {born_date} in {born_location}\\n')\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "scrape_quotes(base_url)\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "def scrape_quotes(base_url):\n",
                                    "    # Send a request to get the main page content\n",
                                    "    response = requests.get(base_url)\n",
                                    "    # Create a BeautifulSoup object from the response text\n",
                                    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                                    "\n",
                                    "    # Select all quotes on the main page\n",
                                    "    quotes = soup.select('.quote')\n",
                                    "\n",
                                    "    for quote in quotes:\n",
                                    "        # Extract the text of the quote\n",
                                    "        text = quote.select_one('.text').get_text()\n",
                                    "        # Extract the author's name\n",
                                    "        author = quote.select_one('.author').get_text()\n",
                                    "        print(f'{text} - {author}')\n",
                                    "\n",
                                    "        # Extract the relative URL to the author's page\n",
                                    "        endpoint_to_about_page = quote.select_one('span a')['href']\n",
                                    "\n",
                                    "        # Generate the full URL\n",
                                    "        url_to_about_page = base_url + endpoint_to_about_page\n",
                                    "\n",
                                    "        # Send a request to get the author's page content\n",
                                    "        response = requests.get(url_to_about_page)\n",
                                    "\n",
                                    "        # Create a BeautifulSoup object from the author's page\n",
                                    "        soup_about = BeautifulSoup(response.text, 'html.parser')\n",
                                    "\n",
                                    "        # TODO: Extract the author's birth date from the linked page using CSS selector and get it's text\n",
                                    "        # Hint: The class name of the necessary elemenet is 'author-born-date'\n",
                                    "        born_date = soup_about.select_one('.author-born-date').get_text()\n",
                                    "\n",
                                    "        # TODO: Extract the author's birth location from the linked page using CSS selector and get it's text\n",
                                    "        # Hint: The class name of the necessary elemenet is 'author-born-location'\n",
                                    "        born_location = soup_about.select_one('.author-born-location').get_text()\n",
                                    "\n",
                                    "        print(f'{author} was born on {born_date} in {born_location}\\n')\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "scrape_quotes(base_url)\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Scrape Books and Author Bios\n",
                                    "\n",
                                    "Awesome work on the previous tasks!\n",
                                    "\n",
                                    "Now, let's shift to the books scraping in this exercise. In this task, we are scraping the books page, then navigating to each individual book page and retrieving information for each book\n",
                                    "\n",
                                    "Follow the TODO instructions to complete the task to fetch the necessary information for each book as a product.\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "def parse_product_info(product_page_url):\n",
                                    "    product_html = requests.get(product_page_url)\n",
                                    "    product_soup = BeautifulSoup(product_html.text, 'html.parser')\n",
                                    "\n",
                                    "    table = product_soup.select_one(\".table.table-striped\")\n",
                                    "\n",
                                    "    info = {}\n",
                                    "\n",
                                    "    # TODO: Find all 'tr' elements in the table\n",
                                    "    \n",
                                    "    # TODO: Iterate over all the rows\n",
                                    "        \n",
                                    "        # TODO: Extract 'th' of each row as key\n",
                                    "\n",
                                    "        # TODO: Extract 'td' of each row as value\n",
                                    "\n",
                                    "        # TODO: Store the key-value pair in the info dictionary\n",
                                    "\n",
                                    "    return info\n",
                                    "\n",
                                    "def scrape_books(base_url):\n",
                                    "    response = requests.get(base_url)\n",
                                    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                                    "\n",
                                    "    books = soup.select('.product_pod')\n",
                                    "\n",
                                    "    for book in books:\n",
                                    "        title = book.select_one('h3 a')['title']\n",
                                    "        author_page_endpoint = book.select_one('h3 a')['href']\n",
                                    "        product_page_url = base_url + author_page_endpoint\n",
                                    "\n",
                                    "        info = parse_product_info(product_page_url)\n",
                                    "\n",
                                    "        print(f'Book: {title}')\n",
                                    "        print(f'Info: {info}')\n",
                                    "\n",
                                    "base_url = 'http://books.toscrape.com/'\n",
                                    "scrape_books(base_url)\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "def parse_product_info(product_page_url):\n",
                                    "    product_html = requests.get(product_page_url)\n",
                                    "    product_soup = BeautifulSoup(product_html.text, 'html.parser')\n",
                                    "\n",
                                    "    table = product_soup.select_one(\".table.table-striped\")\n",
                                    "\n",
                                    "    info = {}\n",
                                    "\n",
                                    "    # TODO: Find all 'tr' elements in the table\n",
                                    "    rows = table.find_all('tr')\n",
                                    "    \n",
                                    "    # TODO: Iterate over all the rows\n",
                                    "    for row in rows:\n",
                                    "        \n",
                                    "        # TODO: Extract 'th' of each row as key\n",
                                    "        key = row.find('th').get_text(strip=True)\n",
                                    "\n",
                                    "        # TODO: Extract 'td' of each row as value\n",
                                    "        value = row.find('td').get_text(strip=True)\n",
                                    "\n",
                                    "        # TODO: Store the key-value pair in the info dictionary\n",
                                    "        info[key] = value\n",
                                    "\n",
                                    "    return info\n",
                                    "\n",
                                    "def scrape_books(base_url):\n",
                                    "    response = requests.get(base_url)\n",
                                    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                                    "\n",
                                    "    books = soup.select('.product_pod')\n",
                                    "\n",
                                    "    for book in books:\n",
                                    "        title = book.select_one('h3 a')['title']\n",
                                    "        author_page_endpoint = book.select_one('h3 a')['href']\n",
                                    "        product_page_url = base_url + author_page_endpoint\n",
                                    "\n",
                                    "        info = parse_product_info(product_page_url)\n",
                                    "\n",
                                    "        print(f'Book: {title}')\n",
                                    "        print(f'Info: {info}')\n",
                                    "\n",
                                    "base_url = 'http://books.toscrape.com/'\n",
                                    "scrape_books(base_url)\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Navigate and Scrape Author Details\n",
                                    "\n",
                                    "You've completed several exercises to practice navigating through links and extracting detailed information.\n",
                                    "\n",
                                    "Now, it's time to put all that knowledge into action. Write a Python script using BeautifulSoup to scrape quotes from a webpage and navigate to the author's page to extract additional details.\n",
                                    "\n",
                                    "Remember, great scraping starts with a great website analysis, so don't hesitate to open the URLs in the web browser and inspect their content.\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "# TODO: Define the function scrape_quotes(base_url)\n",
                                    "\n",
                                    "    # TODO: Send a request to the main URL and get the page content\n",
                                    "\n",
                                    "    # TODO: Create a BeautifulSoup object from the response text\n",
                                    "\n",
                                    "    # TODO: Find all quotes in the main page using the appropriate CSS selector\n",
                                    "\n",
                                    "    # TODO: Iterate over each quote and extract the text and author\n",
                                    "\n",
                                    "    # TODO: For each quote, find the relative URL to the author's page\n",
                                    "\n",
                                    "        # TODO: Create the full URL to the author's page by concatenating it with the base URL\n",
                                    "\n",
                                    "        # TODO: Send a request to the author's page URL\n",
                                    "\n",
                                    "        # TODO: Create a BeautifulSoup object from the author's page content\n",
                                    "\n",
                                    "        # TODO: Extract the author's birth date\n",
                                    "\n",
                                    "        # TODO: Extract the author's birth location\n",
                                    "\n",
                                    "        # TODO: Print the author's name, birth date, and birth location\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "scrape_quotes(base_url)\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "def scrape_quotes(base_url):\n",
                                    "    \"\"\"\n",
                                    "    Scrapes quotes from a webpage, navigates to the author's page, and\n",
                                    "    extracts additional details about the author.\n",
                                    "    \"\"\"\n",
                                    "    # Send a request to the main URL and get the page content\n",
                                    "    main_page_response = requests.get(base_url)\n",
                                    "    \n",
                                    "    # Check if the request was successful\n",
                                    "    if main_page_response.status_code != 200:\n",
                                    "        print(f\"Failed to retrieve the main page. Status code: {main_page_response.status_code}\")\n",
                                    "        return\n",
                                    "\n",
                                    "    # Create a BeautifulSoup object from the response text\n",
                                    "    soup = BeautifulSoup(main_page_response.text, 'html.parser')\n",
                                    "\n",
                                    "    # Find all quotes in the main page using the appropriate CSS selector\n",
                                    "    quotes = soup.find_all('div', class_='quote')\n",
                                    "\n",
                                    "    # Iterate over each quote and extract the text and author\n",
                                    "    for quote in quotes:\n",
                                    "        text = quote.find('span', class_='text').get_text(strip=True)\n",
                                    "        author_name = quote.find('small', class_='author').get_text(strip=True)\n",
                                    "        \n",
                                    "        # For each quote, find the relative URL to the author's page\n",
                                    "        author_link_tag = quote.find('a', href=True)\n",
                                    "        if author_link_tag:\n",
                                    "            relative_url = author_link_tag['href']\n",
                                    "\n",
                                    "            # Create the full URL to the author's page by concatenating it with the base URL\n",
                                    "            author_url = base_url + relative_url\n",
                                    "\n",
                                    "            # Send a request to the author's page URL\n",
                                    "            author_page_response = requests.get(author_url)\n",
                                    "\n",
                                    "            # Check if the request to the author's page was successful\n",
                                    "            if author_page_response.status_code == 200:\n",
                                    "                # Create a BeautifulSoup object from the author's page content\n",
                                    "                author_soup = BeautifulSoup(author_page_response.text, 'html.parser')\n",
                                    "\n",
                                    "                # Extract the author's birth date\n",
                                    "                born_date = author_soup.find('span', class_='author-born-date').get_text(strip=True)\n",
                                    "\n",
                                    "                # Extract the author's birth location\n",
                                    "                born_location = author_soup.find('span', class_='author-born-location').get_text(strip=True)\n",
                                    "\n",
                                    "                # Print the author's name, birth date, and birth location\n",
                                    "                print(f\"Quote: {text}\")\n",
                                    "                print(f\"Author: {author_name}\")\n",
                                    "                print(f\"Born: {born_date} {born_location}\")\n",
                                    "                print(\"-\" * 20)\n",
                                    "            else:\n",
                                    "                print(f\"Failed to retrieve author page for {author_name}. Status code: {author_page_response.status_code}\")\n",
                                    "\n",
                                    "base_url = 'http://quotes.toscrape.com'\n",
                                    "scrape_quotes(base_url)\n",
                                    "```"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
