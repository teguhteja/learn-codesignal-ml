{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Unit 1 Handling Issues During Web Scraping\n",
                                    "\n",
                                    "Hello\\! In today's lesson, we're diving into the world of **error handling** in web scraping. Error handling is crucial because it helps ensure that your scraping scripts run smoothly, even when they encounter issues such as **HTTP** errors, parsing errors, or missing data.\n",
                                    "\n",
                                    "Before we begin, let's understand the common types of errors you might encounter while scraping the web:\n",
                                    "\n",
                                    "  - **HTTP Errors**: These occur when there's a problem with fetching the web page, such as a 404 Not Found error or a 500 Internal Server Error.\n",
                                    "  - **Parsing Errors**: These arise when the **HTML** content is malformed or unexpected, causing issues during parsing.\n",
                                    "  - **Missing Data/Attributes**: Sometimes, the necessary **HTML** elements or attributes may be missing, leading to errors.\n",
                                    "\n",
                                    "By handling these issues, you can build robust and reliable web scraping scripts that continue to perform well even in the face of challenges.\n",
                                    "\n",
                                    "### Handling HTTP Errors\n",
                                    "\n",
                                    "**HTTP** errors occur when there is a problem with the request made to the server. Common **HTTP** status codes include:\n",
                                    "\n",
                                    "  - **200 OK**: The request was successful.\n",
                                    "  - **404 Not Found**: The requested resource could not be found.\n",
                                    "  - **500 Internal Server Error**: The server encountered an unexpected condition.\n",
                                    "\n",
                                    "Handling these errors gracefully is essential to ensure your script can proceed effectively or log meaningful error messages.\n",
                                    "\n",
                                    "In Python, the `requests` library makes it simple to handle **HTTP** errors using the `response.raise_for_status()` method. This method raises an `HTTPError` if the **HTTP** request returned an unsuccessful status code.\n",
                                    "\n",
                                    "Here's how we can implement it:\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "\n",
                                    "def fetch_page(url):\n",
                                    "    try:\n",
                                    "        response = requests.get(url)\n",
                                    "        response.raise_for_status()  # Check for HTTP errors\n",
                                    "        return response.text\n",
                                    "    except requests.HTTPError as e:\n",
                                    "        print(f\"HTTP error: {e}\")\n",
                                    "        return None\n",
                                    "\n",
                                    "url = 'http://quotes.toscrape.com'\n",
                                    "html = fetch_page(url)\n",
                                    "\n",
                                    "if html:\n",
                                    "    print(html[:500])  # Print the first 500 characters of the page content\n",
                                    "else:\n",
                                    "    print(\"An HTTP Error Occurred\")\n",
                                    "```\n",
                                    "\n",
                                    "In this code:\n",
                                    "\n",
                                    "  - We use a `try` block to attempt to fetch the page content.\n",
                                    "  - The `response.raise_for_status()` method checks for **HTTP** errors.\n",
                                    "  - In the `except` block, we catch `requests.HTTPError` and print an error message if an error occurs.\n",
                                    "\n",
                                    "### Handling Parsing Errors with BeautifulSoup\n",
                                    "\n",
                                    "Parsing errors can occur if the **HTML** content is malformed or unexpected. By using `try` and `except` blocks, you can handle these errors gracefully.\n",
                                    "\n",
                                    "Here's an example using `BeautifulSoup` to parse **HTML** content and extract quotes from a webpage:\n",
                                    "\n",
                                    "```python\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "import requests\n",
                                    "\n",
                                    "html = fetch_page('http://quotes.toscrape.com/')\n",
                                    "\n",
                                    "def parse_and_extract_quotes(html):\n",
                                    "    try:\n",
                                    "        soup = BeautifulSoup(html, 'html.parser')\n",
                                    "        quotes = soup.find_all('div', class_='quote')\n",
                                    "        print(f'Found {len(quotes)} quotes')\n",
                                    "    except Exception as e:\n",
                                    "        print(f\"Parsing error: {e}\")\n",
                                    "\n",
                                    "if html:\n",
                                    "    parse_and_extract_quotes(html) # Will print the number of quotes found\n",
                                    "parse_and_extract_quotes({}) # Will raise a parsing error\n",
                                    "```\n",
                                    "\n",
                                    "This code demonstrates how to handle parsing errors when using `BeautifulSoup`. The `try` block attempts to parse the **HTML** content and extract quotes. If an error occurs during parsing, the `except` block catches the exception and prints an error message.\n",
                                    "\n",
                                    "### Handling Missing Attributes and Data\n",
                                    "\n",
                                    "Attribute errors occur when an expected **HTML** element or attribute is missing. For instance, if a `span` tag with the class `text` is not found, an `AttributeError` will be raised.\n",
                                    "\n",
                                    "We can use `try` and `except` blocks to handle missing attributes gracefully. Here's how:\n",
                                    "\n",
                                    "```python\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "import requests\n",
                                    "\n",
                                    "html = fetch_page('http://quotes.toscrape.com/')\n",
                                    "\n",
                                    "def parse_and_extract_quotes(html):\n",
                                    "    try:\n",
                                    "        soup = BeautifulSoup(html, 'html.parser')\n",
                                    "        quotes = soup.find_all('div', class_='quote')\n",
                                    "        quote = quotes[0]\n",
                                    "        try:\n",
                                    "            text = quote.find('span', class_='text').get_text()\n",
                                    "            author = quote.find('small', class_='author').get_text()\n",
                                    "            tags = [tag.get_text() for tag in quote.find_all('a', class_='tag')]\n",
                                    "            invalid_attribute = quote.find('invalid', class_='invalid').get_text() # This will raise an AttributeError\n",
                                    "            print(text, author, tags, invalid_attribute)\n",
                                    "        except AttributeError as e:\n",
                                    "            print(f\"Attribute error: {e}\")\n",
                                    "    except Exception as e:\n",
                                    "        print(f\"Parsing error: {e}\")\n",
                                    "\n",
                                    "if html:\n",
                                    "    parse_and_extract_quotes(html)\n",
                                    "```\n",
                                    "\n",
                                    "In this code:\n",
                                    "\n",
                                    "  - The inner `try` block attempts to extract the `text`, `author`, and `tags` from each quote which are expected attributes. However, it also tries to extract an `invalid` attribute that doesn't exist.\n",
                                    "  - The `except AttributeError` block catches any missing attribute errors and logs the error message.\n",
                                    "\n",
                                    "In this case, we catch the `AttributeError` and print an error message. This helps us identify and handle missing attributes without causing the script to crash.\n",
                                    "\n",
                                    "### Summary\n",
                                    "\n",
                                    "In this lesson, we covered the basics of error handling in web scraping. We discussed how to handle **HTTP** errors, parsing errors, and missing attributes gracefully. By now, you should feel comfortable handling various issues that may arise during web scraping. This will make your scripts more robust and reliable.\n",
                                    "\n",
                                    "Keep practicing these concepts to master error management in web scraping. Happy scraping\\!"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Run and Observe Error Handling\n",
                                    "\n",
                                    "Great work on learning about error handling in web scraping!\n",
                                    "\n",
                                    "Let's observe the code you saw in the lesson to see how it manages different types of errors. Run the code to see the result.\n",
                                    "\n",
                                    "As a refresher, this code will:\n",
                                    "\n",
                                    "Fetch a webpage and handle HTTP errors.\n",
                                    "Parse the HTML content and handle parsing errors.\n",
                                    "Extract quote details and handle missing attribute errors.\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "# URL to scrape\n",
                                    "url = 'http://quotes.toscrape.com'\n",
                                    "\n",
                                    "# Function to fetch the page content\n",
                                    "def fetch_page(url):\n",
                                    "    try:\n",
                                    "        response = requests.get(url)\n",
                                    "        response.raise_for_status()  # Check for HTTP errors\n",
                                    "        return response.text\n",
                                    "    except requests.HTTPError as e:\n",
                                    "        print(f\"HTTP error: {e}\")\n",
                                    "        return None\n",
                                    "\n",
                                    "# Function to parse and extract quote details\n",
                                    "def parse_and_extract_quotes(html):\n",
                                    "    try:\n",
                                    "        soup = BeautifulSoup(html, 'html.parser')\n",
                                    "        quotes = soup.find_all('div', class_='quote')\n",
                                    "        for quote in quotes:\n",
                                    "            try:\n",
                                    "                text = quote.find('span', class_='text').get_text()\n",
                                    "                author = quote.find('small', class_='author').get_text()\n",
                                    "                tags = [tag.get_text() for tag in quote.find_all('a', class_='tag')]\n",
                                    "                print({'text': text, 'author': author, 'tags': tags})\n",
                                    "\n",
                                    "                novels = quote.find_all('a', class_='novel').get_text()\n",
                                    "                print(novels)\n",
                                    "            except AttributeError as e:\n",
                                    "                print(f\"Attribute error encountered: {e}\")\n",
                                    "    except Exception as e:\n",
                                    "        print(f\"Parsing error: {e}\")\n",
                                    "\n",
                                    "# Fetch the page content\n",
                                    "html = fetch_page(url)\n",
                                    "\n",
                                    "if html:\n",
                                    "    # Parse and extract quotes if the page content is successfully retrieved\n",
                                    "    parse_and_extract_quotes(html)\n",
                                    "else:\n",
                                    "    print(\"An HTTP Error occurred.\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Based on the code provided, here is the output you can expect to see after running the script.\n",
                                    "\n",
                                    "-----\n",
                                    "\n",
                                    "The code will first successfully fetch the page from `http://quotes.toscrape.com`. It will then proceed to find each quote on the page, and for every single one, it will print a similar block of output.\n",
                                    "\n",
                                    "You will see a series of dictionaries printed, each containing the `text`, `author`, and `tags` for a quote. This shows the code is successfully extracting the main content.\n",
                                    "\n",
                                    "Directly below each of these dictionaries, you will see a repeated error message like this:\n",
                                    "\n",
                                    "```\n",
                                    "Attribute error encountered: 'list' object has no attribute 'get_text'\n",
                                    "```\n",
                                    "\n",
                                    "### What's Happening\n",
                                    "\n",
                                    "This error is an excellent example of a **robust scraper catching an unexpected issue**.\n",
                                    "\n",
                                    "The `AttributeError` occurs at this line:\n",
                                    "\n",
                                    "```python\n",
                                    "novels = quote.find_all('a', class_='novel').get_text()\n",
                                    "```\n",
                                    "\n",
                                    "Here's a breakdown of why:\n",
                                    "\n",
                                    "1.  **`find_all()` vs. `find()`:** The `find_all()` method is designed to return a list of all matching elements, even if that list contains only one item, or is empty. In this case, there are no elements on the page with the class `novel`, so `quote.find_all(...)` returns an empty list, `[]`.\n",
                                    "2.  **Calling a method that doesn't exist:** The `get_text()` method is for a single tag object, not for a list of tags. Since the code is trying to call `get_text()` on an empty list, Python raises an `AttributeError`.\n",
                                    "3.  **The code keeps running:** The `try...except AttributeError` block you see is what prevents the script from crashing. It gracefully catches the error, prints the informative message, and allows the `for` loop to continue processing the next quote.\n",
                                    "\n",
                                    "This demonstrates how **error handling** is crucial for building reliable web scrapers that can handle inconsistencies in a webpage's structure without failing completely."
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Fix the Scraping Script\n",
                                    "\n",
                                    "Great job handling errors so far! Now let's identify and fix an error in a script that scrapes quotes from a webpage.\n",
                                    "\n",
                                    "The script is supposed to fetch quotes from a webpage and print them. We simulated an attribute error in the script by changing the class name of the quote text element to txt instead of text. And we want to check if the exception handling is working correctly. However, the script is not handling the error as expected, it's giving a syntax error instead. Can you identify and fix the issue so that the script handles the attribute error gracefully?\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "# URL to scrape\n",
                                    "url = 'http://quotes.toscrape.com'\n",
                                    "\n",
                                    "# Function to fetch the page content\n",
                                    "def fetch_page(url):\n",
                                    "    try:\n",
                                    "        response = requests.get(url)\n",
                                    "        response.raise_for_status()  # Check for HTTP errors\n",
                                    "        return response.text\n",
                                    "    except requests.HTTPError as e:\n",
                                    "        print(f\"HTTP error: {e}\")\n",
                                    "        return None\n",
                                    "\n",
                                    "# Function to parse and extract quote details\n",
                                    "def parse_and_extract_quotes(html):\n",
                                    "    try:\n",
                                    "        soup = BeautifulSoup(html, 'html.parser')\n",
                                    "        quotes = soup.find_all('div', class_='quote')\n",
                                    "        for quote in quotes:\n",
                                    "            text = quote.find('span', class_='txt').get_text()\n",
                                    "            print(f\"Quote: {text}\")\n",
                                    "    catch Exception as e:\n",
                                    "        print(f\"Parsing error: {e}\")\n",
                                    "\n",
                                    "# Fetch the page content\n",
                                    "html = fetch_page(url)\n",
                                    "\n",
                                    "if html:\n",
                                    "    # Parse and extract quotes if the page content is successfully retrieved\n",
                                    "    parse_and_extract_quotes(html)\n",
                                    "else:\n",
                                    "    print(\"An HTTP Error occurred.\")\n",
                                    "```\n",
                                    "\n",
                                    "## Fix the Scraping Script\n",
                                    "\n",
                                    "Great job handling errors so far! Now let's identify and fix an error in a script that scrapes quotes from a webpage.\n",
                                    "\n",
                                    "The script is supposed to fetch quotes from a webpage and print them. We simulated an attribute error in the script by changing the class name of the quote text element to txt instead of text. And we want to check if the exception handling is working correctly. However, the script is not handling the error as expected, it's giving a syntax error instead. Can you identify and fix the issue so that the script handles the attribute error gracefully?\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "# URL to scrape\n",
                                    "url = 'http://quotes.toscrape.com'\n",
                                    "\n",
                                    "# Function to fetch the page content\n",
                                    "def fetch_page(url):\n",
                                    "    try:\n",
                                    "        response = requests.get(url)\n",
                                    "        response.raise_for_status()  # Check for HTTP errors\n",
                                    "        return response.text\n",
                                    "    except requests.HTTPError as e:\n",
                                    "        print(f\"HTTP error: {e}\")\n",
                                    "        return None\n",
                                    "\n",
                                    "# Function to parse and extract quote details\n",
                                    "def parse_and_extract_quotes(html):\n",
                                    "    try:\n",
                                    "        soup = BeautifulSoup(html, 'html.parser')\n",
                                    "        quotes = soup.find_all('div', class_='quote')\n",
                                    "        for quote in quotes:\n",
                                    "            text = quote.find('span', class_='txt').get_text()\n",
                                    "            print(f\"Quote: {text}\")\n",
                                    "    catch Exception as e:\n",
                                    "        print(f\"Parsing error: {e}\")\n",
                                    "\n",
                                    "# Fetch the page content\n",
                                    "html = fetch_page(url)\n",
                                    "\n",
                                    "if html:\n",
                                    "    # Parse and extract quotes if the page content is successfully retrieved\n",
                                    "    parse_and_extract_quotes(html)\n",
                                    "else:\n",
                                    "    print(\"An HTTP Error occurred.\")\n",
                                    "```\n",
                                    "\n",
                                    "This is an excellent sign\\! The error message you're seeing confirms that the script is now working exactly as intended.\n",
                                    "\n",
                                    "The `try...except` block we added is successfully catching the `AttributeError`, so the script isn't crashing. It's simply telling you that it couldn't find the text for each quote and is moving on.\n",
                                    "\n",
                                    "### Why You're Seeing the Error\n",
                                    "\n",
                                    "The error, `'NoneType' object has no attribute 'get_text'`, is happening because of this line:\n",
                                    "\n",
                                    "```python\n",
                                    "text = quote.find('span', class_='txt').get_text()\n",
                                    "```\n",
                                    "\n",
                                    "The `find()` method returned **`None`** because it couldn't find a `<span>` tag with the class `'txt'`. As a result, when the code tried to call `.get_text()` on the `None` object, it raised the error.\n",
                                    "\n",
                                    "To get the script to work correctly, you just need to fix the typo in the class name.\n",
                                    "\n",
                                    "### The Final Fix\n",
                                    "\n",
                                    "Change `'txt'` to the correct class name, which is **`'text'`**.\n",
                                    "\n",
                                    "Here is the complete and final working script:\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "# URL to scrape\n",
                                    "url = 'http://quotes.toscrape.com'\n",
                                    "\n",
                                    "# Function to fetch the page content\n",
                                    "def fetch_page(url):\n",
                                    "    try:\n",
                                    "        response = requests.get(url)\n",
                                    "        response.raise_for_status()\n",
                                    "        return response.text\n",
                                    "    except requests.HTTPError as e:\n",
                                    "        print(f\"HTTP error: {e}\")\n",
                                    "        return None\n",
                                    "\n",
                                    "# Function to parse and extract quote details\n",
                                    "def parse_and_extract_quotes(html):\n",
                                    "    try:\n",
                                    "        soup = BeautifulSoup(html, 'html.parser')\n",
                                    "        quotes = soup.find_all('div', class_='quote')\n",
                                    "        \n",
                                    "        for quote in quotes:\n",
                                    "            try:\n",
                                    "                # FIX: Change 'txt' back to 'text'\n",
                                    "                text_element = quote.find('span', class_='text')\n",
                                    "                if text_element:\n",
                                    "                    text = text_element.get_text()\n",
                                    "                    print(f\"Quote: {text}\")\n",
                                    "                else:\n",
                                    "                    print(\"Quote text element not found. Skipping.\")\n",
                                    "            except AttributeError as e:\n",
                                    "                print(f\"Attribute error encountered: {e}. Skipping this quote.\")\n",
                                    "        \n",
                                    "    except Exception as e:\n",
                                    "        print(f\"A general parsing error occurred: {e}\")\n",
                                    "\n",
                                    "# Fetch the page content\n",
                                    "html = fetch_page(url)\n",
                                    "\n",
                                    "if html:\n",
                                    "    parse_and_extract_quotes(html)\n",
                                    "else:\n",
                                    "    print(\"An HTTP Error occurred.\")\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Handling Errors in Web Scraping\n",
                                    "\n",
                                    "Great progress on learning about error handling so far!\n",
                                    "\n",
                                    "For this practice, let's focus on handling errors while fetching and parsing web pages. You need to complete the function fetch_page to handle HTTP errors and complete the function parse_and_extract_quotes to handle parsing and attribute errors.\n",
                                    "\n",
                                    "Complete the TODO comments and fill in the missing parts of the code to ensure the script is robust when encountering issues.\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "# URL to scrape\n",
                                    "url = 'http://quotes.toscrape.com'\n",
                                    "\n",
                                    "# Function to fetch the page content\n",
                                    "def fetch_page(url):\n",
                                    "    try:\n",
                                    "        response = requests.get(url)\n",
                                    "        # TODO: Handle HTTP errors with the raise_for_status method\n",
                                    "\n",
                                    "        return response.text\n",
                                    "    except requests.HTTPError as e:\n",
                                    "        print(f\"HTTP error: {e}\")\n",
                                    "        return None\n",
                                    "\n",
                                    "# Function to parse and extract quote details\n",
                                    "def parse_and_extract_quotes(html):\n",
                                    "    try:\n",
                                    "        soup = BeautifulSoup(html, 'html.parser')\n",
                                    "        quotes = soup.find_all('div', class_='quote')\n",
                                    "        for quote in quotes:\n",
                                    "            try:\n",
                                    "                text = quote.find('span', class_='text').get_text()\n",
                                    "                author = quote.find('small', class_='author').get_text()\n",
                                    "                tags = [tag.get_text() for tag in quote.find_all('a', class_='tag')]\n",
                                    "                print({'text': text, 'author': author, 'tags': tags})\n",
                                    "            # TODO: Handle missing attribute errors with an AttributeError exception\n",
                                    "                print(f\"Attribute error: {e}\")\n",
                                    "    # TODO: Handle parsing errors with a generic exception\n",
                                    "        print(f\"Parsing error: {e}\")\n",
                                    "\n",
                                    "# Fetch the page content\n",
                                    "html = fetch_page(url)\n",
                                    "\n",
                                    "if html:\n",
                                    "    # Parse and extract quotes if the page content is successfully retrieved\n",
                                    "    parse_and_extract_quotes(html)\n",
                                    "else:\n",
                                    "    print(\"An HTTP Error occurred.\")\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "# URL to scrape\n",
                                    "url = 'http://quotes.toscrape.com'\n",
                                    "\n",
                                    "# Function to fetch the page content\n",
                                    "def fetch_page(url):\n",
                                    "    try:\n",
                                    "        response = requests.get(url)\n",
                                    "        # TODO: Handle HTTP errors with the raise_for_status method\n",
                                    "        response.raise_for_status()\n",
                                    "\n",
                                    "        return response.text\n",
                                    "    except requests.HTTPError as e:\n",
                                    "        print(f\"HTTP error: {e}\")\n",
                                    "        return None\n",
                                    "\n",
                                    "# Function to parse and extract quote details\n",
                                    "def parse_and_extract_quotes(html):\n",
                                    "    try:\n",
                                    "        soup = BeautifulSoup(html, 'html.parser')\n",
                                    "        quotes = soup.find_all('div', class_='quote')\n",
                                    "        for quote in quotes:\n",
                                    "            try:\n",
                                    "                text = quote.find('span', class_='text').get_text()\n",
                                    "                author = quote.find('small', class_='author').get_text()\n",
                                    "                tags = [tag.get_text() for tag in quote.find_all('a', class_='tag')]\n",
                                    "                print({'text': text, 'author': author, 'tags': tags})\n",
                                    "            # TODO: Handle missing attribute errors with an AttributeError exception\n",
                                    "            except AttributeError as e:\n",
                                    "                print(f\"Attribute error: {e}\")\n",
                                    "    # TODO: Handle parsing errors with a generic exception\n",
                                    "    except Exception as e:\n",
                                    "        print(f\"Parsing error: {e}\")\n",
                                    "\n",
                                    "# Fetch the page content\n",
                                    "html = fetch_page(url)\n",
                                    "\n",
                                    "if html:\n",
                                    "    # Parse and extract quotes if the page content is successfully retrieved\n",
                                    "    parse_and_extract_quotes(html)\n",
                                    "else:\n",
                                    "    print(\"An HTTP Error occurred.\")\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Web Scraping Error Handling\n",
                                    "\n",
                                    "You've done a great job so far! Now, let's put everything together.\n",
                                    "\n",
                                    "In this final task, your goal is to write a complete web scraping script from scratch. Follow the instructions in the starter code to implement the logic.\n",
                                    "\n",
                                    "Good luck!\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "# URL to scrape\n",
                                    "url = 'http://quotes.toscrape.com'\n",
                                    "\n",
                                    "# Function to fetch the page content\n",
                                    "def fetch_page(url):\n",
                                    "    # TODO: Implement the function to fetch page content and handle HTTP errors\n",
                                    "    # Make sure to return the page content if the request is successful, otherwise return None\n",
                                    "\n",
                                    "    pass\n",
                                    "\n",
                                    "# Function to parse and extract quote details\n",
                                    "def parse_and_extract_quotes(html):\n",
                                    "    # TODO: Implement the function to parse HTML content and handle parsing errors with generic Exception\n",
                                    "    # Make sure to handle missing attributes for each quote while extracting quote text with AttributeError exception\n",
                                    "    pass\n",
                                    "\n",
                                    "# Fetch the page content\n",
                                    "html = fetch_page(url)\n",
                                    "\n",
                                    "if html:\n",
                                    "    # Parse and extract quotes if the page content is successfully retrieved\n",
                                    "    parse_and_extract_quotes(html)\n",
                                    "else:\n",
                                    "    print(\"An HTTP Error occurred.\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```python\n",
                                    "import requests\n",
                                    "from bs4 import BeautifulSoup\n",
                                    "\n",
                                    "# URL to scrape\n",
                                    "url = 'http://quotes.toscrape.com'\n",
                                    "\n",
                                    "# Function to fetch the page content\n",
                                    "def fetch_page(url):\n",
                                    "    # TODO: Implement the function to fetch page content and handle HTTP errors\n",
                                    "    # Make sure to return the page content if the request is successful, otherwise return None\n",
                                    "    try:\n",
                                    "        response = requests.get(url)\n",
                                    "        response.raise_for_status()\n",
                                    "        return response.text\n",
                                    "    except requests.HTTPError as e:\n",
                                    "        print(f\"HTTP error: {e}\")\n",
                                    "        return None\n",
                                    "    except requests.RequestException as e:\n",
                                    "        print(f\"An error occurred during the request: {e}\")\n",
                                    "        return None\n",
                                    "\n",
                                    "# Function to parse and extract quote details\n",
                                    "def parse_and_extract_quotes(html):\n",
                                    "    # TODO: Implement the function to parse HTML content and handle parsing errors with generic Exception\n",
                                    "    # Make sure to handle missing attributes for each quote while extracting quote text with AttributeError exception\n",
                                    "    try:\n",
                                    "        soup = BeautifulSoup(html, 'html.parser')\n",
                                    "        quotes = soup.find_all('div', class_='quote')\n",
                                    "        for quote in quotes:\n",
                                    "            try:\n",
                                    "                text = quote.find('span', class_='text').get_text()\n",
                                    "                author = quote.find('small', class_='author').get_text()\n",
                                    "                tags = [tag.get_text() for tag in quote.find_all('a', class_='tag')]\n",
                                    "                print({'text': text, 'author': author, 'tags': tags})\n",
                                    "            except AttributeError as e:\n",
                                    "                print(f\"Attribute error: {e}\")\n",
                                    "    except Exception as e:\n",
                                    "        print(f\"Parsing error: {e}\")\n",
                                    "\n",
                                    "# Fetch the page content\n",
                                    "html = fetch_page(url)\n",
                                    "\n",
                                    "if html:\n",
                                    "    # Parse and extract quotes if the page content is successfully retrieved\n",
                                    "    parse_and_extract_quotes(html)\n",
                                    "else:\n",
                                    "    print(\"An HTTP Error occurred.\")\n",
                                    "\n",
                                    "```"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
