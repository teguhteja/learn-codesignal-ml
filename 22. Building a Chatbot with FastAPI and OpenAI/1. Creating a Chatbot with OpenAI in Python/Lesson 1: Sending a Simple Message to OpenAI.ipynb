{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1: Sending a Simple Message to OpenAI\n",
    "\n",
    "\n",
    "Welcome to the first lesson of our course on creating a chatbot with OpenAI. In this lesson, we will explore the basics of interacting with OpenAI's API, which is a powerful tool for building chatbots. OpenAI provides advanced language models that can understand and generate human-like text, making it an excellent choice for chatbot development. Our goal in this lesson is to send a simple message to OpenAI's language model and receive a response. This foundational step will set the stage for more complex interactions in future lessons.\n",
    "\n",
    "## Setting Up Your Environment\n",
    "\n",
    "Before we can send a message to OpenAI, we need to set up our development environment. This involves installing the necessary tools and libraries. For this course, you will need the `openai` library, which allows us to interact with OpenAI's API.\n",
    "\n",
    "To install this library, you can use the following command in your terminal:\n",
    "\n",
    "```bash\n",
    "pip install openai\n",
    "```\n",
    "\n",
    "If you are using the CodeSignal platform, this library is pre-installed, so you can focus on writing and running your code without worrying about installation.\n",
    "\n",
    "## Setting the OpenAI API Key as an Environment Variable\n",
    "\n",
    "In this course, you'll be using the CodeSignal coding environment, where we've already set up everything you need to start working with OpenAI models. This means you don't need to worry about setting up an API key or configuring environment variablesâ€”it's all taken care of for you.\n",
    "\n",
    "However, it's still useful to understand how this process works in case you want to set it up on your own computer in the future. To work with OpenAI models outside of CodeSignal, you need to set up a payment method and obtain an API key from their website. This API key is essential for accessing OpenAI's services and making requests to their API.\n",
    "\n",
    "To keep your API key secure, you can use an environment variable. An environment variable is like a special note that your computer can read to find out important details, such as your OpenAI API key, without having to write it directly in your code. This helps keep your key safe and secure.\n",
    "\n",
    "If you were setting this up on your own system, here's how you would do it:\n",
    "\n",
    "### On macOS and Linux\n",
    "\n",
    "Open your terminal and use the export command to set the environment variable:\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY=your_api_key_here\n",
    "```\n",
    "\n",
    "### For Windows\n",
    "\n",
    "You can set the environment variable using the `set` command in the Command Prompt:\n",
    "\n",
    "```batch\n",
    "set OPENAI_API_KEY=your_api_key_here\n",
    "```\n",
    "\n",
    "If you are using PowerShell, use the following command:\n",
    "\n",
    "```powershell\n",
    "$env:OPENAI_API_KEY=\"your_api_key_here\"\n",
    "```\n",
    "\n",
    "These commands will set the environment variable for the current session. But remember, while using CodeSignal, you can skip these steps and jump straight into experimenting with OpenAI models.\n",
    "\n",
    "## Initializing the OpenAI Client\n",
    "\n",
    "Once the environment variable is set, you can initialize the OpenAI client in your script. This is done by importing the OpenAI class from the `openai` library and then creating an instance of it. The library will automatically identify your API key from the environment variable:\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "```\n",
    "\n",
    "By initializing the client in this manner, you ensure that your script is ready to authenticate requests to OpenAI's API securely.\n",
    "\n",
    "## Sending Your First Message to OpenAI\n",
    "\n",
    "Now that your environment is set up and your API client is configured, it's time to send your first message to OpenAI. We'll start by defining a simple user prompt and then use the `chat.completions.create` method to send this message to the AI model.\n",
    "\n",
    "Here's the code to accomplish this:\n",
    "\n",
    "```python\n",
    "# Define a simple user message to test the API\n",
    "prompt = \"Hi, can you tell me a joke?\"\n",
    "\n",
    "# Create a chat completion request to get the AI response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "```\n",
    "\n",
    "In this code, we define a user prompt asking the AI to tell a joke. The `chat.completions.create` method of the OpenAI client is used to send a message to the AI model and receive a response. It takes some basic parameters to function:\n",
    "\n",
    "- The `model` parameter specifies which AI model to use for generating the response. In this example, we use \"gpt-4\", which is a version of OpenAI's language model known for its advanced text understanding and generation capabilities.\n",
    "  \n",
    "- The `messages` parameter is a list of dictionaries where each dictionary represents a message in the conversation. Each dictionary must include a \"role\", which indicates the role of the message sender, such as \"user\" for the person interacting with the AI, and \"content\", which contains the actual text of the message.\n",
    "\n",
    "## Extracting and Displaying the AI's Reply\n",
    "\n",
    "After sending the message to OpenAI, the next step is to extract the AI's reply from the API response and display it. Here's how you can do that:\n",
    "\n",
    "```python\n",
    "# Extract the AI's response from the API result\n",
    "reply = response.choices[0].message.content.strip()\n",
    "\n",
    "# Show both sides of the conversation\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"Response:\", reply)\n",
    "```\n",
    "\n",
    "Once the `create` method is called, it returns a response object. To extract the AI's reply, you need to access the `choices` list from the response object, which contains possible responses generated by the AI. You then select the first choice with `choices[0]` and retrieve the message content using `message.content.strip()`, which removes any extra spaces or newlines.\n",
    "\n",
    "Finally, we print both the prompt and the AI's reply to see the interaction. This helps verify that the message was successfully sent and received. When you run this code, you should see an output similar to the following:\n",
    "\n",
    "```plaintext\n",
    "Prompt: Hi, can you tell me a joke?\n",
    "Response: Why don't scientists trust atoms? Because they make up everything!\n",
    "```\n",
    "\n",
    "This output demonstrates a successful interaction with the AI, where it responds to the user's prompt with a joke.\n",
    "\n",
    "## Example: Full Code Implementation\n",
    "\n",
    "Let's look at the complete code example for sending a message to OpenAI. This example includes all the steps we've discussed so far:\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Define a simple user message to test the API\n",
    "prompt = \"Hi, can you tell me a joke?\"\n",
    "\n",
    "# Create a chat completion request to get the AI response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "# Extract the AI's response from the API result\n",
    "reply = response.choices[0].message.content.strip()\n",
    "\n",
    "# Show both sides of the conversation\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"Response:\", reply)\n",
    "```\n",
    "\n",
    "## Summary and Next Steps\n",
    "\n",
    "In this lesson, we covered the essential steps to send a simple message to OpenAI's language model. We set up our environment, configured API access, and sent a message to receive a response. This foundational knowledge is crucial as we move forward in building more complex chatbot interactions.\n",
    "\n",
    "As you proceed to the practice exercises, I encourage you to experiment with different prompts and explore the AI's responses. This hands-on practice will reinforce what you've learned and prepare you for the next unit, where we'll delve deeper into handling API parameters. Keep up the great work, and enjoy the journey of creating your chatbot with OpenAI!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying Your First API Request to Get a Fun Fact\n",
    "\n",
    "Nice work! Now, let's put that knowledge into practice by sending your first message to OpenAI!\n",
    "\n",
    "Your task is to modify the existing prompt from asking for a joke to asking for a fun fact. This will help you see how different prompts can lead to different responses from the AI.\n",
    "\n",
    "Give it a try and see what interesting fact the AI shares with you!\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# TODO: Change the prompt to ask for a fun fact instead of a joke\n",
    "prompt = \"Hi, can you tell me a joke?\"\n",
    "\n",
    "# Create a chat completion request to get the AI response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "# Extract the AI's response from the API result\n",
    "reply = response.choices[0].message.content.strip()\n",
    "\n",
    "# Show both sides of the conversation\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"Response:\", reply)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "To modify the code to ask for a fun fact instead of a joke, you just need to update the prompt message. Here's the updated code:\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Change the prompt to ask for a fun fact instead of a joke\n",
    "prompt = \"Hi, can you tell me a fun fact?\"\n",
    "\n",
    "# Create a chat completion request to get the AI response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "# Extract the AI's response from the API result\n",
    "reply = response.choices[0].message.content.strip()\n",
    "\n",
    "# Show both sides of the conversation\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"Response:\", reply)\n",
    "```\n",
    "\n",
    "In this updated code:\n",
    "- The `prompt` variable now asks, \"Hi, can you tell me a fun fact?\".\n",
    "- The rest of the process remains the same, calling the OpenAI API and receiving a response.\n",
    "\n",
    "When you run this, you should receive a fun fact from the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switching Models to Improve Reasoning Accuracy\n",
    "\n",
    "You've done well sending your first message to OpenAI. Now, let's make a small but important change to the code.\n",
    "\n",
    "Here's what you need to do:\n",
    "\n",
    "Run the code as it is using the \"gpt-4\" model and observe the AI's response. Since \"gpt-4\" doesn't specialize in reasoning, it is more likely to answer this question incorrectly.\n",
    "Modify the model to \"o3-mini\" and run the code again. The \"o3-mini\" model is known for its reasoning capabilities, making it more likely to correctly answer questions that require logic.\n",
    "This will help you understand how to specify different models when interacting with OpenAI's API.\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Define a simple user message to test the API\n",
    "prompt = \"How many times does the letter 'r' appear in the word 'strawberry'?\"\n",
    "\n",
    "# TODO: Change the model to \"o3-mini\"\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "# Extract the AI's response from the API result\n",
    "reply = response.choices[0].message.content.strip()\n",
    "\n",
    "# Show both sides of the conversation\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"Response:\", reply)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "To improve reasoning accuracy, you'll need to modify the model to `\"o3-mini\"` as instructed. Below is the updated code:\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Define a simple user message to test the API\n",
    "prompt = \"How many times does the letter 'r' appear in the word 'strawberry'?\"\n",
    "\n",
    "# Change the model to \"o3-mini\" for better reasoning capabilities\n",
    "response = client.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "# Extract the AI's response from the API result\n",
    "reply = response.choices[0].message.content.strip()\n",
    "\n",
    "# Show both sides of the conversation\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"Response:\", reply)\n",
    "```\n",
    "\n",
    "### What's changed:\n",
    "- The model has been updated from `\"gpt-4\"` to `\"o3-mini\"`. The \"o3-mini\" model has improved reasoning abilities, which should allow it to better handle logical or reasoning-based questions like counting the number of occurrences of a letter.\n",
    "\n",
    "Now, when you run the code, you should get a more accurate response to the question!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing a Bug in API Response Handling\n",
    "\n",
    "Now, let's tackle a small bug in the code. Your task is to find and fix this bug that prevents us from seeing the AI's response.\n",
    "\n",
    "This exercise will help you understand how to handle API responses effectively. Dive in and see how you can make the interaction work smoothly!\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Define a simple user message to test the API\n",
    "prompt = \"If animals could talk, what would a dog say about its day?\"\n",
    "\n",
    "# Create a chat completion request to get the AI response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "# Extract the AI's response from the API result\n",
    "reply = response.choices.message.content.strip()\n",
    "\n",
    "# Show both sides of the conversation\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"Response:\", reply)\n",
    "```\n",
    "\n",
    "The issue in the code lies in the way the response is being accessed. The `choices` attribute of the response is a list, so the code should reference the first item of that list, i.e., `response.choices[0]`, instead of just `response.choices`.\n",
    "\n",
    "Here's the corrected version of the code:\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Define a simple user message to test the API\n",
    "prompt = \"If animals could talk, what would a dog say about its day?\"\n",
    "\n",
    "# Create a chat completion request to get the AI response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "# Extract the AI's response from the API result\n",
    "reply = response.choices[0].message.content.strip()  # Fixed here by using [0] to access the first choice\n",
    "\n",
    "# Show both sides of the conversation\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"Response:\", reply)\n",
    "```\n",
    "\n",
    "### Explanation of the fix:\n",
    "- The `response.choices` is a list, and you need to access the first element of the list to retrieve the response. The correct code is `response.choices[0].message.content`, which gets the content of the first choice.\n",
    "  \n",
    "Now, when you run the code, it should correctly display both the prompt and the AI's response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requesting Multiple AI Responses with the n Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completing a Basic OpenAI API Interaction"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
