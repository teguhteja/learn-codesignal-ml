{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Lesson 2: Exploring Model Parameters\n",
                                    "\n",
                                    "\n",
                                    "Selamat datang kembali! Di pelajaran sebelumnya, kamu telah belajar cara mengirim pesan sederhana ke model bahasa OpenAI dan menerima respons. Sekarang, kita akan melangkah lebih jauh dengan mengeksplorasi **parameter model** yang memungkinkan kamu menyesuaikan respons AI. Parameter ini penting untuk mengatur perilaku chatbot sesuai kebutuhan spesifik.\n",
                                    "\n",
                                    "Dalam pelajaran ini, kita akan fokus pada 4 parameter utama:\n",
                                    "\n",
                                    "- `max_tokens`\n",
                                    "- `temperature`\n",
                                    "- `presence_penalty`\n",
                                    "- `frequency_penalty`\n",
                                    "\n",
                                    "Memahami parameter ini akan membantumu mengontrol kreativitas, panjang, dan konten dari respons AI, serta meningkatkan fungsionalitas chatbot milikmu.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## ✂️ Controlling Response Length with `max_tokens`\n",
                                    "\n",
                                    "Parameter `max_tokens` menetapkan batas maksimum jumlah token yang dapat dihasilkan AI dalam respons-nya. Satu *token* bisa berupa satu kata penuh atau sebagian dari kata. Misalnya:\n",
                                    "\n",
                                    "- “chatbot” → 1 token\n",
                                    "- “hello” → bisa menjadi 2 token: “hel” dan “lo”\n",
                                    "\n",
                                    "Setelah mencapai batas ini, model akan **berhenti menghasilkan teks**, bahkan jika kalimat belum selesai.\n",
                                    "\n",
                                    "### 💡 Contoh penggunaan:\n",
                                    "```python\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"gpt-4\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=100\n",
                                    ")\n",
                                    "```\n",
                                    "\n",
                                    "❗ Perlu diingat: `max_tokens` **tidak membuat model menjadi ringkas**, tapi hanya membatasi panjang output untuk mengelola biaya dan penggunaan API.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## 🎨 Exploring `temperature`\n",
                                    "\n",
                                    "Parameter `temperature` mengontrol **tingkat kreativitas atau keacakan** dari respons AI.\n",
                                    "\n",
                                    "- Nilai rendah (misal `0.2`) → respons lebih **fokus dan dapat diprediksi**\n",
                                    "- Nilai tinggi (misal `0.8`) → respons lebih **beragam dan kreatif**\n",
                                    "\n",
                                    "### 💡 Contoh penggunaan:\n",
                                    "```python\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"gpt-4\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    temperature=0.7\n",
                                    ")\n",
                                    "```\n",
                                    "\n",
                                    "Dengan `temperature=0.7`, kamu mendapatkan keseimbangan antara kreativitas dan koherensi. Cobalah bereksperimen untuk menemukan nilai yang sesuai!\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## 🧠 Encouraging New Topics with `presence_penalty`\n",
                                    "\n",
                                    "Parameter `presence_penalty` mendorong AI untuk **membahas topik baru** dengan memberi penalti saat kata yang sama digunakan kembali.\n",
                                    "\n",
                                    "- `0.0` → AI lebih cenderung **mengulang** kata (fokus)\n",
                                    "- `1.0` → AI lebih terdorong untuk **menghindari pengulangan**\n",
                                    "\n",
                                    "### 💡 Contoh penggunaan:\n",
                                    "```python\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"gpt-4\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    presence_penalty=0.6\n",
                                    ")\n",
                                    "```\n",
                                    "\n",
                                    "Ini berguna jika kamu ingin menjaga agar percakapan tetap segar dan menarik.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## 🔁 Reducing Repetition with `frequency_penalty`\n",
                                    "\n",
                                    "Parameter `frequency_penalty` membantu **mengurangi pengulangan** dalam satu respons dengan menghukum penggunaan kata yang sama terlalu sering.\n",
                                    "\n",
                                    "- `0.0` → pengulangan diizinkan\n",
                                    "- `1.0` → pengulangan sangat dikurangi\n",
                                    "\n",
                                    "### 🔍 Perbedaan:\n",
                                    "- `presence_penalty`: mendorong topik baru\n",
                                    "- `frequency_penalty`: mengurangi kata/frasa yang sama dalam satu respons\n",
                                    "\n",
                                    "### 💡 Contoh penggunaan:\n",
                                    "```python\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"gpt-4\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    frequency_penalty=0.3\n",
                                    ")\n",
                                    "```\n",
                                    "\n",
                                    "Hasilnya adalah percakapan yang lebih **dinamis dan menarik**, namun tetap relevan.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## 🧪 Example: Implementing All Parameters in Code\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message to test the API\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"gpt-4\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    temperature=0.7,         # Controls response creativity\n",
                                    "    max_tokens=100,          # Limits response length\n",
                                    "    presence_penalty=0.6,    # Encourages new topics\n",
                                    "    frequency_penalty=0.3    # Reduces repetition\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "```\n",
                                    "\n",
                                    "Dengan menyetel parameter di atas, kamu dapat mengatur bagaimana AI merespons, menciptakan keseimbangan antara kreativitas, variasi, dan panjang teks.\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "## 🧾 Summary and Preparation for Practice\n",
                                    "\n",
                                    "📌 Dalam pelajaran ini, kamu telah belajar:\n",
                                    "- 📏 `max_tokens` untuk membatasi panjang teks\n",
                                    "- 🎲 `temperature` untuk mengatur kreativitas\n",
                                    "- 🧭 `presence_penalty` untuk memperluas topik\n",
                                    "- 🔄 `frequency_penalty` untuk menghindari pengulangan\n",
                                    "\n",
                                    "⚙️ Dengan menggunakan parameter ini, kamu bisa menyesuaikan respons AI agar sesuai dengan kebutuhan spesifik chatbot milikmu.\n",
                                    "\n",
                                    "➡️ **Selanjutnya**, kamu akan belajar cara mengelola *conversation history* dan jenis pesan. Jangan ragu untuk bereksperimen dengan parameter dan lihat efeknya secara langsung!\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Exploring Default AI Behavior with Basic Parameters\n",
                                    "\n",
                                    "Nice progress in understanding how to interact with the AI model! Now, let's see the default behavior of the AI without any additional parameters.\n",
                                    "\n",
                                    "Run the given code as it is, without making any changes to the parameters. This will give you a baseline for comparison when you start adding more parameters.\n",
                                    "\n",
                                    "Enjoy the process and see what the AI comes up with!\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# Get response with only model and messages parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"gpt-4\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "\n",
                                    "\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Controlling Response Length with max_tokens Parameter\n",
                                    "\n",
                                    "Now, let's focus on controlling the length of the AI's response. Your task is to add the max_tokens parameter to the code. This will help you ensure that the AI's responses are concise and within a desired length.\n",
                                    "\n",
                                    "Here's what you need to do:\n",
                                    "\n",
                                    "Add the max_tokens parameter to limit the response length.\n",
                                    "Set it to a value like 100 to see how it affects the output.\n",
                                    "This exercise will give you a clear view of how to manage response length effectively. Dive in and see the impact!\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"gpt-4\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    # TODO: Add the max_tokens parameter and set it to 100 to limit response length\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Berikut adalah versi yang sudah diperbarui dari kode tersebut dengan menambahkan parameter `max_tokens` untuk mengontrol panjang respon AI:\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"gpt-4\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=100  # ✅ Set max_tokens to limit response length\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "```\n",
                                    "\n",
                                    "### 📌 Penjelasan Singkat\n",
                                    "- `max_tokens=100`: Parameter ini membatasi jumlah token maksimum dalam respon. Ini sangat berguna agar respon tidak terlalu panjang, sehingga bisa lebih efisien dalam penggunaan API.\n",
                                    "\n",
                                    "Silakan jalankan dan amati bagaimana panjang respons menjadi lebih terkontrol! 🧪✨"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Adding Temperature Parameter to Control AI Creativity\n",
                                    "\n",
                                    "Nice work on understanding model parameters! Now, let's put that knowledge into practice by adding a key parameter to the code. Your task is to:\n",
                                    "\n",
                                    "Add the temperature parameter to control the AI's creativity.\n",
                                    "Set it to a low value for more focused responses, such as 0.2.\n",
                                    "This exercise will help you see how small changes can influence the AI's behavior. Dive in and see the impact firsthand!\n",
                                    "\n",
                                    "```python\n",
                                    "\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"gpt-4\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=100,\n",
                                    "    # TODO: Add the temperature parameter and set it to a low value\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "Berikut versi kode yang sudah ditambahkan parameter `temperature` dengan nilai rendah (misalnya `0.2`) untuk menghasilkan respon yang lebih fokus dan deterministik:\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"gpt-4\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=100,\n",
                                    "    temperature=0.2  # ✅ Low temperature for more focused, predictable output\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "```\n",
                                    "\n",
                                    "### 🔍 Penjelasan:\n",
                                    "- `temperature=0.2`: Menurunkan nilai ini membuat output AI lebih “aman” dan konsisten. Cocok untuk jawaban yang membutuhkan akurasi tinggi atau bahasa yang lebih formal.\n",
                                    "\n",
                                    "💡 **Coba ubah nilai ini nanti ke 0.7 atau 0.9 dan bandingkan perbedaannya** — kamu akan melihat variasi jawaban yang lebih kreatif dan imajinatif!"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Exploring High Temperature Settings in AI Response Generation\n",
                                    "\n",
                                    "Well done on exploring model parameters! Now, let's see how the setting the temperature too high affects AI responses.\n",
                                    "\n",
                                    "Your task is to change the temperature from 0.2 to a much higher value, such as 1.7.\n",
                                    "\n",
                                    "Observe how this impacts the AI's creativity and randomness. Note that a super high temperature can make the response unpredictable and potentially out of control, leading to outputs that may lack coherence or relevance.\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"gpt-4\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=100,\n",
                                    "    temperature=0.2  # TODO: Set the temperature to 1.7\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "To experiment with the effect of a high temperature setting (such as 1.7), you can modify the code by changing the `temperature` parameter from `0.2` to `1.7`. Below is the updated version of your script:\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"gpt-4\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=100,\n",
                                    "    temperature=1.7  # Set the temperature to 1.7\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "```\n",
                                    "\n",
                                    "### What you can expect with a high temperature setting:\n",
                                    "- **Higher Creativity**: With a temperature of 1.7, the AI's response will be much more creative and less predictable. It may generate responses that are more imaginative and diverse.\n",
                                    "- **Increased Randomness**: The text may become more varied, with less adherence to logical progression. This could lead to more quirky or unexpected outputs.\n",
                                    "- **Less Coherence**: The response might lack structure or coherence, making it less reliable but potentially more engaging or surprising.\n",
                                    "\n",
                                    "By setting the temperature to 1.7, you're allowing the model to \"explore\" a wider range of possible completions, which can result in more unusual or novel responses."
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Implementing Presence Penalty to Encourage Topic Diversity\n",
                                    "\n",
                                    "Great job on mastering the basics of model parameters! Now, let's apply what you've learned by adding the presence_penalty parameter to the code.\n",
                                    "\n",
                                    "The presence_penalty parameter works by penalizing the AI for using words that have already appeared in the conversation, thus promoting diversity in the dialogue. A low value (e.g., 0.0) means less penalty, allowing the AI to repeat topics more freely, while a high value (e.g., 1.0) strongly encourages the AI to introduce new topics by avoiding repetition.\n",
                                    "\n",
                                    "Your task is to add the presence_penalty parameter with a value of 0.8 to encourage new topics in the AI's responses. This exercise will help you understand how to make conversations more dynamic. Jump in and see the difference it makes!\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# TODO: Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"gpt-4\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=100,\n",
                                    "    # TODO: Add presence_penalty parameter to encourage new topics\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "```\n",
                                    "\n",
                                    "\n",
                                    "To add the `presence_penalty` parameter, we can modify the code to include it in the `chat.completions.create` method. Setting the `presence_penalty` to a value of 0.8 will encourage the AI to introduce new topics and avoid repeating the same words or concepts, which can make the conversation more dynamic.\n",
                                    "\n",
                                    "Here's how you can modify the code to include `presence_penalty`:\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"gpt-4\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=100,\n",
                                    "    temperature=1.0,  # Optional: You can also set temperature to 1.0 for added creativity\n",
                                    "    presence_penalty=0.8  # Add presence_penalty to encourage new topics\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "```\n",
                                    "\n",
                                    "### Explanation of `presence_penalty`:\n",
                                    "- **Presence Penalty (`presence_penalty=0.8`)**: The value of `0.8` will penalize the AI if it repeats the same words or topics, encouraging the model to generate new or different content in its responses.\n",
                                    "- **Effect**: The AI will be more likely to introduce new ideas or subjects, rather than repeating or dwelling on the same topic. This can help maintain a more engaging and varied conversation.\n",
                                    "\n",
                                    "By adding this parameter, you’ll see how the AI responds differently, with more variation and creativity in its output."
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Reducing Repetition with Frequency Penalty Parameter\n",
                                    "\n",
                                    "You've done well in understanding how to control AI responses! Now, let's focus on customizing the AI's output by using the frequency_penalty parameter to minimize repetition.\n",
                                    "\n",
                                    "The frequency_penalty parameter helps reduce repetition in the AI's responses by penalizing the AI for using the same words or phrases multiple times within its response. A low value (e.g., 0.0) allows for more repetition, while a high value (e.g., 1.0) discourages it. In this task, setting it to 0.9 will strongly reduce repetition, encouraging more varied and dynamic responses.\n",
                                    "\n",
                                    "Your task is to add the frequency_penalty parameter with a value of 0.9 to the code. This will result in responses that avoid repeating words, making the conversation more engaging and diverse.\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# TODO: Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"gpt-4\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=100,\n",
                                    "    # TODO: Add a very high frequency penalty to maximize repetition\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "To minimize repetition in the AI's responses, you can add the `frequency_penalty` parameter with a value of `0.9` in the `chat.completions.create` method. This will strongly discourage the AI from repeating the same words or phrases, leading to more dynamic and engaging responses.\n",
                                    "\n",
                                    "Here's the updated code with the `frequency_penalty` added:\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "# Initialize the OpenAI client\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# Define a simple user message\n",
                                    "prompt = \"Describe a sunset over the ocean\"\n",
                                    "\n",
                                    "# Get response with specific parameters\n",
                                    "response = client.chat.completions.create(\n",
                                    "    model=\"gpt-4\",\n",
                                    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                                    "    max_tokens=100,\n",
                                    "    temperature=1.0,  # Optional: for added creativity\n",
                                    "    presence_penalty=0.8,  # Optional: encourage new topics\n",
                                    "    frequency_penalty=0.9  # Add frequency_penalty to reduce repetition\n",
                                    ")\n",
                                    "\n",
                                    "# Process the response\n",
                                    "reply = response.choices[0].message.content.strip()\n",
                                    "print(\"Assistant:\", reply)\n",
                                    "```\n",
                                    "\n",
                                    "### Explanation of `frequency_penalty`:\n",
                                    "- **Frequency Penalty (`frequency_penalty=0.9`)**: This value of `0.9` discourages the model from repeating the same words or phrases multiple times within a response. It creates a more varied response by reducing redundancy.\n",
                                    "- **Effect**: The AI will produce a more diverse and engaging response by avoiding unnecessary repetitions of words or concepts.\n",
                                    "\n",
                                    "By setting the `frequency_penalty` to a high value, you ensure that the conversation remains fresh and avoids excessive redundancy in the output."
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
