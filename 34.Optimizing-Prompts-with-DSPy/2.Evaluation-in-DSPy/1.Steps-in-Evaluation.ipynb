{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Unit 1"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Steps in Evaluation\n",
                "\n",
                "Of course, here is the text you provided, translated into English and formatted in Markdown.\n",
                "\n",
                "-----\n",
                "\n",
                "# Introduction to Evaluation in DSPy\n",
                "\n",
                "Welcome to the first lesson of the **\"Evaluation in DSPy\"** course. In this lesson, we will explore the foundational steps involved in evaluating DSPy systems. Evaluation is a crucial part of developing any system, as it helps you understand how well your system performs and where improvements are needed.\n",
                "\n",
                "In DSPy, evaluation involves three main steps:\n",
                "\n",
                "1.  Collecting an initial development set.\n",
                "2.  Defining DSPy metrics.\n",
                "3.  Running development evaluations.\n",
                "\n",
                "By the end of this lesson, you will be equipped with the knowledge to systematically refine your DSPy projects through effective evaluation techniques.\n",
                "\n",
                "-----\n",
                "\n",
                "### Step 1: Collecting an Initial Development Set\n",
                "\n",
                "The first step in the evaluation process is to collect an initial development set. This set serves as the foundation for systematically refining your system. A development set typically consists of input examples that your system will process. Even a small set of 20 examples can be useful, though having around 200 examples can provide more comprehensive insights. Depending on your evaluation metric, you may need just the inputs or both the inputs and the final outputs of your system. This set will help you test and refine your system iteratively.\n",
                "\n",
                "-----\n",
                "\n",
                "### Step 2: Defining Your DSPy Metric\n",
                "\n",
                "Once you have your development set, the next step is to define your DSPy metric. A metric is a function that evaluates the outputs of your system and returns a score indicating their quality. It is essential to start with a simple metric and improve it incrementally over time. For instance, you might begin with a basic accuracy metric that checks if the system's output matches the expected result.\n",
                "\n",
                "Here is a simple example of a metric function:\n",
                "\n",
                "```python\n",
                "def validate_answer(example, pred, trace=None):\n",
                "    return example.answer.lower() == pred.answer.lower()\n",
                "```\n",
                "\n",
                "In this example, the `validate_answer` function compares the expected answer with the predicted answer, ignoring case differences. This simple metric can be a starting point for evaluating your system's performance.\n",
                "\n",
                "-----\n",
                "\n",
                "### Step 3: Running Development Evaluations\n",
                "\n",
                "With your development set and metric in place, you can now run development evaluations. This step involves testing your system's pipeline designs to understand their trade-offs. By examining the outputs and metric scores, you can identify any major issues and establish a baseline for future improvements.\n",
                "\n",
                "Here's a concise example of running an evaluation loop in Python:\n",
                "\n",
                "```python\n",
                "scores = []\n",
                "for x in devset:\n",
                "    pred = program(**x.inputs())\n",
                "    score = metric(x, pred)\n",
                "    scores.append(score)\n",
                "```\n",
                "\n",
                "In this code snippet, we iterate over the development set, generate predictions using the system, and calculate scores using the defined metric. This process helps you assess the system's performance and identify areas for enhancement.\n",
                "\n",
                "-----\n",
                "\n",
                "### Example Section: Applying the Evaluation Steps\n",
                "\n",
                "Let's walk through a practical example of applying the evaluation steps. Suppose you are developing a question-answering system. First, you collect a development set of question-answer pairs. Next, you define a simple metric to validate the system's answers. Finally, you run evaluations to interpret the results and refine your system.\n",
                "\n",
                "For instance, consider the following development set:\n",
                "\n",
                "```python\n",
                "qa_pair = dspy.Example(question=\"What is the capital of France?\", answer=\"Paris\")\n",
                "```\n",
                "\n",
                "You can define a metric to check if the system's answer matches the expected answer:\n",
                "\n",
                "```python\n",
                "def validate_answer(example, pred, trace=None):\n",
                "    return example.answer.lower() == pred.answer.lower()\n",
                "```\n",
                "\n",
                "Then, run the evaluation loop:\n",
                "\n",
                "```python\n",
                "scores = []\n",
                "for x in devset:\n",
                "    pred = program(**x.inputs())\n",
                "    score = metric(x, pred)\n",
                "    scores.append(score)\n",
                "```\n",
                "\n",
                "By analyzing the scores, you can determine how well your system performs and identify areas for improvement.\n",
                "\n",
                "-----\n",
                "\n",
                "### Summary and Preparation for Practice\n",
                "\n",
                "In this lesson, we covered the essential steps in evaluating DSPy systems: collecting an initial development set, defining DSPy metrics, and running development evaluations. Each step plays a vital role in refining your projects and ensuring their success. As you move forward, remember the importance of starting with simple metrics and iterating over time. Now, you are ready to apply what you've learned in the practice exercises that follow. These exercises will give you hands-on experience in evaluating DSPy systems, helping you solidify your understanding and skills. Good luck, and enjoy the journey of refining your DSPy projects\\!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## DSPy Evaluation Steps Quiz\n",
                "\n",
                "1.  **Collecting an initial development set.** This step is the foundation for the entire evaluation process.\n",
                "2.  **To evaluate the quality of system outputs.** A DSPy metric is a function designed specifically to score how well the system's output meets a certain standard.\n",
                "3.  **It compares the expected answer with the predicted answer, ignoring case differences.** The code `example.answer.lower() == pred.answer.lower()` explicitly converts both answers to lowercase before checking for equality.\n",
                "4.  **To test system pipeline designs and understand their trade-offs.** By running the evaluation loop, developers can get a baseline score and identify where their system is performing well or needs improvement before making further adjustments."
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
