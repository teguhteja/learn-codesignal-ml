{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Lesson 1: Implementing Bagging with Decision Trees in Python\n",
                                    "\n",
                                    "# Implementing Bagging with Decision Trees in Python\n",
                                    "\n",
                                    "## Introduction\n",
                                    "Welcome to our exploration of implementing bagging. This lesson expands upon your machine learning toolkit by introducing you to the bagging technique and illustrating its use with decision trees. You will also gain hands-on experience with these concepts through a Python implementation. So, let's embark on our bagging adventure!\n",
                                    "\n",
                                    "## Understanding Bagging\n",
                                    "Bagging, or bootstrap aggregating, is a technique in ensemble learning that aims to reduce the variance of the machine learning model. The essence of bagging involves generating multiple subsets from the original dataset and then using these subsets to train separate models. Note that the subsets are chosen with replacement, so it is possible to have duplicate data points in a single subset. The final prediction is then made by aggregating the predictions from these individual models. Essentially, it is a voting for the best answer: the final class prediction is the class that was predicted by the majority of votes.\n",
                                    "\n",
                                    "We will use decision trees as our base models. Capable of supporting both categorical and continuous input variables, decision trees follow sequential, hierarchical decision rules to output a final decision.\n",
                                    "\n",
                                    "## Python Implementation and Code Walkthrough: Initializations and Data Loading\n",
                                    "Our Python implementation calls upon several libraries, such as `numpy` for advanced mathematical computations on multi-dimensional arrays, `sklearn` for providing machine learning and statistical modeling tools, and `scipy` for statistical functions.\n",
                                    "\n",
                                    "First, we load our dataset. For this lesson, we use the widely recognized iris dataset, which we split into training and test data. The iris dataset is popular in data science and machine learning. It contains measurements of 150 iris flowers from three different species - setosa, versicolor, and virginica. The measurements include the lengths and the widths of the sepals and petals of the flowers.\n",
                                    "\n",
                                    "The variable `n_models`, set here as 100, determines the number of decision tree classifiers we plan to build.\n",
                                    "\n",
                                    "```python\n",
                                    "import numpy as np\n",
                                    "from scipy import stats\n",
                                    "from sklearn import datasets\n",
                                    "from sklearn.metrics import accuracy_score\n",
                                    "from sklearn.model_selection import train_test_split\n",
                                    "from sklearn.tree import DecisionTreeClassifier\n",
                                    "\n",
                                    "# Load the data\n",
                                    "iris = datasets.load_iris()\n",
                                    "X = iris.data\n",
                                    "y = iris.target\n",
                                    "\n",
                                    "# Split the data into train and test sets\n",
                                    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
                                    "\n",
                                    "# Parameters\n",
                                    "n_models = 100\n",
                                    "random_states = [i for i in range(n_models)]\n",
                                    "```\n",
                                    "\n",
                                    "## Python Implementation and Code Walkthrough: Bagging Algorithm\n",
                                    "Next, we define our helper functions, `bootstrapping` and `predict`, which are pivotal to constructing our bagging model.\n",
                                    "\n",
                                    "Subsequently, we iteratively train our decision tree models, make predictions, and calculate the model's accuracy using `sklearn`'s `accuracy_score()` function.\n",
                                    "\n",
                                    "```python\n",
                                    "# Helper function for bootstrapping\n",
                                    "def bootstrapping(X, y):\n",
                                    "    n_samples = X.shape[0]\n",
                                    "    idxs = np.random.choice(n_samples, n_samples, replace=True)\n",
                                    "    return X[idxs], y[idxs]\n",
                                    "```\n",
                                    "\n",
                                    "The bootstrapping function generates bootstrapped datasets, choosing random subsets from the data.\n",
                                    "\n",
                                    "```python\n",
                                    "# Helper function for bagging prediction\n",
                                    "def predict(X, models):\n",
                                    "    predictions = np.array([model.predict(X) for model in models])\n",
                                    "    predictions = stats.mode(predictions)[0]\n",
                                    "    return predictions\n",
                                    "```\n",
                                    "\n",
                                    "The `predict` function consolidates predictions from various trained models to deliver the final decision. We use mode (the most frequent prediction) as the final answer.\n",
                                    "\n",
                                    "```python\n",
                                    "# Create a list to store all the tree models\n",
                                    "tree_models = []\n",
                                    "\n",
                                    "# Iteratively train decision trees on bootstrapped samples\n",
                                    "for i in range(n_models):\n",
                                    "    X_, y_ = bootstrapping(X_train, y_train)\n",
                                    "    tree = DecisionTreeClassifier(max_depth=2, random_state=random_states[i])\n",
                                    "    tree.fit(X_, y_)\n",
                                    "    tree_models.append(tree)\n",
                                    "\n",
                                    "# Predict on the test set\n",
                                    "y_pred = predict(X_test, tree_models)\n",
                                    "\n",
                                    "# Print the accuracy\n",
                                    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
                                    "```\n",
                                    "\n",
                                    "We can freely use another model instead of decision trees; they are chosen as an example.\n",
                                    "\n",
                                    "## Model Evaluation, Lesson Summary, and Practice\n",
                                    "After implementing a model, we must evaluate its performance. In our bagging model, the accuracy score serves as a performance metric: the ratio of correct predictions to the total number of predictions. We utilize `sklearn`'s `accuracy_score()` function to calculate this metric and gauge the performance of our model.\n",
                                    "\n",
                                    "Congratulations! You've successfully navigated the basics of bagging with decision trees. You've learned about the fundamentals of bagging, implemented a bagging algorithm using decision trees in Python, and assessed the model's accuracy. Your understanding of these concepts will be further solidified through exercises in the next section. Have fun practicing!\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Ensemble Predictions with Bagging and Decision Trees"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Navigating the Data Cosmos with Bootstrapping and Prediction Functions"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Implementing Bootstrapping and Prediction in Ensemble Learning"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Predicting with Bagging and Decision Trees"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Observing Bagging with Decision Trees in Action"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
