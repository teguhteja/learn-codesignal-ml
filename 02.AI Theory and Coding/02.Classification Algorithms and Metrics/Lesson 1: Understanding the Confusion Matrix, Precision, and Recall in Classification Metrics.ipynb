{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Lesson 1: Understanding the Confusion Matrix, Precision, and Recall in Classification Metrics\n",
                                    "\n",
                                    "Here's the markdown version of the content you provided:\n",
                                    "\n",
                                    "---\n",
                                    "\n",
                                    "# Understanding the Confusion Matrix, Precision, and Recall in Classification Metrics\n",
                                    "\n",
                                    "## Introduction\n",
                                    "\n",
                                    "Welcome! Today, we are peeling back the layers of classification metrics, notably the confusion matrix, precision, and recall. This lesson delves into their theory and provides a practical illustration in Python.\n",
                                    "\n",
                                    "## Theory of Confusion Matrix\n",
                                    "\n",
                                    "The performance of binary classifiers is evaluated by comparing predicted and actual values; this structure is encoded as a **confusion matrix**. A confusion matrix produces four outcomes:\n",
                                    "\n",
                                    "- **True Positive (TP):** Correct positive prediction.\n",
                                    "- **True Negative (TN):** Correct negative prediction.\n",
                                    "- **False Positive (FP):** Incorrect positive prediction.\n",
                                    "- **False Negative (FN):** Incorrect negative prediction.\n",
                                    "\n",
                                    "Consider an email spam filter, classifying Spam (positive) and Not Spam (negative) as follows:\n",
                                    "\n",
                                    "| Actual \\ Predicted  | Spam (Predicted)      | Not Spam (Predicted)  |\n",
                                    "|---------------------|-----------------------|-----------------------|\n",
                                    "| **Spam (Actual)**   | True Positives (TP)    | False Negatives (FN)   |\n",
                                    "| **Not Spam (Actual)** | False Positives (FP)  | True Negatives (TN)    |\n",
                                    "\n",
                                    "## Understanding Precision and Recall\n",
                                    "\n",
                                    "The simplest way to measure the model's performance is to calculate its **accuracy**, simply the percentage of the correct predictions.\n",
                                    "\n",
                                    "Accuracy measures total correct guesses, but it canâ€™t tell the difference between certain errors. If you're often wrong about specific things, accuracy won't show it, which is a problem for particular tasks. For example, in medical tests, we want to minimize the number of incorrect negative predictions (False Negatives) so we don't let the disease slip away in the early stages.\n",
                                    "\n",
                                    "**Precision** and **recall** are vital metrics for assessing classifiers:\n",
                                    "\n",
                                    "- **Precision** tells us how often we're correct when we make a positive prediction.\n",
                                    "- **Recall** tells us how frequently we catch actual positives.\n",
                                    "\n",
                                    "These two metrics give us a clearer picture of our strong or weak prediction skills, which is crucial in real-life situations.\n",
                                    "\n",
                                    "\\[\n",
                                    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
                                    "\\]\n",
                                    "\n",
                                    "\\[\n",
                                    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
                                    "\\]\n",
                                    "\n",
                                    "Let's bring these metrics to life using Python.\n",
                                    "\n",
                                    "## Implementing Confusion Matrix in Python\n",
                                    "\n",
                                    "We'll assemble a confusion matrix using a binary classification:\n",
                                    "\n",
                                    "```python\n",
                                    "import numpy as np\n",
                                    "\n",
                                    "true_labels = np.array([0, 0, 1, 1, 0, 1, 0, 1, 1, 1])\n",
                                    "predicted_labels = np.array([0, 1, 0, 1, 0, 1, 1, 1, 1, 0])\n",
                                    "\n",
                                    "TP = np.sum((predicted_labels == 1) & (true_labels == 1))\n",
                                    "TN = np.sum((predicted_labels == 0) & (true_labels == 0))\n",
                                    "FP = np.sum((predicted_labels == 1) & (true_labels == 0))\n",
                                    "FN = np.sum((predicted_labels == 0) & (true_labels == 1))\n",
                                    "\n",
                                    "print(\"Confusion Matrix:\\n TP: \", TP, \"\\tFP: \", FP, \"\\n FN: \", FN, \"\\tTN: \", TN)\n",
                                    "```\n",
                                    "\n",
                                    "**Output:**\n",
                                    "\n",
                                    "```\n",
                                    "Confusion Matrix:\n",
                                    " TP:  4 \tFP:  2 \n",
                                    " FN:  2 \tTN:  2\n",
                                    "```\n",
                                    "\n",
                                    "The code uses numpy's bitwise `&` operator to perform element-wise comparison between the `predicted_labels` and `true_labels` arrays. It then uses numpy's `sum` function to count the number of `True` values in the resulting comparison and assigns these counts to the `TP`, `TN`, `FP`, and `FN` variables.\n",
                                    "\n",
                                    "## Implementing Precision and Recall Functions in Python\n",
                                    "\n",
                                    "We use the confusion matrix variables to calculate precision and recall:\n",
                                    "\n",
                                    "```python\n",
                                    "def calculate_precision(TP, FP):\n",
                                    "    return TP / (TP + FP)\n",
                                    "\n",
                                    "def calculate_recall(TP, FN):\n",
                                    "    return TP / (TP + FN)\n",
                                    "\n",
                                    "precision = calculate_precision(TP, FP)\n",
                                    "recall = calculate_recall(TP, FN)\n",
                                    "\n",
                                    "print(\"Precision: \", round(precision, 2))  # 0.67\n",
                                    "print(\"Recall: \", round(recall, 2))  # 0.67\n",
                                    "```\n",
                                    "\n",
                                    "Our Python script defines two functions: `calculate_precision` and `calculate_recall`. These return precision and recall, respectively. Finally, we print the values of precision and recall.\n",
                                    "\n",
                                    "## Summary and Real-World Application\n",
                                    "\n",
                                    "The confusion matrix, precision, and recall form the foundation for performance measurement in classification tasks. They help us understand our model's functionality, which is becoming vital in real-world applications. For instance, in medical or spam classification scenarios, emphasis may shift between precision and recall depending on the specific evaluation aspect.\n",
                                    "\n",
                                    "Congratulations! You've untangled the mysteries of the Confusion Matrix, Precision, and Recall metrics and their implementation in Python. Let's get to practice!\n",
                                    "\n",
                                    "---"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Calculating True Negatives and False Positives in Medical Diagnostics"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Precision and Recall in Medical Diagnostics"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Precision Calculation in Medical Diagnostics"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Medical Test Recall Calculation Correction"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Calculating Precision and Recall in Medical Diagnostics"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
