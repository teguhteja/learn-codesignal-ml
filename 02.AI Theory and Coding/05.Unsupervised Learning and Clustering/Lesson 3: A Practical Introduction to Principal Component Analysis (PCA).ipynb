{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Lesson 3: A Practical Introduction to Principal Component Analysis (PCA)\n",
                                    "\n",
                                    "# A Practical Introduction to Principal Component Analysis (PCA)\n",
                                    "\n",
                                    "## An Introduction to Principal Component Analysis (PCA)\n",
                                    "Let's dive into **Principal Component Analysis (PCA)**, a technique often used in machine learning to simplify complex data while keeping important details. PCA transforms datasets with many closely connected parts into datasets where parts do not directly relate to each other. Think of it as organizing a messy room and putting everything in clear, separate bins.\n",
                                    "\n",
                                    "## Make A Simple Dataset\n",
                                    "To start using PCA, we'll create a simple 3D dataset of 200 points:\n",
                                    "\n",
                                    "```python\n",
                                    "import numpy as np\n",
                                    "import matplotlib.pyplot as plt\n",
                                    "from mpl_toolkits.mplot3d import Axes3D\n",
                                    "\n",
                                    "np.random.seed(0)\n",
                                    "# Creating 200-point 3D dataset\n",
                                    "X = np.dot(np.random.random(size=(3, 3)), np.random.normal(size=(3, 200))).T\n",
                                    "# Plotting the dataset\n",
                                    "fig = plt.figure()\n",
                                    "ax = fig.add_subplot(111, projection='3d')\n",
                                    "ax.scatter(X[:,0], X[:,1], X[:,2])\n",
                                    "plt.title(\"Scatter Plot of Original Dataset\")\n",
                                    "plt.show()\n",
                                    "```\n",
                                    "\n",
                                    "## Standardizing the Dataset\n",
                                    "Before applying PCA, we need to standardize our dataset. This ensures that all features have a mean of 0 and a similar range of values:\n",
                                    "\n",
                                    "```python\n",
                                    "# Calculate the mean and the standard deviation\n",
                                    "X_mean = np.mean(X, axis=0)\n",
                                    "X_std = np.std(X, axis=0)\n",
                                    "# Make the dataset standard\n",
                                    "X = (X - X_mean) / X_std\n",
                                    "```\n",
                                    "\n",
                                    "The above code calculates the dataset's average (`np.mean`) and spread (`np.std`), and then adjusts each point accordingly.\n",
                                    "\n",
                                    "## Covariance Matrix\n",
                                    "Next, we calculate the **covariance matrix**, which shows how much two variables correlate:\n",
                                    "\n",
                                    "```python\n",
                                    "# Calculate Covariance Matrix\n",
                                    "cov_matrix = np.cov(X.T)\n",
                                    "```\n",
                                    "\n",
                                    "We use `np.cov` to compute the covariance matrix.\n",
                                    "\n",
                                    "## Eigendecomposition\n",
                                    "The covariance matrix is then decomposed into **eigenvectors** and **eigenvalues**. This process helps us understand the direction and magnitude of the data's spread:\n",
                                    "\n",
                                    "```python\n",
                                    "# Break into eigenvectors and eigenvalues\n",
                                    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
                                    "```\n",
                                    "\n",
                                    "Eigenvalues represent the spread of the data, while eigenvectors represent the direction of that spread.\n",
                                    "\n",
                                    "## Sorting Eigenvalues and Eigenvectors\n",
                                    "We sort the eigenvalues and their corresponding eigenvectors in descending order to identify the principal components:\n",
                                    "\n",
                                    "```python\n",
                                    "# Sort out eigenvalues and corresponding eigenvectors\n",
                                    "eigen_pairs = [(np.abs(eigenvalues[i]), eigenvectors[:,i]) for i in range(len(eigenvalues))]\n",
                                    "eigen_pairs.sort(reverse=True)\n",
                                    "```\n",
                                    "\n",
                                    "## Projecting the Original Dataset\n",
                                    "Now that we have sorted the eigenvalues, we can select the top `k` eigenvectors to form the projection matrix. This step allows us to transform the original dataset into fewer dimensions:\n",
                                    "\n",
                                    "```python\n",
                                    "# Make the projection matrix\n",
                                    "W = np.hstack((eigen_pairs[0][1].reshape(3,1), eigen_pairs[1][1].reshape(3,1)))\n",
                                    "# Change the original dataset\n",
                                    "X_pca = X.dot(W)\n",
                                    "```\n",
                                    "\n",
                                    "## Visualizing Results\n",
                                    "Finally, we visualize the simplified dataset after applying PCA, showing how we've reduced it from three dimensions to two without losing important information:\n",
                                    "\n",
                                    "```python\n",
                                    "plt.figure()\n",
                                    "plt.scatter(X_pca[:, 0], X_pca[:, 1])\n",
                                    "plt.title(\"Scatter Plot of Transformed Dataset Using PCA\")\n",
                                    "plt.show()\n",
                                    "```\n",
                                    "\n",
                                    "This graph demonstrates how PCA simplified the data while retaining its essential structure.\n",
                                    "\n",
                                    "## Wrapping Up\n",
                                    "Well done! You've just learned about **Principal Component Analysis (PCA)**, a powerful technique for simplifying data without losing important details. Now it's time for you to practice! Remember, practice is the key to mastering any new concept. Keep learning!\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Visualizing Dimension Reduction with PCA"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Expanding the Horizon with Two Principal Components"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Unveiling the Secrets of PCA: Eigendecomposition and Transformation"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
