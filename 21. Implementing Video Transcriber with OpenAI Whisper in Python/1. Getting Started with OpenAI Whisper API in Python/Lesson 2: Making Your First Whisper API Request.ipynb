{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Lesson 2: Making Your First Whisper API Request\n",
                                    "\n",
                                    "Welcome back! In the previous lesson, we set up a development environment using a virtual environment and installed the necessary dependencies to interact with the OpenAI API. Today, we're diving into making your first API request using Whisper, which is crucial for creating a transcription system. This builds on your understanding of environment setup and Python scripting, and now we’ll focus on interacting with APIs.\n",
                                    "\n",
                                    "You'll learn to transform audio data into text using the Whisper API.\n",
                                    "\n",
                                    "## Understanding Making Your First Whisper API Request\n",
                                    "\n",
                                    "The Whisper API from OpenAI is designed to handle audio transcription. The core idea is to send audio data to the API, which then returns a transcribed text. This process begins with a valid API key that authenticates your requests. The API interprets byte-stream data from audio files, transcribing what’s spoken into text with varying levels of detail depending on its configuration.\n",
                                    "\n",
                                    "While Whisper handles diverse audio inputs, it primarily focuses on capturing spoken content and might skip non-verbal sounds while ensuring the output is human-readable. The result is a JSON object containing the transcribed text and, sometimes, details like the duration of the audio.\n",
                                    "\n",
                                    "## Making Your First API Request\n",
                                    "\n",
                                    "Let’s explore a simple example demonstrating how to make your first transcription request using the Whisper API:\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "def transcribe_audio(file_path):\n",
                                    "    \"\"\"\n",
                                    "    Transcribe an audio file using OpenAI's Whisper API.\n",
                                    "    \"\"\"\n",
                                    "    try:\n",
                                    "        with open(file_path, 'rb') as audio_file:\n",
                                    "            transcript = client.audio.transcriptions.create(\n",
                                    "                model=\"whisper-1\",\n",
                                    "                file=audio_file,\n",
                                    "                timeout=60\n",
                                    "            )\n",
                                    "            return transcript.text\n",
                                    "    except Exception as e:\n",
                                    "        raise Exception(f\"Transcription failed: {str(e)}\")\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    result = transcribe_audio(\"resources/sample_audio.mp3\")\n",
                                    "    print(\"Transcription:\", result)\n",
                                    "```\n",
                                    "\n",
                                    "### This code demonstrates the transcription process:\n",
                                    "\n",
                                    "1. **Client Initialization**: Instantiate an `openai.OpenAI` client. This client manages your requests to the OpenAI API, authenticated by the previously loaded API key. This client automatically uses the `OPENAI_API_KEY` environment variable for authentication.\n",
                                    "\n",
                                    "2. **File Handling**: Open the audio file in binary read mode (\"rb\"). Reading as bytes ensures the data format is suitable for API processing.\n",
                                    "\n",
                                    "3. **API Call**: The `client.audio.transcriptions.create` method submits the audio data for transcription. The model specifies which version of Whisper to use, in this case, \"whisper-1\". The timeout defines how long the request can take before it times out.\n",
                                    "\n",
                                    "4. **Handling the Response**: The API call returns a JSON response. Access the `text` attribute to retrieve the transcribed content, ready for further processing or storage.\n",
                                    "\n",
                                    "## Moving On To Practice\n",
                                    "\n",
                                    "Now, that we know how to make an API request to OpenAI, let's try to do some practice! Onward and upward!\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Add Missing Code for Whisper API Transcription\n",
                                    "\n",
                                    "Welcome back, Explorer! Now, let's see how our Whisper OpenAI model works in action. Run the code, and you will see a preview window opened, where you can choose the sample audio or video file, click the transcribe button, and it will send an API request to Whisper to receive the transcription. Easy as that!\n",
                                    "\n",
                                    "Under the hood, the transcribe function in the code retrieves the transcription using the OpenAI SDK. Take your time to go through the code to understand the code thoroughly.\n",
                                    "\n",
                                    "Hint: You can open and use the terminal tab to see how requests are being processed.\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "\n",
                                    "def transcribe(file_path):\n",
                                    "    \"\"\"\n",
                                    "    Transcribe an audio file using OpenAI's API.\n",
                                    "    \"\"\"\n",
                                    "    try:\n",
                                    "        with open(file_path, 'rb') as audio_file:\n",
                                    "            transcript = client.audio.transcriptions.create(\n",
                                    "                model=\"whisper-1\",\n",
                                    "                file=audio_file\n",
                                    "            )\n",
                                    "            return transcript.text\n",
                                    "    except Exception as e:\n",
                                    "        raise Exception(f\"Transcription failed: {str(e)}\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```markdown\n",
                                    "## Add Missing Code for Whisper API Transcription\n",
                                    "\n",
                                    "Welcome back, Explorer! Now, let's see how our Whisper OpenAI model works in action. Run the code, and you will see a preview window opened, where you can choose the sample audio or video file, click the transcribe button, and it will send an API request to Whisper to receive the transcription. Easy as that!\n",
                                    "\n",
                                    "Under the hood, the `transcribe` function in the code retrieves the transcription using the OpenAI SDK. Take your time to go through the code to understand the code thoroughly.\n",
                                    "\n",
                                    "Hint: You can open and use the terminal tab to see how requests are being processed.\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "def transcribe(file_path):\n",
                                    "    \"\"\"\n",
                                    "    Transcribe an audio file using OpenAI's API.\n",
                                    "    \"\"\"\n",
                                    "    try:\n",
                                    "        # Open the audio file in binary read mode ('rb')\n",
                                    "        with open(file_path, 'rb') as audio_file:\n",
                                    "            # Use the OpenAI SDK to send the transcription request\n",
                                    "            transcript = client.audio.transcriptions.create(\n",
                                    "                model=\"whisper-1\",  # Specify which Whisper model to use\n",
                                    "                file=audio_file     # Provide the file to be transcribed\n",
                                    "            )\n",
                                    "            return transcript.text  # Return the transcribed text\n",
                                    "    except Exception as e:\n",
                                    "        # Handle any exceptions by raising an error with a message\n",
                                    "        raise Exception(f\"Transcription failed: {str(e)}\")\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    # Example usage: Provide the path to an audio file for transcription\n",
                                    "    file_path = \"path/to/your/audio/file.mp3\"\n",
                                    "    try:\n",
                                    "        result = transcribe(file_path)\n",
                                    "        print(\"Transcription:\", result)  # Print the transcribed text\n",
                                    "    except Exception as e:\n",
                                    "        print(f\"Error: {str(e)}\")  # Print any errors that occur\n",
                                    "```\n",
                                    "\n",
                                    "### How It Works:\n",
                                    "- **`transcribe` function**: This function takes an audio file's path as input and sends the audio data to OpenAI's Whisper API. The transcription is then returned as text.\n",
                                    "- **File Handling**: The audio file is opened in binary read mode ('rb') to ensure it’s in the proper format for the API.\n",
                                    "- **API Call**: The transcription request is made with `client.audio.transcriptions.create`. This sends the audio to the Whisper model for processing.\n",
                                    "- **Error Handling**: If the transcription fails for any reason, an exception will be raised, providing a helpful error message.\n",
                                    "\n",
                                    "Now, with the code in place, run the script and test it out with your own audio file. Happy transcribing!\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Audio Transcription Enhancement with OpenAI Whisper API"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Transcribing Audio with Whisper API"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
