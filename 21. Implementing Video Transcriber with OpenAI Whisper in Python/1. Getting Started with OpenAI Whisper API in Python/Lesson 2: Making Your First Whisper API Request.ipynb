{
         "cells": [
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "# Lesson 2: Making Your First Whisper API Request\n",
                                    "\n",
                                    "Welcome back! In the previous lesson, we set up a development environment using a virtual environment and installed the necessary dependencies to interact with the OpenAI API. Today, we're diving into making your first API request using Whisper, which is crucial for creating a transcription system. This builds on your understanding of environment setup and Python scripting, and now we’ll focus on interacting with APIs.\n",
                                    "\n",
                                    "You'll learn to transform audio data into text using the Whisper API.\n",
                                    "\n",
                                    "## Understanding Making Your First Whisper API Request\n",
                                    "\n",
                                    "The Whisper API from OpenAI is designed to handle audio transcription. The core idea is to send audio data to the API, which then returns a transcribed text. This process begins with a valid API key that authenticates your requests. The API interprets byte-stream data from audio files, transcribing what’s spoken into text with varying levels of detail depending on its configuration.\n",
                                    "\n",
                                    "While Whisper handles diverse audio inputs, it primarily focuses on capturing spoken content and might skip non-verbal sounds while ensuring the output is human-readable. The result is a JSON object containing the transcribed text and, sometimes, details like the duration of the audio.\n",
                                    "\n",
                                    "## Making Your First API Request\n",
                                    "\n",
                                    "Let’s explore a simple example demonstrating how to make your first transcription request using the Whisper API:\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "def transcribe_audio(file_path):\n",
                                    "    \"\"\"\n",
                                    "    Transcribe an audio file using OpenAI's Whisper API.\n",
                                    "    \"\"\"\n",
                                    "    try:\n",
                                    "        with open(file_path, 'rb') as audio_file:\n",
                                    "            transcript = client.audio.transcriptions.create(\n",
                                    "                model=\"whisper-1\",\n",
                                    "                file=audio_file,\n",
                                    "                timeout=60\n",
                                    "            )\n",
                                    "            return transcript.text\n",
                                    "    except Exception as e:\n",
                                    "        raise Exception(f\"Transcription failed: {str(e)}\")\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    result = transcribe_audio(\"resources/sample_audio.mp3\")\n",
                                    "    print(\"Transcription:\", result)\n",
                                    "```\n",
                                    "\n",
                                    "### This code demonstrates the transcription process:\n",
                                    "\n",
                                    "1. **Client Initialization**: Instantiate an `openai.OpenAI` client. This client manages your requests to the OpenAI API, authenticated by the previously loaded API key. This client automatically uses the `OPENAI_API_KEY` environment variable for authentication.\n",
                                    "\n",
                                    "2. **File Handling**: Open the audio file in binary read mode (\"rb\"). Reading as bytes ensures the data format is suitable for API processing.\n",
                                    "\n",
                                    "3. **API Call**: The `client.audio.transcriptions.create` method submits the audio data for transcription. The model specifies which version of Whisper to use, in this case, \"whisper-1\". The timeout defines how long the request can take before it times out.\n",
                                    "\n",
                                    "4. **Handling the Response**: The API call returns a JSON response. Access the `text` attribute to retrieve the transcribed content, ready for further processing or storage.\n",
                                    "\n",
                                    "## Moving On To Practice\n",
                                    "\n",
                                    "Now, that we know how to make an API request to OpenAI, let's try to do some practice! Onward and upward!\n"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Add Missing Code for Whisper API Transcription\n",
                                    "\n",
                                    "Welcome back, Explorer! Now, let's see how our Whisper OpenAI model works in action. Run the code, and you will see a preview window opened, where you can choose the sample audio or video file, click the transcribe button, and it will send an API request to Whisper to receive the transcription. Easy as that!\n",
                                    "\n",
                                    "Under the hood, the transcribe function in the code retrieves the transcription using the OpenAI SDK. Take your time to go through the code to understand the code thoroughly.\n",
                                    "\n",
                                    "Hint: You can open and use the terminal tab to see how requests are being processed.\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "\n",
                                    "def transcribe(file_path):\n",
                                    "    \"\"\"\n",
                                    "    Transcribe an audio file using OpenAI's API.\n",
                                    "    \"\"\"\n",
                                    "    try:\n",
                                    "        with open(file_path, 'rb') as audio_file:\n",
                                    "            transcript = client.audio.transcriptions.create(\n",
                                    "                model=\"whisper-1\",\n",
                                    "                file=audio_file\n",
                                    "            )\n",
                                    "            return transcript.text\n",
                                    "    except Exception as e:\n",
                                    "        raise Exception(f\"Transcription failed: {str(e)}\")\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "```markdown\n",
                                    "## Add Missing Code for Whisper API Transcription\n",
                                    "\n",
                                    "Welcome back, Explorer! Now, let's see how our Whisper OpenAI model works in action. Run the code, and you will see a preview window opened, where you can choose the sample audio or video file, click the transcribe button, and it will send an API request to Whisper to receive the transcription. Easy as that!\n",
                                    "\n",
                                    "Under the hood, the `transcribe` function in the code retrieves the transcription using the OpenAI SDK. Take your time to go through the code to understand the code thoroughly.\n",
                                    "\n",
                                    "Hint: You can open and use the terminal tab to see how requests are being processed.\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "def transcribe(file_path):\n",
                                    "    \"\"\"\n",
                                    "    Transcribe an audio file using OpenAI's API.\n",
                                    "    \"\"\"\n",
                                    "    try:\n",
                                    "        # Open the audio file in binary read mode ('rb')\n",
                                    "        with open(file_path, 'rb') as audio_file:\n",
                                    "            # Use the OpenAI SDK to send the transcription request\n",
                                    "            transcript = client.audio.transcriptions.create(\n",
                                    "                model=\"whisper-1\",  # Specify which Whisper model to use\n",
                                    "                file=audio_file     # Provide the file to be transcribed\n",
                                    "            )\n",
                                    "            return transcript.text  # Return the transcribed text\n",
                                    "    except Exception as e:\n",
                                    "        # Handle any exceptions by raising an error with a message\n",
                                    "        raise Exception(f\"Transcription failed: {str(e)}\")\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    # Example usage: Provide the path to an audio file for transcription\n",
                                    "    file_path = \"path/to/your/audio/file.mp3\"\n",
                                    "    try:\n",
                                    "        result = transcribe(file_path)\n",
                                    "        print(\"Transcription:\", result)  # Print the transcribed text\n",
                                    "    except Exception as e:\n",
                                    "        print(f\"Error: {str(e)}\")  # Print any errors that occur\n",
                                    "```\n",
                                    "\n",
                                    "### How It Works:\n",
                                    "- **`transcribe` function**: This function takes an audio file's path as input and sends the audio data to OpenAI's Whisper API. The transcription is then returned as text.\n",
                                    "- **File Handling**: The audio file is opened in binary read mode ('rb') to ensure it’s in the proper format for the API.\n",
                                    "- **API Call**: The transcription request is made with `client.audio.transcriptions.create`. This sends the audio to the Whisper model for processing.\n",
                                    "- **Error Handling**: If the transcription fails for any reason, an exception will be raised, providing a helpful error message.\n",
                                    "\n",
                                    "Now, with the code in place, run the script and test it out with your own audio file. Happy transcribing!\n",
                                    "```"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Audio Transcription Enhancement with OpenAI Whisper API\n",
                                    "\n",
                                    "Local files are nice, but can we actually process remote mp4 videos? Let's try it out and see! Given the remote mp4 file URL in the code, organize running OpenAI Whisper transcribe operation on it.\n",
                                    "\n",
                                    "Hint: you will need to specify the video format in order for Whisper to parse the content properly. You can do that by providing the file name on top of the content: file=('video.mp4', <content bytes>)\n",
                                    "\n",
                                    "\n",
                                    "```python\n",
                                    "\n",
                                    "from openai import OpenAI\n",
                                    "import requests\n",
                                    "\n",
                                    "# TODO: Define the OpenAI client\n",
                                    "client = ____\n",
                                    "\n",
                                    "\n",
                                    "def transcribe_remote(url):\n",
                                    "    \"\"\"\n",
                                    "    Transcribe a remote video file from a URL using OpenAI's Whisper API.\n",
                                    "    \"\"\"\n",
                                    "    try:\n",
                                    "        # TODO: Download the content using the `requests` library\n",
                                    "        \n",
                                    "        # TODO: Send the content to OpenAI API\n",
                                    "        transcript = client.audio.transcriptions.create(\n",
                                    "            model=\"whisper-1\",\n",
                                    "            file=______\n",
                                    "        )\n",
                                    "        return transcript.text\n",
                                    "        \n",
                                    "    except Exception as e:\n",
                                    "        return f\"Error: {str(e)}\"\n",
                                    "\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    remote_video_url = \"http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/WeAreGoingOnBullrun.mp4\"\n",
                                    "    print(transcribe_remote(remote_video_url))\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "To make this script work for transcribing a remote MP4 file using OpenAI's Whisper API, you'll need to implement a couple of missing steps. Specifically, you'll download the file from the provided URL and send it to the Whisper API for transcription.\n",
                                    "\n",
                                    "Here’s how you can complete the code:\n",
                                    "\n",
                                    "1. **Download the file from the URL**: Use the `requests` library to get the content of the video.\n",
                                    "2. **Provide the file content to OpenAI's Whisper API**: You'll send the file as a binary stream (using `file=('video.mp4', <content_bytes>)`).\n",
                                    "\n",
                                    "Here’s the updated code with the missing steps filled in:\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "import requests\n",
                                    "\n",
                                    "# Define the OpenAI client\n",
                                    "client = OpenAI(api_key='your-openai-api-key')\n",
                                    "\n",
                                    "def transcribe_remote(url):\n",
                                    "    \"\"\"\n",
                                    "    Transcribe a remote video file from a URL using OpenAI's Whisper API.\n",
                                    "    \"\"\"\n",
                                    "    try:\n",
                                    "        # Download the content using the `requests` library\n",
                                    "        response = requests.get(url)\n",
                                    "        \n",
                                    "        if response.status_code == 200:\n",
                                    "            # Send the content to OpenAI API for transcription\n",
                                    "            transcript = client.audio.transcriptions.create(\n",
                                    "                model=\"whisper-1\",\n",
                                    "                file=(\"video.mp4\", response.content)\n",
                                    "            )\n",
                                    "            return transcript.text\n",
                                    "        else:\n",
                                    "            return f\"Error: Failed to download the video (status code: {response.status_code})\"\n",
                                    "        \n",
                                    "    except Exception as e:\n",
                                    "        return f\"Error: {str(e)}\"\n",
                                    "\n",
                                    "\n",
                                    "if __name__ == \"__main__\":\n",
                                    "    remote_video_url = \"http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/WeAreGoingOnBullrun.mp4\"\n",
                                    "    print(transcribe_remote(remote_video_url))\n",
                                    "```\n",
                                    "\n",
                                    "### Key Changes:\n",
                                    "1. **Download the file**: `requests.get(url)` is used to fetch the MP4 content from the given URL.\n",
                                    "2. **Error handling**: If the download fails (non-200 HTTP status), the function will return an error message with the status code.\n",
                                    "3. **Send file to Whisper API**: The file is passed as a tuple `(\"video.mp4\", response.content)` to the Whisper API for transcription.\n",
                                    "\n",
                                    "### Notes:\n",
                                    "- Make sure to replace `'your-openai-api-key'` with your actual OpenAI API key.\n",
                                    "- You can modify the `remote_video_url` to point to any other MP4 file URL you wish to transcribe.\n",
                                    "\n",
                                    "This should work to transcribe the video from a remote source via the Whisper API. Let me know if you need further adjustments!"
                           ]
                  },
                  {
                           "cell_type": "markdown",
                           "metadata": {},
                           "source": [
                                    "## Transcribing Audio with Whisper API\n",
                                    "\n",
                                    "Galactic Pioneer, your mission is to journey to new frontiers by transcribing audio using the Whisper API. This time, start by downloading the mp3 file from the URL provided in the code. Once downloaded, load environment variables, set the API key, open the downloaded audio file, and create the transcription request. Follow the step-by-step guidance, and watch the magic unfold as you transform audio into text.\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "import requests\n",
                                    "\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "\n",
                                    "# URL of the mp3 file\n",
                                    "url = \"https://dare.wisc.edu/wp-content/uploads/sites/1051/2008/04/Arthur.mp3\"\n",
                                    "\n",
                                    "# TODO: Download the mp3 file from the URL\n",
                                    "\n",
                                    "# TODO: Open the audio file in binary mode\n",
                                    "\n",
                                    "# TODO: Create a transcription request with a timeout and specific model\n",
                                    "\n",
                                    "# TODO: Print the transcribed text\n",
                                    "\n",
                                    "\n",
                                    "```\n",
                                    "\n",
                                    "To transcribe the audio from the provided URL using the Whisper API, here are the steps you need to follow:\n",
                                    "\n",
                                    "1. **Download the mp3 file**: Use the `requests` library to download the audio file from the given URL.\n",
                                    "2. **Set up environment variables**: You'll need to load your OpenAI API key from the environment variables.\n",
                                    "3. **Open the downloaded audio file**: Open the file in binary mode for the Whisper API to process it.\n",
                                    "4. **Create the transcription request**: Send the audio file to OpenAI's Whisper API for transcription.\n",
                                    "5. **Handle the transcription**: Extract and print the transcribed text.\n",
                                    "\n",
                                    "Here’s the full implementation with the missing steps:\n",
                                    "\n",
                                    "```python\n",
                                    "from openai import OpenAI\n",
                                    "import requests\n",
                                    "import os\n",
                                    "\n",
                                    "# Set up OpenAI client with API key\n",
                                    "client = OpenAI()\n",
                                    "\n",
                                    "# URL of the mp3 file\n",
                                    "url = \"https://dare.wisc.edu/wp-content/uploads/sites/1051/2008/04/Arthur.mp3\"\n",
                                    "\n",
                                    "# Step 1: Download the mp3 file from the URL\n",
                                    "response = requests.get(url)\n",
                                    "if response.status_code != 200:\n",
                                    "    print(f\"Error: Failed to download the mp3 file (status code: {response.status_code})\")\n",
                                    "    exit()\n",
                                    "\n",
                                    "# Step 2: Open the audio file in binary mode\n",
                                    "audio_data = response.content\n",
                                    "\n",
                                    "# Step 3: Create a transcription request with a timeout and specific model\n",
                                    "try:\n",
                                    "    transcription = client.audio.transcriptions.create(\n",
                                    "        model=\"whisper-1\",  # Specifying the Whisper model\n",
                                    "        file=(\"Arthur.mp3\", audio_data),\n",
                                    "        timeout=120  # Optional: set a timeout in case the process takes too long\n",
                                    "    )\n",
                                    "\n",
                                    "    # Step 4: Print the transcribed text\n",
                                    "    print(\"Transcription:\\n\", transcription.text)\n",
                                    "    \n",
                                    "except Exception as e:\n",
                                    "    print(f\"Error: {str(e)}\")\n",
                                    "```\n",
                                    "\n",
                                    "### Key Steps:\n",
                                    "1. **Download the mp3 file**: Using `requests.get(url)` to fetch the audio file.\n",
                                    "2. **Open the audio file in binary mode**: The file content is stored in `audio_data` using `response.content`.\n",
                                    "3. **Create transcription request**: The transcription request is created using the `client.audio.transcriptions.create` method, specifying the Whisper model (`whisper-1`) and the binary file data.\n",
                                    "4. **Handle errors**: If the API request fails, an error message is printed.\n",
                                    "\n",
                                    "### Notes:\n",
                                    "- Make sure that the `OPENAI_API_KEY` environment variable is set properly. You can load it using a `.env` file or set it directly in your environment.\n",
                                    "- If you are running this in a local environment, you might want to use `python-dotenv` to load the environment variables from a `.env` file.\n",
                                    "\n",
                                    "Now when you run this script, it will download the mp3 file, transcribe it using the Whisper API, and print the resulting text. Let me know if you have any further questions!"
                           ]
                  }
         ],
         "metadata": {
                  "language_info": {
                           "name": "python"
                  }
         },
         "nbformat": 4,
         "nbformat_minor": 5
}
