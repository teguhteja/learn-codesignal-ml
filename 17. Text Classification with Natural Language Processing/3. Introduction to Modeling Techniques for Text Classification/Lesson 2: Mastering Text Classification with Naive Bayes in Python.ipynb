{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71519ef6",
   "metadata": {},
   "source": [
    "# Lesson 2: Mastering Text Classification with Naive Bayes in Python\n",
    "\n",
    "# Overview: Text Classification With Naive Bayes\n",
    "\n",
    "Hello and welcome! Today, we will explore the world of text classification using the Naive Bayes algorithm, specifically in Python with the Scikit-learn library. By the end of this lesson, you will understand how Naive Bayes works, how to implement a Naive Bayes model in Python, and how to evaluate its performance. Let's get started!\n",
    "\n",
    "## Understanding the Fundamentals of Naive Bayes\n",
    "\n",
    "The Naive Bayes algorithm is a category of simple \"probabilistic classifiers\" based on applying Bayes' theorem with strong (naïve) independence assumptions between the features. It calculates the probability that a certain event will occur given that another event has already occurred. In text classification, the event we're interested in is a specific class label, such as spam or ham (not spam), while the given event is the text input we have — a particular SMS in our case.\n",
    "\n",
    "The 'naive' in Naive Bayes comes from the assumption that each feature contributes independently to the probability of a particular outcome. Although this assumption often isn't valid in the real world (words in an SMS are often not independent), the Naive Bayes algorithm still tends to perform very well in text classification, particularly as a simple and fast method.\n",
    "\n",
    "## Dataset Loading and Preparation\n",
    "\n",
    "Before we start building our Naive Bayes model, let's load our dataset and perform the necessary preparations:\n",
    "\n",
    "```python\n",
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datasets\n",
    "\n",
    "# Load the dataset\n",
    "spam_dataset = datasets.load_dataset('codesignal/sms-spam-collection', split='train')\n",
    "spam_dataset = pd.DataFrame(spam_dataset)\n",
    "\n",
    "# Define X (input features) and Y (output labels)\n",
    "X = spam_dataset[\"message\"]\n",
    "Y = spam_dataset[\"label\"]\n",
    "\n",
    "# Perform the train-test split using stratified cross-validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "```\n",
    "\n",
    "In the above code, we load our SMS dataset and conduct a train-test split. These steps prepare our dataset for modeling. By separating our data into a training set and a test set, we ensure that our model can learn from one portion of the data (the training set) and then have its performance evaluated on unseen data (the test set).\n",
    "\n",
    "## Text Data Transformation Into Numerical Features\n",
    "\n",
    "Before building the Naive Bayes model, we need to prepare our data. Since machine learning algorithms operate on numeric data, we must convert our SMS text data into numerical features:\n",
    "\n",
    "```python\n",
    "# Initialize the CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data \n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_count = count_vectorizer.transform(X_test)\n",
    "```\n",
    "\n",
    "In this code block, we implement the CountVectorizer, which performs two important tasks: it tokenizes the sentences (breaking the text down into individual words) and counts the frequency of each word in each sentence. This information is used to transform each sentence into a numerical vector that our machine learning model can understand. The vectors produced by CountVectorizer result in a matrix of token counts: `X_train_count` and `X_test_count`.\n",
    "\n",
    "## Building the Naive Bayes Model\n",
    "\n",
    "Now that we've transformed our text data into numerical vectors, we can create our Naive Bayes classifier:\n",
    "\n",
    "```python\n",
    "# Initialize the MultinomialNB model\n",
    "naive_bayes_model = MultinomialNB()\n",
    "\n",
    "# Fit the model on the training data\n",
    "naive_bayes_model.fit(X_train_count, Y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = naive_bayes_model.predict(X_test_count)\n",
    "```\n",
    "\n",
    "Here, we initialize a Naive Bayes classifier using the `MultinomialNB` class from Scikit-learn. The `fit` method trains our model on the training data, learning the probabilities of each label (spam or ham) given the input features (token counts). Once the model is trained, we use the `predict` method to make predictions on our test data.\n",
    "\n",
    "## Predicting and Evaluating the Model Performance\n",
    "\n",
    "Accuracy is a common metric for classification, calculated as the ratio of the number of correct predictions to the total number of input samples:\n",
    "\n",
    "```python\n",
    "# Calculate the accuracy of the model\n",
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(Y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy of Naive Bayes Classifier: {accuracy:.2f}\")\n",
    "```\n",
    "\n",
    "The output will be:\n",
    "\n",
    "```\n",
    "Accuracy of Naive Bayes Classifier: 0.98\n",
    "```\n",
    "\n",
    "This indicates that our classifier has a very high accuracy rate, rarely misclassifying SMS messages. This high level of accuracy demonstrates the effectiveness of the Naive Bayes classifier for text classification tasks.\n",
    "\n",
    "## Lesson Summary and Practice\n",
    "\n",
    "Well done on reaching the end of this lesson! We explored the Naive Bayes algorithm, implemented it in Python for text classification, and evaluated its performance. The Naive Bayes classifier is a powerful and fast classification tool ideal for text data, even if its assumptions largely ignore the semantics of text.\n",
    "\n",
    "In the upcoming exercises, you will have the chance to implement a Naive Bayes classifier and gain valuable hands-on experience. Remember that practicing what you've learned is essential in your learning journey. So, get your hands dirty with our exercises and improve your problem-solving abilities and understanding of the Naive Bayes classifier. Let's go! Happy coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11882f89",
   "metadata": {},
   "source": [
    "## Tuning Alpha Parameter in Naive Bayes Model\n",
    "\n",
    "Greetings, Space Explorer! Your mission is to tune the Naive Bayes classifier used for SMS classification by adjusting the alpha parameter. The alpha parameter is a smoothing variable used in the Naive Bayes algorithm to account for features not present in the learning samples and to prevent zero probabilities in further computations. Setting alpha too low may cause underfitting, while setting it too high may result in overfitting. Originally, our model uses an alpha value of 0. Let's see what happens when we adjust the alpha to 1, the default value of the parameter. Implement this change and report the accuracy of the updated model on the test set.\n",
    "\n",
    "```python\n",
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import datasets\n",
    "\n",
    "# Load the dataset\n",
    "spam_dataset = datasets.load_dataset('codesignal/sms-spam-collection', split='train')\n",
    "spam_dataset = pd.DataFrame(spam_dataset)\n",
    "\n",
    "# Define X (input features) and Y (output labels)\n",
    "X = spam_dataset[\"message\"]\n",
    "Y = spam_dataset[\"label\"]\n",
    "\n",
    "# Perform the train test split using stratified cross-validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data \n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the MultinomialNB model with alpha=0\n",
    "naive_bayes_model = MultinomialNB(alpha=0)\n",
    "\n",
    "# Fit the model on the training data\n",
    "naive_bayes_model.fit(X_train_count, Y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = naive_bayes_model.predict(X_test_count)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = metrics.accuracy_score(Y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy of Naive Bayes Classifier with alpha=0: {accuracy:.2f}\")\n",
    "\n",
    "```\n",
    "\n",
    "Abacus AI ChatLLM:\n",
    "To adjust the Naive Bayes classifier by changing the alpha parameter from 0 to 1, you can modify the initialization of the `MultinomialNB` model. Below is the updated code that implements this change and reports the accuracy of the updated model on the test set.\n",
    "\n",
    "```python\n",
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import datasets\n",
    "\n",
    "# Load the dataset\n",
    "spam_dataset = datasets.load_dataset('codesignal/sms-spam-collection', split='train')\n",
    "spam_dataset = pd.DataFrame(spam_dataset)\n",
    "\n",
    "# Define X (input features) and Y (output labels)\n",
    "X = spam_dataset[\"message\"]\n",
    "Y = spam_dataset[\"label\"]\n",
    "\n",
    "# Perform the train test split using stratified cross-validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data \n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the MultinomialNB model with alpha=1 (default value)\n",
    "naive_bayes_model = MultinomialNB(alpha=1)\n",
    "\n",
    "# Fit the model on the training data\n",
    "naive_bayes_model.fit(X_train_count, Y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = naive_bayes_model.predict(X_test_count)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = metrics.accuracy_score(Y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy of Naive Bayes Classifier with alpha=1: {accuracy:.2f}\")\n",
    "```\n",
    "\n",
    "### Explanation of Changes:\n",
    "- The line `naive_bayes_model = MultinomialNB(alpha=0)` has been changed to `naive_bayes_model = MultinomialNB(alpha=1)` to set the alpha parameter to its default value.\n",
    "\n",
    "### Expected Output:\n",
    "When you run this code, it will print the accuracy of the Naive Bayes classifier with the updated alpha value. The output will look something like this:\n",
    "\n",
    "```\n",
    "Accuracy of Naive Bayes Classifier with alpha=1: [accuracy_value]\n",
    "```\n",
    "\n",
    "Replace `[accuracy_value]` with the actual accuracy obtained from running the code. This will give you insight into how changing the alpha parameter affects the model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6978c4",
   "metadata": {},
   "source": [
    "## Fill in the Blanks: Building Naive Bayes Model\n",
    "\n",
    "Space Voyager, your task awaits! We have prepared a Naive Bayes model for text classification. There are some missing pieces marked with ____. Can you fill in the blanks to make the code work? We aim to replace the ____ with the correct syntax to create a Multinomial Naive Bayes object, then train the model with the training dataset.\n",
    "\n",
    "```python\n",
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import ____ \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import datasets\n",
    "\n",
    "# Load the dataset\n",
    "spam_dataset = datasets.load_dataset('codesignal/sms-spam-collection', split='train')\n",
    "spam_dataset = pd.DataFrame(spam_dataset)\n",
    "\n",
    "# Define X (input features) and Y (output labels)\n",
    "X = spam_dataset[\"message\"]\n",
    "Y = spam_dataset[\"label\"]\n",
    "\n",
    "# Perform the train test split using stratified cross-validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data \n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the MultinomialNB model\n",
    "naive_bayes_model = ____(alpha=1) \n",
    "\n",
    "# Fit the model on the training data\n",
    "naive_bayes_model.____(X_train_count, Y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = naive_bayes_model.predict(X_test_count)\n",
    "\n",
    "print(f\"The model's first 10 predictions: {y_pred[:10]}\")\n",
    "\n",
    "```\n",
    "\n",
    "Abacus AI ChatLLM:\n",
    "To complete the code for the Naive Bayes model for text classification, you need to fill in the blanks with the appropriate syntax. Here’s the completed code with the missing pieces filled in:\n",
    "\n",
    "```python\n",
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB  # Fill in the blank here\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import datasets\n",
    "\n",
    "# Load the dataset\n",
    "spam_dataset = datasets.load_dataset('codesignal/sms-spam-collection', split='train')\n",
    "spam_dataset = pd.DataFrame(spam_dataset)\n",
    "\n",
    "# Define X (input features) and Y (output labels)\n",
    "X = spam_dataset[\"message\"]\n",
    "Y = spam_dataset[\"label\"]\n",
    "\n",
    "# Perform the train test split using stratified cross-validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data \n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the MultinomialNB model\n",
    "naive_bayes_model = MultinomialNB(alpha=1)  # Fill in the blank here\n",
    "\n",
    "# Fit the model on the training data\n",
    "naive_bayes_model.fit(X_train_count, Y_train)  # Fill in the blank here\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = naive_bayes_model.predict(X_test_count)\n",
    "\n",
    "print(f\"The model's first 10 predictions: {y_pred[:10]}\")\n",
    "```\n",
    "\n",
    "### Summary of Changes:\n",
    "- **First Blank:** `MultinomialNB` is the correct class to import for the Naive Bayes model.\n",
    "- **Second Blank:** The method to fit the model is `fit`.\n",
    "\n",
    "This code will now correctly initialize a Multinomial Naive Bayes model, train it with the training dataset, and make predictions on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230e32d5",
   "metadata": {},
   "source": [
    "## Fill in the Blanks: Predicting Using Naive Bayes Model\n",
    "\n",
    "Stellar Navigator, it’s your turn! Please fill in the missing pieces represented as ____ in the code. You will need to transform the training and test data, fit the Naive Bayes model on the training data, and make predictions on the test data. Are you up for this adventure?\n",
    "\n",
    "```python\n",
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datasets\n",
    "\n",
    "# Load the dataset\n",
    "spam_dataset = datasets.load_dataset('codesignal/sms-spam-collection', split='train')\n",
    "spam_dataset = pd.DataFrame(spam_dataset)\n",
    "\n",
    "# Define X (input features) and Y (output labels)\n",
    "X = spam_dataset[\"message\"]\n",
    "Y = spam_dataset[\"label\"]\n",
    "\n",
    "# Perform the train test split using stratified cross-validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data \n",
    "X_train_count = count_vectorizer.____(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_count = count_vectorizer.____(X_test)\n",
    "\n",
    "# Initialize the MultinomialNB model\n",
    "naive_bayes_model = MultinomialNB()\n",
    "\n",
    "# Fit the model on the training data\n",
    "naive_bayes_model.____(X_train_count, Y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = naive_bayes_model.____(X_test_count)\n",
    "\n",
    "# Print the first 5 predictions and actual labels for comparison\n",
    "print(\"First 5 Predictions: \", y_pred[:5])\n",
    "print(\"Actual Labels: \", Y_test[:5].tolist())\n",
    "\n",
    "```\n",
    "\n",
    "Abacus AI ChatLLM:\n",
    "Absolutely, Stellar Navigator! Let's fill in the missing pieces in the code to ensure it works correctly for training and predicting with the Naive Bayes model. Here’s the completed code:\n",
    "\n",
    "```python\n",
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datasets\n",
    "\n",
    "# Load the dataset\n",
    "spam_dataset = datasets.load_dataset('codesignal/sms-spam-collection', split='train')\n",
    "spam_dataset = pd.DataFrame(spam_dataset)\n",
    "\n",
    "# Define X (input features) and Y (output labels)\n",
    "X = spam_dataset[\"message\"]\n",
    "Y = spam_dataset[\"label\"]\n",
    "\n",
    "# Perform the train test split using stratified cross-validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data \n",
    "X_train_count = count_vectorizer.fit_transform(X_train)  # Fill in the blank here\n",
    "\n",
    "# Transform the test data\n",
    "X_test_count = count_vectorizer.transform(X_test)  # Fill in the blank here\n",
    "\n",
    "# Initialize the MultinomialNB model\n",
    "naive_bayes_model = MultinomialNB()\n",
    "\n",
    "# Fit the model on the training data\n",
    "naive_bayes_model.fit(X_train_count, Y_train)  # Fill in the blank here\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = naive_bayes_model.predict(X_test_count)  # Fill in the blank here\n",
    "\n",
    "# Print the first 5 predictions and actual labels for comparison\n",
    "print(\"First 5 Predictions: \", y_pred[:5])\n",
    "print(\"Actual Labels: \", Y_test[:5].tolist())\n",
    "```\n",
    "\n",
    "### Summary of Changes:\n",
    "- **First Blank:** `fit_transform` is used to fit the `CountVectorizer` on the training data and transform it into a numerical format.\n",
    "- **Second Blank:** `transform` is used to convert the test data into the same numerical format using the already fitted `CountVectorizer`.\n",
    "- **Third Blank:** `fit` is the method used to train the Naive Bayes model on the transformed training data.\n",
    "- **Fourth Blank:** `predict` is the method used to make predictions on the transformed test data.\n",
    "\n",
    "This code will now correctly process the SMS dataset, train the Naive Bayes model, and output the first five predictions along with the actual labels for comparison. Happy coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36df7499",
   "metadata": {},
   "source": [
    "## Visualize Naive Bayes Model Predictions\n",
    "\n",
    "Greetings, Stellar Navigator! For this assignment, we're focusing on model initialization and training. You will find a TODO comment in the provided starter code. Fill it in to define the Naive Bayes model and train it! You'll be able to see the difference between your model's prediction and the actual results visually on a scatter plot. Let's dive in!\n",
    "\n",
    "```python\n",
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n",
    "\n",
    "# Load the dataset\n",
    "spam_dataset = datasets.load_dataset('codesignal/sms-spam-collection', split='train')\n",
    "spam_dataset = pd.DataFrame(spam_dataset)\n",
    "\n",
    "# Define X (input features) and Y (output labels)\n",
    "X = spam_dataset[\"message\"]\n",
    "Y = spam_dataset[\"label\"]\n",
    "\n",
    "# Perform the train test split using stratified cross-validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data \n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "# TODO: Initialize the MultinomialNB model and fit it on the training data\n",
    "\n",
    "# Make predictions on the test data\n",
    "Y_pred = naive_bayes_model.predict(X_test_count)\n",
    "\n",
    "# Create a DataFrame with actual and predicted labels\n",
    "results_df = pd.DataFrame({\"Actual\": Y_test, \"Predicted\": Y_pred})\n",
    "\n",
    "# We now generate indices for our scatter plot for clarity\n",
    "indices = range(1, 51)\n",
    "\n",
    "# Plotting the comparison scatter plot for the first 50 messages\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot actual labels\n",
    "plt.scatter(indices, results_df[\"Actual\"].values[:50], edgecolor='b', facecolors='none', label='Actual')\n",
    "\n",
    "# Plot predicted labels\n",
    "plt.scatter(indices, results_df[\"Predicted\"].values[:50], edgecolor='none',color='r', label='Predicted', marker='x')\n",
    "\n",
    "plt.yticks([0, 1], ['Ham', 'Spam'])\n",
    "plt.ylabel('Category')\n",
    "plt.xlabel('Message Number')\n",
    "plt.title('Actual vs Predicted Labels for First 50 Messages')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "\n",
    "Abacus AI ChatLLM:\n",
    "Greetings, Stellar Navigator! Let's fill in the TODO comment in the provided code to initialize the Naive Bayes model and fit it on the training data. Here’s the completed code:\n",
    "\n",
    "```python\n",
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n",
    "\n",
    "# Load the dataset\n",
    "spam_dataset = datasets.load_dataset('codesignal/sms-spam-collection', split='train')\n",
    "spam_dataset = pd.DataFrame(spam_dataset)\n",
    "\n",
    "# Define X (input features) and Y (output labels)\n",
    "X = spam_dataset[\"message\"]\n",
    "Y = spam_dataset[\"label\"]\n",
    "\n",
    "# Perform the train test split using stratified cross-validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data \n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "# TODO: Initialize the MultinomialNB model and fit it on the training data\n",
    "naive_bayes_model = MultinomialNB()  # Initialize the model\n",
    "naive_bayes_model.fit(X_train_count, Y_train)  # Fit the model on the training data\n",
    "\n",
    "# Make predictions on the test data\n",
    "Y_pred = naive_bayes_model.predict(X_test_count)\n",
    "\n",
    "# Create a DataFrame with actual and predicted labels\n",
    "results_df = pd.DataFrame({\"Actual\": Y_test, \"Predicted\": Y_pred})\n",
    "\n",
    "# We now generate indices for our scatter plot for clarity\n",
    "indices = range(1, 51)\n",
    "\n",
    "# Plotting the comparison scatter plot for the first 50 messages\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot actual labels\n",
    "plt.scatter(indices, results_df[\"Actual\"].values[:50], edgecolor='b', facecolors='none', label='Actual')\n",
    "\n",
    "# Plot predicted labels\n",
    "plt.scatter(indices, results_df[\"Predicted\"].values[:50], edgecolor='none', color='r', label='Predicted', marker='x')\n",
    "\n",
    "plt.yticks([0, 1], ['Ham', 'Spam'])\n",
    "plt.ylabel('Category')\n",
    "plt.xlabel('Message Number')\n",
    "plt.title('Actual vs Predicted Labels for First 50 Messages')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Summary of Changes:\n",
    "- **Model Initialization:** `naive_bayes_model = MultinomialNB()` initializes the Multinomial Naive Bayes model.\n",
    "- **Model Fitting:** `naive_bayes_model.fit(X_train_count, Y_train)` fits the model on the training data.\n",
    "\n",
    "### Explanation:\n",
    "- After fitting the model, predictions are made on the test data, and a scatter plot is generated to visually compare the actual and predicted labels for the first 50 messages. The blue circles represent the actual labels, while the red crosses represent the predicted labels.\n",
    "\n",
    "This code will now run successfully, allowing you to visualize the performance of your Naive Bayes model in classifying SMS messages as spam or ham. Happy coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb303153",
   "metadata": {},
   "source": [
    "## Evaluate Naive Bayes Model with Confusion Matrix\n",
    "\n",
    "Dear Space Voyager, your skills are needed once again! Using what you've learned about the Naive Bayes Model, your mission is to evaluate your model using a confusion matrix. Implement the Naive Bayes model, make predictions, and then generate a confusion matrix for the model using the test data. Plot the results of the confusion matrix for visual assessment.\n",
    "\n",
    "```python\n",
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import datasets\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "spam_dataset = datasets.load_dataset('codesignal/sms-spam-collection', split='train')\n",
    "spam_dataset = pd.DataFrame(spam_dataset)\n",
    "\n",
    "# Define X (input features) and Y (output labels)\n",
    "X = spam_dataset[\"message\"]\n",
    "Y = spam_dataset[\"label\"]\n",
    "\n",
    "# Perform the train test split using stratified cross-validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "# TODO: Initialize the CountVectorizer and fit and transform the training data\n",
    "\n",
    "# TODO: Transform the test data\n",
    "\n",
    "# TODO: Initialize the MultinomialNB model\n",
    "\n",
    "# TODO: Fit the model on the training data\n",
    "\n",
    "# TODO: Make predictions on the test data\n",
    "\n",
    "# Generate confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "# Create a DataFrame with confusion matrix\n",
    "confusion_df = pd.DataFrame(confusion_matrix, index=['ham', 'spam'], columns=['ham', 'spam'])\n",
    "\n",
    "# Print the confusion DataFrame\n",
    "print(confusion_df)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(confusion_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "\n",
    "Abacus AI ChatLLM:\n",
    "Dear Space Voyager, let's complete the provided code to implement the Naive Bayes model, make predictions, and generate a confusion matrix for evaluation. Here’s the completed code with the necessary sections filled in:\n",
    "\n",
    "```python\n",
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import datasets\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "spam_dataset = datasets.load_dataset('codesignal/sms-spam-collection', split='train')\n",
    "spam_dataset = pd.DataFrame(spam_dataset)\n",
    "\n",
    "# Define X (input features) and Y (output labels)\n",
    "X = spam_dataset[\"message\"]\n",
    "Y = spam_dataset[\"label\"]\n",
    "\n",
    "# Perform the train test split using stratified cross-validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "# TODO: Initialize the CountVectorizer and fit and transform the training data\n",
    "count_vectorizer = CountVectorizer()  # Initialize CountVectorizer\n",
    "X_train_count = count_vectorizer.fit_transform(X_train)  # Fit and transform the training data\n",
    "\n",
    "# TODO: Transform the test data\n",
    "X_test_count = count_vectorizer.transform(X_test)  # Transform the test data\n",
    "\n",
    "# TODO: Initialize the MultinomialNB model\n",
    "naive_bayes_model = MultinomialNB()  # Initialize the model\n",
    "\n",
    "# TODO: Fit the model on the training data\n",
    "naive_bayes_model.fit(X_train_count, Y_train)  # Fit the model on the training data\n",
    "\n",
    "# TODO: Make predictions on the test data\n",
    "Y_pred = naive_bayes_model.predict(X_test_count)  # Make predictions on the test data\n",
    "\n",
    "# Generate confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "# Create a DataFrame with confusion matrix\n",
    "confusion_df = pd.DataFrame(confusion_matrix, index=['ham', 'spam'], columns=['ham', 'spam'])\n",
    "\n",
    "# Print the confusion DataFrame\n",
    "print(confusion_df)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(confusion_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Summary of Changes:\n",
    "- **CountVectorizer Initialization and Transformation:** The `CountVectorizer` is initialized, and the training data is fitted and transformed.\n",
    "- **Test Data Transformation:** The test data is transformed using the fitted `CountVectorizer`.\n",
    "- **Model Initialization and Fitting:** The `MultinomialNB` model is initialized and fitted on the training data.\n",
    "- **Predictions:** Predictions are made on the test data.\n",
    "\n",
    "### Explanation:\n",
    "- After fitting the model and making predictions, a confusion matrix is generated using `metrics.confusion_matrix()`. This matrix is then converted into a DataFrame for better readability.\n",
    "- Finally, the confusion matrix is visualized using a heatmap from the Seaborn library, providing a clear visual assessment of the model's performance.\n",
    "\n",
    "This code will now run successfully, allowing you to evaluate the performance of your Naive Bayes model using a confusion matrix. Happy coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7d9ea-e3a7-429b-aa44-87b2d986aeed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
