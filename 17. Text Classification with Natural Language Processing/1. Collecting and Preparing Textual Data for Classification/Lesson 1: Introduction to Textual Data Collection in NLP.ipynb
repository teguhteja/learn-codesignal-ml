{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a80bfe6d",
   "metadata": {},
   "source": [
    "# Lesson 1: Introduction to Textual Data Collection in NLP\n",
    "\n",
    "### **Introduction to Text Data Collection** üìö\n",
    "\n",
    "#### **1. Pengenalan** üåü  \n",
    "- Sebagai profesional di bidang data science dan machine learning, terutama dalam Natural Language Processing (NLP), seringkali kita bekerja dengan data teks.  \n",
    "- Data teks umumnya tidak terstruktur dan lebih sulit dianalisis dibandingkan data terstruktur.  \n",
    "- Contohnya meliputi email, posting media sosial, buku, atau transkrip percakapan.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Dataset 20 Newsgroups** üì∞  \n",
    "- Dataset ini terdiri dari sekitar 20.000 dokumen dari diskusi di newsgroups (forum diskusi lama di internet).  \n",
    "- Terbagi menjadi 20 kategori topik seperti sains, agama, politik, olahraga, dll.  \n",
    "- Berguna untuk tugas klasifikasi teks karena datanya tersegmentasi dengan baik.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Mengakses dan Memahami Struktur Data** üîç  \n",
    "- **Library yang digunakan**: `sklearn.datasets.fetch_20newsgroups()`.  \n",
    "- **Struktur data**:  \n",
    "  - `data`: Konten teks (berformat list).  \n",
    "  - `target`: Label teks (berformat numpy array).  \n",
    "  - `target_names`: Nama label.  \n",
    "\n",
    "**Contoh kode:**\n",
    "```python\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Ambil data\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "\n",
    "# Struktur data\n",
    "print(f'Type of data: {type(newsgroups.data)}')  # Output: list\n",
    "print(f'Type of target: {type(newsgroups.target)}')  # Output: numpy.ndarray\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Eksplorasi Data** üîé  \n",
    "- **Jumlah data**: 18.846 dokumen.  \n",
    "- **Jumlah label**: Sama dengan jumlah data (18.846).  \n",
    "- **Kategori**: 20 kelas, contohnya:  \n",
    "  - `alt.atheism`, `comp.graphics`, `rec.autos`, `talk.religion.misc`, dll.\n",
    "\n",
    "**Contoh kode:**\n",
    "```python\n",
    "print(f'Number of datapoints: {len(newsgroups.data)}')\n",
    "print(f'Number of target variables: {len(newsgroups.target)}')\n",
    "print(f'Possible classes: {newsgroups.target_names}')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Preview Sampel Data** üìù  \n",
    "- **Contoh artikel**: Artikel ke-10.  \n",
    "- **Kategori**: `talk.religion.misc`.  \n",
    "\n",
    "**Contoh kode:**\n",
    "```python\n",
    "print(f'Article:\\n{newsgroups.data[10]}')\n",
    "print(f'Corresponding Topic: {newsgroups.target_names[newsgroups.target[10]]}')\n",
    "```\n",
    "\n",
    "**Hasil:**\n",
    "- Artikel berisi diskusi tentang agama dan hewan untuk ritual.  \n",
    "- Topik: `talk.religion.misc`.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **6. Ringkasan Pelajaran** üìñ  \n",
    "- Hari ini kita belajar cara mengakses dan menganalisis data teks menggunakan Python.  \n",
    "- Memahami struktur dataset seperti `20 Newsgroups` adalah langkah awal penting dalam tugas klasifikasi teks.  \n",
    "\n",
    "**Langkah Berikutnya** üöÄ:  \n",
    "1. Membersihkan data teks.  \n",
    "2. Menangani nilai kosong.  \n",
    "3. Mengorganisir data untuk analisis lebih lanjut.  \n",
    "\n",
    "Setiap langkah ini akan meningkatkan keahlian Anda dalam klasifikasi teks. Tetap semangat belajar! üéâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea32742d",
   "metadata": {},
   "source": [
    "## Explore More of the 20 Newsgroups Dataset\n",
    "\n",
    "Excellent job, Space Voyager! Now, make a small alteration to the starter code: change it to print out the first 150 characters of the 500th article from our 20 Newsgroups dataset, and also display its corresponding topic.\n",
    "\n",
    "python\n",
    "# Import necessary libraries and modules\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Fetch the dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "\n",
    "# Here we are fetching the first 100 characters of the 200th article and its corresponding topic\n",
    "print(f'\\nArticle:')\n",
    "print(f'{newsgroups.data[200][:100]}')\n",
    "print(f'\\nCorresponding Topic:')\n",
    "print(f'{newsgroups.target_names[newsgroups.target[200]]}')\n",
    "\n",
    "Here‚Äôs the updated code snippet to fetch the **first 150 characters of the 500th article** and display its corresponding topic:\n",
    "\n",
    "```python\n",
    "# Import necessary libraries and modules\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Fetch the dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "\n",
    "# Fetch and display the first 150 characters of the 500th article and its corresponding topic\n",
    "print(f'\\nArticle:')\n",
    "print(f'{newsgroups.data[500][:150]}')\n",
    "print(f'\\nCorresponding Topic:')\n",
    "print(f'{newsgroups.target_names[newsgroups.target[500]]}')\n",
    "```\n",
    "\n",
    "### Changes Made:\n",
    "1. **Article Selection**: Changed the article index from `200` to `500`.  \n",
    "2. **Character Limit**: Adjusted the character limit to the **first 150 characters** (was previously 100).\n",
    "\n",
    "This will now output a preview of the 500th article along with its topic label! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db23a75",
   "metadata": {},
   "source": [
    "## Uncover the End of 20 Newsgroups Dataset\n",
    "\n",
    "Celestial Traveler, your journey continues! Fill in the blanks (____) to import and explore our dataset. We aim to extract and display the last three articles and their corresponding topics. Can you reveal what's at the end of our dataset?\n",
    "\n",
    "```python\n",
    "# Import necessary libraries\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Fetch the dataset\n",
    "newsgroups = ____(subset='all')\n",
    "\n",
    "# Fetch last three articles\n",
    "last_three_articles = newsgroups.____[-3:]\n",
    "\n",
    "# Fetch the corresponding topics\n",
    "corresponding_topics = [newsgroups.target_names[i] for i in newsgroups.____[-3:]]\n",
    "\n",
    "# Display Last three articles and their corresponding topics\n",
    "for i in range(3):\n",
    "    print(f'\\nLast article {i+1}:') \n",
    "    print(f'{last_three_articles[i]}\\n')\n",
    "    print(f'Corresponding Topic {i+1}:')\n",
    "    print(f'{corresponding_topics[i]}\\n')\n",
    "```\n",
    "\n",
    "Here's the completed code snippet to fetch and display the last three articles and their corresponding topics from the 20 Newsgroups dataset:\n",
    "\n",
    "```python\n",
    "# Import necessary libraries\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Fetch the dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "\n",
    "# Fetch last three articles\n",
    "last_three_articles = newsgroups.data[-3:]\n",
    "\n",
    "# Fetch the corresponding topics\n",
    "corresponding_topics = [newsgroups.target_names[i] for i in newsgroups.target[-3:]]\n",
    "\n",
    "# Display Last three articles and their corresponding topics\n",
    "for i in range(3):\n",
    "    print(f'\\nLast article {i+1}:') \n",
    "    print(f'{last_three_articles[i]}\\n')\n",
    "    print(f'Corresponding Topic {i+1}:')\n",
    "    print(f'{corresponding_topics[i]}\\n')\n",
    "```\n",
    "\n",
    "### Explanation of Blanks:\n",
    "1. **`newsgroups = fetch_20newsgroups(subset='all')`**: Fetch the dataset.  \n",
    "2. **`last_three_articles = newsgroups.data[-3:]`**: Extract the last three articles using slicing on the `data` attribute.  \n",
    "3. **`newsgroups.target[-3:]`**: Retrieve the last three topic indices from the `target` attribute.  \n",
    "\n",
    "This code will reveal the last three articles and their topics. Let's uncover the dataset's finale! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa24e893",
   "metadata": {},
   "source": [
    "## Fetch Specific Categories from Dataset\n",
    "\n",
    "Celestial Traveler, let's narrow down our data collection. Modify the provided code to fetch only the 'alt.atheism' and 'talk.religion.misc' categories from our dataset. Then, display the first two articles from these categories along with their corresponding labels.\n",
    "\n",
    "```python\n",
    "# Import necessary libraries\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Fetch a subset of the dataset containing selected categories. Update the categories as needed.\n",
    "newsgroups_subset = fetch_20newsgroups(subset='all', categories=['comp.graphics', 'sci.space'])\n",
    "\n",
    "# Display the first two articles and their corresponding topics from this subset\n",
    "for i in range(2):\n",
    "    print(f'\\nArticle {i+1}:') \n",
    "    print(f'{newsgroups_subset.data[i]}\\n')\n",
    "    print(f'Corresponding Topic {i+1}:')\n",
    "    print(f'{newsgroups_subset.target_names[newsgroups_subset.target[i]]}\\n')\n",
    "```\n",
    "\n",
    "Here‚Äôs the updated code snippet to fetch only the **'alt.atheism'** and **'talk.religion.misc'** categories and display the first two articles along with their labels:\n",
    "\n",
    "```python\n",
    "# Import necessary libraries\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Fetch a subset of the dataset containing the selected categories\n",
    "newsgroups_subset = fetch_20newsgroups(subset='all', categories=['alt.atheism', 'talk.religion.misc'])\n",
    "\n",
    "# Display the first two articles and their corresponding topics from this subset\n",
    "for i in range(2):\n",
    "    print(f'\\nArticle {i+1}:') \n",
    "    print(f'{newsgroups_subset.data[i]}\\n')\n",
    "    print(f'Corresponding Topic {i+1}:')\n",
    "    print(f'{newsgroups_subset.target_names[newsgroups_subset.target[i]]}\\n')\n",
    "```\n",
    "\n",
    "### Changes Made:\n",
    "1. **Categories Selection**: Updated the `categories` parameter to `['alt.atheism', 'talk.religion.misc']`.  \n",
    "2. **Variable Usage**: Adjusted the code to work with the specific subset defined by the new categories.  \n",
    "\n",
    "### Output:\n",
    "This code will fetch the dataset with only the selected categories and display the **first two articles** and their corresponding topics. Time to explore these specific discussions! üåå"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f627262",
   "metadata": {},
   "source": [
    "## Fetching the Third Article from Dataset\n",
    "\n",
    "Well done, Stellar Navigator! Next, fill in the missing line in the code below to fetch and display the third article from the 20 Newsgroups dataset with its corresponding topic. Prepare your spacecraft for another adventure in data exploration!\n",
    "\n",
    "```python\n",
    "# Import necessary libraries\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Fetch the dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "\n",
    "# TODO: Fetch the third article and its corresponding topic \n",
    "\n",
    "```\n",
    "\n",
    "Here‚Äôs the completed code to fetch and display the third article along with its corresponding topic from the 20 Newsgroups dataset:\n",
    "\n",
    "```python\n",
    "# Import necessary libraries\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Fetch the dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "\n",
    "# Fetch the third article and its corresponding topic\n",
    "third_article = newsgroups.data[2]\n",
    "third_topic = newsgroups.target_names[newsgroups.target[2]]\n",
    "\n",
    "# Display the results\n",
    "print(f'\\nArticle 3:\\n{third_article}\\n')\n",
    "print(f'Corresponding Topic:\\n{third_topic}\\n')\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "1. **`newsgroups.data[2]`**: Access the third article (index starts at 0).  \n",
    "2. **`newsgroups.target[2]`**: Get the topic index of the third article.  \n",
    "3. **`newsgroups.target_names`**: Use the index to find the human-readable topic name.\n",
    "\n",
    "This code will display the full content of the third article and its corresponding topic. Happy exploring, Data Voyager! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169fea1d",
   "metadata": {},
   "source": [
    "## Exploring Text Length in Newsgroups Dataset\n",
    "\n",
    "Great job, Space Voyager! Now, as a final task, write a Python script that calculates and displays the lengths of the first five articles (in terms of the number of characters) from the 20 Newsgroups dataset.\n",
    "\n",
    "```python\n",
    "# Import necessary libraries and modules\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# TODO: Fetch the 20 Newsgroups dataset\n",
    "\n",
    "# TODO: Iterate over the first five articles,\n",
    "# TODO: Calculate their length in terms of the number of characters and display it\n",
    "```\n",
    "\n",
    "Here‚Äôs the Python script to calculate and display the lengths (in terms of characters) of the first five articles from the 20 Newsgroups dataset:\n",
    "\n",
    "```python\n",
    "# Import necessary libraries and modules\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Fetch the 20 Newsgroups dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "\n",
    "# Iterate over the first five articles, calculate their length, and display it\n",
    "for i in range(5):\n",
    "    article_length = len(newsgroups.data[i])  # Calculate the length in characters\n",
    "    print(f'Article {i+1} length: {article_length} characters\\n')\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "1. **`len(newsgroups.data[i])`**: This calculates the length of each article by counting the number of characters.\n",
    "2. **`range(5)`**: Loops over the first five articles.\n",
    "3. **Print statement**: Displays the length of each article in characters.\n",
    "\n",
    "This script will output the length of the first five articles from the dataset. Enjoy your data exploration journey! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35145c0-375b-407d-9acd-d49512144044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
