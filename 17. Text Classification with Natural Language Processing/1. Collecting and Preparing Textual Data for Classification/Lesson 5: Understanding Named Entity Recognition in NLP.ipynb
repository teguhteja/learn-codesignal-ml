{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "303ef01a",
   "metadata": {},
   "source": [
    "# Lesson 5: Understanding Named Entity Recognition in NLP\n",
    "\n",
    "## Introduction\n",
    "Welcome to our lesson on Named Entity Recognition! Today, we'll be diving deep into the world of NLP and discovering how we can identify informative chunks of text, namely \"Named Entities\". The goal of this lesson is to learn about Part of Speech (POS) tagging and Named Entity Recognition (NER). By the end, you'll be able to gather specific types of data from text and get a few steps closer to mastering text classification.\n",
    "\n",
    "## What is Named Entity Recognition?\n",
    "Imagine we have a piece of text and we want to get some quick insights. What are the main subjects? Are there any specific locations or organizations being talked about? This is where Named Entity Recognition (NER) comes in handy.\n",
    "\n",
    "In natural language processing (NLP), NER is a subtask of information extraction that seeks to locate and classify named entities in text into pre-defined categories such as names of persons, organizations, locations, expressions of times, quantities, monetary values, and percentages.\n",
    "\n",
    "For instance, consider the sentence: \"Apple Inc. is planning to open a new store in San Francisco.\" Using NER, we could identify that \"Apple Inc.\" is an organization and \"San Francisco\" is a location. Such information can be incredibly valuable for numerous NLP tasks.\n",
    "\n",
    "## Part of Speech (POS) Tagging\n",
    "Every word in a sentence has a particular role. Some words are objects, some are verbs, some are adjectives, and so on. Tagging these parts of speech, or POS tagging, can be a critical component to many NLP tasks. It can help answer many questions, like what are the main objects in a sentence, what actions are being taken, and what's the context of these actions?\n",
    "\n",
    "Let's start with a sentence example: \"Apple Inc. is planning to open a new store in San Francisco.\"\n",
    "\n",
    "```python\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "example_sentence = \"Apple Inc. is planning to open a new store in San Francisco.\"\n",
    "tokens = word_tokenize(example_sentence)\n",
    "pos_tags = pos_tag(tokens)\n",
    "print(f'The first 5 POS tags are: {pos_tags[:5]}')\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "The first 5 POS tags are: [('Apple', 'NNP'), ('Inc.', 'NNP'), ('is', 'VBZ'), ('planning', 'VBG'), ('to', 'TO')]\n",
    "```\n",
    "\n",
    "## Named Entity Recognition with NLTK\n",
    "Named Entity Recognition (NER) can be considered a step beyond regular POS tagging. It groups together one or more words that signify a named entity such as \"San Francisco\" or \"Apple Inc.\" into a single category, i.e., location or organization in this case.\n",
    "\n",
    "```python\n",
    "from nltk import ne_chunk\n",
    "\n",
    "named_entities = ne_chunk(pos_tags)\n",
    "print(f'The named entities in our example sentences are:\\n{named_entities}')\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "The named entities in our example sentences are:\n",
    "(S\n",
    "  (PERSON Apple/NNP)\n",
    "  (ORGANIZATION Inc./NNP)\n",
    "  is/VBZ\n",
    "  planning/VBG\n",
    "  to/TO\n",
    "  open/VB\n",
    "  a/DT\n",
    "  new/JJ\n",
    "  store/NN\n",
    "  in/IN\n",
    "  (GPE San/NNP Francisco/NNP)\n",
    "  ./.)\n",
    "```\n",
    "\n",
    "### Understanding the Output\n",
    "* The 'S' at the beginning signifies the start of a sentence\n",
    "* Words inside parentheses, prefixed with labels such as PERSON, ORGANIZATION, or GPE are recognized named entities\n",
    "* Words outside parentheses are not recognized as part of a named entity but are part of the sentence\n",
    "* '(GPE San/NNP Francisco/NNP)' indicates that 'San Francisco' is recognized as a geopolitical entity\n",
    "\n",
    "## Applying PoS Tagging and NER to a Real Dataset\n",
    "Let's use these techniques on the 20 Newsgroups dataset:\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from nltk import pos_tag, ne_chunk, word_tokenize\n",
    "\n",
    "# Loading the data with metadata removed\n",
    "newsgroups_data = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Selecting the first document \n",
    "first_doc = newsgroups_data.data[0]\n",
    "\n",
    "# Trimming the document's text down to the first 67 characters\n",
    "first_doc = first_doc[:67]\n",
    "\n",
    "# Tokenizing the text\n",
    "tokens_first_doc = word_tokenize(first_doc)\n",
    "\n",
    "# Applying POS tagging\n",
    "pos_tags_first_doc = pos_tag(tokens_first_doc)\n",
    "\n",
    "# Applying Named Entity Recognition\n",
    "named_entities = ne_chunk(pos_tags_first_doc)\n",
    "\n",
    "print(f'The first chunk of named entities in the first document are:\\n{named_entities}')\n",
    "```\n",
    "\n",
    "## Lesson Summary\n",
    "In this lesson, we have covered:\n",
    "* Part of Speech (POS) tagging\n",
    "* Named Entity Recognition (NER)\n",
    "* Application of these techniques to real-world data\n",
    "* Understanding and interpreting NER output\n",
    "\n",
    "These concepts are fundamental to text preprocessing in Natural Language Processing. Having a grasp over these will allow you to approach more advanced topics in NLP with ease.\n",
    "\n",
    "Keep practicing these techniques to reinforce your understanding and improve your Natural Language Processing skills. Enjoy the hands-on session and keep learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38844bfe",
   "metadata": {},
   "source": [
    "## Changing the Sentence for Named Entity Recognition\n",
    "\n",
    "Great work, Space Voyager!\n",
    "\n",
    "Now, change the sentence in the provided code to \"Microsoft Corporation aims to reach 95% global coverage by 2025.\" and observe how the named entities identified by the Named Entity Recognition (NER) change.\n",
    "\n",
    "Keep advancing!\n",
    "\n",
    "```python\n",
    "from nltk import pos_tag, word_tokenize, ne_chunk\n",
    "\n",
    "# Given sentence\n",
    "sample_sentence = \"Apple Inc. planned to open a new store in San Francisco in 82% of time by 2020.\"\n",
    "\n",
    "# Get tokens\n",
    "tokens = word_tokenize(sample_sentence)\n",
    "\n",
    "# Get POS tags\n",
    "pos_tags = pos_tag(tokens)\n",
    "\n",
    "# Perform NER\n",
    "named_entities = ne_chunk(pos_tags)\n",
    "\n",
    "# Print the identified named entities\n",
    "print(named_entities)\n",
    "```\n",
    "\n",
    "Here's how the code would look after modifying the sentence, along with an explanation of the expected changes in Named Entity Recognition (NER) output:\n",
    "\n",
    "---\n",
    "\n",
    "### Updated Code:\n",
    "```python\n",
    "from nltk import pos_tag, word_tokenize, ne_chunk\n",
    "\n",
    "# Updated sentence\n",
    "sample_sentence = \"Microsoft Corporation aims to reach 95% global coverage by 2025.\"\n",
    "\n",
    "# Get tokens\n",
    "tokens = word_tokenize(sample_sentence)\n",
    "\n",
    "# Get POS tags\n",
    "pos_tags = pos_tag(tokens)\n",
    "\n",
    "# Perform NER\n",
    "named_entities = ne_chunk(pos_tags)\n",
    "\n",
    "# Print the identified named entities\n",
    "print(named_entities)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Expected Changes in NER Output:  \n",
    "Given the new sentence, the Named Entity Recognition (NER) should yield the following:\n",
    "\n",
    "1. **\"Microsoft Corporation\"**:  \n",
    "   - Will likely be classified as an **ORGANIZATION** because it is a known corporate entity.  \n",
    "\n",
    "2. **\"2025\"**:  \n",
    "   - Should be categorized as a **DATE**, as it refers to a specific year.  \n",
    "\n",
    "3. **\"95%\"**:  \n",
    "   - May not be classified as a named entity but should retain its POS tag (e.g., as a **CD** for cardinal number).  \n",
    "\n",
    "---\n",
    "\n",
    "### Expected Output:\n",
    "```plaintext\n",
    "(S\n",
    "  (ORGANIZATION Microsoft/NNP Corporation/NNP)\n",
    "  aims/VBZ\n",
    "  to/TO\n",
    "  reach/VB\n",
    "  95/CD\n",
    "  %/NN\n",
    "  global/JJ\n",
    "  coverage/NN\n",
    "  by/IN\n",
    "  (DATE 2025/CD)\n",
    "  ./.)\n",
    "```\n",
    "\n",
    "- **(ORGANIZATION Microsoft/NNP Corporation/NNP)**: Recognized as an organization.\n",
    "- **(DATE 2025/CD)**: Recognized as a date.  \n",
    "- Other words (e.g., \"aims\", \"global\", \"coverage\") retain their respective POS tags.\n",
    "\n",
    "---\n",
    "\n",
    "### Observations:\n",
    "- Replacing the sentence changes the entities identified (e.g., *Microsoft Corporation* vs. *Apple Inc.*).  \n",
    "- Dates like \"2025\" are tagged explicitly as **DATE**, showcasing NER's ability to classify time-related expressions.  \n",
    "\n",
    "Let me know if youâ€™d like to analyze further! ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409e8278",
   "metadata": {},
   "source": [
    "## Implementing Tokenization and POS Tagging\n",
    "\n",
    "Excellent work, Space Explorer!\n",
    "\n",
    "Let's reinforce your learning by inserting the missing code. Fill in the appropriate functions to perform tokenization and POS tagging. Use nltk's powerful tools to achieve this. Happy learning!\n",
    "\n",
    "```python\n",
    "from nltk import ____, word_tokenize\n",
    "\n",
    "# Given sentence\n",
    "sample_sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Get tokens\n",
    "tokens = word_tokenize(sample_sentence)\n",
    "\n",
    "# Get POS tags\n",
    "pos_tags = ____(tokens)\n",
    "\n",
    "# Print the POS tags\n",
    "print(pos_tags)\n",
    "\n",
    "```\n",
    "\n",
    "Here's the completed code snippet with the appropriate functions filled in: \n",
    "\n",
    "```python\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "# Given sentence\n",
    "sample_sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Get tokens\n",
    "tokens = word_tokenize(sample_sentence)\n",
    "\n",
    "# Get POS tags\n",
    "pos_tags = pos_tag(tokens)\n",
    "\n",
    "# Print the POS tags\n",
    "print(pos_tags)\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "1. **`word_tokenize`**: This function splits the sentence into individual words (tokens).\n",
    "2. **`pos_tag`**: This function assigns Part-of-Speech (POS) tags to the tokens, providing their grammatical roles.\n",
    "\n",
    "### Output:\n",
    "When you run this code, the output will look like this:\n",
    "```\n",
    "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'JJ'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN')]\n",
    "```\n",
    "\n",
    "This output represents the tokenized words along with their respective POS tags. For example:\n",
    "- `'DT'` = Determiner\n",
    "- `'JJ'` = Adjective\n",
    "- `'NN'` = Noun\n",
    "- `'VBZ'` = Verb, 3rd person singular present\n",
    "- `'IN'` = Preposition    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2820f6",
   "metadata": {},
   "source": [
    "## Applying Named Entity Recognition to a Sentence\n",
    "\n",
    "Great job, Space Voyager!\n",
    "\n",
    "Now that you've created a function to perform Named Entity Recognition (NER), it's time to use it on some text. Fill in the blanks to apply your apply_ner function to the sentence: \"CodeSignal is headquartered in San Francisco.\"\n",
    "\n",
    "Print the recognized named entities from the sentence to see how it works.\n",
    "\n",
    "Keep advancing!\n",
    "\n",
    "```python\n",
    "from nltk import ____, pos_tag, word_tokenize\n",
    "\n",
    "def apply_ner(sentence):\n",
    "    # Tokenize the sentence\n",
    "    tokens = word_tokenize(sentence)\n",
    "\n",
    "    # Apply POS tagging\n",
    "    pos_tags = pos_tag(tokens)\n",
    "\n",
    "    # Apply NER\n",
    "    named_entities = ____(____)\n",
    "\n",
    "    # Return the identified named entities\n",
    "    return named_entities\n",
    "\n",
    "# Apply the function to a specific sentence\n",
    "named_entities_in_sentence = apply_ner(\"CodeSignal is headquartered in San Francisco.\")\n",
    "print(named_entities_in_sentence)\n",
    "\n",
    "```\n",
    "\n",
    "I'll help you complete this code by filling in the blanks. Here's how to perform Named Entity Recognition on that sentence.\n",
    "\n",
    "```python\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "\n",
    "def apply_ner(sentence):\n",
    "    # Tokenize the sentence\n",
    "    tokens = word_tokenize(sentence)\n",
    "\n",
    "    # Apply POS tagging\n",
    "    pos_tags = pos_tag(tokens)\n",
    "\n",
    "    # Apply NER\n",
    "    named_entities = ne_chunk(pos_tags)\n",
    "\n",
    "    # Return the identified named entities\n",
    "    return named_entities\n",
    "\n",
    "# Apply the function to a specific sentence\n",
    "named_entities_in_sentence = apply_ner(\"CodeSignal is headquartered in San Francisco.\")\n",
    "print(named_entities_in_sentence)\n",
    "```\n",
    "\n",
    "I filled in:\n",
    "1. `ne_chunk` in the import statement - this is NLTK's function for Named Entity Recognition\n",
    "2. `ne_chunk(pos_tags)` in the function - this applies NER to our POS-tagged tokens\n",
    "\n",
    "When you run this code, it will output something like:\n",
    "```\n",
    "(S\n",
    "  (ORGANIZATION CodeSignal/NNP)\n",
    "  is/VBZ\n",
    "  headquartered/VBN\n",
    "  in/IN\n",
    "  (GPE San/NNP Francisco/NNP)\n",
    "  ./.)\n",
    "```\n",
    "\n",
    "The output shows that:\n",
    "- \"CodeSignal\" is recognized as an ORGANIZATION\n",
    "- \"San Francisco\" is recognized as a GPE (Geo-Political Entity)\n",
    "- Other words are tagged with their parts of speech but aren't identified as named entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac406275",
   "metadata": {},
   "source": [
    "## Implementing a Named Entity Extraction Function\n",
    "\n",
    "Galactic Pioneer, you're doing great!\n",
    "\n",
    "Your task is to complete the function extract_named_entities. This function should tokenize the related text, perform POS tagging, and carry out Named Entity Recognition (NER). The function should then return the named entities. Forge ahead!\n",
    "\n",
    "```python\n",
    "from nltk import pos_tag, word_tokenize, ne_chunk\n",
    "\n",
    "def extract_named_entities(text):\n",
    "    # TODO: Tokenize the text\n",
    "    # TODO: Apply POS tagging\n",
    "    # TODO: Perform NER and return the result\n",
    "    pass\n",
    "\n",
    "# Provided sentence\n",
    "sentence = \"Microsoft Corporation aims to reach 95% global coverage by 2025.\"\n",
    "\n",
    "# Print the extracted named entities\n",
    "print(extract_named_entities(sentence))\n",
    "```\n",
    "\n",
    "\n",
    "Hereâ€™s the completed function that extracts named entities using nltk:\n",
    "\n",
    "Extract Named Entities\n",
    "```python\n",
    "from nltk import pos_tag, word_tokenize, ne_chunk\n",
    "from nltk.tree import Tree\n",
    "\n",
    "def extract_named_entities(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Apply POS tagging\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    \n",
    "    # Perform Named Entity Recognition (NER)\n",
    "    named_entities_tree = ne_chunk(pos_tags)\n",
    "    \n",
    "    # Extract named entities from the tree\n",
    "    named_entities = []\n",
    "    for subtree in named_entities_tree:\n",
    "        if isinstance(subtree, Tree):  # Named entity detected\n",
    "            entity_name = \" \".join([token for token, pos in subtree.leaves()])\n",
    "            entity_type = subtree.label()  # Get entity type (e.g., PERSON, ORGANIZATION)\n",
    "            named_entities.append((entity_name, entity_type))\n",
    "    \n",
    "    return named_entities\n",
    "\n",
    "# Provided sentence\n",
    "sentence = \"Microsoft Corporation aims to reach 95% global coverage by 2025.\"\n",
    "\n",
    "# Print the extracted named entities\n",
    "print(extract_named_entities(sentence))\n",
    "```\n",
    "\n",
    "This function:\n",
    "\n",
    "Tokenizes the input text.\n",
    "1. Applies POS (Part-of-Speech) tagging.\n",
    "2. Uses ne_chunk to perform Named Entity Recognition (NER).\n",
    "3. Extracts named entities along with their labels (e.g., ORGANIZATION, PERSON, etc.).\n",
    "4. Returns a list of named entities and their types.\n",
    "Try running it with different sentences to see how it detects named entities! ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b183c9cb-48d4-4fef-b85c-028611d1df2f",
   "metadata": {},
   "source": [
    "Brilliant trajectory, Space Voyager!\n",
    "\n",
    "You have been assigned a challenging task. Add the missing lines to tokenize the first document in newsgroups_data, and then perform POS tagging and Named Entity Recognition. Afterwards, print the named entities. Keep pushing boundaries!\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# TODO: Import the necessary NLTK modules for tokenization, POS tagging, and NER\n",
    "\n",
    "\n",
    "# Loading the data with metadata removed\n",
    "newsgroups_data = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# TODO: Extract the first document from the dataset\n",
    "\n",
    "# TODO: Tokenize the text\n",
    "\n",
    "# TODO: Apply POS tagging\n",
    "\n",
    "# TODO: Apply Named Entity Recognition\n",
    "\n",
    "# TODO: Print the identified named entities\n",
    "\n",
    "```\n",
    "\n",
    "To complete the task of extracting named entities from the first document in the `newsgroups_data` dataset, we'll need to import the necessary modules from NLTK for tokenization, POS tagging, and Named Entity Recognition (NER). We'll then apply these tools to the text data retrieved from `fetch_20newsgroups`. Here's how you can do it:\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from nltk import pos_tag, word_tokenize, ne_chunk, tree\n",
    "\n",
    "# Loading the data with metadata removed\n",
    "newsgroups_data = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Extract the first document from the dataset\n",
    "first_document = newsgroups_data.data[0]\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = word_tokenize(first_document)\n",
    "\n",
    "# Apply POS tagging\n",
    "tagged = pos_tag(tokens)\n",
    "\n",
    "# Apply Named Entity Recognition\n",
    "ner_tree = ne_chunk(tagged)\n",
    "\n",
    "# Extract and print the identified named entities\n",
    "named_entities = []\n",
    "for subtree in ner_tree:\n",
    "    if type(subtree) == tree.Tree:  # Check if it is a NER subtree\n",
    "        entity_label = subtree.label()  # Get the entity type (e.g., PERSON, ORGANIZATION)\n",
    "        entity_name = \" \".join(word for word, tag in subtree.leaves())  # Join the entity words\n",
    "        named_entities.append((entity_name, entity_label))\n",
    "\n",
    "# Print the named entities\n",
    "for entity in named_entities:\n",
    "    print(entity)\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "- **Loading Data**: The `fetch_20newsgroups` function is used to load the newsgroups data. We specify `subset='train'` to get the training subset and `remove=('headers', 'footers', 'quotes')` to strip off additional metadata and text that could skew the analysis.\n",
    "- **Extract First Document**: We take the first document from the dataset by accessing the zeroth index of the `data` attribute.\n",
    "- **Tokenization**: We use `word_tokenize` to split the document into individual tokens (words and punctuation).\n",
    "- **POS Tagging**: The `pos_tag` function assigns a part-of-speech tag to each token.\n",
    "- **Named Entity Recognition**: The `ne_chunk` function processes the tagged tokens to identify named entities. It returns a tree structure where named entities are grouped into subtrees with labels indicating their types.\n",
    "- **Extract Named Entities**: We iterate through the elements of the tree. If an element is a subtree, we identify it as a named entity, extract its label and the words forming the entity, and store these as tuples in the `named_entities` list.\n",
    "- **Print Named Entities**: Finally, we print each named entity found in the document.\n",
    "\n",
    "This script will output all named entities recognized in the first document of the `newsgroups_data` dataset, providing insights into the types of entities (like organizations, persons, locations) mentioned in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80c3937-94d2-42ea-a174-c664ff8c334e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
