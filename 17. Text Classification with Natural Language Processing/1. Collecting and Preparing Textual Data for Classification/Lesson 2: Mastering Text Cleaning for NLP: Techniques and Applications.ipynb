{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c025834c",
   "metadata": {},
   "source": [
    "# Lesson 2: Mastering Text Cleaning for NLP: Techniques and Applications\n",
    "\n",
    "### üöÄ **Text Cleaning in NLP: Master the Basics!**  \n",
    "\n",
    "#### üìö **Introduction**  \n",
    "- **Objective**: Learn how to clean textual data using Python for better Natural Language Processing (NLP) results.  \n",
    "- **Importance**: Clean input data leads to more accurate NLP model outputs.\n",
    "\n",
    "---\n",
    "\n",
    "#### üßπ **Understanding Text Cleaning**  \n",
    "1. **Why Text Cleaning?**  \n",
    "   - Handles noisy data (e.g., slang, abbreviations, emojis).  \n",
    "   - Prepares text for machine comprehension by removing distractions like punctuation and stop words.  \n",
    "\n",
    "2. **Key Tool**:  \n",
    "   - **Python's Regex (`re`)**: Simplifies pattern-based string replacement using `re.sub(pattern, repl, string)`.\n",
    "\n",
    "---\n",
    "\n",
    "#### üõ† **Text Cleaning Process**  \n",
    "Using the Python function `clean_text`:  \n",
    "\n",
    "```python\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)  # Remove email addresses\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters and punctuation\n",
    "    text = re.sub(r'\\d', ' ', text)  # Remove digits\n",
    "    text = re.sub(r'\\s\\s+', ' ', text)  # Remove extra spaces\n",
    "    return text\n",
    "```\n",
    "\n",
    "**Steps Explained**:  \n",
    "- **Lowercase**: Normalizes case sensitivity (e.g., `The` = `the`).  \n",
    "- **Remove Emails**: Excludes unnecessary email addresses.  \n",
    "- **Remove URLs**: Eliminates irrelevant links.  \n",
    "- **Special Characters**: Filters out symbols, punctuation.  \n",
    "- **Numbers**: Discards numeric distractions.  \n",
    "- **Extra Spaces**: Cleans up formatting.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîç **Demo Example**  \n",
    "\n",
    "Input:  \n",
    "```python\n",
    "print(clean_text('Check out the course at www.codesignal.com/course123'))\n",
    "```\n",
    "\n",
    "Output:  \n",
    "```\n",
    "check out the course at www codesignal com course\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### üìä **Dataset Implementation**  \n",
    "Apply `clean_text` to a dataset using Pandas:  \n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Load dataset\n",
    "newsgroups_data = fetch_20newsgroups(subset='train')\n",
    "nlp_df = pd.DataFrame(newsgroups_data.data, columns=['text'])\n",
    "\n",
    "# Apply cleaning function\n",
    "nlp_df['text'] = nlp_df['text'].apply(lambda x: clean_text(x))\n",
    "\n",
    "print(nlp_df.head())\n",
    "```\n",
    "\n",
    "**Result**: A cleaned DataFrame ready for further NLP tasks.  \n",
    "\n",
    "---\n",
    "\n",
    "#### üß™ **Testing the Cleaning Function**  \n",
    "Example with various inputs:  \n",
    "\n",
    "```python\n",
    "test_texts = ['This is an EXAMPLE!', 'Another ex:ample123 with $#@!', 'example@mail.com is an email.']\n",
    "\n",
    "for text in test_texts:\n",
    "    print(f'Original: {text}')\n",
    "    print(f'Cleaned: {clean_text(text)}')\n",
    "```\n",
    "\n",
    "**Output**:  \n",
    "- Original: `This is an EXAMPLE!` ‚Üí Cleaned: `this is an example`  \n",
    "- Original: `Another ex:ample123 with $#@!` ‚Üí Cleaned: `another ex ample with `  \n",
    "- Original: `example@mail.com is an email.` ‚Üí Cleaned: `is an email `  \n",
    "\n",
    "---\n",
    "\n",
    "### üìù **Lesson Summary**  \n",
    "- **What You Learned**:  \n",
    "  - Importance of text cleaning in NLP.  \n",
    "  - Implementing a Python function to clean data.  \n",
    "  - Application to real datasets using Pandas.  \n",
    "\n",
    "- **Next Steps**:  \n",
    "  - Practice cleaning datasets to build better NLP pipelines!  \n",
    "\n",
    "**Happy Cleaning!** üßπ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93ec095",
   "metadata": {},
   "source": [
    "## Update String and Clean Text\n",
    "\n",
    "Well done, Space Voyager! Now, to further explore the workings of our text cleaning function, let's use a different sentence. Replace the first sentence in the test_texts list with the phrase \"I love learning at CodeSignal; it's so interactive and fun!\". Then run the clean_text function with the updated list.\n",
    "\n",
    "```python\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert text to lower case\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)  # Remove email addresses\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation and special characters but leave spaces\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Normalize whitespace to single spaces\n",
    "\n",
    "    return text.strip()  # Strip leading and trailing spaces\n",
    "\n",
    "test_texts = ['This is an EXAMPLE!', \n",
    "              'Another ex:ample123 with special characters $#@!', \n",
    "              'example@mail.com is an email address.']\n",
    "for text in test_texts:\n",
    "    print(f'Original: {text}')\n",
    "    print(f'Cleaned: {clean_text(text)}')\n",
    "    print('--')\n",
    "    \n",
    "```\n",
    "\n",
    "Here's the updated code and output with the first sentence replaced as per your instructions:\n",
    "\n",
    "```python\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert text to lower case\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)  # Remove email addresses\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation and special characters but leave spaces\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Normalize whitespace to single spaces\n",
    "\n",
    "    return text.strip()  # Strip leading and trailing spaces\n",
    "\n",
    "# Updated test_texts list\n",
    "test_texts = ['I love learning at CodeSignal; it\\'s so interactive and fun!', \n",
    "              'Another ex:ample123 with special characters $#@!', \n",
    "              'example@mail.com is an email address.']\n",
    "\n",
    "# Test the clean_text function with the updated list\n",
    "for text in test_texts:\n",
    "    print(f'Original: {text}')\n",
    "    print(f'Cleaned: {clean_text(text)}')\n",
    "    print('--')\n",
    "```\n",
    "\n",
    "### **Output:**\n",
    "\n",
    "```\n",
    "Original: I love learning at CodeSignal; it's so interactive and fun!\n",
    "Cleaned: i love learning at codesignal its so interactive and fun\n",
    "--\n",
    "Original: Another ex:ample123 with special characters $#@!\n",
    "Cleaned: another ex ample with special characters\n",
    "--\n",
    "Original: example@mail.com is an email address.\n",
    "Cleaned: is an email address\n",
    "--\n",
    "```\n",
    "\n",
    "### **Explanation of Updates:**\n",
    "1. The first sentence was replaced with `\"I love learning at CodeSignal; it's so interactive and fun!\"`.\n",
    "2. The `clean_text` function:\n",
    "   - Converted the sentence to lowercase.\n",
    "   - Removed punctuation (`;`, `'`).\n",
    "   - Normalized spaces and stripped leading/trailing whitespace.\n",
    "3. Output reflects cleaned versions of the updated text inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62200471",
   "metadata": {},
   "source": [
    "## Filling in Python Functions and Regex Patterns\n",
    "\n",
    "Superb job! Now, let's ensure you have grasped the core Python functions and regex patterns used in text cleaning.\n",
    "\n",
    "Fill in the blanks (____) to transform all text to lowercase and remove extra spaces.\n",
    "\n",
    "```python\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.____()  # Convert text to lower case\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)  # Remove email addresses\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove punctuation and special characters\n",
    "    text = re.sub(r'\\d', ' ', text)  # Remove digits\n",
    "    text = re.sub(r'\\____\\s+', ' ', text)  # Remove extra spaces\n",
    "    return text.strip()\n",
    "\n",
    "test_texts = ['Fill me In! I enjoy problem-solving tasks like these; they are quite engaging.', \n",
    "              'Another ex:ample123 with special characters $#@!', \n",
    "              'example@mail.com is an email address.']\n",
    "for text in test_texts:\n",
    "    print(f'Original: {text}')\n",
    "    print(f'Cleaned: {clean_text(text)}')\n",
    "    print('--')\n",
    "\n",
    "```\n",
    "\n",
    "Here‚Äôs the filled-in code:\n",
    "\n",
    "```python\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert text to lower case\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)  # Remove email addresses\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove punctuation and special characters\n",
    "    text = re.sub(r'\\d', ' ', text)  # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    return text.strip()\n",
    "\n",
    "test_texts = ['Fill me In! I enjoy problem-solving tasks like these; they are quite engaging.', \n",
    "              'Another ex:ample123 with special characters $#@!', \n",
    "              'example@mail.com is an email address.']\n",
    "for text in test_texts:\n",
    "    print(f'Original: {text}')\n",
    "    print(f'Cleaned: {clean_text(text)}')\n",
    "    print('--')\n",
    "```\n",
    "\n",
    "### **Explanation of the Filled Blanks:**\n",
    "1. `text.lower()` was filled in to convert the text to lowercase. This ensures that all words are treated uniformly regardless of their original casing.\n",
    "2. `\\s+` was filled in the regex pattern to identify one or more whitespace characters. This is used to normalize multiple spaces into a single space.\n",
    "\n",
    "### **Output:**\n",
    "```\n",
    "Original: Fill me In! I enjoy problem-solving tasks like these; they are quite engaging.\n",
    "Cleaned: fill me in i enjoy problem solving tasks like these they are quite engaging\n",
    "--\n",
    "Original: Another ex:ample123 with special characters $#@!\n",
    "Cleaned: another ex ample with special characters\n",
    "--\n",
    "Original: example@mail.com is an email address.\n",
    "Cleaned: is an email address\n",
    "--\n",
    "```\n",
    "\n",
    "This output confirms that the `clean_text` function works as intended after filling in the blanks!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315678c0",
   "metadata": {},
   "source": [
    "## Mastering Text Cleaning with Python Regex\n",
    "\n",
    "Charming maneuvering, Stellar Navigator!\n",
    "\n",
    "Now, I want to see more of your Python prowess. Replace the missing parts (____), ensuring that they perform the right operations. We aim to transform all text to lowercase and eliminate email addresses, URLs, special characters, digits, and extra spaces.\n",
    "\n",
    "```python\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.____()  # Convert text to lower case\n",
    "    text = re.sub(r'____', '', text)  # Remove email addresses\n",
    "    text = re.sub(r'____', '', text)  # Remove URLs\n",
    "    text = re.sub(r'____', ' ', text)  # Remove punctuation and special characters\n",
    "    text = re.sub(r'____', '', text)  # Remove digits\n",
    "    text = re.sub(r'____', ' ', text)  # Remove extra spaces\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "test_texts = ['Sample Text with EMAIL! mailsample@mail.com', \n",
    "              'URL example: https://www.codesignal.com', \n",
    "              'Special characters #formed.', \n",
    "              'Digits included: 1234!!',\n",
    "              'Extra spaces   included.']\n",
    "for text in test_texts:\n",
    "    print(f'Original: {text}')\n",
    "    print(f'Cleaned: {clean_text(text)}')\n",
    "    print('--')\n",
    "\n",
    "```\n",
    "\n",
    "Here's how to complete the `clean_text` function to transform all text to lowercase, remove email addresses, URLs, special characters, digits, and extra spaces:\n",
    "\n",
    "```python\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert text to lower case\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)  # Remove email addresses\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # Remove punctuation and special characters\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "test_texts = ['Sample Text with EMAIL! mailsample@mail.com', \n",
    "              'URL example: https://www.codesignal.com', \n",
    "              'Special characters #formed.', \n",
    "              'Digits included: 1234!!',\n",
    "              'Extra spaces   included.']\n",
    "for text in test_texts:\n",
    "    print(f'Original: {text}')\n",
    "    print(f'Cleaned: {clean_text(text)}')\n",
    "    print('--')\n",
    "```\n",
    "\n",
    "### Explanation of the regex patterns:\n",
    "1. **`text.lower()`**: Converts the entire text to lowercase.\n",
    "2. **`r'\\S*@\\S*\\s?'`**: Removes any email address (anything in the format of `user@example.com`).\n",
    "3. **`r'http\\S+'`**: Removes URLs (anything starting with \"http\" followed by non-whitespace characters).\n",
    "4. **`r'[^\\w\\s]'`**: Removes punctuation and special characters, leaving only word characters (letters, digits) and whitespace.\n",
    "5. **`r'\\d+'`**: Removes digits from the text.\n",
    "6. **`r'\\s+'`**: Removes extra spaces and normalizes them to a single space.\n",
    "\n",
    "This code will ensure that text is clean, with only necessary elements left for further processing or analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b9929c",
   "metadata": {},
   "source": [
    "## Implement Text Cleaning on Dataset\n",
    "\n",
    "Off to a flying start, Celestial Traveler! Your new task requires you to insert missing code into two sections. First, write code that transforms the collected dataset into a DataFrame. Then, ensure that you apply the clean_text function to the DataFrame to clean up the textual data. Bon Voyage!\n",
    "\n",
    "```python\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert text to lower case\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)  # Remove email addresses\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove punctuation and special characters\n",
    "    text = re.sub(r'\\d', ' ', text)  # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Normalize whitespace to single spaces\n",
    "\n",
    "    return text.strip()  # Strip leading and trailing spaces\n",
    "\n",
    "# Fetch the dataset\n",
    "newsgroups_data = fetch_20newsgroups(subset='train')\n",
    "\n",
    "# Create DataFrame from the dataset\n",
    "# TODO: Write the required code to create a dataframe from the dataset. Name the dataframe as nlp_df and the column as 'text'.\n",
    "\n",
    "# Apply the clean_text function to the text data in the DataFrame\n",
    "# TODO: Write the code to apply the clean_text function to the 'text' column in the dataframe. \n",
    "\n",
    "# Check the cleaned text\n",
    "print(nlp_df.head())\n",
    "\n",
    "```\n",
    "\n",
    "To complete the task, let's proceed with the following steps:\n",
    "\n",
    "1. Create a DataFrame from the `newsgroups_data` and store it in `nlp_df`, with the relevant column being `'text'`.\n",
    "2. Apply the `clean_text` function to the `'text'` column to clean the textual data.\n",
    "\n",
    "Here‚Äôs the completed code:\n",
    "\n",
    "```python\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert text to lower case\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)  # Remove email addresses\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove punctuation and special characters\n",
    "    text = re.sub(r'\\d', ' ', text)  # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Normalize whitespace to single spaces\n",
    "\n",
    "    return text.strip()  # Strip leading and trailing spaces\n",
    "\n",
    "# Fetch the dataset\n",
    "newsgroups_data = fetch_20newsgroups(subset='train')\n",
    "\n",
    "# Create DataFrame from the dataset\n",
    "nlp_df = pd.DataFrame(newsgroups_data.data, columns=['text'])\n",
    "\n",
    "# Apply the clean_text function to the 'text' column in the dataframe\n",
    "nlp_df['text'] = nlp_df['text'].apply(clean_text)\n",
    "\n",
    "# Check the cleaned text\n",
    "print(nlp_df.head())\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "- **Step 1**: We fetch the `20newsgroups` dataset using `fetch_20newsgroups(subset='train')` and store the raw data in `newsgroups_data`. We then create a DataFrame (`nlp_df`) using `pd.DataFrame()` where the data is placed under the column `'text'`.\n",
    "  \n",
    "- **Step 2**: We apply the `clean_text` function to the `'text'` column using the `apply()` method, which processes each row (i.e., each piece of text) in the column.\n",
    "\n",
    "### Expected Output:\n",
    "The first few rows of the cleaned DataFrame will be displayed, where the text has been transformed, with all unwanted characters and patterns removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb5d6b3",
   "metadata": {},
   "source": [
    "## Mastering Text Cleaning with Python Regex on a Dataset\n",
    "\n",
    "Excellent work so far, Stellar Navigator! This time, you'll master how to clean textual data. We aim to transform pieces of text into cleaner versions, making them more suitable for further analysis. Let's put the focus on the cleaning functions you've built previously. Implement a combined function that runs all these cleaning operations in sequence: converting text to lowercase letters, removing email addresses, URLs, special characters, digits, and extra spaces. Finally,apply this unified cleaning function to a dataset.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import re\n",
    "\n",
    "def lower_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_email(text):\n",
    "    return re.sub(r'\\S*@\\S*\\s?', '', text)\n",
    "\n",
    "def remove_url(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    return re.sub(r'\\W', ' ', text)\n",
    "\n",
    "def remove_digits(text):\n",
    "    return re.sub(r'\\d', ' ', text)\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# TODO: Implement a function clean_text that runs all the functions above in a sequence\n",
    "\n",
    "# Fetch the dataset\n",
    "newsgroups_data = fetch_20newsgroups(subset='train')\n",
    "\n",
    "# TODO: Create a DataFrame from the dataset\n",
    "\n",
    "# TODO: Apply the cleaning functions to the DataFrame\n",
    "\n",
    "# TODO: Check the cleaned text\n",
    "\n",
    "```\n",
    "\n",
    "To implement a unified `clean_text` function that combines all the text cleaning functions and applies them in sequence, we'll follow these steps:\n",
    "\n",
    "1. **Combine all functions**: We'll create a `clean_text` function that calls each of the existing functions one after the other.\n",
    "2. **Apply the function**: We'll apply the `clean_text` function to the text data in the dataset.\n",
    "3. **Create the DataFrame**: We'll create a DataFrame from the dataset to hold the cleaned text.\n",
    "\n",
    "Here‚Äôs the completed code:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import re\n",
    "\n",
    "def lower_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_email(text):\n",
    "    return re.sub(r'\\S*@\\S*\\s?', '', text)\n",
    "\n",
    "def remove_url(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    return re.sub(r'\\W', ' ', text)\n",
    "\n",
    "def remove_digits(text):\n",
    "    return re.sub(r'\\d', ' ', text)\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# Combine all cleaning functions into a single clean_text function\n",
    "def clean_text(text):\n",
    "    text = lower_text(text)  # Convert to lowercase\n",
    "    text = remove_email(text)  # Remove email addresses\n",
    "    text = remove_url(text)  # Remove URLs\n",
    "    text = remove_special_chars(text)  # Remove special characters\n",
    "    text = remove_digits(text)  # Remove digits\n",
    "    text = remove_extra_spaces(text)  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "# Fetch the dataset\n",
    "newsgroups_data = fetch_20newsgroups(subset='train')\n",
    "\n",
    "# Create a DataFrame from the dataset\n",
    "nlp_df = pd.DataFrame(newsgroups_data.data, columns=['text'])\n",
    "\n",
    "# Apply the cleaning functions to the DataFrame\n",
    "nlp_df['text'] = nlp_df['text'].apply(clean_text)\n",
    "\n",
    "# Check the cleaned text\n",
    "print(nlp_df.head())\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "1. **Clean Text Function**: \n",
    "   - The `clean_text` function now combines all the individual functions (`lower_text`, `remove_email`, `remove_url`, `remove_special_chars`, `remove_digits`, and `remove_extra_spaces`) into a single pipeline.\n",
    "   \n",
    "2. **DataFrame Creation**:\n",
    "   - We create a `DataFrame` (`nlp_df`) with the `newsgroups_data.data`, assigning the text to the column `'text'`.\n",
    "   \n",
    "3. **Apply Cleaning**:\n",
    "   - The `apply()` method is used to apply the `clean_text` function to every text entry in the `'text'` column of the DataFrame.\n",
    "\n",
    "### Expected Output:\n",
    "The first few rows of the cleaned text will be displayed, showing that all unwanted elements (such as emails, URLs, special characters, digits, and excessive spaces) have been removed. This dataset will now be ready for further processing or analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
