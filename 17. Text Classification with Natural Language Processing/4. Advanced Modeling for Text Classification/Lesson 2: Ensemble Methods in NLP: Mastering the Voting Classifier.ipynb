{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7a43821",
   "metadata": {},
   "source": [
    "# Lesson 2: Ensemble Methods in NLP: Mastering the Voting Classifier\n",
    "\n",
    "Hello, and welcome back! In this lesson, we will dive into Ensemble Modeling with a focus on the Voting Classifier. The Voting Classifier is a powerful concept that takes advantage of the strengths of multiple classifiers to yield more robust and accurate predictions. If you're ready to take your understanding of Machine Learning (ML) modeling to new heights, this lesson is definitely for you.\n",
    "\n",
    "## Data Preparation Revisited\n",
    "\n",
    "Before we start exploring ensemble models, let's revisit the process of preparing our data for machine learning. We start with obtaining our dataset and progressing through feature extraction and label encoding to partitioning the data for training and testing.\n",
    "\n",
    "```python\n",
    "# Import required libraries\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import reuters\n",
    "import nltk\n",
    "\n",
    "nltk.download('reuters', quiet=True)\n",
    "\n",
    "# Limiting the data for quick execution\n",
    "categories = reuters.categories()[:5]\n",
    "documents = reuters.fileids(categories)\n",
    "\n",
    "# Preparing the dataset\n",
    "text_data = [\" \".join([word for word in reuters.words(fileid)]) for fileid in documents]\n",
    "categories_data = [reuters.categories(fileid)[0] for fileid in documents]\n",
    "\n",
    "# Using count vectorizer for feature extraction\n",
    "count_vectorizer = CountVectorizer(max_features=1000)\n",
    "X = count_vectorizer.fit_transform(text_data)\n",
    "y = LabelEncoder().fit_transform(categories_data)\n",
    "\n",
    "# Split the data for train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "```\n",
    "\n",
    "This section of the code does most of the heavy lifting for us, handling all the necessary data preprocessing required to further proceed with our modeling.\n",
    "\n",
    "## Constructing the Voting Classifier\n",
    "\n",
    "In our case, we employ the Voting Classifier for ensemble modeling. The `VotingClassifier` in `sklearn` is a meta-estimator, fitting several base machine learning models on the dataset and using their decisions to predict the class labels. It does this based on the majority vote principle, meaning the predicted class label for a given sample is the class label that has collected the most votes from individual classifiers.\n",
    "\n",
    "```python\n",
    "# Building multiple classification models\n",
    "log_clf = LogisticRegression(solver=\"liblinear\")\n",
    "svm_clf = SVC(gamma=\"scale\", random_state=1)\n",
    "dt_clf = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Creating a voting classifier with these models\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('svc', svm_clf), ('dt', dt_clf)],\n",
    "    voting='hard')\n",
    "```\n",
    "\n",
    "Here, we initially create three separate classifiers: Logistic Regression, Support Vector Machine, and Decision Tree. Subsequently, we incorporate all these models under a single Voting Classifier.\n",
    "\n",
    "## Further Insight into the Classifier\n",
    "\n",
    "Exploring the parameters of the Voting Classifier can significantly enhance your modeling strategy. Here's a focused rundown:\n",
    "\n",
    "- **estimators**: This is a list of the base classifiers that will be part of the ensemble, combining different models to capture a broad spectrum of data patterns.\n",
    "- **voting**: It dictates the final prediction method. `'hard'` voting uses a majority vote system, while `'soft'` voting relies on the predicted probabilities, useful when classifiers provide calibrated probabilities.\n",
    "- **weights**: Assigning weights to individual classifiers can influence their contribution to the final decision, especially beneficial when some models are more trustworthy.\n",
    "\n",
    "Mastering these parameters allows for tailored model adjustments, leading to more accurate and robust ensemble classifiers for your text classification tasks.\n",
    "\n",
    "## Model Training and Prediction\n",
    "\n",
    "Training our model involves fitting it to the data using the `.fit()` method. It helps our model learn the underlying relationships in our dataset. We then test our model's learning effectiveness by making predictions using the `.predict()` method.\n",
    "\n",
    "```python\n",
    "# Training the voting classifier on the training data\n",
    "voting_clf.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# Predicting the labels of the test set\n",
    "y_pred = voting_clf.predict(X_test.toarray())\n",
    "```\n",
    "\n",
    "In this code snippet, `voting_clf.fit()` meticulously trains our ensemble, leveraging each base model's strengths. Subsequently, `voting_clf.predict()` translates our ensemble's collective intelligence onto the test data, generating predictions that embody a consensus among individual models' insights.\n",
    "\n",
    "## Model Evaluation\n",
    "\n",
    "After fitting the model to the data and making predictions with it, it's essential to determine how well it has performed. For classification tasks, accuracy is a common and important metric. It quantifies the ratio of correct predictions to total predictions.\n",
    "\n",
    "```python\n",
    "# Checking the performance of the model on test data\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "```\n",
    "\n",
    "The output will be something like:\n",
    "\n",
    "```\n",
    "Accuracy:  0.9803625377643505\n",
    "```\n",
    "\n",
    "The above message denotes a high accuracy score, indicating that our Voting Classifier model has performed excellently on the test data, identifying most of the class labels correctly.\n",
    "\n",
    "## Lesson Summary\n",
    "\n",
    "Congratulations on completing this lesson! You've mastered the concept of Ensemble Modeling with a focus on the Voting Classifier in Python. You've also learned how to:\n",
    "\n",
    "- Prepare text data\n",
    "- Split it into training and testing sets\n",
    "- Combine multiple classifiers into a Voting Classifier\n",
    "- Train the ensemble model\n",
    "- Evaluate its performance\n",
    "\n",
    "As always, practice is a vital part of learning. Don't miss out on the next activities that have been designed to reinforce and practically upskill your understanding of ensemble methods in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376997f9",
   "metadata": {},
   "source": [
    "## Switch to Soft Voting in Classifier Ensemble\n",
    "\n",
    "Great work, Space Explorer! Now, I want you to make a change in the Python script. In the existing code, you are using the hard voting strategy. I would like you to change it to soft voting. Don't forget to set probability=True in the SVC classifier, as soft voting requires predict_proba support. Run the script and compare the accuracy with the previous result.\n",
    "\n",
    "```python\n",
    "# Import required libraries\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import reuters\n",
    "import nltk\n",
    "\n",
    "# Limiting the data for quick execution\n",
    "categories = reuters.categories()[:5]\n",
    "documents = reuters.fileids(categories)\n",
    "\n",
    "# Preparing the dataset\n",
    "text_data = [\" \".join([word for word in reuters.words(fileid)]) for fileid in documents]\n",
    "categories_data = [reuters.categories(fileid)[0] for fileid in documents]\n",
    "\n",
    "# Using count vectorizer for feature extraction\n",
    "count_vectorizer = CountVectorizer(max_features=1000)\n",
    "X = count_vectorizer.fit_transform(text_data)\n",
    "y = LabelEncoder().fit_transform(categories_data)\n",
    "\n",
    "# Split the data for train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Building multiple classification models\n",
    "log_clf = LogisticRegression(solver=\"liblinear\")\n",
    "svm_clf = SVC(gamma=\"scale\", random_state=1)\n",
    "dt_clf = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Creating a voting classifier with these models\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('svc', svm_clf), ('dt', dt_clf)],\n",
    "    voting='hard')\n",
    "\n",
    "# Training the voting classifier on the training data\n",
    "voting_clf.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# Predicting the labels of the test set\n",
    "y_pred = voting_clf.predict(X_test.toarray())\n",
    "\n",
    "# Checking the performance of the model on test data\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "```\n",
    "\n",
    "I've updated the script to use soft voting and set `probability=True` for the SVC classifier. Hereâ€™s the corrected version:\n",
    "\n",
    "```python\n",
    "# Import required libraries\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import reuters\n",
    "import nltk\n",
    "\n",
    "# Limiting the data for quick execution\n",
    "categories = reuters.categories()[:5]\n",
    "documents = reuters.fileids(categories)\n",
    "\n",
    "# Preparing the dataset\n",
    "text_data = [\" \".join([word for word in reuters.words(fileid)]) for fileid in documents]\n",
    "categories_data = [reuters.categories(fileid)[0] for fileid in documents]\n",
    "\n",
    "# Using count vectorizer for feature extraction\n",
    "count_vectorizer = CountVectorizer(max_features=1000)\n",
    "X = count_vectorizer.fit_transform(text_data)\n",
    "y = LabelEncoder().fit_transform(categories_data)\n",
    "\n",
    "# Split the data for train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Building multiple classification models\n",
    "log_clf = LogisticRegression(solver=\"liblinear\")\n",
    "svm_clf = SVC(gamma=\"scale\", random_state=1, probability=True)  # Set probability=True for soft voting\n",
    "dt_clf = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Creating a voting classifier with soft voting\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('svc', svm_clf), ('dt', dt_clf)],\n",
    "    voting='soft')  # Changed to soft voting\n",
    "\n",
    "# Training the voting classifier on the training data\n",
    "voting_clf.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# Predicting the labels of the test set\n",
    "y_pred = voting_clf.predict(X_test.toarray())\n",
    "\n",
    "# Checking the performance of the model on test data\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "```\n",
    "\n",
    "### Changes Made:\n",
    "1. **Switched from \"hard\" to \"soft\" voting in `VotingClassifier`**.\n",
    "2. **Set `probability=True` in the `SVC` classifier**, as required for soft voting.\n",
    "\n",
    "Run the script and compare the accuracy with the previous result. Let me know if you need any further modifications! ðŸš€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bcfb71",
   "metadata": {},
   "source": [
    "## Implementing and Training a Voting Classifier\n",
    "\n",
    "Stellar effort, Space Voyager! Now it's time to strengthen your ensemble modeling skills. In the code provided, there are some parts related to the Voting Classifier that are missing. Fill in the blanks (____) with the appropriate code to instantiate the Voting Classifier correctly and train it on the preprocessed dataset.\n",
    "\n",
    "```python\n",
    "# Import required libraries\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import reuters\n",
    "import nltk\n",
    "\n",
    "# Limiting the data for quick execution\n",
    "categories = reuters.categories()[:5]\n",
    "documents = reuters.fileids(categories)\n",
    "\n",
    "# Preparing the dataset\n",
    "text_data = [\" \".join([word for word in reuters.words(fileid)]) for fileid in documents]\n",
    "categories_data = [reuters.categories(fileid)[0] for fileid in documents]\n",
    "\n",
    "# Using count vectorizer for feature extraction\n",
    "count_vectorizer = CountVectorizer(max_features=1000)\n",
    "X = count_vectorizer.fit_transform(text_data)\n",
    "y = LabelEncoder().fit_transform(categories_data)\n",
    "\n",
    "# Split the data for train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Building multiple classification models\n",
    "log_clf = LogisticRegression(solver=\"liblinear\")\n",
    "svm_clf = SVC(gamma=\"scale\", random_state=1, probability=True)\n",
    "dt_clf = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Creating a voting classifier with these models\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', ____), ('svc', ____), ('dt', ____)],\n",
    "    voting=____)\n",
    "\n",
    "# Training the voting classifier on the training data\n",
    "voting_clf.____(X_train.toarray(), y_train)\n",
    "\n",
    "# Predicting the labels of the test set\n",
    "y_pred = ____.___(X_test.toarray())\n",
    "\n",
    "# Checking the performance of the model on test data\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "```\n",
    "\n",
    "Hereâ€™s the corrected version of your script with the missing parts filled in:\n",
    "\n",
    "```python\n",
    "# Import required libraries\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import reuters\n",
    "import nltk\n",
    "\n",
    "# Limiting the data for quick execution\n",
    "categories = reuters.categories()[:5]\n",
    "documents = reuters.fileids(categories)\n",
    "\n",
    "# Preparing the dataset\n",
    "text_data = [\" \".join([word for word in reuters.words(fileid)]) for fileid in documents]\n",
    "categories_data = [reuters.categories(fileid)[0] for fileid in documents]\n",
    "\n",
    "# Using count vectorizer for feature extraction\n",
    "count_vectorizer = CountVectorizer(max_features=1000)\n",
    "X = count_vectorizer.fit_transform(text_data)\n",
    "y = LabelEncoder().fit_transform(categories_data)\n",
    "\n",
    "# Split the data for train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Building multiple classification models\n",
    "log_clf = LogisticRegression(solver=\"liblinear\")\n",
    "svm_clf = SVC(gamma=\"scale\", random_state=1, probability=True)\n",
    "dt_clf = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Creating a voting classifier with these models\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('svc', svm_clf), ('dt', dt_clf)],\n",
    "    voting='soft')  # Using soft voting for better performance\n",
    "\n",
    "# Training the voting classifier on the training data\n",
    "voting_clf.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# Predicting the labels of the test set\n",
    "y_pred = voting_clf.predict(X_test.toarray())\n",
    "\n",
    "# Checking the performance of the model on test data\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "```\n",
    "\n",
    "### **Missing Parts Filled:**\n",
    "1. **`('lr', log_clf), ('svc', svm_clf), ('dt', dt_clf)`** â†’ Filled in the classifier instances.\n",
    "2. **`voting='soft'`** â†’ Using soft voting since SVC supports `predict_proba()`.\n",
    "3. **`voting_clf.fit(X_train.toarray(), y_train)`** â†’ Training the classifier.\n",
    "4. **`y_pred = voting_clf.predict(X_test.toarray())`** â†’ Making predictions.\n",
    "\n",
    "Now you can run the script and evaluate its performance. Let me know if you need further improvements! ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9062b4f3",
   "metadata": {},
   "source": [
    "## Incorporating Soft Voting in Ensemble Classifier Model\n",
    "\n",
    "Impressive work so far, Galactic Pioneer!\n",
    "\n",
    "In our journey of working with Ensemble Classifiers, this exercise will focus on the 'soft' voting strategy. The provided code has a VotingClassifier instance set up with several base models, but there are some missing pieces. Fill in the blanks (____) to correctly set the VotingClassifier's voting strategy to 'soft' and implement the model training using the training datasets. Run the script to train your VotingClassifier to make correct predictions.\n",
    "\n",
    "```python\n",
    "# Import required libraries\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import reuters\n",
    "import nltk\n",
    "\n",
    "# Limiting the data for quick execution\n",
    "categories = reuters.categories()[:5]\n",
    "documents = reuters.fileids(categories)\n",
    "\n",
    "# Preparing the dataset\n",
    "text_data = [\" \".join([word for word in reuters.words(fileid)]) for fileid in documents]\n",
    "categories_data = [reuters.categories(fileid)[0] for fileid in documents]\n",
    "\n",
    "# Using count vectorizer for feature extraction\n",
    "count_vectorizer = CountVectorizer(max_features=1000)\n",
    "X = count_vectorizer.fit_transform(text_data)\n",
    "y = LabelEncoder().fit_transform(categories_data)\n",
    "\n",
    "# Split the data for train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Building multiple classification models\n",
    "log_clf = LogisticRegression(solver=\"liblinear\")\n",
    "svm_clf = SVC(gamma=\"scale\", random_state=1, probability=True)\n",
    "dt_clf = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Creating a voting classifier with these models\n",
    "voting_clf = ____(\n",
    "    estimators=[('lr', log_clf), ('svc', svm_clf), ('dt', dt_clf)],\n",
    "    voting=____,\n",
    "    weights=[1, 1, 2])\n",
    "\n",
    "# Training the voting classifier on the training data\n",
    "____.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# Predicting the labels of the test set\n",
    "y_pred = voting_clf.predict(X_test.toarray())\n",
    "\n",
    "# Checking the performance of the model on test data\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "```\n",
    "\n",
    "Hereâ€™s the completed script with the missing parts correctly filled in:\n",
    "\n",
    "```python\n",
    "# Import required libraries\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import reuters\n",
    "import nltk\n",
    "\n",
    "# Limiting the data for quick execution\n",
    "categories = reuters.categories()[:5]\n",
    "documents = reuters.fileids(categories)\n",
    "\n",
    "# Preparing the dataset\n",
    "text_data = [\" \".join([word for word in reuters.words(fileid)]) for fileid in documents]\n",
    "categories_data = [reuters.categories(fileid)[0] for fileid in documents]\n",
    "\n",
    "# Using count vectorizer for feature extraction\n",
    "count_vectorizer = CountVectorizer(max_features=1000)\n",
    "X = count_vectorizer.fit_transform(text_data)\n",
    "y = LabelEncoder().fit_transform(categories_data)\n",
    "\n",
    "# Split the data for train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Building multiple classification models\n",
    "log_clf = LogisticRegression(solver=\"liblinear\")\n",
    "svm_clf = SVC(gamma=\"scale\", random_state=1, probability=True)  # probability=True is required for soft voting\n",
    "dt_clf = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Creating a voting classifier with these models\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('svc', svm_clf), ('dt', dt_clf)],\n",
    "    voting='soft',  # Using soft voting\n",
    "    weights=[1, 1, 2])  # Giving higher weight to Decision Tree\n",
    "\n",
    "# Training the voting classifier on the training data\n",
    "voting_clf.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# Predicting the labels of the test set\n",
    "y_pred = voting_clf.predict(X_test.toarray())\n",
    "\n",
    "# Checking the performance of the model on test data\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "```\n",
    "\n",
    "### **Filled Missing Parts:**\n",
    "1. **`VotingClassifier`** â†’ The correct class for ensemble learning.\n",
    "2. **`voting='soft'`** â†’ Setting soft voting for better probability-based decision-making.\n",
    "3. **`voting_clf.fit(X_train.toarray(), y_train)`** â†’ Training the ensemble classifier.\n",
    "\n",
    "Now, you can run the script and compare the accuracy with the previous hard voting approach. ðŸš€ Let me know if you need any modifications!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cf5f05",
   "metadata": {},
   "source": [
    "## Creating the Voting Classifier Model\n",
    "\n",
    "Impressive work, Stellar Navigator!\n",
    "\n",
    "This part will directly test your understanding of creating the Voting Classifier model. Fill in the TODO section to create the Voting Classifier model with 'hard' voting, and run the code to make your model ready for training! You've got this!\n",
    "\n",
    "```python\n",
    "# Import required libraries\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import reuters\n",
    "import nltk\n",
    "\n",
    "# Limiting the data for quick execution\n",
    "categories = reuters.categories()[:5]\n",
    "documents = reuters.fileids(categories)\n",
    "\n",
    "# Preparing the dataset\n",
    "text_data = [\" \".join([word for word in reuters.words(fileid)]) for fileid in documents]\n",
    "categories_data = [reuters.categories(fileid)[0] for fileid in documents]\n",
    "\n",
    "# Using count vectorizer for feature extraction\n",
    "count_vectorizer = CountVectorizer(max_features=1000)\n",
    "X = count_vectorizer.fit_transform(text_data)\n",
    "y = LabelEncoder().fit_transform(categories_data)\n",
    "\n",
    "# Split the data for train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Building multiple classification models\n",
    "log_clf = LogisticRegression(solver=\"liblinear\")\n",
    "svm_clf = SVC(gamma=\"scale\", random_state=1, probability=True)\n",
    "dt_clf = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# TODO: Create a voting classifier with these models\n",
    "\n",
    "# Training the voting classifier on the training data\n",
    "voting_clf.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# Predicting the labels of the test set\n",
    "y_pred = voting_clf.predict(X_test.toarray())\n",
    "\n",
    "# Checking the performance of the model on test data\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "```\n",
    "\n",
    "Hereâ€™s the completed script with the missing part correctly filled in:\n",
    "\n",
    "```python\n",
    "# Import required libraries\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import reuters\n",
    "import nltk\n",
    "\n",
    "# Limiting the data for quick execution\n",
    "categories = reuters.categories()[:5]\n",
    "documents = reuters.fileids(categories)\n",
    "\n",
    "# Preparing the dataset\n",
    "text_data = [\" \".join([word for word in reuters.words(fileid)]) for fileid in documents]\n",
    "categories_data = [reuters.categories(fileid)[0] for fileid in documents]\n",
    "\n",
    "# Using count vectorizer for feature extraction\n",
    "count_vectorizer = CountVectorizer(max_features=1000)\n",
    "X = count_vectorizer.fit_transform(text_data)\n",
    "y = LabelEncoder().fit_transform(categories_data)\n",
    "\n",
    "# Split the data for train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Building multiple classification models\n",
    "log_clf = LogisticRegression(solver=\"liblinear\")\n",
    "svm_clf = SVC(gamma=\"scale\", random_state=1, probability=True)\n",
    "dt_clf = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# TODO: Create a voting classifier with these models\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('svc', svm_clf), ('dt', dt_clf)],\n",
    "    voting='hard'  # Using hard voting strategy\n",
    ")\n",
    "\n",
    "# Training the voting classifier on the training data\n",
    "voting_clf.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# Predicting the labels of the test set\n",
    "y_pred = voting_clf.predict(X_test.toarray())\n",
    "\n",
    "# Checking the performance of the model on test data\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "```\n",
    "\n",
    "### **Filled Missing Parts:**\n",
    "1. **Created `VotingClassifier`** â†’ `voting_clf = VotingClassifier(...)`\n",
    "2. **Set `voting='hard'`** â†’ Hard voting strategy for ensemble learning.\n",
    "\n",
    "Now, run the script and test the accuracy! ðŸš€ Let me know if you need further modifications. ðŸŽ¯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5724074e",
   "metadata": {},
   "source": [
    "## Building a Soft Voting Classifier from Scratch\n",
    "\n",
    "Fantastic work, Space Voyager! Now, let's wrap up what we have learned about Ensemble Modeling with one final coding task. You will write a voting classifier using the 'soft' voting strategy from scratch. Make sure to apply everything you have learned from our previous exercises. You can do it!\n",
    "\n",
    "```python\n",
    "# Import required libraries\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import reuters\n",
    "import nltk\n",
    "\n",
    "# Limiting the data for quick execution\n",
    "categories = reuters.categories()[:5]\n",
    "documents = reuters.fileids(categories)\n",
    "\n",
    "# Preparing the dataset\n",
    "text_data = [\" \".join([word for word in reuters.words(fileid)]) for fileid in documents]\n",
    "categories_data = [reuters.categories(fileid)[0] for fileid in documents]\n",
    "\n",
    "# TODO: Use count vectorizer for feature extraction\n",
    "# TODO: Split the data for train and test\n",
    "# TODO: Built multiple classification models\n",
    "# TODO: Create a voting classifier with these models\n",
    "# TODO: Train the voting classifier on the training data\n",
    "\n",
    "# Predicting the labels of the test set\n",
    "y_pred = voting_clf.predict(X_test.toarray())\n",
    "\n",
    "# Checking the performance of the model on test data\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
