{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Unit 3"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Calculating Perplexity in Language Models\n",
                "\n",
                "### Introduction to Perplexity\n",
                "\n",
                "Welcome back to the \"Scoring LLM Outputs with Logprobs and Perplexity\" course. In the previous lesson, you explored how to compare sentence likelihoods using log probabilities. In this lesson, you’ll learn about perplexity—a metric used to evaluate how well a language model predicts text.\n",
                "\n",
                "Perplexity gives us a sense of how “surprised” a model is by a sequence. A lower value means the model finds the sentence more natural; a higher value suggests the model finds it awkward or unexpected.\n",
                "\n",
                "By the end of this lesson, you'll understand what perplexity means, how it's related to log probabilities, and how to approximate it using OpenAI’s API.\n",
                "\n",
                "### Understanding Perplexity\n",
                "\n",
                "In traditional NLP, perplexity is computed as the exponential of the average negative log-likelihood of a token sequence:\n",
                "\n",
                "$$Perplexity = e^{-\\frac{1}{N}\\sum_{i=1}^{N}\\log P(w_i)}$$\n",
                "\n",
                "Let’s break this down:\n",
                "\n",
                "  * $N$ is the total number of tokens in the sequence.\n",
                "  * $P(w\\_i)$ is the probability that the model assigns to the $i$-th token, given the previous tokens.\n",
                "  * $\\\\log P(w\\_i)$ is the log probability of the $i$-th token.\n",
                "  * The sum $\\\\sum\\_{i=1}^{N}\\\\log P(w\\_i)$ adds up the log probabilities for all tokens in the sequence.\n",
                "  * Dividing by $N$ gives the average log probability per token.\n",
                "  * Multiplying by $-1$ turns this into the average negative log probability (also called the average \"surprisal\").\n",
                "  * Taking the exponential ($e...$) converts this average surprisal back into the original probability scale, giving us the perplexity.\n",
                "\n",
                "A lower perplexity means the model is less \"surprised\" by the sequence (it assigns higher probabilities to the tokens), while a higher perplexity means the model finds the sequence less predictable.\n",
                "\n",
                "### Example: Approximating Perplexity\n",
                "\n",
                "We’ll compare two sentences—one fluent, one awkward—and use the log probability of the generated token to approximate perplexity.\n",
                "\n",
                "```python\n",
                "import math\n",
                "from openai import OpenAI\n",
                "\n",
                "client = OpenAI()\n",
                "\n",
                "sentences = [\n",
                "    \"Cats sleep on the windowsill.\",\n",
                "    \"Cats windowsill the on sleep.\"\n",
                "]\n",
                "\n",
                "for sentence in sentences:\n",
                "    response = client.completions.create(\n",
                "        model=\"gpt-3.5-turbo-instruct\",\n",
                "        prompt=sentence,\n",
                "        max_tokens=1,\n",
                "        logprobs=5\n",
                "    )\n",
                "    # Get the logprob of the generated token (first in the list)\n",
                "    logprob = response.choices[0].logprobs.token_logprobs[0]\n",
                "    perplexity = math.exp(-logprob)\n",
                "    print(f\"Sentence: {sentence}\")\n",
                "    print(f\"Log probability: {logprob:.4f}\")\n",
                "    print(f\"Approximate Perplexity: {perplexity:.2f}\\n\")\n",
                "```\n",
                "\n",
                "Example output:\n",
                "\n",
                "```\n",
                "Sentence: Cats sleep on the windowsill.\n",
                "Log probability: -3.8244\n",
                "Approximate Perplexity: 45.80\n",
                "\n",
                "Sentence: Cats windowsill the on sleep.\n",
                "Log probability: -5.7439\n",
                "Approximate Perplexity: 312.27\n",
                "```\n",
                "\n",
                "Explanation of the output:\n",
                "\n",
                "  * For \"Cats sleep on the windowsill.\", the log probability is higher (less negative), and the perplexity is much lower (45.80). This means the model finds this sentence more natural and likely.\n",
                "  * For \"Cats windowsill the on sleep.\", the log probability is lower (more negative), and the perplexity is much higher (312.27). This means the model finds this sentence much less likely or more surprising.\n",
                "\n",
                "The absolute values of perplexity may vary depending on the model and API version, but the key point is that the fluent sentence has a significantly lower perplexity than the awkward one. This demonstrates that perplexity can be used to compare the relative fluency or naturalness of different sentences according to the language model.\n",
                "\n",
                "### Interpreting Results and Common Pitfalls\n",
                "\n",
                "  * Lower perplexity means the sentence is more natural to the model.\n",
                "  * Higher perplexity indicates the sentence is confusing or unlikely.\n",
                "  * We’re approximating perplexity with one token—not a full sequence—so results are directional, not absolute.\n",
                "  * Make sure `max_tokens` is set to 1 or more to ensure a generated token is returned.\n",
                "\n",
                "### Summary and Next Steps\n",
                "\n",
                "In this lesson, you learned how to approximate perplexity using log probabilities from OpenAI’s API. While not a full traditional measure, this technique provides a useful proxy for evaluating sentence fluency. In the next unit, you’ll compare multiple models using perplexity to evaluate their fluency on the same sentence.\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Implementing the Perplexity Formula\n",
                "\n",
                "Now that you understand the concept of perplexity and have seen how it relates to log probabilities, let's focus on the core mathematical relationship between them. In this exercise, you'll create a function that calculates perplexity directly from a log probability value.\n",
                "\n",
                "Your task is to implement the calculate_perplexity function that:\n",
                "\n",
                "Takes a log probability value as input\n",
                "Applies the formula: perplexity = exp(-logprob)\n",
                "Includes error handling for invalid inputs\n",
                "Returns the calculated perplexity\n",
                "This exercise isolates the mathematical operation behind perplexity calculation, helping you build a solid foundation before we move on to comparing models using this metric in the next lesson.\n",
                "\n",
                "```python\n",
                "import math\n",
                "\n",
                "def calculate_perplexity(log_probability):\n",
                "    \"\"\"\n",
                "    Calculate perplexity from a single log probability value.\n",
                "    \n",
                "    Args:\n",
                "        log_probability (float): The log probability value\n",
                "        \n",
                "    Returns:\n",
                "        float: The calculated perplexity\n",
                "        \n",
                "    Raises:\n",
                "        TypeError: If input is not a number\n",
                "    \"\"\"\n",
                "    # TODO: Check if input is a valid number and raise TypeError with message\n",
                "    # \"Log probability must be a number\" if it's not a number\n",
                "    \n",
                "    # TODO: Calculate perplexity using the formula: exp(-logprob)\n",
                "    \n",
                "    # TODO: Return the calculated perplexity value\n",
                "    pass\n",
                "\n",
                "# Test the function with sample values\n",
                "if __name__ == \"__main__\":\n",
                "    test_values = [\n",
                "        -1.5,    # Should give perplexity of about 4.48\n",
                "        -0.5,    # Should give perplexity of about 1.65\n",
                "        -3.0,    # Should give perplexity of about 20.09\n",
                "        0.0      # Should give perplexity of 1.0\n",
                "    ]\n",
                "    \n",
                "    print(\"Testing perplexity calculation:\")\n",
                "    print(\"-\" * 40)\n",
                "    \n",
                "    for logprob in test_values:\n",
                "        try:\n",
                "            ppl = calculate_perplexity(logprob)\n",
                "            print(f\"Log probability: {logprob:.4f} | Perplexity: {ppl:.2f}\")\n",
                "        except Exception as e:\n",
                "            print(f\"Error with input {logprob}: {e}\")\n",
                "    \n",
                "    # Try with an invalid input\n",
                "    try:\n",
                "        calculate_perplexity(\"not a number\")\n",
                "    except Exception as e:\n",
                "        print(f\"\\nExpected error with invalid input: {e}\")\n",
                "```\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Applying Perplexity to Real Sentences\n",
                "\n",
                "Excellent job implementing the perplexity calculation function! Now let's put that function to work with real language model outputs. In this exercise, you'll apply your perplexity function to analyze how \"surprised\" a language model is by different sentences.\n",
                "\n",
                "Your tasks are to:\n",
                "\n",
                "Complete the calculate_perplexity function you created earlier.\n",
                "Extract log probabilities from the OpenAI API responses.\n",
                "Calculate perplexity for each sentence in the list.\n",
                "Format and display the results clearly.\n",
                "By comparing perplexity scores between grammatical and ungrammatical sentences, you'll see firsthand how this metric reflects the model's understanding of natural language patterns — a key skill for evaluating language model performance.\n",
                "\n",
                "```python\n",
                "import math\n",
                "from openai import OpenAI\n",
                "\n",
                "def calculate_perplexity(log_probability):\n",
                "    \"\"\"\n",
                "    Calculate perplexity from a single log probability value.\n",
                "    \n",
                "    Args:\n",
                "        log_probability (float): The log probability value\n",
                "        \n",
                "    Returns:\n",
                "        float: The calculated perplexity\n",
                "        \n",
                "    Raises:\n",
                "        TypeError: If input is not a number\n",
                "    \"\"\"\n",
                "    # TODO: Check if input is a valid number and raise TypeError with message\n",
                "    # \"Log probability must be a number\" if it's not a number\n",
                "    \n",
                "    # TODO: Calculate perplexity using the formula: exp(-logprob)\n",
                "    \n",
                "    # TODO: Return the calculated perplexity value\n",
                "    pass\n",
                "\n",
                "# Initialize the OpenAI client\n",
                "client = OpenAI()\n",
                "\n",
                "# List of sentences to analyze\n",
                "sentences = [\n",
                "    \"Cats sleep on the windowsill.\",\n",
                "    \"Cats windowsill the on sleep.\",\n",
                "    \"The weather is nice today.\",\n",
                "    \"Today nice the weather is.\"\n",
                "]\n",
                "\n",
                "# Process each sentence\n",
                "for sentence in sentences:\n",
                "    # Call the API to get log probabilities\n",
                "    response = client.chat.completions.create(\n",
                "        model=\"gpt-3.5-turbo\",\n",
                "        messages=[{\"role\": \"user\", \"content\": sentence}],\n",
                "        max_tokens=1,\n",
                "        logprobs=True,\n",
                "        top_logprobs=5\n",
                "    )\n",
                "\n",
                "    # TODO: Extract the log probability of the first token from the response\n",
                "    \n",
                "    # TODO: Calculate perplexity using our function\n",
                "    \n",
                "    # TODO: Print the results in a clear format with the sentence, log probability \n",
                "    # (formatted to 4 decimal places), and perplexity (formatted to 2 decimal places)\n",
                "    # Add a separator line between sentences for readability\n",
                "```\n",
                "\n",
                "```python\n",
                "import math\n",
                "from openai import OpenAI\n",
                "\n",
                "def calculate_perplexity(log_probability):\n",
                "    \"\"\"\n",
                "    Calculate perplexity from a single log probability value.\n",
                "    \n",
                "    Args:\n",
                "        log_probability (float): The log probability value\n",
                "        \n",
                "    Returns:\n",
                "        float: The calculated perplexity\n",
                "        \n",
                "    Raises:\n",
                "        TypeError: If input is not a number\n",
                "    \"\"\"\n",
                "    # Check if input is a valid number and raise TypeError with message\n",
                "    # \"Log probability must be a number\" if it's not a number\n",
                "    if not isinstance(log_probability, (int, float)):\n",
                "        raise TypeError(\"Log probability must be a number\")\n",
                "    \n",
                "    # Calculate perplexity using the formula: exp(-logprob)\n",
                "    perplexity = math.exp(-log_probability)\n",
                "    \n",
                "    # Return the calculated perplexity value\n",
                "    return perplexity\n",
                "\n",
                "# Initialize the OpenAI client\n",
                "# Replace with your actual API key or use environment variables\n",
                "client = OpenAI()\n",
                "\n",
                "# List of sentences to analyze\n",
                "sentences = [\n",
                "    \"Cats sleep on the windowsill.\",\n",
                "    \"Cats windowsill the on sleep.\",\n",
                "    \"The weather is nice today.\",\n",
                "    \"Today nice the weather is.\"\n",
                "]\n",
                "\n",
                "# Process each sentence\n",
                "for sentence in sentences:\n",
                "    # Call the API to get log probabilities\n",
                "    response = client.chat.completions.create(\n",
                "        model=\"gpt-3.5-turbo\",\n",
                "        messages=[{\"role\": \"user\", \"content\": sentence}],\n",
                "        max_tokens=1,\n",
                "        logprobs=True,\n",
                "        top_logprobs=5\n",
                "    )\n",
                "\n",
                "    # Extract the log probability of the first token from the response\n",
                "    # The response structure for logprobs is a bit nested.\n",
                "    # We are interested in the log probability of the single token we requested.\n",
                "    log_probability = response.choices[0].logprobs.content[0].logprob\n",
                "\n",
                "    # Calculate perplexity using our function\n",
                "    perplexity = calculate_perplexity(log_probability)\n",
                "    \n",
                "    # Print the results in a clear format with the sentence, log probability \n",
                "    # (formatted to 4 decimal places), and perplexity (formatted to 2 decimal places)\n",
                "    print(f\"Sentence: {sentence}\")\n",
                "    print(f\"Log Probability: {log_probability:.4f}\")\n",
                "    print(f\"Perplexity: {perplexity:.2f}\")\n",
                "    \n",
                "    # Add a separator line between sentences for readability\n",
                "    print(\"-\" * 30)\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Flexible Token Generation for Perplexity Analysis\n",
                "\n",
                "Fantastic work applying perplexity to real sentences! Now let's make our code more flexible by allowing for different token generation settings. In our previous examples, we used a fixed value of 1 for the max_tokens parameter, but what happens if we generate more tokens?\n",
                "\n",
                "Your task is to modify the perplexity analysis code to make the max_tokens parameter configurable. This will allow you to:\n",
                "\n",
                "Experiment with different token generation settings\n",
                "Compare how perplexity changes with different max_tokens values\n",
                "Create more versatile code that can be adapted to different analysis needs\n",
                "By making this parameter configurable, you'll gain deeper insights into how language models respond to different contexts and learn an important programming principle: parameterization makes code more reusable and powerful for experimentation.\n",
                "\n",
                "```python\n",
                "import math\n",
                "from openai import OpenAI\n",
                "\n",
                "def calculate_perplexity(log_probability):\n",
                "    \"\"\"\n",
                "    Calculate perplexity from a log probability value.\n",
                "    \n",
                "    Args:\n",
                "        log_probability (float): The log probability value\n",
                "        \n",
                "    Returns:\n",
                "        float: The calculated perplexity\n",
                "    \"\"\"\n",
                "    if not isinstance(log_probability, (int, float)):\n",
                "        raise TypeError(\"Log probability must be a number\")\n",
                "    \n",
                "    return math.exp(-log_probability)\n",
                "\n",
                "# TODO: Modify this function to accept a max_tokens parameter with a default value of 1\n",
                "def analyze_sentence_perplexity(sentence):\n",
                "    \"\"\"\n",
                "    Analyze the perplexity of a sentence using the OpenAI API.\n",
                "    \n",
                "    Args:\n",
                "        sentence (str): The sentence to analyze\n",
                "        \n",
                "    Returns:\n",
                "        tuple: (log_probability, perplexity)\n",
                "    \"\"\"\n",
                "    client = OpenAI()\n",
                "    \n",
                "    # TODO: Update this API call to use the max_tokens parameter instead of the fixed value\n",
                "    response = client.chat.completions.create(\n",
                "        model=\"gpt-3.5-turbo\",\n",
                "        messages=[{\"role\": \"user\", \"content\": sentence}],\n",
                "        max_tokens=1,  # Fixed value that needs to be configurable\n",
                "        logprobs=True,\n",
                "        top_logprobs=5\n",
                "    )\n",
                "\n",
                "    # Get logprob of the first token generated\n",
                "    logprob = response.choices[0].logprobs.content[0].logprob\n",
                "\n",
                "    # Compute perplexity\n",
                "    perplexity = calculate_perplexity(logprob)\n",
                "    \n",
                "    return logprob, perplexity\n",
                "\n",
                "# Test sentences\n",
                "sentences = [\n",
                "    \"Cats sleep on the windowsill.\",\n",
                "    \"Cats windowsill the on sleep.\"\n",
                "]\n",
                "\n",
                "# TODO: Create a list of different max_tokens values to test (e.g., [1, 3, 5])\n",
                "\n",
                "for sentence in sentences:\n",
                "    print(f\"Analyzing: \\\"{sentence}\\\"\")\n",
                "    print(\"-\" * 50)\n",
                "    \n",
                "    # TODO: Replace this single call with a loop that tests different max_tokens values\n",
                "    logprob, perplexity = analyze_sentence_perplexity(sentence)\n",
                "    print(f\"Logprob: {logprob:.4f} | Perplexity: {perplexity:.2f}\")\n",
                "    print(\"-\" * 30)\n",
                "    \n",
                "    print(\"\\n\")\n",
                "```\n",
                "\n",
                "```python\n",
                "import math\n",
                "from openai import OpenAI\n",
                "\n",
                "def calculate_perplexity(log_probability):\n",
                "    \"\"\"\n",
                "    Calculate perplexity from a log probability value.\n",
                "    \n",
                "    Args:\n",
                "        log_probability (float): The log probability value\n",
                "        \n",
                "    Returns:\n",
                "        float: The calculated perplexity\n",
                "    \"\"\"\n",
                "    if not isinstance(log_probability, (int, float)):\n",
                "        raise TypeError(\"Log probability must be a number\")\n",
                "    \n",
                "    return math.exp(-log_probability)\n",
                "\n",
                "def analyze_sentence_perplexity(sentence, max_tokens=1):\n",
                "    \"\"\"\n",
                "    Analyze the perplexity of a sentence using the OpenAI API.\n",
                "    \n",
                "    Args:\n",
                "        sentence (str): The sentence to analyze\n",
                "        max_tokens (int): The number of tokens to generate. Defaults to 1.\n",
                "        \n",
                "    Returns:\n",
                "        tuple: (log_probability, perplexity)\n",
                "    \"\"\"\n",
                "    client = OpenAI()\n",
                "    \n",
                "    # Update this API call to use the max_tokens parameter\n",
                "    response = client.chat.completions.create(\n",
                "        model=\"gpt-3.5-turbo\",\n",
                "        messages=[{\"role\": \"user\", \"content\": sentence}],\n",
                "        max_tokens=max_tokens,\n",
                "        logprobs=True,\n",
                "        top_logprobs=5\n",
                "    )\n",
                "\n",
                "    # Get logprob of the first token generated\n",
                "    # Note: For perplexity of a full sentence, you would typically sum logprobs and divide by the number of tokens.\n",
                "    # However, this exercise focuses on the logprob of the *first* generated token to show flexibility.\n",
                "    logprob = response.choices[0].logprobs.content[0].logprob\n",
                "\n",
                "    # Compute perplexity\n",
                "    perplexity = calculate_perplexity(logprob)\n",
                "    \n",
                "    return logprob, perplexity\n",
                "\n",
                "# Test sentences\n",
                "sentences = [\n",
                "    \"Cats sleep on the windowsill.\",\n",
                "    \"Cats windowsill the on sleep.\"\n",
                "]\n",
                "\n",
                "# Create a list of different max_tokens values to test\n",
                "max_tokens_values = [1, 3, 5]\n",
                "\n",
                "for sentence in sentences:\n",
                "    print(f\"Analyzing: \\\"{sentence}\\\"\")\n",
                "    print(\"-\" * 50)\n",
                "    \n",
                "    # Replace this single call with a loop that tests different max_tokens values\n",
                "    for max_tokens in max_tokens_values:\n",
                "        logprob, perplexity = analyze_sentence_perplexity(sentence, max_tokens=max_tokens)\n",
                "        print(f\"max_tokens: {max_tokens} | Logprob: {logprob:.4f} | Perplexity: {perplexity:.2f}\")\n",
                "    \n",
                "    print(\"\\n\")\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Error Handling for Perplexity Calculations\n",
                "\n",
                "Now that you've made your perplexity code more flexible, let's focus on making it more reliable. When working with external APIs like OpenAI, many things can go wrong — network issues, rate limits, or unexpected response formats.\n",
                "\n",
                "Your task is to enhance the perplexity calculation code with proper error handling:\n",
                "\n",
                "Add try-except blocks around the API call to catch potential exceptions.\n",
                "Handle cases where log probability data might be missing.\n",
                "Ensure the program continues processing other sentences even if one fails.\n",
                "Provide clear error messages that help diagnose problems.\n",
                "In real-world applications, robust error handling is just as important as the core functionality. By completing this exercise, you'll learn how to make your perplexity calculations work reliably even when things don't go as planned.\n",
                "\n",
                "```python\n",
                "import math\n",
                "from openai import OpenAI\n",
                "import time\n",
                "\n",
                "def calculate_perplexity(log_probability):\n",
                "    \"\"\"\n",
                "    Calculate perplexity from a log probability value.\n",
                "    \n",
                "    Args:\n",
                "        log_probability (float): The log probability value\n",
                "        \n",
                "    Returns:\n",
                "        float: The calculated perplexity\n",
                "    \"\"\"\n",
                "    if not isinstance(log_probability, (int, float)):\n",
                "        raise TypeError(\"Log probability must be a number\")\n",
                "    \n",
                "    return math.exp(-log_probability)\n",
                "\n",
                "# Initialize the OpenAI client\n",
                "client = OpenAI()\n",
                "\n",
                "# List of sentences to analyze\n",
                "sentences = [\n",
                "    \"Cats sleep on the windowsill.\",\n",
                "    \"Cats windowsill the on sleep.\",\n",
                "    \"The weather is nice today.\",\n",
                "    \"Today nice the weather is.\"\n",
                "]\n",
                "\n",
                "# Process each sentence\n",
                "for sentence in sentences:\n",
                "    print(f\"Processing: \\\"{sentence}\\\"\")\n",
                "    \n",
                "    # TODO: Add a try-except block to handle all errors for this sentence\n",
                "    \n",
                "    # TODO: Add a try-except block specifically for the API call\n",
                "    response = client.chat.completions.create(\n",
                "        model=\"gpt-3.5-turbo\",\n",
                "        messages=[{\"role\": \"user\", \"content\": sentence}],\n",
                "        max_tokens=1,\n",
                "        logprobs=True,\n",
                "        top_logprobs=5\n",
                "    )\n",
                "        \n",
                "    # TODO: Add a try-except block for safely extracting the log probability\n",
                "    # TODO: Add checks to verify response contains the expected data\n",
                "    logprob = response.choices[0].logprobs.content[0].logprob\n",
                "    \n",
                "    # Calculate perplexity\n",
                "    perplexity = calculate_perplexity(logprob)\n",
                "    \n",
                "    # Print the results\n",
                "    print(f\"Log probability: {logprob:.4f}\")\n",
                "    print(f\"Perplexity: {perplexity:.2f}\")\n",
                "    \n",
                "    print(\"-\" * 50 + \"\\n\")\n",
                "```\n",
                "\n",
                "To improve the reliability of your perplexity calculation code, you need to add several layers of error handling. This includes catching issues with the API call itself and handling cases where the API response might be missing data.\n",
                "\n",
                "Here is the revised code with proper `try-except` blocks and data validation.\n",
                "\n",
                "```python\n",
                "import math\n",
                "from openai import OpenAI\n",
                "from openai import OpenAI\n",
                "import time\n",
                "\n",
                "def calculate_perplexity(log_probability):\n",
                "    \"\"\"\n",
                "    Calculate perplexity from a log probability value.\n",
                "    \n",
                "    Args:\n",
                "        log_probability (float): The log probability value\n",
                "        \n",
                "    Returns:\n",
                "        float: The calculated perplexity\n",
                "    \"\"\"\n",
                "    if not isinstance(log_probability, (int, float)):\n",
                "        raise TypeError(\"Log probability must be a number\")\n",
                "    \n",
                "    return math.exp(-log_probability)\n",
                "\n",
                "# Initialize the OpenAI client\n",
                "client = OpenAI()\n",
                "\n",
                "# List of sentences to analyze\n",
                "sentences = [\n",
                "    \"Cats sleep on the windowsill.\",\n",
                "    \"Cats windowsill the on sleep.\",\n",
                "    \"The weather is nice today.\",\n",
                "    \"Today nice the weather is.\"\n",
                "]\n",
                "\n",
                "# Process each sentence\n",
                "for sentence in sentences:\n",
                "    print(f\"Processing: \\\"{sentence}\\\"\")\n",
                "    \n",
                "    # Use a single try-except block to handle all potential errors for the sentence\n",
                "    try:\n",
                "        # Try-except block for the API call to handle network issues, rate limits, etc.\n",
                "        try:\n",
                "            response = client.chat.completions.create(\n",
                "                model=\"gpt-3.5-turbo\",\n",
                "                messages=[{\"role\": \"user\", \"content\": sentence}],\n",
                "                max_tokens=1,\n",
                "                logprobs=True,\n",
                "                top_logprobs=5\n",
                "            )\n",
                "        except Exception as api_error:\n",
                "            print(f\"ERROR: API call failed for sentence. Details: {api_error}\")\n",
                "            # Skip to the next sentence\n",
                "            print(\"-\" * 50 + \"\\n\")\n",
                "            continue\n",
                "            \n",
                "        # Try-except block for safely extracting the log probability\n",
                "        try:\n",
                "            # Check if the response contains the expected data\n",
                "            if (response.choices and \n",
                "                response.choices[0].logprobs and \n",
                "                response.choices[0].logprobs.content and \n",
                "                response.choices[0].logprobs.content[0].logprob is not None):\n",
                "                \n",
                "                logprob = response.choices[0].logprobs.content[0].logprob\n",
                "                \n",
                "                # Calculate perplexity\n",
                "                perplexity = calculate_perplexity(logprob)\n",
                "                \n",
                "                # Print the results\n",
                "                print(f\"Log probability: {logprob:.4f}\")\n",
                "                print(f\"Perplexity: {perplexity:.2f}\")\n",
                "            else:\n",
                "                print(\"ERROR: Incomplete or missing log probability data in the API response.\")\n",
                "                \n",
                "        except (AttributeError, IndexError, TypeError) as data_error:\n",
                "            print(f\"ERROR: Failed to parse API response. Details: {data_error}\")\n",
                "\n",
                "    except Exception as overall_error:\n",
                "        print(f\"An unexpected error occurred: {overall_error}\")\n",
                "    \n",
                "    print(\"-\" * 50 + \"\\n\")\n",
                "```\n",
                "\n",
                "-----\n",
                "\n",
                "### Key Improvements\n",
                "\n",
                "  - **Nested `try-except` Blocks**: The code now uses a main `try-except` block to ensure that the program never crashes. Inside this, there are two separate `try-except` blocks: one for the API call and another for parsing the response. This helps you pinpoint the exact cause of the failure.\n",
                "  - **Specific Error Messages**: The `except` blocks now provide more descriptive error messages, differentiating between an API failure and a data parsing error. This is crucial for diagnosing problems.\n",
                "  - **Robust Data Validation**: The `if` statement checks for the existence of `response.choices`, `logprobs`, and `logprobs.content` before attempting to access them. This prevents `AttributeError` and `IndexError` when the API returns an unexpected or empty response.\n",
                "  - **Graceful Handling**: The `continue` statement within the API error handling block ensures that if one sentence fails, the program simply moves on to the next one instead of halting completely. This is essential for processing large datasets."
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
