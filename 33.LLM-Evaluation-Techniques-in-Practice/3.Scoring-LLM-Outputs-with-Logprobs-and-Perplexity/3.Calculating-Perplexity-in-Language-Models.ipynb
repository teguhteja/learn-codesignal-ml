{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Unit 3"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Calculating Perplexity in Language Models\n",
                "\n",
                "### Introduction to Perplexity\n",
                "\n",
                "Welcome back to the \"Scoring LLM Outputs with Logprobs and Perplexity\" course. In the previous lesson, you explored how to compare sentence likelihoods using log probabilities. In this lesson, you’ll learn about perplexity—a metric used to evaluate how well a language model predicts text.\n",
                "\n",
                "Perplexity gives us a sense of how “surprised” a model is by a sequence. A lower value means the model finds the sentence more natural; a higher value suggests the model finds it awkward or unexpected.\n",
                "\n",
                "By the end of this lesson, you'll understand what perplexity means, how it's related to log probabilities, and how to approximate it using OpenAI’s API.\n",
                "\n",
                "### Understanding Perplexity\n",
                "\n",
                "In traditional NLP, perplexity is computed as the exponential of the average negative log-likelihood of a token sequence:\n",
                "\n",
                "$$Perplexity = e^{-\\frac{1}{N}\\sum_{i=1}^{N}\\log P(w_i)}$$\n",
                "\n",
                "Let’s break this down:\n",
                "\n",
                "  * $N$ is the total number of tokens in the sequence.\n",
                "  * $P(w\\_i)$ is the probability that the model assigns to the $i$-th token, given the previous tokens.\n",
                "  * $\\\\log P(w\\_i)$ is the log probability of the $i$-th token.\n",
                "  * The sum $\\\\sum\\_{i=1}^{N}\\\\log P(w\\_i)$ adds up the log probabilities for all tokens in the sequence.\n",
                "  * Dividing by $N$ gives the average log probability per token.\n",
                "  * Multiplying by $-1$ turns this into the average negative log probability (also called the average \"surprisal\").\n",
                "  * Taking the exponential ($e...$) converts this average surprisal back into the original probability scale, giving us the perplexity.\n",
                "\n",
                "A lower perplexity means the model is less \"surprised\" by the sequence (it assigns higher probabilities to the tokens), while a higher perplexity means the model finds the sequence less predictable.\n",
                "\n",
                "### Example: Approximating Perplexity\n",
                "\n",
                "We’ll compare two sentences—one fluent, one awkward—and use the log probability of the generated token to approximate perplexity.\n",
                "\n",
                "```python\n",
                "import math\n",
                "from openai import OpenAI\n",
                "\n",
                "client = OpenAI()\n",
                "\n",
                "sentences = [\n",
                "    \"Cats sleep on the windowsill.\",\n",
                "    \"Cats windowsill the on sleep.\"\n",
                "]\n",
                "\n",
                "for sentence in sentences:\n",
                "    response = client.completions.create(\n",
                "        model=\"gpt-3.5-turbo-instruct\",\n",
                "        prompt=sentence,\n",
                "        max_tokens=1,\n",
                "        logprobs=5\n",
                "    )\n",
                "    # Get the logprob of the generated token (first in the list)\n",
                "    logprob = response.choices[0].logprobs.token_logprobs[0]\n",
                "    perplexity = math.exp(-logprob)\n",
                "    print(f\"Sentence: {sentence}\")\n",
                "    print(f\"Log probability: {logprob:.4f}\")\n",
                "    print(f\"Approximate Perplexity: {perplexity:.2f}\\n\")\n",
                "```\n",
                "\n",
                "Example output:\n",
                "\n",
                "```\n",
                "Sentence: Cats sleep on the windowsill.\n",
                "Log probability: -3.8244\n",
                "Approximate Perplexity: 45.80\n",
                "\n",
                "Sentence: Cats windowsill the on sleep.\n",
                "Log probability: -5.7439\n",
                "Approximate Perplexity: 312.27\n",
                "```\n",
                "\n",
                "Explanation of the output:\n",
                "\n",
                "  * For \"Cats sleep on the windowsill.\", the log probability is higher (less negative), and the perplexity is much lower (45.80). This means the model finds this sentence more natural and likely.\n",
                "  * For \"Cats windowsill the on sleep.\", the log probability is lower (more negative), and the perplexity is much higher (312.27). This means the model finds this sentence much less likely or more surprising.\n",
                "\n",
                "The absolute values of perplexity may vary depending on the model and API version, but the key point is that the fluent sentence has a significantly lower perplexity than the awkward one. This demonstrates that perplexity can be used to compare the relative fluency or naturalness of different sentences according to the language model.\n",
                "\n",
                "### Interpreting Results and Common Pitfalls\n",
                "\n",
                "  * Lower perplexity means the sentence is more natural to the model.\n",
                "  * Higher perplexity indicates the sentence is confusing or unlikely.\n",
                "  * We’re approximating perplexity with one token—not a full sequence—so results are directional, not absolute.\n",
                "  * Make sure `max_tokens` is set to 1 or more to ensure a generated token is returned.\n",
                "\n",
                "### Summary and Next Steps\n",
                "\n",
                "In this lesson, you learned how to approximate perplexity using log probabilities from OpenAI’s API. While not a full traditional measure, this technique provides a useful proxy for evaluating sentence fluency. In the next unit, you’ll compare multiple models using perplexity to evaluate their fluency on the same sentence.\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Implementing the Perplexity Formula\n",
                "\n",
                "Now that you understand the concept of perplexity and have seen how it relates to log probabilities, let's focus on the core mathematical relationship between them. In this exercise, you'll create a function that calculates perplexity directly from a log probability value.\n",
                "\n",
                "Your task is to implement the calculate_perplexity function that:\n",
                "\n",
                "Takes a log probability value as input\n",
                "Applies the formula: perplexity = exp(-logprob)\n",
                "Includes error handling for invalid inputs\n",
                "Returns the calculated perplexity\n",
                "This exercise isolates the mathematical operation behind perplexity calculation, helping you build a solid foundation before we move on to comparing models using this metric in the next lesson.\n",
                "\n",
                "```python\n",
                "import math\n",
                "\n",
                "def calculate_perplexity(log_probability):\n",
                "    \"\"\"\n",
                "    Calculate perplexity from a single log probability value.\n",
                "    \n",
                "    Args:\n",
                "        log_probability (float): The log probability value\n",
                "        \n",
                "    Returns:\n",
                "        float: The calculated perplexity\n",
                "        \n",
                "    Raises:\n",
                "        TypeError: If input is not a number\n",
                "    \"\"\"\n",
                "    # TODO: Check if input is a valid number and raise TypeError with message\n",
                "    # \"Log probability must be a number\" if it's not a number\n",
                "    \n",
                "    # TODO: Calculate perplexity using the formula: exp(-logprob)\n",
                "    \n",
                "    # TODO: Return the calculated perplexity value\n",
                "    pass\n",
                "\n",
                "# Test the function with sample values\n",
                "if __name__ == \"__main__\":\n",
                "    test_values = [\n",
                "        -1.5,    # Should give perplexity of about 4.48\n",
                "        -0.5,    # Should give perplexity of about 1.65\n",
                "        -3.0,    # Should give perplexity of about 20.09\n",
                "        0.0      # Should give perplexity of 1.0\n",
                "    ]\n",
                "    \n",
                "    print(\"Testing perplexity calculation:\")\n",
                "    print(\"-\" * 40)\n",
                "    \n",
                "    for logprob in test_values:\n",
                "        try:\n",
                "            ppl = calculate_perplexity(logprob)\n",
                "            print(f\"Log probability: {logprob:.4f} | Perplexity: {ppl:.2f}\")\n",
                "        except Exception as e:\n",
                "            print(f\"Error with input {logprob}: {e}\")\n",
                "    \n",
                "    # Try with an invalid input\n",
                "    try:\n",
                "        calculate_perplexity(\"not a number\")\n",
                "    except Exception as e:\n",
                "        print(f\"\\nExpected error with invalid input: {e}\")\n",
                "```\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Applying Perplexity to Real Sentences"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Flexible Token Generation for Perplexity Analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Error Handling for Perplexity Calculations"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Error Handling for Perplexity Calculations"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
