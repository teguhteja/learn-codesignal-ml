{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Unit 3"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Improving Evaluation: Fuzzy Answer Matching\n",
                "\n",
                "# Introduction to Evaluation Challenges\n",
                "\n",
                "Welcome back\\! In the previous lesson, we explored different prompting styles and their impact on the performance of large language models (LLMs) in question-answering (QA) tasks. We learned how zero-shot, one-shot, and few-shot prompting can influence the accuracy of model responses. As a reminder, these prompting styles help provide context to the model, which can significantly affect its ability to generate accurate answers.\n",
                "\n",
                "In this lesson, we will address a common challenge in evaluating QA systems: the limitations of exact match evaluation. Often, correct answers are not counted due to minor variations in wording or phrasing. For example, if the expected answer is \"New York City\" and the model responds with \"NYC,\" an exact match evaluation would mark this as incorrect, even though the response is valid. To overcome this, we will introduce the concept of **fuzzy matching**, which allows for more flexible and reliable evaluation by considering the similarity between responses.\n",
                "\n",
                "For this unit, you will not need to call the model, as we will prepare the results for you. Your task will be to evaluate these results using the techniques discussed.\n",
                "\n",
                "## Understanding Similarity Scoring\n",
                "\n",
                "**Similarity scoring** is a technique used to measure how closely two pieces of text resemble each other. This approach is particularly useful in QA evaluations, where minor variations in wording can lead to incorrect assessments. By using similarity scoring, we can increase the reliability of our evaluations and ensure that valid responses are recognized.\n",
                "\n",
                "In Python, one of the tools we can use for similarity scoring is the `SequenceMatcher` from the `difflib` library. This tool compares two strings and returns a ratio indicating their similarity. A ratio closer to 1 means the strings are very similar, while a ratio closer to 0 indicates they are quite different. By setting a threshold, we can determine what level of similarity is acceptable for considering two responses as equivalent.\n",
                "\n",
                "## Implementing Fuzzy Matching in Python\n",
                "\n",
                "Let's dive into the implementation of fuzzy matching using Python. We will use the `SequenceMatcher` from the `difflib` library to compare the model's response with the expected answer. Additionally, we'll include a simple visualization to represent the fuzzy accuracy as a percentage bar. Here's the code snippet from the `solution.py` file:\n",
                "\n",
                "```python\n",
                "from difflib import SequenceMatcher\n",
                "import csv\n",
                "\n",
                "def is_similar(a, b, threshold=0.75):\n",
                "    return SequenceMatcher(None, a.lower(), b.lower()).ratio() > threshold\n",
                "\n",
                "def create_visual_bar(percentage, max_length=20):\n",
                "    \"\"\"Create a simple visual bar to represent a percentage.\"\"\"\n",
                "    filled_length = int(percentage / 100 * max_length)\n",
                "    bar = '█' * filled_length + '░' * (max_length - filled_length)\n",
                "    return bar\n",
                "\n",
                "with open(\"triviaqa.csv\") as f:\n",
                "    qa_pairs = list(csv.DictReader(f))\n",
                "\n",
                "correct = 0\n",
                "for q in qa_pairs:\n",
                "    response = q['model_response']  # Pre-prepared model response\n",
                "    if is_similar(response, q['answer']):\n",
                "        correct += 1\n",
                "\n",
                "fuzzy_accuracy = (correct / len(qa_pairs)) * 100\n",
                "print(f\"Fuzzy Accuracy: {correct}/{len(qa_pairs)}\")\n",
                "print(f\"Visual Representation: {create_visual_bar(fuzzy_accuracy)}\")\n",
                "```\n",
                "\n",
                "In this code, we define a function `is_similar` that takes two strings, `a` and `b`, and a similarity `threshold`. The function uses `SequenceMatcher` to calculate the similarity ratio between the two strings, ignoring case differences. If the ratio exceeds the threshold, the function returns `True`, indicating that the strings are similar enough to be considered equivalent. We then iterate over the question-answer pairs from the `TriviaQA` dataset, using the pre-prepared model responses, and use the `is_similar` function to evaluate the response. The fuzzy accuracy is calculated by counting the number of similar responses.\n",
                "\n",
                "To visually represent the fuzzy accuracy, we use the `create_visual_bar` function, which generates a simple bar chart to illustrate the percentage of correct responses. This visual aid helps in quickly assessing the model's performance.\n",
                "\n",
                "## Example: Evaluating Trivia QA with Fuzzy Matching\n",
                "\n",
                "Let's walk through an example of evaluating the `TriviaQA` dataset using fuzzy matching. Suppose we have a question-answer pair where the question is \"What is the capital of France?\" and the expected answer is \"Paris.\" If the model responds with \"The capital of France is Paris,\" an exact match evaluation would mark this as incorrect. However, using fuzzy matching, the `is_similar` function would likely return `True`, as the response is sufficiently similar to the expected answer.\n",
                "\n",
                "By running the provided code, you will see an output indicating the fuzzy accuracy of the model. This metric reflects the number of responses that were considered similar to the expected answers, providing a more reliable assessment of the model's performance.\n",
                "\n",
                "## Summary and Preparation for Practice\n",
                "\n",
                "In this lesson, we addressed the limitations of exact match evaluation in QA systems and introduced the concept of fuzzy matching. We explored how similarity scoring can improve evaluation reliability by considering variations in phrasing. By implementing fuzzy matching in Python, we demonstrated how to evaluate model responses more accurately.\n",
                "\n",
                "As you move forward, practice these concepts with the exercises provided. Experiment with different similarity thresholds and observe how they affect the evaluation accuracy. This hands-on experience will reinforce your understanding and prepare you for more advanced evaluation techniques in future lessons. Remember, mastering fuzzy matching is key to enhancing the reliability of QA evaluations and achieving better results in real-world applications."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Building Your First Fuzzy Matcher\n",
                "\n",
                "Now that we've learned about the limitations of exact match evaluation, let's build our first fuzzy matching function! In this exercise, you'll implement the core component that makes flexible answer evaluation possible.\n",
                "\n",
                "Your task is to complete the is_similar function using Python's SequenceMatcher. This function needs to:\n",
                "\n",
                "Convert both input strings to lowercase.\n",
                "Calculate the similarity ratio between them.\n",
                "Return True if the ratio exceeds the threshold; False otherwise.\n",
                "The test cases included will show you how this function behaves with different types of string pairs — from abbreviations to reordered sentences. Pay attention to the similarity ratios that get printed, as they'll help you understand the nuances of fuzzy matching and why it's so valuable for QA evaluation.\n",
                "\n",
                "Mastering this function is your first step toward building more reliable evaluation systems that can recognize correct answers even when they're phrased differently!\n",
                "\n",
                "```python\n",
                "from difflib import SequenceMatcher\n",
                "\n",
                "def is_similar(a, b, threshold=0.75):\n",
                "    # TODO: Use SequenceMatcher to calculate the similarity ratio between \n",
                "    # the lowercase versions of strings a and b, then return True if the \n",
                "    # ratio exceeds the threshold, False otherwise\n",
                "\n",
                "# Test cases\n",
                "test_cases = [\n",
                "    (\"New York City\", \"NYC\", \"City abbreviation\"),\n",
                "    (\"apple\", \"apples\", \"Singular vs plural\"),\n",
                "    (\"The president lives in the White House\", \"The White House is where the president lives\", \"Reordered sentence\"),\n",
                "    (\"cat\", \"dog\", \"Different words\"),\n",
                "    (\"Python programming\", \"Python coding\", \"Similar concept, different wording\")\n",
                "]\n",
                "\n",
                "print(\"Testing fuzzy matching with different string pairs:\")\n",
                "print(\"-\" * 60)\n",
                "\n",
                "for str1, str2, description in test_cases:\n",
                "    similarity = SequenceMatcher(None, str1.lower(), str2.lower()).ratio()\n",
                "    result = is_similar(str1, str2)\n",
                "    \n",
                "    print(f\"Test: {description}\")\n",
                "    print(f\"String 1: '{str1}'\")\n",
                "    print(f\"String 2: '{str2}'\")\n",
                "    print(f\"Similarity ratio: {similarity:.4f}\")\n",
                "    print(f\"Similar enough (threshold={0.75})? {result}\")\n",
                "    print(\"-\" * 60)\n",
                "```\n",
                "\n",
                "```python\n",
                "from difflib import SequenceMatcher\n",
                "\n",
                "def is_similar(a, b, threshold=0.75):\n",
                "    # TODO: Use SequenceMatcher to calculate the similarity ratio between \n",
                "    # the lowercase versions of strings a and b, then return True if the \n",
                "    # ratio exceeds the threshold, False otherwise\n",
                "    return SequenceMatcher(None, a.lower(), b.lower()).ratio() > threshold\n",
                "\n",
                "# Test cases\n",
                "test_cases = [\n",
                "    (\"New York City\", \"NYC\", \"City abbreviation\"),\n",
                "    (\"apple\", \"apples\", \"Singular vs plural\"),\n",
                "    (\"The president lives in the White House\", \"The White House is where the president lives\", \"Reordered sentence\"),\n",
                "    (\"cat\", \"dog\", \"Different words\"),\n",
                "    (\"Python programming\", \"Python coding\", \"Similar concept, different wording\")\n",
                "]\n",
                "\n",
                "print(\"Testing fuzzy matching with different string pairs:\")\n",
                "print(\"-\" * 60)\n",
                "\n",
                "for str1, str2, description in test_cases:\n",
                "    similarity = SequenceMatcher(None, str1.lower(), str2.lower()).ratio()\n",
                "    result = is_similar(str1, str2)\n",
                "    \n",
                "    print(f\"Test: {description}\")\n",
                "    print(f\"String 1: '{str1}'\")\n",
                "    print(f\"String 2: '{str2}'\")\n",
                "    print(f\"Similarity ratio: {similarity:.4f}\")\n",
                "    print(f\"Similar enough (threshold={0.75})? {result}\")\n",
                "    print(\"-\" * 60)\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Evaluating Model Responses with Fuzzy Matching\n",
                "\n",
                "Excellent work on building your fuzzy matching function! Now let's put it to practical use by evaluating actual model responses against expected answers.\n",
                "\n",
                "In this exercise, you'll use your is_similar() function to analyze results from a zero-shot prompting experiment. Your tasks are to:\n",
                "\n",
                "Read the question-answer pairs and model responses from the provided CSV file.\n",
                "Compare each model response to its expected answer using fuzzy matching.\n",
                "Count how many responses are similar enough to be considered correct.\n",
                "Calculate and display the final accuracy score.\n",
                "This hands-on application will show you the real value of fuzzy matching in evaluation scenarios. By the end, you'll see firsthand how this approach provides a fairer assessment of model performance than strict exact matching would!\n",
                "\n",
                "```python\n",
                "from difflib import SequenceMatcher\n",
                "import csv\n",
                "\n",
                "def is_similar(a, b, threshold=0.75):\n",
                "    return SequenceMatcher(None, a.lower(), b.lower()).ratio() > threshold\n",
                "\n",
                "# TODO: Open and read the CSV file\n",
                "\n",
                "# TODO: Initialize a counter for correct answers\n",
                "\n",
                "# TODO: Loop through each question-answer pair in the CSV\n",
                "    # TODO: Extract the model response and expected answer\n",
                "    \n",
                "    # TODO: Use the is_similar function to check if the response matches the expected answer\n",
                "    \n",
                "    # TODO: Increment the counter if the answer is correct\n",
                "\n",
                "# TODO: Print the final accuracy score (format: \"Fuzzy Accuracy: X/Y\")\n",
                "```\n",
                "\n",
                "Thank you for providing the specific file name and the contents of the CSV. This is extremely helpful\\!\n",
                "\n",
                "The correct file to open is `results_zero_shot.csv`, not `triviaqa.csv`, and the relevant column names are `model_answer` and `expected_answer`.\n",
                "\n",
                "Here is the corrected code that should pass the evaluation:\n",
                "\n",
                "```python\n",
                "from difflib import SequenceMatcher\n",
                "import csv\n",
                "\n",
                "def is_similar(a, b, threshold=0.75):\n",
                "    return SequenceMatcher(None, a.lower(), b.lower()).ratio() > threshold\n",
                "\n",
                "# TODO: Open and read the CSV file\n",
                "with open(\"results_zero_shot.csv\") as f:\n",
                "    qa_pairs = list(csv.DictReader(f))\n",
                "\n",
                "# TODO: Initialize a counter for correct answers\n",
                "correct_answers_count = 0\n",
                "\n",
                "# TODO: Loop through each question-answer pair in the CSV\n",
                "for q in qa_pairs:\n",
                "    # TODO: Extract the model response and expected answer\n",
                "    response = q['model_answer']\n",
                "    expected_answer = q['expected_answer']\n",
                "    \n",
                "    # TODO: Use the is_similar function to check if the response matches the expected answer\n",
                "    if is_similar(response, expected_answer):\n",
                "    \n",
                "    # TODO: Increment the counter if the answer is correct\n",
                "        correct_answers_count += 1\n",
                "\n",
                "# TODO: Print the final accuracy score (format: \"Fuzzy Accuracy: X/Y\")\n",
                "total_questions = len(qa_pairs)\n",
                "print(f\"Fuzzy Accuracy: {correct_answers_count}/{total_questions}\")\n",
                "```\n",
                "\n",
                "This corrected code now properly handles the file name and the specific column names present in your provided data, which will resolve the `KeyError`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Finding the Perfect Similarity Threshold"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Prompting Strategies Showdown with Fuzzy Matching"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Prompting Strategies Showdown with Fuzzy Matching"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
