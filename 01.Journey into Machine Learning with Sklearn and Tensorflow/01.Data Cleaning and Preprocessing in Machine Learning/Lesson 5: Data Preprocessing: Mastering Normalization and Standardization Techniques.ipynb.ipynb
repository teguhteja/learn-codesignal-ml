{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing: Mastering Normalization and Standardization Techniques\n",
    "## Lesson Introduction\n",
    "Welcome to our enlightening session on Normalization and Standardization of Passenger Data. These two techniques play a crucial role in preparing your data for machine learning algorithms. During this lesson, our focus will particularly be on the historical Titanic dataset, where we will practice cleaning, normalizing, and standardizing certain features, such as passenger ages and fares. By the end of this lesson, you should have a solid understanding of normalization and standardization and be able to apply these techniques in any data preprocessing assignment using Python and Pandas.\n",
    "\n",
    "## Understanding Normalization\n",
    "Normalization is a critical preprocessing step, which primarily involves scaling the numerical data in the dataset to a fixed range, usually from 0 to 1. It reduces skewness and bias in the data by bringing all the values to a similar range. Therefore, normalization plays a significant role in algorithms that use a distance measure.\n",
    "\n",
    "To better illustrate how normalization works, let's apply it to the 'age' column of our Titanic dataset. Normalization will transform the age values so that they fall within a range from 0 to 1:\n",
    "\n",
    "```Python\n",
    "# Import necessary libraries\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic Dataset\n",
    "titanic_df = sns.load_dataset('titanic')\n",
    "\n",
    "# Normalize 'age'\n",
    "titanic_df['age'] = (titanic_df['age'] - titanic_df['age'].min()) / (titanic_df['age'].max() - titanic_df['age'].min())\n",
    "\n",
    "# Display the normalized ages\n",
    "print(titanic_df['age'])\n",
    "```\n",
    "Output:\n",
    "\n",
    "```markdown\n",
    "0      0.271174\n",
    "1      0.472229\n",
    "2      0.321438\n",
    "3      0.434531\n",
    "4      0.434531\n",
    "         ...   \n",
    "886    0.334004\n",
    "887    0.233476\n",
    "888         NaN\n",
    "889    0.321438\n",
    "890    0.396833\n",
    "Name: age, Length: 891, dtype: float64\n",
    "```\n",
    "In this code snippet, we first subtract the minimum age from each age value, then divide by the range of ages. The ages are scaled to the range [0, 1]. Normalized columns are easier for some machine-learning models to process.\n",
    "\n",
    "## Understanding Standardization\n",
    "Unlike normalization, standardization does not scale the data to a limited range. Instead, standardization subtracts the mean value of the feature and then divides it by the featureâ€™s standard deviation, transforming the feature values to have a mean of 0 and a standard deviation of 1. This method is often used when you want to compare data that was measured on different scales.\n",
    "\n",
    "Let's apply standardization to the 'fare' column of the Titanic dataset. This column represents how much each passenger paid for their ticket:\n",
    "\n",
    "```Python\n",
    "\n",
    "# Standardize 'fare'\n",
    "titanic_df['fare'] = (titanic_df['fare'] - titanic_df['fare'].mean()) / titanic_df['fare'].std()\n",
    "\n",
    "# Display the standardized fares\n",
    "print(titanic_df['fare'])\n",
    "```\n",
    "Output:\n",
    "\n",
    "```Markdown\n",
    "Copy\n",
    "0     -0.502163\n",
    "1      0.786404\n",
    "2     -0.488580\n",
    "3      0.420494\n",
    "4     -0.486064\n",
    "         ...   \n",
    "886   -0.386454\n",
    "887   -0.044356\n",
    "888   -0.176164\n",
    "889   -0.044356\n",
    "890   -0.492101\n",
    "Name: fare, Length: 891, dtype: float64\n",
    "```\n",
    "Now, the 'fare' column is re-scaled so the fares have an average value of 0 and a standard deviation of 1. Notice that the values are not within the [0, 1] range like normalized data.\n",
    "\n",
    "## Implementing Normalization with Pandas\n",
    "Armed with an understanding of normalization, let's dig a little deeper with the Pandas library. We'll use MinMaxScaler() from the sklearn.preprocessing module, a handy technique for normalizing data in pandas:\n",
    "\n",
    "```Python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Select 'age' column and drop NaN values\n",
    "age = titanic_df[['age']].dropna()\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Use the scaler\n",
    "titanic_df['norm_age'] = pd.DataFrame(scaler.fit_transform(age), columns=age.columns, index=age.index)\n",
    "\n",
    "# Display normalized age values\n",
    "print(titanic_df['norm_age'])\n",
    "Output:\n",
    "\n",
    "```Markdown\n",
    "\n",
    "0      0.271174\n",
    "1      0.472229\n",
    "2      0.321438\n",
    "3      0.434531\n",
    "4      0.434531\n",
    "         ...   \n",
    "886    0.334004\n",
    "887    0.233476\n",
    "888         NaN\n",
    "889    0.321438\n",
    "890    0.396833\n",
    "Name: norm_age, Length: 891, dtype: float64\n",
    "```\n",
    "The MinMaxScaler scales and translates each feature individually so that it falls in the given range on the training set, in our case, between 0 and 1.\n",
    "\n",
    "## Implementing Standardization with Pandas\n",
    "To standardize our data with pandas, we'll make use of the StandardScaler() function from the sklearn.preprocessing module that standardizes features by deducting the mean and scaling to unit variance:\n",
    "\n",
    "```Python\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select 'fare' column and drop NaN values\n",
    "fare = titanic_df[['fare']].dropna()\n",
    "\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Use the scaler\n",
    "titanic_df['stand_fare'] = pd.DataFrame(scaler.fit_transform(fare), columns=fare.columns, index=fare.index)\n",
    "\n",
    "# Display standardized fare values\n",
    "print(titanic_df['stand_fare'])\n",
    "```\n",
    "Output:\n",
    "\n",
    "```Markdown\n",
    "\n",
    "0     -0.502445\n",
    "1      0.786845\n",
    "2     -0.488854\n",
    "3      0.420730\n",
    "4     -0.486337\n",
    "         ...   \n",
    "886   -0.386671\n",
    "887   -0.044381\n",
    "888   -0.176263\n",
    "889   -0.044381\n",
    "890   -0.492378\n",
    "```\n",
    "Name: stand_fare, Length: 891, dtype: float64\n",
    "StandardScaler standardizes a feature by deducting the mean and scaling to unit variance. This operation is performed feature-wise in an independent way. Notice how our standardized fares now have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "## Comparing Normalization and Standardization\n",
    "Choose normalization when your data needs to be bounded within a specific range (0 to 1, for example) and is not heavily influenced by outliers. This is particularly useful for algorithms that are sensitive to the scale of the data, such as neural networks and k-nearest neighbors. On the other hand, standardization is more effective when your data has a Gaussian distribution, and you are dealing with algorithms that assume this, such as linear regression, logistic regression, and linear discriminant analysis.\n",
    "\n",
    "Now that you've got to experience both normalization and standardization, it's safe to say each technique is practical and useful but under different circumstances. Their primary purpose is to handle the varying ranges of data. However, depending on the algorithm deployed and the desired output distribution, normalization or standardization is selected. Remember that not all algorithms benefit from normalization or standardization.\n",
    "\n",
    "## Lesson Summary and Practice\n",
    "Give yourself a pat on the back as you've made it through the session on data preprocessing techniques! We explored the concepts of normalization and standardization, their practical applications, and how to implement these techniques using Python and Pandas. It's key to remember that these techniques are vital tools in enhancing the performance of your machine-learning models.\n",
    "\n",
    "Next up, we have some hands-on practice sessions to get your hands dirty with real-world datasets. Remember, the best way to absorb knowledge is by applying it practically. Looking forward to seeing you in the next session! Happy learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the 'age' Column in the Titanic Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the 'fare' Column with NaN values in the Titanic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize and Standardize 'age' and 'fare' Columns with Missing Values in the Titanic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize on your own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
