{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 5: Evaluating Machine Learning Models: Metrics and Practices\n",
    "\n",
    "Evaluating Machine Learning Models: Metrics and Practices\n",
    "Topic Overview\n",
    "Welcome! In this lesson, we're going to delve into an essential part of the data analysis and Machine Learning process — Model Evaluation — and specifically focus on understanding various evaluation metrics. In the language of Machine Learning, models are mathematical formulas, or algorithms, that process your input data to calculate the result for the task they're designed to perform. To ensure a model's predictions are accurate and reliable, we evaluate it against a set of standards or criteria, known as evaluation metrics.\n",
    "\n",
    "Our primary goal in this lesson is to understand these metrics and learn how to apply them using Python and Sklearn on the Iris dataset. Given the numerous machine learning models available, knowing how to calculate and interpret these evaluation metrics will be crucial in selecting the most suitable model for any task. So, let's dive in!\n",
    "\n",
    "Model Evaluation: An Introduction\n",
    "In the fascinating world of Machine Learning, we often encounter a question -- \"How well is our model performing?\". The response to this question is provided through the process of model evaluation. Model evaluation allows us to quantify our model's performance, essentially telling us how 'good' or 'bad' it is.\n",
    "\n",
    "A standard method for model evaluation is splitting our data into Training and Test Sets. By training our model on the Training Set and then testing it on the Test Set, we ensure that our evaluation is unbiased and indicative of how the model will perform on new, unseen data.\n",
    "\n",
    "The concept of Cross-Validation further refines this process. In Cross-Validation, we divide our dataset into 'K' parts, or folds. We then train our model 'K' times, each time using a different fold as our Test Set. This yields 'K' performance scores, which we average to get a final score.\n",
    "\n",
    "Let's take a look at how this plays out in code:\n",
    "\n",
    "Python\n",
    "Copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into Training and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Print the size of our training and test sets\n",
    "print(\"Number of instances in Training set: \", len(X_train)) \n",
    "print(\"Number of instances in Test set: \", len(X_test)) \n",
    "The output will be:\n",
    "\n",
    "Copy\n",
    "Number of instances in Training set:  105\n",
    "Number of instances in Test set:  45\n",
    "In this example, we split our original dataset, represented by X and y, into Training and Test Sets. We'll use 70% of the data (the Training Set) to train our model, and the remaining 30% (the Test Set) to test our model's performance.\n",
    "\n",
    "Performance Metrics for Regression Models\n",
    "When dealing with regression problems (where the output is a numeric or continuous value), we use metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE). MAE provides the average difference between our predictions and the actual values, while MSE and RMSE yield the average squared difference, with RMSE taking the square root of that difference.\n",
    "\n",
    "Let's apply these metrics to a simple Linear Regression model:\n",
    "\n",
    "Python\n",
    "Copy\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from math import sqrt\n",
    "\n",
    "# Instantiate and train a Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels and calculate errors\n",
    "y_pred = lr_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "\n",
    "print('Mean Absolute Error: ', mae)\n",
    "print('Mean Squared Error: ', mse)\n",
    "print('Root Mean Squared Error: ', rmse)\n",
    "The output will be:\n",
    "\n",
    "Copy\n",
    "Mean Absolute Error:  1.23632\n",
    "Mean Squared Error:  2.37823\n",
    "Root Mean Squared Error:  1.54128\n",
    "In this Python snippet, we create a Linear Regression model using LinearRegression(), train it using our training data with fit(), make predictions on the test data with predict(), and calculate MAE, MSE, and RMSE using the corresponding Scikit-Learn functions.\n",
    "\n",
    "Performance Metrics for Classification Models\n",
    "In classification tasks, where the model's output is a category or class, we use metrics such as Accuracy, Precision, Recall, and the F1 Score.\n",
    "\n",
    "Let's learn what each of these metrics is:\n",
    "\n",
    "Accuracy: Measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. It is a straightforward metric for overall success but can be misleading in cases of class imbalance.\n",
    "\n",
    "Recall: Also known as sensitivity, this metric measures the proportion of actual positives that are correctly identified. It is particularly important when the consequences of false negatives are significant.\n",
    "\n",
    "F1 Score: A harmonic mean of Precision and Recall, providing a balanced measure between the two. It is most useful when we need a single metric to reflect both false positives and false negatives. An ideal F1 Score is 1, indicating perfect precision and recall, while 0 is the worst.\n",
    "\n",
    "These metrics collectively offer a nuanced view of a model's performance, particularly in situations where certain types of errors are more consequential than others.\n",
    "\n",
    "Additionally, we employ the Confusion Matrix — a table that summarizes the performance of classification models.\n",
    "\n",
    "Let's examine this by training and evaluating a Logistic Regression model.\n",
    "\n",
    "Python\n",
    "Copy\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate and train a Logistic Regression model\n",
    "log_model = LogisticRegression(max_iter=200)\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels and calculate scores\n",
    "y_pred = log_model.predict(X_test)\n",
    "accuracy = log_model.score(X_test, y_test)\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "recall = recall_score(y_test, y_pred, average='micro')\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)\n",
    "The output will be:\n",
    "\n",
    "Copy\n",
    "Accuracy:  0.97777\n",
    "Precision:  0.97777\n",
    "Recall:  0.97777\n",
    "F1 Score:  0.97777\n",
    "In this block of code, we created a Logistic Regression model with LogisticRegression(), fitted it to the training data, predicted the labels of the testing set, and calculated Accuracy, Precision, Recall, and the F1 Score for the model on the test data.\n",
    "\n",
    "Decision Tree Model Performance\n",
    "Lastly, when evaluating the performance of a decision tree model, we often use Accuracy and the Gini Index. Accuracy measures the fraction of correct predictions, while the Gini Index quantifies the impurity of an input set.\n",
    "\n",
    "Let's explore this with an example:\n",
    "\n",
    "Python\n",
    "Copy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instantiate and train a Decision Tree model\n",
    "tree_model = DecisionTreeClassifier()\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels and calculate accuracy\n",
    "y_pred = tree_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "The output will be:\n",
    "\n",
    "Copy\n",
    "Accuracy: 0.95555\n",
    "Here, we created a Decision Tree classifier and calculated its accuracy. Give yourself a round of applause if your model has high accuracy!\n",
    "\n",
    "Lesson Summary and Practice\n",
    "Bravo! You've actively learned about and implemented various model evaluation metrics, such as Mean Absolute Error, Mean Squared Error, Root Mean Squared Error for regression models, and Accuracy, Precision, Recall, F1 Score for classification models. Applying these metrics using Python and Sklearn should bring you closer to selecting the most suitable model for your datasets.\n",
    "\n",
    "Now, it's time to apply what you've learned. Delve into practice exercises that will help you consolidate these core concepts and polish your newfound skills. Always remember that understanding and learning are key to success in your machine learning journey. Onwards and upwards!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crunching Numbers: Calculating Mean Absolute Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision in Logistic Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Accuracy of Decision Tree Model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
