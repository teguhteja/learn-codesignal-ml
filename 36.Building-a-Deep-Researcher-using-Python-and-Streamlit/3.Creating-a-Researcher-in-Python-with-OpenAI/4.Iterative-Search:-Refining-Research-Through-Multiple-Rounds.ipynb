{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Unit 4"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Iterative Search: Refining Research Through Multiple Rounds\n",
                "\n",
                "## Introduction: Evolving DeepResearcher with Iterative Search\n",
                "\n",
                "In the previous lesson, you learned how **DeepResearcher** could take a research question, generate search queries, and extract useful information from web pages—all in a **single round**. However, real research often requires digging deeper: using what you've found to guide further searching. In this lesson, we'll focus on the key modifications that transform DeepResearcher from a single-pass tool into an **iterative, multi-round research assistant**.\n",
                "\n",
                "-----\n",
                "\n",
                "## Quick Recap: The Single-Round Approach\n",
                "\n",
                "Previously, DeepResearcher worked as follows:\n",
                "\n",
                "  * It generated a list of search queries from the user's question.\n",
                "  * It searched the web for each query and evaluated the usefulness of each page.\n",
                "  * It extracted relevant information from useful pages.\n",
                "\n",
                "All of this happened in just **one round**—no follow-up searches based on what was found. While this approach works for simple questions, it often misses deeper or related information that only becomes apparent after reviewing initial results.\n",
                "\n",
                "-----\n",
                "\n",
                "## Step-by-Step: What's New in the Iterative Version\n",
                "\n",
                "Let's walk through the key modifications that enable DeepResearcher to perform iterative, multi-round research.\n",
                "\n",
                "### 1\\. Introducing the Iterative Search Loop\n",
                "\n",
                "| Before | Now |\n",
                "| :--- | :--- |\n",
                "| DeepResearcher performed all its work in a single pass. | A `while` loop has been added to the `perform_iterative_research` function. This loop allows the tool to repeat the **search-extract-plan cycle** multiple times, up to a user-defined limit. |\n",
                "\n",
                "```python\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    aggregated_contexts = []\n",
                "    iteration = 0\n",
                "    while iteration < iteration_limit:\n",
                "        print(f\"\\n=== Iteration {iteration + 1} ===\")\n",
                "        iteration_contexts = []\n",
                "        # ...search, extract, and plan...\n",
                "        iteration += 1\n",
                "    return aggregated_contexts\n",
                "```\n",
                "\n",
                "-----\n",
                "\n",
                "### 2\\. Aggregating Contexts Across Rounds\n",
                "\n",
                "| Before | Now |\n",
                "| :--- | :--- |\n",
                "| Extracted information was stored in a single list for one round. | A new list, **`aggregated_contexts`**, collects all useful information found across **every round**. Each iteration's new findings are added to this master list, ensuring nothing is lost as the research progresses. |\n",
                "\n",
                "```python\n",
                "    # Inside the while loop    \n",
                "    if iteration_contexts:\n",
                "        aggregated_contexts.extend(iteration_contexts)\n",
                "    else:\n",
                "        print(\"No useful context found this round.\")\n",
                "```\n",
                "\n",
                "-----\n",
                "\n",
                "### 3\\. Generating New Search Queries After Each Round\n",
                "\n",
                "| Before | Now |\n",
                "| :--- | :--- |\n",
                "| There was no way to generate new queries based on what had already been found. | After each round, DeepResearcher combines all the information it has gathered so far and asks the language model to suggest **new search queries**. This allows the tool to \"think ahead\" and refine its research path. |\n",
                "\n",
                "```python\n",
                "    context_combined = \"\\n\".join(aggregated_contexts)\n",
                "    variables = {\n",
                "        \"user_query\": user_query,\n",
                "        \"previous_search_queries\": str(all_search_queries),\n",
                "        \"context_combined\": context_combined\n",
                "    }\n",
                "    next_queries_str = generate_response(\"research_planner_system\", \"research_planner_user\", variables)\n",
                "    \n",
                "    if next_queries_str.strip() == \"\":\n",
                "        print(\"LLM indicated no further search is needed.\")\n",
                "        break\n",
                "        \n",
                "    try:\n",
                "        new_search_queries = eval(next_queries_str)\n",
                "        if not isinstance(new_search_queries, list):\n",
                "            raise ValueError(\"Not a list\")\n",
                "        print(\"Next queries:\", new_search_queries)\n",
                "        all_search_queries.extend(new_search_queries)\n",
                "    except Exception:\n",
                "        print(\"Could not parse further queries:\", next_queries_str)\n",
                "        break\n",
                "```\n",
                "\n",
                "If the model returns an empty string, the loop stops—signaling that no further searching is needed.\n",
                "\n",
                "-----\n",
                "\n",
                "### 4\\. Tracking All Search Queries\n",
                "\n",
                "| Before | Now |\n",
                "| :--- | :--- |\n",
                "| There was no record of which queries had already been used. | The **`all_search_queries`** list is updated with every new query generated. This prevents DeepResearcher from repeating the same searches and helps it keep track of its research history. |\n",
                "\n",
                "```python\n",
                "    # When new queries are generated and validated:    \n",
                "    all_search_queries.extend(new_search_queries)\n",
                "```\n",
                "\n",
                "-----\n",
                "\n",
                "### 5\\. Improved Output and Error Handling\n",
                "\n",
                "| Before | Now |\n",
                "| :--- | :--- |\n",
                "| There was no indication of which round was running, and errors in query generation could cause issues. | The code prints the **current iteration number** at the start of each round. It notifies the user if **no useful context** was found in a round. It checks that new queries are valid lists and handles **parsing errors** gracefully. |\n",
                "\n",
                "```python\n",
                "    print(f\"\\n=== Iteration {iteration + 1} ===\")\n",
                "    # ...\n",
                "    if iteration_contexts:\n",
                "        aggregated_contexts.extend(iteration_contexts)\n",
                "    else:\n",
                "        print(\"No useful context found this round.\")\n",
                "    # ...\n",
                "    try:\n",
                "        new_search_queries = eval(next_queries_str)\n",
                "        if not isinstance(new_search_queries, list):\n",
                "            raise ValueError(\"Not a list\")\n",
                "        print(\"Next queries:\", new_search_queries)\n",
                "        all_search_queries.extend(new_search_queries)\n",
                "    except Exception:\n",
                "        print(\"Could not parse further queries:\", next_queries_str)\n",
                "        break\n",
                "```\n",
                "\n",
                "-----\n",
                "\n",
                "## Summary\n",
                "\n",
                "With these modifications, DeepResearcher now:\n",
                "\n",
                "1.  Repeats the **search-extract-plan cycle** for multiple rounds.\n",
                "2.  **Aggregates** all useful information across rounds.\n",
                "3.  Uses accumulated knowledge to generate **smarter, more targeted queries**.\n",
                "4.  **Tracks all queries** to avoid repetition.\n",
                "5.  Provides **clearer output** and robust **error handling**.\n",
                "\n",
                "These changes make DeepResearcher a much more powerful and flexible research tool, capable of digging deeper and adapting its strategy as it learns. In the next practice, you'll get hands-on experience with this new iterative approach\\!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Building the Iterative Research Loop\n",
                "\n",
                "Now that you understand how DeepResearcher can be improved with an iterative approach, let's put this knowledge into practice! In this exercise, you'll transform the single-round research tool into one that can perform multiple rounds of research.\n",
                "\n",
                "Your task is to implement the core components that enable iterative research:\n",
                "\n",
                "Set up the iteration counter and while loop structure.\n",
                "Add a formatted print statement to show which iteration is running.\n",
                "Make sure to properly increment the counter after each round.\n",
                "This transformation will allow the research tool to build on what it discovers in each round, making it much more effective at finding comprehensive information. By implementing these changes, you'll see firsthand how a simple loop structure can dramatically improve the research capabilities of your tool.\n",
                "\n",
                "```python\n",
                "from deepresearcher.llm.llm_manager import generate_response, generate_boolean\n",
                "from deepresearcher.web.web_searcher import search_and_fetch_markdown, clear_visited_pages\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    variables = {\"user_query\": user_query}\n",
                "    search_queries_str = generate_response(\"search_generator_system\", \"search_generator_user\", variables)\n",
                "    try:\n",
                "        queries = eval(search_queries_str)\n",
                "        if not isinstance(queries, list):\n",
                "            raise ValueError(\"Not a list\")\n",
                "        return queries\n",
                "    except Exception:\n",
                "        print(\"Invalid response for search queries:\", search_queries_str)\n",
                "        return []\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    # TODO: Set up an iteration counter (e.g., iteration = 0)\n",
                "    # TODO: Add a while loop that runs while iteration < iteration_limit\n",
                "    # TODO: Print the current iteration number at the start of each round\n",
                "\n",
                "    context_list = []\n",
                "\n",
                "    for query in new_search_queries:\n",
                "        results = search_and_fetch_markdown(query, max_results=3)\n",
                "        for page in results:\n",
                "            page_text = page[\"markdown\"]\n",
                "            if not page_text.strip():\n",
                "                continue\n",
                "\n",
                "            variables = {\n",
                "                \"user_query\": user_query,\n",
                "                \"page_text\": page_text[:20000]\n",
                "            }\n",
                "            is_useful = generate_boolean(\"relevance_evaluator_system\", \"relevance_evaluator_user\", variables)\n",
                "            print(f\"{page['url']} - Useful: {is_useful}\")\n",
                "\n",
                "            if is_useful:\n",
                "                variables = {\n",
                "                    \"user_query\": user_query,\n",
                "                    \"search_query\": query,\n",
                "                    \"page_text\": page_text[:20000]\n",
                "                }\n",
                "                context = generate_response(\"extractor_system\", \"extractor_user\", variables)\n",
                "                if context:\n",
                "                    context_list.append(context)\n",
                "    \n",
                "    # TODO: After each round, increment the iteration counter\n",
                "    return []\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    pass\n",
                "\n",
                "\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    clear_visited_pages()\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        return\n",
                "\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "\n",
                "```\n",
                "\n",
                "Here is the updated `perform_iterative_research` function, implementing the core components for the iterative research loop.\n",
                "\n",
                "The changes involve setting up the `iteration` counter, adding the `while` loop, and including the formatted print statement and the counter increment.\n",
                "\n",
                "```python\n",
                "from deepresearcher.llm.llm_manager import generate_response, generate_boolean\n",
                "from deepresearcher.web.web_searcher import search_and_fetch_markdown, clear_visited_pages\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    variables = {\"user_query\": user_query}\n",
                "    search_queries_str = generate_response(\"search_generator_system\", \"search_generator_user\", variables)\n",
                "    try:\n",
                "        queries = eval(search_queries_str)\n",
                "        if not isinstance(queries, list):\n",
                "            raise ValueError(\"Not a list\")\n",
                "        return queries\n",
                "    except Exception:\n",
                "        print(\"Invalid response for search queries:\", search_queries_str)\n",
                "        return []\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    # Aggregated contexts will store ALL useful information across all rounds\n",
                "    aggregated_contexts = []\n",
                "    \n",
                "    # TODO: Set up an iteration counter (e.g., iteration = 0)\n",
                "    iteration = 0 \n",
                "    \n",
                "    # TODO: Add a while loop that runs while iteration < iteration_limit\n",
                "    while iteration < iteration_limit:\n",
                "    \n",
                "        # TODO: Print the current iteration number at the start of each round\n",
                "        print(f\"\\n=== Iteration {iteration + 1} ===\")\n",
                "\n",
                "        # This will hold the contexts found *in the current iteration*\n",
                "        iteration_contexts = []\n",
                "\n",
                "        for query in new_search_queries:\n",
                "            results = search_and_fetch_markdown(query, max_results=3)\n",
                "            for page in results:\n",
                "                page_text = page[\"markdown\"]\n",
                "                if not page_text.strip():\n",
                "                    continue\n",
                "\n",
                "                variables = {\n",
                "                    \"user_query\": user_query,\n",
                "                    \"page_text\": page_text[:20000]\n",
                "                }\n",
                "                is_useful = generate_boolean(\"relevance_evaluator_system\", \"relevance_evaluator_user\", variables)\n",
                "                print(f\"{page['url']} - Useful: {is_useful}\")\n",
                "\n",
                "                if is_useful:\n",
                "                    variables = {\n",
                "                        \"user_query\": user_query,\n",
                "                        \"search_query\": query,\n",
                "                        \"page_text\": page_text[:20000]\n",
                "                    }\n",
                "                    context = generate_response(\"extractor_system\", \"extractor_user\", variables)\n",
                "                    if context:\n",
                "                        iteration_contexts.append(context)\n",
                "                        \n",
                "        # Append the current iteration's useful context to the master list\n",
                "        if iteration_contexts:\n",
                "            aggregated_contexts.extend(iteration_contexts)\n",
                "        else:\n",
                "            print(\"No useful context found this round.\")\n",
                "\n",
                "        # In a complete implementation, you would generate new queries here\n",
                "        # For now, we'll break after the first pass until the next steps\n",
                "        break # We break here to prevent an infinite loop since we can't generate new queries yet\n",
                "        \n",
                "        # TODO: After each round, increment the iteration counter\n",
                "        iteration += 1\n",
                "        \n",
                "    return aggregated_contexts\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    pass\n",
                "\n",
                "\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    clear_visited_pages()\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        return\n",
                "\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    \n",
                "    # Note: I changed the list used for aggregation inside the function\n",
                "    # from context_list to aggregated_contexts for clarity and consistency.\n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Accumulating Knowledge Across Research Rounds\n",
                "\n",
                "Now that you've set up the basic iteration structure, let's take the next step in building our iterative researcher! In this exercise, you'll implement the context management system that allows DeepResearcher to accumulate knowledge across multiple rounds.\n",
                "\n",
                "Your task is to enhance the perform_iterative_research function by:\n",
                "\n",
                "Rename context_list to iteration_context\n",
                "Creating a master list to store all useful contexts found throughout the research process\n",
                "Adding code to check whether any useful contexts were found in each round\n",
                "Extending the master list with new contexts when they're found\n",
                "Adding a helpful message when no useful contexts are found in a round\n",
                "Updating the function to return all accumulated contexts\n",
                "This context management system is what allows DeepResearcher to build on its findings from one round to the next, making each new search smarter than the last. When you complete this exercise, you'll have a tool that can truly learn and adapt as it researches!\n",
                "\n",
                "```python\n",
                "from deepresearcher.llm.llm_manager import generate_response, generate_boolean\n",
                "from deepresearcher.web.web_searcher import search_and_fetch_markdown, clear_visited_pages\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    variables = {\"user_query\": user_query}\n",
                "    search_queries_str = generate_response(\"search_generator_system\", \"search_generator_user\", variables)\n",
                "    try:\n",
                "        queries = eval(search_queries_str)\n",
                "        if not isinstance(queries, list):\n",
                "            raise ValueError(\"Not a list\")\n",
                "        return queries\n",
                "    except Exception:\n",
                "        print(\"Invalid response for search queries:\", search_queries_str)\n",
                "        return []\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    iteration = 0\n",
                "\n",
                "    # TODO: Create a master list to store all useful contexts found throughout the research process\n",
                "\n",
                "    while iteration < iteration_limit:\n",
                "        print(f\"\\n=== Iteration {iteration + 1} ===\")\n",
                "        # TODO: Rename context_list to iteration_context\n",
                "        context_list = []\n",
                "\n",
                "        for query in new_search_queries:\n",
                "            results = search_and_fetch_markdown(query, max_results=3)\n",
                "            for page in results:\n",
                "                page_text = page[\"markdown\"]\n",
                "                if not page_text.strip():\n",
                "                    continue\n",
                "\n",
                "                variables = {\n",
                "                    \"user_query\": user_query,\n",
                "                    \"page_text\": page_text[:20000]\n",
                "                }\n",
                "                is_useful = generate_boolean(\"relevance_evaluator_system\", \"relevance_evaluator_user\", variables)\n",
                "                print(f\"{page['url']} - Useful: {is_useful}\")\n",
                "\n",
                "                if is_useful:\n",
                "                    variables = {\n",
                "                        \"user_query\": user_query,\n",
                "                        \"search_query\": query,\n",
                "                        \"page_text\": page_text[:20000]\n",
                "                    }\n",
                "                    context = generate_response(\"extractor_system\", \"extractor_user\", variables)\n",
                "                    if context:\n",
                "                        # TODO: Append context to iteration_context\n",
                "                        context_list.append(context)\n",
                "        \n",
                "        # TODO: If any useful contexts were found in this round, extend the master list with them\n",
                "        # TODO: If no useful contexts were found, print a helpful message\n",
                "\n",
                "        iteration += 1\n",
                "\n",
                "    # TODO: Return all accumulated contexts (the master list)\n",
                "    return []\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    pass\n",
                "\n",
                "\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    clear_visited_pages()\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        return\n",
                "\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "\n",
                "```\n",
                "\n",
                "```python\n",
                "from deepresearcher.llm.llm_manager import generate_response, generate_boolean\n",
                "from deepresearcher.web.web_searcher import search_and_fetch_markdown, clear_visited_pages\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    variables = {\"user_query\": user_query}\n",
                "    search_queries_str = generate_response(\"search_generator_system\", \"search_generator_user\", variables)\n",
                "    try:\n",
                "        queries = eval(search_queries_str)\n",
                "        if not isinstance(queries, list):\n",
                "            raise ValueError(\"Not a list\")\n",
                "        return queries\n",
                "    except Exception:\n",
                "        print(\"Invalid response for search queries:\", search_queries_str)\n",
                "        return []\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    iteration = 0\n",
                "\n",
                "    # TODO: Create a master list to store all useful contexts found throughout the research process\n",
                "    aggregated_contexts = []\n",
                "\n",
                "    while iteration < iteration_limit:\n",
                "        print(f\"\\n=== Iteration {iteration + 1} ===\")\n",
                "        \n",
                "        # TODO: Rename context_list to iteration_context\n",
                "        iteration_contexts = []\n",
                "\n",
                "        for query in new_search_queries:\n",
                "            results = search_and_fetch_markdown(query, max_results=3)\n",
                "            for page in results:\n",
                "                page_text = page[\"markdown\"]\n",
                "                if not page_text.strip():\n",
                "                    continue\n",
                "\n",
                "                variables = {\n",
                "                    \"user_query\": user_query,\n",
                "                    \"page_text\": page_text[:20000]\n",
                "                }\n",
                "                is_useful = generate_boolean(\"relevance_evaluator_system\", \"relevance_evaluator_user\", variables)\n",
                "                print(f\"{page['url']} - Useful: {is_useful}\")\n",
                "\n",
                "                if is_useful:\n",
                "                    variables = {\n",
                "                        \"user_query\": user_query,\n",
                "                        \"search_query\": query,\n",
                "                        \"page_text\": page_text[:20000]\n",
                "                    }\n",
                "                    context = generate_response(\"extractor_system\", \"extractor_user\", variables)\n",
                "                    if context:\n",
                "                        # TODO: Append context to iteration_context\n",
                "                        iteration_contexts.append(context)\n",
                "        \n",
                "        # TODO: If any useful contexts were found in this round, extend the master list with them\n",
                "        if iteration_contexts:\n",
                "            aggregated_contexts.extend(iteration_contexts)\n",
                "        # TODO: If no useful contexts were found, print a helpful message\n",
                "        else:\n",
                "            print(\"No useful context found this round.\")\n",
                "            \n",
                "        # We must break here for now to prevent an infinite loop \n",
                "        # since we don't have the logic to generate new search queries yet.\n",
                "        break\n",
                "\n",
                "        iteration += 1\n",
                "\n",
                "    # TODO: Return all accumulated contexts (the master list)\n",
                "    return aggregated_contexts\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    pass\n",
                "\n",
                "\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    clear_visited_pages()\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        return\n",
                "\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Creating the Research Planner Brain\n",
                "\n",
                "Cosmo\n",
                "Just now\n",
                "Read message aloud\n",
                "Now that you've built the core structure for iterative research and added context management, let's focus on the \"brain\" of our system! In this exercise, you'll create the prompts that help the LLM decide what to search for next based on what it has already found.\n",
                "\n",
                "Your task is to:\n",
                "\n",
                "Create a clear system prompt that establishes the LLM's role as a research planner\n",
                "Design a user prompt that uses the original query, previous searches, and information found so far to determine if more research is needed, and if so generate a list of new search queries\n",
                "Use this prompt with the correct variables at the end of the research of each iteration in the perform_iterative_research function\n",
                "Print the output of the prompt\n",
                "This research planner is what makes our tool truly adaptive — it analyzes what we've learned so far and decides where to focus next. With good prompts, your research tool will become much smarter about choosing its next searches, leading to more thorough and relevant results!\n",
                "\n",
                "```python\n",
                "# TODO: Write a system prompt that establishes the LLM's role as a research planner\n",
                "\n",
                "# TODO: Create a user prompt that includes:\n",
                "# 1. The original user query using the {{user_query}} variable\n",
                "# 2. The previous search queries using the {{previous_search_queries}} variable\n",
                "# 3. The contexts found so far using the {{context_combined}} variable\n",
                "# 4. Clear instructions for generating new search queries\n",
                "# 5. Format requirements (Python list)\n",
                "# 6. Instructions for when to stop generating new queries\n",
                "\n",
                "from deepresearcher.llm.llm_manager import generate_response, generate_boolean\n",
                "from deepresearcher.web.web_searcher import search_and_fetch_markdown, clear_visited_pages\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    variables = {\"user_query\": user_query}\n",
                "    search_queries_str = generate_response(\"search_generator_system\", \"search_generator_user\", variables)\n",
                "    try:\n",
                "        queries = eval(search_queries_str)\n",
                "        if not isinstance(queries, list):\n",
                "            raise ValueError(\"Not a list\")\n",
                "        return queries\n",
                "    except Exception:\n",
                "        print(\"Invalid response for search queries:\", search_queries_str)\n",
                "        return []\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    aggregated_contexts = []\n",
                "    iteration = 0\n",
                "\n",
                "    while iteration < iteration_limit:\n",
                "        print(f\"\\n=== Iteration {iteration + 1} ===\")\n",
                "        iteration_contexts = []\n",
                "\n",
                "        for query in new_search_queries:\n",
                "            results = search_and_fetch_markdown(query, max_results=3)\n",
                "            for page in results:\n",
                "                page_text = page[\"markdown\"]\n",
                "                if not page_text.strip():\n",
                "                    continue\n",
                "\n",
                "                variables = {\n",
                "                    \"user_query\": user_query,\n",
                "                    \"page_text\": page_text[:20000]\n",
                "                }\n",
                "                is_useful = generate_boolean(\"relevance_evaluator_system\", \"relevance_evaluator_user\", variables)\n",
                "                print(f\"{page['url']} - Useful: {is_useful}\")\n",
                "\n",
                "                if is_useful:\n",
                "                    variables = {\n",
                "                        \"user_query\": user_query,\n",
                "                        \"search_query\": query,\n",
                "                        \"page_text\": page_text[:20000]\n",
                "                    }\n",
                "                    context = generate_response(\"extractor_system\", \"extractor_user\", variables)\n",
                "                    if context:\n",
                "                        iteration_contexts.append(context)\n",
                "\n",
                "        if iteration_contexts:\n",
                "            aggregated_contexts.extend(iteration_contexts)\n",
                "        else:\n",
                "            print(\"No useful context found this round.\")\n",
                "\n",
                "        # TODO: After each iteration, use the research planner prompts to decide if more research is needed\n",
                "        # TODO: Prepare variables for the research planner prompt (user_query, previous_search_queries, context_combined)\n",
                "        # TODO: Call generate_response with \"research_planner_system\" and \"research_planner_user\" and print the output\n",
                "\n",
                "        iteration += 1\n",
                "\n",
                "    return aggregated_contexts\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    pass\n",
                "\n",
                "\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    clear_visited_pages()\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        return\n",
                "\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "\n",
                "```\n",
                "\n",
                "Here are the defined prompts and the updated `perform_iterative_research` function to implement the **Research Planner Brain**.\n",
                "\n",
                "## Research Planner Prompts\n",
                "\n",
                "These prompts instruct the LLM on its role and provide the necessary context to generate new, smarter search queries.\n",
                "\n",
                "```python\n",
                "research_planner_system = \"\"\"You are an expert Research Planner AI. Your goal is to analyze the user's research objective and the information already gathered to decide the next best step.\n",
                "\n",
                "If the existing context is sufficient to fully answer the user's query, or if you cannot find any new angles to search for, you MUST respond with an empty string: \"\".\n",
                "\n",
                "If more research is needed, you MUST generate a list of 1 to 3 new, highly-targeted search queries (strings) that build upon the current knowledge.\n",
                "\n",
                "Your ONLY output must be a Python list of strings (e.g., [\"query 1\", \"query 2\"]) or an empty string (\"\"). DO NOT include any conversational text, explanations, or markdown formatting (like Python code blocks).\"\"\"\n",
                "\n",
                "research_planner_user = \"\"\"\n",
                "Research Objective: {{user_query}}\n",
                "\n",
                "Previous Search Queries (Used in All Rounds):\n",
                "{{previous_search_queries}}\n",
                "\n",
                "Aggregated Contexts Found So Far:\n",
                "---\n",
                "{{context_combined}}\n",
                "---\n",
                "\n",
                "Task: Based on the 'Research Objective' and the 'Aggregated Contexts Found So Far', determine if enough information has been collected.\n",
                "\n",
                "If the information is complete, output an empty string: \"\".\n",
                "If more information is needed, generate a list of 1 to 3 new, highly-focused search queries to find missing details or related facts. The new queries should be entirely new and not present in the 'Previous Search Queries' list.\n",
                "\n",
                "Output (Python List of Strings OR empty string):\n",
                "\"\"\"\n",
                "```\n",
                "\n",
                "-----\n",
                "\n",
                "## Updated `perform_iterative_research` Function\n",
                "\n",
                "The logic for generating and printing the new queries is added at the end of the `while` loop, right before the iteration counter increments.\n",
                "\n",
                "```python\n",
                "from deepresearcher.llm.llm_manager import generate_response, generate_boolean\n",
                "from deepresearcher.web.web_searcher import search_and_fetch_markdown, clear_visited_pages\n",
                "\n",
                "# --- PROMPT DEFINITIONS ---\n",
                "research_planner_system = \"\"\"You are an expert Research Planner AI. Your goal is to analyze the user's research objective and the information already gathered to decide the next best step.\n",
                "\n",
                "If the existing context is sufficient to fully answer the user's query, or if you cannot find any new angles to search for, you MUST respond with an empty string: \"\".\n",
                "\n",
                "If more research is needed, you MUST generate a list of 1 to 3 new, highly-targeted search queries (strings) that build upon the current knowledge.\n",
                "\n",
                "Your ONLY output must be a Python list of strings (e.g., [\"query 1\", \"query 2\"]) or an empty string (\"\"). DO NOT include any conversational text, explanations, or markdown formatting (like Python code blocks).\"\"\"\n",
                "\n",
                "research_planner_user = \"\"\"\n",
                "Research Objective: {{user_query}}\n",
                "\n",
                "Previous Search Queries (Used in All Rounds):\n",
                "{{previous_search_queries}}\n",
                "\n",
                "Aggregated Contexts Found So Far:\n",
                "---\n",
                "{{context_combined}}\n",
                "---\n",
                "\n",
                "Task: Based on the 'Research Objective' and the 'Aggregated Contexts Found So Far', determine if enough information has been collected.\n",
                "\n",
                "If the information is complete, output an empty string: \"\".\n",
                "If more information is needed, generate a list of 1 to 3 new, highly-focused search queries to find missing details or related facts. The new queries should be entirely new and not present in the 'Previous Search Queries' list.\n",
                "\n",
                "Output (Python List of Strings OR empty string):\n",
                "\"\"\"\n",
                "# --------------------------\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    variables = {\"user_query\": user_query}\n",
                "    search_queries_str = generate_response(\"search_generator_system\", \"search_generator_user\", variables)\n",
                "    try:\n",
                "        queries = eval(search_queries_str)\n",
                "        if not isinstance(queries, list):\n",
                "            raise ValueError(\"Not a list\")\n",
                "        return queries\n",
                "    except Exception:\n",
                "        print(\"Invalid response for search queries:\", search_queries_str)\n",
                "        return []\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    aggregated_contexts = []\n",
                "    iteration = 0\n",
                "\n",
                "    while iteration < iteration_limit:\n",
                "        print(f\"\\n=== Iteration {iteration + 1} ===\")\n",
                "        iteration_contexts = []\n",
                "\n",
                "        for query in new_search_queries:\n",
                "            results = search_and_fetch_markdown(query, max_results=3)\n",
                "            for page in results:\n",
                "                page_text = page[\"markdown\"]\n",
                "                if not page_text.strip():\n",
                "                    continue\n",
                "\n",
                "                variables = {\n",
                "                    \"user_query\": user_query,\n",
                "                    \"page_text\": page_text[:20000]\n",
                "                }\n",
                "                is_useful = generate_boolean(\"relevance_evaluator_system\", \"relevance_evaluator_user\", variables)\n",
                "                print(f\"{page['url']} - Useful: {is_useful}\")\n",
                "\n",
                "                if is_useful:\n",
                "                    variables = {\n",
                "                        \"user_query\": user_query,\n",
                "                        \"search_query\": query,\n",
                "                        \"page_text\": page_text[:20000]\n",
                "                    }\n",
                "                    context = generate_response(\"extractor_system\", \"extractor_user\", variables)\n",
                "                    if context:\n",
                "                        iteration_contexts.append(context)\n",
                "\n",
                "        if iteration_contexts:\n",
                "            aggregated_contexts.extend(iteration_contexts)\n",
                "        else:\n",
                "            print(\"No useful context found this round.\")\n",
                "\n",
                "        # TODO: Prepare variables for the research planner prompt (user_query, previous_search_queries, context_combined)\n",
                "        context_combined = \"\\n---\\n\".join(aggregated_contexts)\n",
                "        variables = {\n",
                "            \"user_query\": user_query,\n",
                "            \"previous_search_queries\": str(all_search_queries),\n",
                "            \"context_combined\": context_combined\n",
                "        }\n",
                "        \n",
                "        # TODO: Call generate_response with \"research_planner_system\" and \"research_planner_user\" and print the output\n",
                "        print(\"\\n--- Planning Next Steps ---\")\n",
                "        next_queries_str = generate_response(research_planner_system, research_planner_user, variables)\n",
                "        \n",
                "        # We'll just print the output for this exercise. The logic to use it comes next.\n",
                "        print(\"Planner Output:\", next_queries_str)\n",
                "        print(\"---------------------------\")\n",
                "        \n",
                "        # NOTE: We must break here since we aren't yet parsing the output to update new_search_queries\n",
                "        break\n",
                "\n",
                "        iteration += 1\n",
                "\n",
                "    return aggregated_contexts\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    pass\n",
                "\n",
                "\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    clear_visited_pages()\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        return\n",
                "\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Safely Parsing LLM Query Responses\n",
                "\n",
                "With our context management system in place, we now need to make sure our research tool can safely process the LLM's suggestions for new search queries. In this exercise, you'll add the error handling that keeps our iterative research process running smoothly.\n",
                "\n",
                "Your task is to implement the code that:\n",
                "\n",
                "Checks whether the LLM response is empty (meaning no more research is needed)\n",
                "Safely converts the string response into a Python list using a try/except block\n",
                "Verifies that the parsed result is actually a list\n",
                "Adds the new search queries to our master list of all queries\n",
                "Handles any parsing errors gracefully\n",
                "This error handling is crucial — without it, a single badly formatted response could crash our entire research process! By adding these safeguards, you'll make your research tool much more robust and reliable for real-world use.\n",
                "\n",
                "```python\n",
                "from deepresearcher.llm.llm_manager import generate_response, generate_boolean\n",
                "from deepresearcher.web.web_searcher import search_and_fetch_markdown, clear_visited_pages\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    variables = {\"user_query\": user_query}\n",
                "    search_queries_str = generate_response(\"search_generator_system\", \"search_generator_user\", variables)\n",
                "    # TODO: Check if search_queries_str is empty and handle accordingly\n",
                "    # TODO: Safely parse search_queries_str into a Python list using try/except\n",
                "    # TODO: Verify that the parsed result is actually a list\n",
                "    # TODO: Handle any parsing errors gracefully\n",
                "    try:\n",
                "        queries = eval(search_queries_str)\n",
                "        if not isinstance(queries, list):\n",
                "            raise ValueError(\"Not a list\")\n",
                "        return queries\n",
                "    except Exception:\n",
                "        print(\"Invalid response for search queries:\", search_queries_str)\n",
                "        return []\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    aggregated_contexts = []\n",
                "    iteration = 0\n",
                "\n",
                "    while iteration < iteration_limit:\n",
                "        print(f\"\\n=== Iteration {iteration + 1} ===\")\n",
                "        iteration_contexts = []\n",
                "\n",
                "        for query in new_search_queries:\n",
                "            results = search_and_fetch_markdown(query, max_results=3)\n",
                "            for page in results:\n",
                "                page_text = page[\"markdown\"]\n",
                "                if not page_text.strip():\n",
                "                    continue\n",
                "\n",
                "                variables = {\n",
                "                    \"user_query\": user_query,\n",
                "                    \"page_text\": page_text[:20000]\n",
                "                }\n",
                "                is_useful = generate_boolean(\"relevance_evaluator_system\", \"relevance_evaluator_user\", variables)\n",
                "                print(f\"{page['url']} - Useful: {is_useful}\")\n",
                "\n",
                "                if is_useful:\n",
                "                    variables = {\n",
                "                        \"user_query\": user_query,\n",
                "                        \"search_query\": query,\n",
                "                        \"page_text\": page_text[:20000]\n",
                "                    }\n",
                "                    context = generate_response(\"extractor_system\", \"extractor_user\", variables)\n",
                "                    if context:\n",
                "                        iteration_contexts.append(context)\n",
                "\n",
                "        if iteration_contexts:\n",
                "            aggregated_contexts.extend(iteration_contexts)\n",
                "        else:\n",
                "            print(\"No useful context found this round.\")\n",
                "        \n",
                "        context_combined = \"\\n\".join(aggregated_contexts)\n",
                "        variables = {\n",
                "            \"user_query\": user_query,\n",
                "            \"previous_search_queries\": str(all_search_queries),\n",
                "            \"context_combined\": context_combined\n",
                "        }\n",
                "        next_queries_str = generate_response(\"research_planner_system\", \"research_planner_user\", variables)\n",
                "        # TODO: Check if next_queries_str is empty and break if so\n",
                "        # TODO: Safely parse next_queries_str into a Python list using try/except\n",
                "        # TODO: Verify that the parsed result is actually a list\n",
                "        # TODO: Add new search queries to all_search_queries\n",
                "        # TODO: Handle any parsing errors gracefully and break the loop if parsing fails\n",
                "\n",
                "        iteration += 1\n",
                "\n",
                "    return aggregated_contexts\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    pass\n",
                "\n",
                "\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    clear_visited_pages()\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        return\n",
                "\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "\n",
                "```\n",
                "\n",
                "The core logic for safely parsing the LLM's response and managing the iterative loop has been implemented in the `perform_iterative_research` function. The same logic is also added to `generate_initial_search_queries` for consistency.\n",
                "\n",
                "```python\n",
                "from deepresearcher.llm.llm_manager import generate_response, generate_boolean\n",
                "from deepresearcher.web.web_searcher import search_and_fetch_markdown, clear_visited_pages\n",
                "\n",
                "# NOTE: For the code to run correctly, you would need to define the research_planner_system/user \n",
                "# prompts as strings, but since they are not provided in the current file, we assume they are accessible\n",
                "# via the generate_response function's access to the LLM_Manager.\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    variables = {\"user_query\": user_query}\n",
                "    search_queries_str = generate_response(\"search_generator_system\", \"search_generator_user\", variables)\n",
                "    \n",
                "    # Check if the response is empty (no queries generated)\n",
                "    if search_queries_str.strip() == \"\":\n",
                "        print(\"LLM did not generate initial search queries.\")\n",
                "        return []\n",
                "        \n",
                "    # Safely parse and verify the list\n",
                "    try:\n",
                "        queries = eval(search_queries_str)\n",
                "        if not isinstance(queries, list):\n",
                "            raise ValueError(\"Not a list\")\n",
                "        print(\"Initial Queries:\", queries)\n",
                "        return queries\n",
                "    except Exception:\n",
                "        print(\"Invalid response for search queries:\", search_queries_str)\n",
                "        return []\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    aggregated_contexts = []\n",
                "    iteration = 0\n",
                "\n",
                "    while iteration < iteration_limit:\n",
                "        print(f\"\\n=== Iteration {iteration + 1} ===\")\n",
                "        iteration_contexts = []\n",
                "\n",
                "        for query in new_search_queries:\n",
                "            results = search_and_fetch_markdown(query, max_results=3)\n",
                "            for page in results:\n",
                "                page_text = page[\"markdown\"]\n",
                "                if not page_text.strip():\n",
                "                    continue\n",
                "\n",
                "                variables = {\n",
                "                    \"user_query\": user_query,\n",
                "                    \"page_text\": page_text[:20000]\n",
                "                }\n",
                "                is_useful = generate_boolean(\"relevance_evaluator_system\", \"relevance_evaluator_user\", variables)\n",
                "                print(f\"{page['url']} - Useful: {is_useful}\")\n",
                "\n",
                "                if is_useful:\n",
                "                    variables = {\n",
                "                        \"user_query\": user_query,\n",
                "                        \"search_query\": query,\n",
                "                        \"page_text\": page_text[:20000]\n",
                "                    }\n",
                "                    context = generate_response(\"extractor_system\", \"extractor_user\", variables)\n",
                "                    if context:\n",
                "                        iteration_contexts.append(context)\n",
                "\n",
                "        if iteration_contexts:\n",
                "            aggregated_contexts.extend(iteration_contexts)\n",
                "        else:\n",
                "            print(\"No useful context found this round.\")\n",
                "        \n",
                "        context_combined = \"\\n\".join(aggregated_contexts)\n",
                "        variables = {\n",
                "            \"user_query\": user_query,\n",
                "            \"previous_search_queries\": str(all_search_queries),\n",
                "            \"context_combined\": context_combined\n",
                "        }\n",
                "        next_queries_str = generate_response(\"research_planner_system\", \"research_planner_user\", variables)\n",
                "        \n",
                "        # TODO: Check if next_queries_str is empty and break if so\n",
                "        if next_queries_str.strip() == \"\":\n",
                "            print(\"LLM indicated no further search is needed. Stopping research loop.\")\n",
                "            break\n",
                "            \n",
                "        # TODO: Safely parse next_queries_str into a Python list using try/except\n",
                "        try:\n",
                "            new_search_queries = eval(next_queries_str)\n",
                "            \n",
                "            # TODO: Verify that the parsed result is actually a list\n",
                "            if not isinstance(new_search_queries, list):\n",
                "                raise ValueError(\"Parsed result is not a list.\")\n",
                "                \n",
                "            print(\"Next Queries:\", new_search_queries)\n",
                "            \n",
                "            # TODO: Add new search queries to all_search_queries\n",
                "            all_search_queries.extend(new_search_queries)\n",
                "            \n",
                "        # TODO: Handle any parsing errors gracefully and break the loop if parsing fails\n",
                "        except Exception as e:\n",
                "            print(f\"Could not parse further queries from LLM response: {next_queries_str}\")\n",
                "            print(f\"Error: {e}\")\n",
                "            print(\"Stopping research loop due to parsing error.\")\n",
                "            break\n",
                "\n",
                "        iteration += 1\n",
                "\n",
                "    return aggregated_contexts\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    pass\n",
                "\n",
                "\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    clear_visited_pages()\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        return\n",
                "\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Testing Your Iterative Research System\n",
                "\n",
                "You've built a powerful iterative research system that can search, learn, and adapt! Now it's time to put your creation to the test with a real research topic. In this exercise, you'll try the iterative search system you built.\n",
                "\n",
                "Your task is to:\n",
                "\n",
                "Complete the code in app.py and run it\n",
                "Choose a complex research topic that will benefit from multiple rounds of exploration\n",
                "Observe how your system builds knowledge across iterations\n",
                "Good test topics include questions with multiple facets, such as \"How does climate change affect agriculture?\" or \"What are the ethical implications of AI?\" These topics typically require several iterations to be fully explored.\n",
                "\n",
                "As you watch your system work, pay attention to how the search queries evolve based on what has been discovered and how information accumulates across rounds. This hands-on testing will help you understand the power of iterative research and verify that all components of your system are working together smoothly.\n",
                "\n",
                "```python\n",
                "from deepresearcher.main import perform_iterative_research, generate_initial_search_queries\n",
                "\n",
                "\n",
                "def test_iterative_research():\n",
                "    \n",
                "    print(\"=== Testing Iterative Research System ===\")\n",
                "    # TODO: Choose a complex topic that will likely need multiple iterations\n",
                "    user_query = \"\"\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    iteration_limit = 2\n",
                "    \n",
                "    # TODO: Run the main research function and print the results\n",
                "    \n",
                "    print(\"\\n=== Test Complete ===\")\n",
                "    print(\"Review the output above to see how the iterative research process worked.\")\n",
                "    print(\"Check that:\")\n",
                "    print(\"1. Multiple iterations were performed\")\n",
                "    print(\"2. Search queries evolved based on previous findings\")\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    test_iterative_research()\n",
                "\n",
                "```\n",
                "\n",
                "It looks like you're ready to put your final code to the test\\! Since the provided code snippet is a test function calling external library parts (`deepresearcher.main`), I'll complete the necessary sections within that function using a **complex, multi-faceted topic** and provide the complete runnable test script.\n",
                "\n",
                "I'll choose the topic: **\"What are the major environmental and societal impacts of deep-sea mining?\"** This question requires separate searches for environmental impacts, societal/economic impacts, and specific case studies, making it an excellent candidate for iterative research.\n",
                "\n",
                "## Completed Iterative Research Test Script\n",
                "\n",
                "Here is the completed `test_iterative_research` function, ready to run (assuming `deepresearcher.main` contains the fully implemented `perform_iterative_research` and `generate_initial_search_queries` functions).\n",
                "\n",
                "```python\n",
                "from deepresearcher.main import perform_iterative_research, generate_initial_search_queries\n",
                "\n",
                "\n",
                "def test_iterative_research():\n",
                "    \n",
                "    print(\"=== Testing Iterative Research System ===\")\n",
                "    \n",
                "    # TODO: Choose a complex topic that will likely need multiple iterations\n",
                "    user_query = \"What are the major environmental and societal impacts of deep-sea mining?\"\n",
                "    print(f\"Research Topic: {user_query}\")\n",
                "    \n",
                "    # 1. Generate initial queries\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        print(\"Failed to generate initial search queries. Aborting test.\")\n",
                "        return\n",
                "        \n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    iteration_limit = 3  # Set to 3 iterations for a solid demonstration\n",
                "    \n",
                "    print(f\"Initial Queries: {all_search_queries}\")\n",
                "    print(f\"Iteration Limit Set: {iteration_limit}\")\n",
                "    \n",
                "    # 2. Run the main research function and capture the results\n",
                "    # The perform_iterative_research function will now print the full step-by-step process\n",
                "    aggregated_contexts = perform_iterative_research(\n",
                "        user_query, \n",
                "        new_search_queries, \n",
                "        all_search_queries, \n",
                "        iteration_limit\n",
                "    )\n",
                "    \n",
                "    # 3. Print the final summary\n",
                "    print(\"\\n\\n===================================\")\n",
                "    print(\"=== Test Complete: Final Summary ===\")\n",
                "    print(f\"Total Contexts Found: {len(aggregated_contexts)}\")\n",
                "    print(f\"Total Unique Queries Used: {len(set(all_search_queries))}\")\n",
                "    print(\"===================================\\n\")\n",
                "    \n",
                "    # 4. Review instructions\n",
                "    print(\"Review the output above to see how the iterative research process worked. 🧐\")\n",
                "    print(\"Check that:\")\n",
                "    print(f\"1. Multiple iterations were performed (up to {iteration_limit})\")\n",
                "    print(\"2. Search queries evolved based on previous findings (from the 'Next Queries' output in each round)\")\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    test_iterative_research()\n",
                "```\n",
                "\n",
                "-----\n",
                "\n",
                "## Expected Observations\n",
                "\n",
                "When you run this script, you should observe the following key aspects of your iterative system working:\n",
                "\n",
                "1.  **Iteration 1:** The system uses the broad initial queries (e.g., `\"deep-sea mining environmental impact\"`, `\"deep-sea mining societal costs\"`). It gathers some general context on both topics.\n",
                "2.  **Planner Logic:** The research planner then analyzes the initial context. It might notice a lack of information on specific regions or regulatory bodies.\n",
                "3.  **Iteration 2:** The system starts a new round with more focused queries, such as `\"deep-sea mining polymetallic nodules controversy\"` or `\"ISA deep-sea mining regulations\"`. It builds on the general knowledge found in the first round.\n",
                "4.  **Loop Termination:** The process continues until the `iteration_limit` is reached, or the planner decides that enough context has been aggregated and returns an empty string, triggering the graceful loop exit.\n",
                "\n",
                "This demonstrates how the **accumulated knowledge** and the **Research Planner Brain** work together to guide the search toward a more complete and nuanced understanding of the complex topic. 👍"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
