{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Unit 5"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Creating the Final Research Report\n",
                "\n",
                "## Introduction: Wrapping Up the Research Process\n",
                "\n",
                "Welcome to the final lesson of the **DeepResearcher** course\\! Up to this point, you've learned how to set up the DeepResearcher project, generate search queries using **OpenAI**, filter and extract useful information from web pages, and refine your research through multiple search rounds.\n",
                "\n",
                "Now, it's time to bring everything together. In this lesson, you will learn how to create a **final research report**. This report is the end goal of all your previous work â€” it combines the user's original question with all the relevant information you've gathered and uses AI to write a clear, well-structured summary. By the end of this lesson, you'll know exactly how DeepResearcher produces a professional report from your research process.\n",
                "\n",
                "-----\n",
                "\n",
                "## Recall: From Contexts to Report\n",
                "\n",
                "Let's quickly remind ourselves of what you've already accomplished. In earlier lessons, you learned how to collect and store relevant information from web pages. Each time you found a useful piece of information, you added it to a list called **contexts**. This list is important because it holds all the key details that will be used to write your final report.\n",
                "\n",
                "Think of **contexts** as a collection of research notes. Now, your task is to turn these notes into a polished report that answers the user's original question.\n",
                "\n",
                "-----\n",
                "\n",
                "## How the Final Report Is Generated\n",
                "\n",
                "The final report is created by a function called `generate_final_report`. This function takes two main inputs:\n",
                "\n",
                "1.  The user's original research question (`user_query`)\n",
                "2.  The list of relevant information you gathered (`contexts`)\n",
                "\n",
                "The function then combines these inputs and uses a prompt template to guide the AI in writing a detailed report. Let's break down how this works, step by step.\n",
                "\n",
                "### Step 1: Preparing the Inputs\n",
                "\n",
                "First, you need to combine all the gathered contexts into a single string. This is done by joining the list with newline characters so the AI can see all the information at once.\n",
                "\n",
                "```python\n",
                "context_combined = \"\\n\".join(contexts)\n",
                "```\n",
                "\n",
                "Here, `contexts` is your list of research notes, and `context_combined` is a single string containing all of them, separated by new lines.\n",
                "\n",
                "### Step 2: Setting Up the Variables for the Prompt\n",
                "\n",
                "Next, you create a dictionary called `variables` that holds the user's query and the combined contexts. This dictionary will be used to fill in the prompt template.\n",
                "\n",
                "```python\n",
                "variables = {\n",
                "    \"user_query\": user_query,\n",
                "    \"context_combined\": context_combined\n",
                "}\n",
                "```\n",
                "\n",
                "  * `user_query` is the original question or topic the user wants to research.\n",
                "  * `context_combined` is the string of all relevant information you've gathered.\n",
                "\n",
                "### Step 3: Generating the Report with the AI\n",
                "\n",
                "Now, you use the `generate_response` function to ask the AI to write the report. This function takes the names of the prompt templates and the variables you just prepared.\n",
                "\n",
                "```python\n",
                "final_report = generate_response(\"report_writer_system\", \"report_writer_user\", variables)\n",
                "```\n",
                "\n",
                "  * `\"report_writer_system\"` and `\"report_writer_user\"` are the names of the prompt files that guide the AI on how to write the report. You will write them in the practices.\n",
                "  * `variables` provides the actual content for the AI to use.\n",
                "\n",
                "The AI reads the prompt, sees the user's question and all the gathered contexts, and writes a detailed report.\n",
                "\n",
                "-----\n",
                "\n",
                "## Example: Generating a Report in Code\n",
                "\n",
                "Let's look at a complete example of how to generate the final report. Here's the relevant part of the code from your project:\n",
                "\n",
                "```python\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    variables = {\n",
                "        \"user_query\": user_query,\n",
                "        \"context_combined\": \"\\n\".join(contexts)\n",
                "    }\n",
                "    final_report = generate_response(\"report_writer_system\", \"report_writer_user\", variables)\n",
                "    print(\"\\n==== FINAL REPORT ====\")\n",
                "    print(final_report)\n",
                "```\n",
                "\n",
                "Let's break this down:\n",
                "\n",
                "  * The function takes the user's query and the list of contexts.\n",
                "  * It prepares the variables for the prompt.\n",
                "  * It calls `generate_response` to get the AI-generated report.\n",
                "  * It prints the final report to the screen.\n",
                "\n",
                "### Example Output:\n",
                "\n",
                "Suppose the user's query is:\n",
                "\n",
                "```\n",
                "What are the latest advancements in solar panel technology?\n",
                "```\n",
                "\n",
                "And the `contexts` list contains:\n",
                "\n",
                "```python\n",
                "[\n",
                "    \"Recent studies show that perovskite solar cells have reached 25% efficiency.\",\n",
                "    \"Flexible solar panels are now being used in portable devices.\",\n",
                "    \"Researchers have developed transparent solar panels for windows.\"\n",
                "]\n",
                "```\n",
                "\n",
                "The output might look like:\n",
                "\n",
                "```\n",
                "==== FINAL REPORT ====\n",
                "Recent advancements in solar panel technology include significant improvements in efficiency, flexibility, and application.\n",
                "\n",
                "Perovskite solar cells have achieved up to 25% efficiency, making them a promising alternative to traditional silicon-based panels. Flexible solar panels are increasingly used in portable devices, expanding the range of solar-powered products. Additionally, transparent solar panels have been developed for use in windows, allowing buildings to generate electricity without altering their appearance. These innovations are driving the solar industry forward and opening new possibilities for clean energy adoption.\n",
                "```\n",
                "\n",
                "This example shows how the function takes your research notes and turns them into a clear, well-organized report.\n",
                "\n",
                "-----\n",
                "\n",
                "## Summary And Congratulations\n",
                "\n",
                "In this lesson, you learned how to generate a **final research report** by combining the user's question with all the relevant information you gathered. You saw how to prepare the inputs, use prompt templates, and call the AI to write a detailed summary. This step completes the DeepResearcher workflow, turning your research process into a professional, readable report.\n",
                "\n",
                "**Congratulations** on reaching the end of the DeepResearcher course\\! You now have all the skills needed to build and use your own AI-powered research tool. Take a moment to celebrate your progress, and get ready to apply what you've learned in the hands-on practice exercises that follow. Well done\\! ðŸŽ‰\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Crafting Prompts for Research Reports\n",
                "\n",
                "Now that you understand how the final report is generated, it's time to create the prompt templates that will guide the AI in writing high-quality research reports. In this exercise, you'll design two essential prompt files that form the heart of the report generation process.\n",
                "\n",
                "Your task is to write both the system prompt (report_writer_system.txt) and the user prompt (report_writer_user.txt) that will be used by the generate_final_report function we just explored.\n",
                "\n",
                "The system prompt should define the AI's role as a report writer, while the user prompt needs to provide specific instructions on how to transform the gathered contexts into a well-structured report that addresses the original query.\n",
                "\n",
                "Remember that these prompts directly impact the quality of the final output â€” a good prompt leads to a clear, comprehensive, and useful research report. This is your chance to shape how DeepResearcher presents its findings to users!\n",
                "\n",
                "```python\n",
                "# TODO: Write a system prompt that defines the AI's role as a report writer.\n",
                "# This prompt should establish the AI's capabilities and approach to creating research reports.\n",
                "\n",
                "User Query: {{user_query}}\n",
                "\n",
                "Gathered Relevant Contexts:\n",
                "{{context_combined}}\n",
                "\n",
                "# TODO: Write instructions for the AI to create a comprehensive research report.\n",
                "# Your instructions should guide the AI on:\n",
                "# - How to structure the report\n",
                "# - What to include from the contexts\n",
                "# - The style and tone to use\n",
                "# - Any specific sections the report should have\n",
                "# - How to ensure the report directly addresses the original query\n",
                "\n",
                "```\n",
                "\n",
                "Here are the contents for the system and user prompt files that will guide the AI in generating a high-quality research report.\n",
                "\n",
                "-----\n",
                "\n",
                "## 1\\. System Prompt (`report_writer_system.txt`)\n",
                "\n",
                "This prompt defines the AI's role, expertise, and expected behavior.\n",
                "\n",
                "```\n",
                "You are an expert Research Report Writer named **DeepResearcher Finalizer**.\n",
                "\n",
                "Your sole function is to take a user's research query and a collection of factual, verified contexts gathered from web sources, and synthesize them into a clear, comprehensive, and professional research report.\n",
                "\n",
                "**Core Directives:**\n",
                "1.  **Strictly adhere to the provided contexts.** Do not introduce any external information, assumptions, or speculation. Every point in the final report must be traceable back to the 'Gathered Relevant Contexts'.\n",
                "2.  **Maintain a professional, objective, and academic tone.** The report must be concise, well-structured, and easy to read.\n",
                "3.  **The primary goal is to directly and fully answer the 'User Query'** using the provided 'Gathered Relevant Contexts'.\n",
                "4.  **Do not include any preamble, concluding remarks, or conversational filler.** Start immediately with the title and content of the report as defined by the user instructions.\n",
                "```\n",
                "\n",
                "-----\n",
                "\n",
                "## 2\\. User Prompt (`report_writer_user.txt`)\n",
                "\n",
                "This prompt provides the structure and specific instructions for creating the final report using the provided data.\n",
                "\n",
                "```\n",
                "**TASK:** Create a comprehensive, well-structured research report that directly answers the User Query by synthesizing the provided Gathered Relevant Contexts.\n",
                "\n",
                "**User Query:**\n",
                "{{user_query}}\n",
                "\n",
                "**Gathered Relevant Contexts:**\n",
                "{{context_combined}}\n",
                "\n",
                "**REPORT REQUIREMENTS:**\n",
                "\n",
                "1.  **Title:** The report must begin with a clear, informative **title** that summarizes the topic of the query.\n",
                "2.  **Structure:** Use **Markdown headings** (##) to create logical sections. At a minimum, include:\n",
                "    * **Introduction/Summary:** A brief opening paragraph that clearly states the answer to the query or summarizes the key findings.\n",
                "    * **Detailed Findings:** One or more sections that elaborate on the main points using the information from the contexts. Use bolding for key terms or metrics.\n",
                "    * **Conclusion/Implications (if applicable):** A brief concluding paragraph summarizing the overall significance of the findings, without adding new information.\n",
                "3.  **Formatting:**\n",
                "    * Use clear, paragraph-style writing. Do **not** use bulleted or numbered lists unless a list is explicitly contained within the contexts.\n",
                "    * Ensure smooth transitions between synthesized points.\n",
                "4.  **Output:** Generate the complete report based *only* on the 'Gathered Relevant Contexts' provided below.\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Implementing the Final Report Generator\n",
                "\n",
                "Now that you've created the prompt templates for your research reports, it's time to implement the function that brings everything together! In this exercise, you'll complete the generate_final_report function, which transforms your gathered research into a polished final report.\n",
                "\n",
                "Your task is to implement three key components of the function:\n",
                "\n",
                "Create a variables dictionary containing the user query and combined contexts\n",
                "Call the generate_response function with the appropriate prompt templates\n",
                "This exercise puts into practice what you've learned about preparing data for AI processing and using prompt templates effectively. By completing this function, you'll finalize the last piece of the DeepResearcher workflow, allowing you to turn raw research data into valuable insights for users.\n",
                "\n",
                "```python\n",
                "from deepresearcher.llm.llm_manager import generate_response, generate_boolean\n",
                "from deepresearcher.web.web_searcher import search_and_fetch_markdown, clear_visited_pages\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    variables = {\"user_query\": user_query}\n",
                "    search_queries_str = generate_response(\"search_generator_system\", \"search_generator_user\", variables)\n",
                "    try:\n",
                "        queries = eval(search_queries_str)\n",
                "        if not isinstance(queries, list):\n",
                "            raise ValueError(\"Not a list\")\n",
                "        return queries\n",
                "    except Exception:\n",
                "        print(\"Invalid response for search queries:\", search_queries_str)\n",
                "        return []\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    aggregated_contexts = []\n",
                "    iteration = 0\n",
                "\n",
                "    while iteration < iteration_limit:\n",
                "        print(f\"\\n=== Iteration {iteration + 1} ===\")\n",
                "        iteration_contexts = []\n",
                "\n",
                "        for query in new_search_queries:\n",
                "            results = search_and_fetch_markdown(query, max_results=3)\n",
                "            for page in results:\n",
                "                page_text = page[\"markdown\"]\n",
                "                if not page_text.strip():\n",
                "                    continue\n",
                "\n",
                "                variables = {\n",
                "                    \"user_query\": user_query,\n",
                "                    \"page_text\": page_text[:20000]\n",
                "                }\n",
                "                is_useful = generate_boolean(\"relevance_evaluator_system\", \"relevance_evaluator_user\", variables)\n",
                "                print(f\"{page['url']} - Useful: {is_useful}\")\n",
                "\n",
                "                if is_useful:\n",
                "                    variables = {\n",
                "                        \"user_query\": user_query,\n",
                "                        \"search_query\": query,\n",
                "                        \"page_text\": page_text[:20000]\n",
                "                    }\n",
                "                    context = generate_response(\"extractor_system\", \"extractor_user\", variables)\n",
                "                    if context:\n",
                "                        iteration_contexts.append(context)\n",
                "\n",
                "        if iteration_contexts:\n",
                "            aggregated_contexts.extend(iteration_contexts)\n",
                "        else:\n",
                "            print(\"No useful context found this round.\")\n",
                "\n",
                "        context_combined = \"\\n\".join(aggregated_contexts)\n",
                "        variables = {\n",
                "            \"user_query\": user_query,\n",
                "            \"previous_search_queries\": str(all_search_queries),\n",
                "            \"context_combined\": context_combined\n",
                "        }\n",
                "        next_queries_str = generate_response(\"research_planner_system\", \"research_planner_user\", variables)\n",
                "        if next_queries_str.strip() == \"[]\":\n",
                "            print(\"LLM indicated no further search is needed.\")\n",
                "            break\n",
                "\n",
                "        try:\n",
                "            new_search_queries = eval(next_queries_str)\n",
                "            if not isinstance(new_search_queries, list):\n",
                "                raise ValueError(\"Not a list\")\n",
                "            print(\"Next queries:\", new_search_queries)\n",
                "            all_search_queries.extend(new_search_queries)\n",
                "        except Exception:\n",
                "            print(\"Could not parse further queries:\", next_queries_str)\n",
                "            break\n",
                "\n",
                "        iteration += 1\n",
                "\n",
                "    return aggregated_contexts\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    # TODO: Create a variables dictionary with \"user_query\" and \"context_combined\" keys\n",
                "    # The \"context_combined\" value should join all contexts with newlines\n",
                "    \n",
                "    # TODO: Call generate_response with the report writer prompt templates and variables\n",
                "    pass\n",
                "\n",
                "\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    clear_visited_pages()\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        return\n",
                "\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "\n",
                "```\n",
                "\n",
                "Here is the completed `generate_final_report` function, implementing the steps to combine the contexts, prepare the variables, and call the AI to generate the final report.\n",
                "\n",
                "```python\n",
                "from deepresearcher.llm.llm_manager import generate_response, generate_boolean\n",
                "from deepresearcher.web.web_searcher import search_and_fetch_markdown, clear_visited_pages\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    variables = {\"user_query\": user_query}\n",
                "    search_queries_str = generate_response(\"search_generator_system\", \"search_generator_user\", variables)\n",
                "    try:\n",
                "        queries = eval(search_queries_str)\n",
                "        if not isinstance(queries, list):\n",
                "            raise ValueError(\"Not a list\")\n",
                "        return queries\n",
                "    except Exception:\n",
                "        print(\"Invalid response for search queries:\", search_queries_str)\n",
                "        return []\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    aggregated_contexts = []\n",
                "    iteration = 0\n",
                "\n",
                "    while iteration < iteration_limit:\n",
                "        print(f\"\\n=== Iteration {iteration + 1} ===\")\n",
                "        iteration_contexts = []\n",
                "\n",
                "        for query in new_search_queries:\n",
                "            results = search_and_fetch_markdown(query, max_results=3)\n",
                "            for page in results:\n",
                "                page_text = page[\"markdown\"]\n",
                "                if not page_text.strip():\n",
                "                    continue\n",
                "\n",
                "                variables = {\n",
                "                    \"user_query\": user_query,\n",
                "                    \"page_text\": page_text[:20000]\n",
                "                }\n",
                "                is_useful = generate_boolean(\"relevance_evaluator_system\", \"relevance_evaluator_user\", variables)\n",
                "                print(f\"{page['url']} - Useful: {is_useful}\")\n",
                "\n",
                "                if is_useful:\n",
                "                    variables = {\n",
                "                        \"user_query\": user_query,\n",
                "                        \"search_query\": query,\n",
                "                        \"page_text\": page_text[:20000]\n",
                "                    }\n",
                "                    context = generate_response(\"extractor_system\", \"extractor_user\", variables)\n",
                "                    if context:\n",
                "                        iteration_contexts.append(context)\n",
                "\n",
                "        if iteration_contexts:\n",
                "            aggregated_contexts.extend(iteration_contexts)\n",
                "        else:\n",
                "            print(\"No useful context found this round.\")\n",
                "\n",
                "        context_combined = \"\\n\".join(aggregated_contexts)\n",
                "        variables = {\n",
                "            \"user_query\": user_query,\n",
                "            \"previous_search_queries\": str(all_search_queries),\n",
                "            \"context_combined\": context_combined\n",
                "        }\n",
                "        next_queries_str = generate_response(\"research_planner_system\", \"research_planner_user\", variables)\n",
                "        if next_queries_str.strip() == \"[]\":\n",
                "            print(\"LLM indicated no further search is needed.\")\n",
                "            break\n",
                "\n",
                "        try:\n",
                "            new_search_queries = eval(next_queries_str)\n",
                "            if not isinstance(new_search_queries, list):\n",
                "                raise ValueError(\"Not a list\")\n",
                "            print(\"Next queries:\", new_search_queries)\n",
                "            all_search_queries.extend(new_search_queries)\n",
                "        except Exception:\n",
                "            print(\"Could not parse further queries:\", next_queries_str)\n",
                "            break\n",
                "\n",
                "        iteration += 1\n",
                "\n",
                "    return aggregated_contexts\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    # Create a variables dictionary with \"user_query\" and \"context_combined\" keys\n",
                "    # The \"context_combined\" value should join all contexts with newlines\n",
                "    variables = {\n",
                "        \"user_query\": user_query,\n",
                "        \"context_combined\": \"\\n\".join(contexts)\n",
                "    }\n",
                "    \n",
                "    # Call generate_response with the report writer prompt templates and variables\n",
                "    final_report = generate_response(\"report_writer_system\", \"report_writer_user\", variables)\n",
                "\n",
                "    print(\"\\n==== FINAL REPORT ====\")\n",
                "    print(final_report)\n",
                "\n",
                "\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    clear_visited_pages()\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        return\n",
                "\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Print the Final Report\n",
                "\n",
                "With your final report generated, its time to complete the final piece of the DeepResearcher workflow! In this exercise, you'll implement the end of the generate_final_report function, which transforms your collected research into a polished, readable report.\n",
                "\n",
                "Your task is to fill in the missing code that:\n",
                "\n",
                "Print a clear header\n",
                "Print the formatted report\n",
                "This function is what turns all your hard work into something valuable for the end user. A well-formatted report makes the difference between raw data and actionable insights that answer the original research question.\n",
                "\n",
                "When you complete this function, you'll have finished building a complete AI research assistant from start to finish!\n",
                "\n",
                "```python\n",
                "from deepresearcher.llm.llm_manager import generate_response, generate_boolean\n",
                "from deepresearcher.web.web_searcher import search_and_fetch_markdown, clear_visited_pages\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    variables = {\"user_query\": user_query}\n",
                "    search_queries_str = generate_response(\"search_generator_system\", \"search_generator_user\", variables)\n",
                "    try:\n",
                "        queries = eval(search_queries_str)\n",
                "        if not isinstance(queries, list):\n",
                "            raise ValueError(\"Not a list\")\n",
                "        return queries\n",
                "    except Exception:\n",
                "        print(\"Invalid response for search queries:\", search_queries_str)\n",
                "        return []\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    aggregated_contexts = []\n",
                "    iteration = 0\n",
                "\n",
                "    while iteration < iteration_limit:\n",
                "        print(f\"\\n=== Iteration {iteration + 1} ===\")\n",
                "        iteration_contexts = []\n",
                "\n",
                "        for query in new_search_queries:\n",
                "            results = search_and_fetch_markdown(query, max_results=3)\n",
                "            for page in results:\n",
                "                page_text = page[\"markdown\"]\n",
                "                if not page_text.strip():\n",
                "                    continue\n",
                "\n",
                "                variables = {\n",
                "                    \"user_query\": user_query,\n",
                "                    \"page_text\": page_text[:20000]\n",
                "                }\n",
                "                is_useful = generate_boolean(\"relevance_evaluator_system\", \"relevance_evaluator_user\", variables)\n",
                "                print(f\"{page['url']} - Useful: {is_useful}\")\n",
                "\n",
                "                if is_useful:\n",
                "                    variables = {\n",
                "                        \"user_query\": user_query,\n",
                "                        \"search_query\": query,\n",
                "                        \"page_text\": page_text[:20000]\n",
                "                    }\n",
                "                    context = generate_response(\"extractor_system\", \"extractor_user\", variables)\n",
                "                    if context:\n",
                "                        iteration_contexts.append(context)\n",
                "\n",
                "        if iteration_contexts:\n",
                "            aggregated_contexts.extend(iteration_contexts)\n",
                "        else:\n",
                "            print(\"No useful context found this round.\")\n",
                "\n",
                "        context_combined = \"\\n\".join(aggregated_contexts)\n",
                "        variables = {\n",
                "            \"user_query\": user_query,\n",
                "            \"previous_search_queries\": str(all_search_queries),\n",
                "            \"context_combined\": context_combined\n",
                "        }\n",
                "        next_queries_str = generate_response(\"research_planner_system\", \"research_planner_user\", variables)\n",
                "        if next_queries_str.strip() == \"[]\":\n",
                "            print(\"LLM indicated no further search is needed.\")\n",
                "            break\n",
                "\n",
                "        try:\n",
                "            new_search_queries = eval(next_queries_str)\n",
                "            if not isinstance(new_search_queries, list):\n",
                "                raise ValueError(\"Not a list\")\n",
                "            print(\"Next queries:\", new_search_queries)\n",
                "            all_search_queries.extend(new_search_queries)\n",
                "        except Exception:\n",
                "            print(\"Could not parse further queries:\", next_queries_str)\n",
                "            break\n",
                "\n",
                "        iteration += 1\n",
                "\n",
                "    return aggregated_contexts\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    variables = {\n",
                "        \"user_query\": user_query,\n",
                "        \"context_combined\": \"\\n\".join(contexts)\n",
                "    }\n",
                "    final_report = generate_response(\"report_writer_system\", \"report_writer_user\", variables)\n",
                "    # TODO: Print the final report with a clear header like \"==== FINAL REPORT ====\"\n",
                "\n",
                "\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    clear_visited_pages()\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        return\n",
                "\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "\n",
                "```\n",
                "\n",
                "Here is the completed `generate_final_report` function with the printing code added. You've finished the DeepResearcher workflow\\! ðŸŽ‰\n",
                "\n",
                "```python\n",
                "from deepresearcher.llm.llm_manager import generate_response, generate_boolean\n",
                "from deepresearcher.web.web_searcher import search_and_fetch_markdown, clear_visited_pages\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    variables = {\"user_query\": user_query}\n",
                "    search_queries_str = generate_response(\"search_generator_system\", \"search_generator_user\", variables)\n",
                "    try:\n",
                "        queries = eval(search_queries_str)\n",
                "        if not isinstance(queries, list):\n",
                "            raise ValueError(\"Not a list\")\n",
                "        return queries\n",
                "    except Exception:\n",
                "        print(\"Invalid response for search queries:\", search_queries_str)\n",
                "        return []\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    aggregated_contexts = []\n",
                "    iteration = 0\n",
                "\n",
                "    while iteration < iteration_limit:\n",
                "        print(f\"\\n=== Iteration {iteration + 1} ===\")\n",
                "        iteration_contexts = []\n",
                "\n",
                "        for query in new_search_queries:\n",
                "            results = search_and_fetch_markdown(query, max_results=3)\n",
                "            for page in results:\n",
                "                page_text = page[\"markdown\"]\n",
                "                if not page_text.strip():\n",
                "                    continue\n",
                "\n",
                "                variables = {\n",
                "                    \"user_query\": user_query,\n",
                "                    \"page_text\": page_text[:20000]\n",
                "                }\n",
                "                is_useful = generate_boolean(\"relevance_evaluator_system\", \"relevance_evaluator_user\", variables)\n",
                "                print(f\"{page['url']} - Useful: {is_useful}\")\n",
                "\n",
                "                if is_useful:\n",
                "                    variables = {\n",
                "                        \"user_query\": user_query,\n",
                "                        \"search_query\": query,\n",
                "                        \"page_text\": page_text[:20000]\n",
                "                    }\n",
                "                    context = generate_response(\"extractor_system\", \"extractor_user\", variables)\n",
                "                    if context:\n",
                "                        iteration_contexts.append(context)\n",
                "\n",
                "        if iteration_contexts:\n",
                "            aggregated_contexts.extend(iteration_contexts)\n",
                "        else:\n",
                "            print(\"No useful context found this round.\")\n",
                "\n",
                "        context_combined = \"\\n\".join(aggregated_contexts)\n",
                "        variables = {\n",
                "            \"user_query\": user_query,\n",
                "            \"previous_search_queries\": str(all_search_queries),\n",
                "            \"context_combined\": context_combined\n",
                "        }\n",
                "        next_queries_str = generate_response(\"research_planner_system\", \"research_planner_user\", variables)\n",
                "        if next_queries_str.strip() == \"[]\":\n",
                "            print(\"LLM indicated no further search is needed.\")\n",
                "            break\n",
                "\n",
                "        try:\n",
                "            new_search_queries = eval(next_queries_str)\n",
                "            if not isinstance(new_search_queries, list):\n",
                "                raise ValueError(\"Not a list\")\n",
                "            print(\"Next queries:\", new_search_queries)\n",
                "            all_search_queries.extend(new_search_queries)\n",
                "        except Exception:\n",
                "            print(\"Could not parse further queries:\", next_queries_str)\n",
                "            break\n",
                "\n",
                "        iteration += 1\n",
                "\n",
                "    return aggregated_contexts\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    variables = {\n",
                "        \"user_query\": user_query,\n",
                "        \"context_combined\": \"\\n\".join(contexts)\n",
                "    }\n",
                "    final_report = generate_response(\"report_writer_system\", \"report_writer_user\", variables)\n",
                "    \n",
                "    # Print the final report with a clear header like \"==== FINAL REPORT ====\"\n",
                "    print(\"\\n==== FINAL REPORT ====\")\n",
                "    print(final_report)\n",
                "\n",
                "\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    clear_visited_pages()\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        return\n",
                "\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Testing Your AI Research Assistant\n",
                "\n",
                "Fantastic work implementing the final report generator! Now it's time to put your complete DeepResearcher system to the test with a real research query. This is where all your hard work comes together â€” from crafting search queries to extracting relevant information to generating a polished report.\n",
                "\n",
                "Choose a research topic you're curious about and run your implementation to see how it performs in action. Pay attention to:\n",
                "\n",
                "How your system generates initial search queries\n",
                "Which web pages it finds useful during each iteration\n",
                "How the research evolves across multiple iterations\n",
                "The quality and structure of your final report\n",
                "Testing with real queries will help you understand the strengths of your implementation and identify any areas for improvement. The satisfaction of seeing your AI research assistant deliver valuable insights on a topic you care about makes all your coding efforts worthwhile!\n",
                "\n",
                "\n",
                "```python\n",
                "from deepresearcher.llm.llm_manager import generate_response, generate_boolean\n",
                "from deepresearcher.web.web_searcher import search_and_fetch_markdown, clear_visited_pages\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    variables = {\"user_query\": user_query}\n",
                "    search_queries_str = generate_response(\"search_generator_system\", \"search_generator_user\", variables)\n",
                "    try:\n",
                "        queries = eval(search_queries_str)\n",
                "        if not isinstance(queries, list):\n",
                "            raise ValueError(\"Not a list\")\n",
                "        return queries\n",
                "    except Exception:\n",
                "        print(\"Invalid response for search queries:\", search_queries_str)\n",
                "        return []\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    aggregated_contexts = []\n",
                "    iteration = 0\n",
                "\n",
                "    while iteration < iteration_limit:\n",
                "        print(f\"\\n=== Iteration {iteration + 1} ===\")\n",
                "        iteration_contexts = []\n",
                "\n",
                "        for query in new_search_queries:\n",
                "            results = search_and_fetch_markdown(query, max_results=3)\n",
                "            for page in results:\n",
                "                page_text = page[\"markdown\"]\n",
                "                if not page_text.strip():\n",
                "                    continue\n",
                "\n",
                "                variables = {\n",
                "                    \"user_query\": user_query,\n",
                "                    \"page_text\": page_text[:20000]\n",
                "                }\n",
                "                is_useful = generate_boolean(\"relevance_evaluator_system\", \"relevance_evaluator_user\", variables)\n",
                "                print(f\"{page['url']} - Useful: {is_useful}\")\n",
                "\n",
                "                if is_useful:\n",
                "                    variables = {\n",
                "                        \"user_query\": user_query,\n",
                "                        \"search_query\": query,\n",
                "                        \"page_text\": page_text[:20000]\n",
                "                    }\n",
                "                    context = generate_response(\"extractor_system\", \"extractor_user\", variables)\n",
                "                    if context:\n",
                "                        iteration_contexts.append(context)\n",
                "\n",
                "        if iteration_contexts:\n",
                "            aggregated_contexts.extend(iteration_contexts)\n",
                "        else:\n",
                "            print(\"No useful context found this round.\")\n",
                "\n",
                "        context_combined = \"\\n\".join(aggregated_contexts)\n",
                "        variables = {\n",
                "            \"user_query\": user_query,\n",
                "            \"previous_search_queries\": str(all_search_queries),\n",
                "            \"context_combined\": context_combined\n",
                "        }\n",
                "        next_queries_str = generate_response(\"research_planner_system\", \"research_planner_user\", variables)\n",
                "        if next_queries_str.strip() == \"[]\":\n",
                "            print(\"LLM indicated no further search is needed.\")\n",
                "            break\n",
                "\n",
                "        try:\n",
                "            new_search_queries = eval(next_queries_str)\n",
                "            if not isinstance(new_search_queries, list):\n",
                "                raise ValueError(\"Not a list\")\n",
                "            print(\"Next queries:\", new_search_queries)\n",
                "            all_search_queries.extend(new_search_queries)\n",
                "        except Exception:\n",
                "            print(\"Could not parse further queries:\", next_queries_str)\n",
                "            break\n",
                "\n",
                "        iteration += 1\n",
                "\n",
                "    return aggregated_contexts\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    variables = {\n",
                "        \"user_query\": user_query,\n",
                "        \"context_combined\": \"\\n\".join(contexts)\n",
                "    }\n",
                "    final_report = generate_response(\"report_writer_system\", \"report_writer_user\", variables)\n",
                "    print(\"\\n==== FINAL REPORT ====\")\n",
                "    print(final_report)\n",
                "\n",
                "\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    clear_visited_pages()\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        return\n",
                "\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "\n",
                "```"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
