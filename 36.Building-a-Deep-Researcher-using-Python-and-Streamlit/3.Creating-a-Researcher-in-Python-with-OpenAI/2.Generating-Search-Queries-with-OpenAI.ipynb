{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Unit 2"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Generating Search Queries with OpenAI\n",
                "\n",
                "## Welcome Back\\! Generating Initial Search Queries\n",
                "\n",
                "Welcome back\\! In the previous lesson, you learned how the **DeepResearcher** project is organized and how the main program connects different parts of the research tool. Now, we are ready to dive into one of the most important steps in automated research: generating **search queries**.\n",
                "\n",
                "When you want to research a topic, you usually start by typing a question or a phrase into a search engine. The **quality of your search queries** can make a big difference in the results you get. In DeepResearcher, we want to automate this process so that the tool can come up with several smart search queries based on a user’s topic. This helps us gather more complete and relevant information from the web.\n",
                "\n",
                "In this lesson, you will learn how DeepResearcher uses **OpenAI** to generate a list of search queries from a user’s input. This is a key step that powers the rest of the research process.\n",
                "\n",
                "-----\n",
                "\n",
                "## How DeepResearcher Generates Search Queries\n",
                "\n",
                "Let’s look at how DeepResearcher turns a user’s research topic into a set of search queries using OpenAI.\n",
                "\n",
                "The main function responsible for this is called `generate_initial_search_queries`. Here’s how it works, step by step.\n",
                "\n",
                "### 1\\. Collecting the User’s Query\n",
                "\n",
                "First, we need to get the topic or question the user wants to research. This is usually a string, like \"What are the health benefits of green tea?\"\n",
                "\n",
                "```python\n",
                "user_query = input(\"Enter your research query/topic: \").strip()\n",
                "```\n",
                "\n",
                "  * `input()` asks the user to type in their research topic.\n",
                "  * `.strip()` removes any extra spaces at the beginning or end.\n",
                "\n",
                "### 2\\. Preparing Variables for the Language Model\n",
                "\n",
                "Next, we prepare the user’s query to send to the language model. We put it into a dictionary called `variables`.\n",
                "\n",
                "```python\n",
                "variables = {\"user_query\": user_query}\n",
                "```\n",
                "\n",
                "This dictionary will be used to fill in the prompt template for the language model.\n",
                "\n",
                "### 3\\. Generating the Search Queries with OpenAI\n",
                "\n",
                "Now, we use the `generate_response` function to ask the language model (like GPT-3.5 or GPT-4) to generate search queries for us. We provide it with two prompt files and the variables.\n",
                "\n",
                "```python\n",
                "search_queries_str = generate_response(\n",
                "    \"search_generator_system\",\n",
                "    \"search_generator_user\",\n",
                "    variables\n",
                ")\n",
                "```\n",
                "\n",
                "  * `\"search_generator_system\"` and `\"search_generator_user\"` are the names of the prompt files that you will have to write.\n",
                "  * `variables` is the dictionary we just created.\n",
                "\n",
                "The language model will read the prompts and the user’s query, then return a string that should look like a Python list of search queries.\n",
                "\n",
                "-----\n",
                "\n",
                "## Understanding and Validating Model Output\n",
                "\n",
                "The language model is supposed to return a Python list of strings, like this:\n",
                "\n",
                "```\n",
                "['health benefits of green tea', 'green tea antioxidants', 'green tea and weight loss', 'green tea side effects']\n",
                "```\n",
                "\n",
                "But sometimes, the output might not be exactly what we expect. We need to check and handle this.\n",
                "\n",
                "### 1\\. Evaluating the Output\n",
                "\n",
                "We use the **`eval()`** function to turn the string into a real Python list.\n",
                "\n",
                "```python\n",
                "try:\n",
                "    queries = eval(search_queries_str)\n",
                "    if not isinstance(queries, list):\n",
                "        raise ValueError(\"Not a list\")\n",
                "    return queries\n",
                "except Exception:\n",
                "    print(\"Invalid response for search queries:\", search_queries_str)\n",
                "    return []\n",
                "```\n",
                "\n",
                "  * `eval(search_queries_str)` tries to convert the string to a Python object.\n",
                "  * We check if the result is a list. If not, we raise an error.\n",
                "  * If anything goes wrong, we print an error message and return an **empty list**.\n",
                "\n",
                "This makes sure that our program only continues if we get a **valid list** of search queries.\n",
                "\n",
                "### 2\\. Why This Validation Is Important\n",
                "\n",
                "Language models can sometimes return results in the wrong format, especially if the prompt is not clear or if there is a mistake. By checking the output, we make sure our program doesn’t crash or use bad data.\n",
                "\n",
                "-----\n",
                "\n",
                "## Summary And What’s Next\n",
                "\n",
                "In this lesson, you learned how DeepResearcher uses OpenAI to generate a set of search queries from a user’s research topic. You saw how we:\n",
                "\n",
                "  * Collect the user’s input\n",
                "  * Prepare **variables** for the language model\n",
                "  * Use **prompt files** to guide the model\n",
                "  * **Validate the output** to make sure it’s a proper list of search queries\n",
                "\n",
                "These steps are essential for making sure our research tool starts with strong, relevant search queries. In the next set of practice exercises, you’ll get hands-on experience with generating and handling search queries yourself. This will help you see how good queries can lead to better research results."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Designing Prompts for Search Generation\n",
                "\n",
                "Let's move on to the heart of our search query generation system: the prompts! As we saw in the lesson, DeepResearcher uses two prompt files to guide the AI in generating useful search queries.\n",
                "\n",
                "In this exercise, you'll create the system and user prompts that tell the AI exactly what we need. These prompts are crucial because they directly influence the quality and format of the search queries the AI generates.\n",
                "\n",
                "Your task is to:\n",
                "\n",
                "Design a concise system prompt that establishes the AI's role as a research assistant.\n",
                "Create a detailed user prompt that includes the {{user_query}} variable.\n",
                "Make sure your user prompt clearly specifies the output format (a Python list of strings).\n",
                "Remember that good prompts are clear, specific, and focused on the task. The better your prompts, the more relevant and diverse search queries you'll get, which means better research results down the line!\n",
                "\n",
                "```python\n",
                "# search_generator_system prompt.txt\n",
                "# TODO: Write a system prompt that establishes the AI's role as a research assistant for generating search queries\n",
                "\n",
                "# search_generator_user prompt.txt\n",
                "# TODO: Create a user prompt that includes:\n",
                "# 1. The original user query using the {{user_query}} variable\n",
                "# 2. Clear instructions to generate up to four distinct, precise search queries\n",
                "# 3. A requirement to return only a Python list of strings (not in markdown)\n",
                "# 4. An example output format\n",
                "```\n",
                "\n",
                "This is a great task for testing how clear instructions can control the output of an LLM\\!\n",
                "\n",
                "Here is the design for the search query generation system prompts, as requested, focusing on clarity, the AI's role, and the specific Python list output format **without Markdown**.\n",
                "\n",
                "-----\n",
                "\n",
                "## 1\\. System Prompt (Role and Goal)\n",
                "\n",
                "This prompt establishes the AI's specific role as a dedicated machine for generating diverse and optimal search queries.\n",
                "\n",
                "```text\n",
                "# search_generator_system prompt.txt\n",
                "You are an expert, meticulous research assistant. Your sole function is to take a given high-level research query and transform it into a set of 1 to 4 distinct, precise, and effective search engine queries. The queries must be optimized for finding the most relevant and current information. You must only output a single, valid, executable Python list of strings, and nothing else.\n",
                "```\n",
                "\n",
                "-----\n",
                "\n",
                "## 2\\. User Prompt (Instructions and Format)\n",
                "\n",
                "This prompt provides detailed instructions, uses the `{{user_query}}` input variable, and strictly defines the desired raw Python list output format.\n",
                "\n",
                "````text\n",
                "# search_generator_user prompt.txt\n",
                "Based on the following user research query: \"{{user_query}}\", generate up to four (4) distinct, precise, and targeted search engine queries.\n",
                "\n",
                "Each query in the list must approach the topic from a different relevant angle to maximize research coverage. Do not repeat concepts and ensure the queries are highly specific.\n",
                "\n",
                "**Crucial Output Requirement:**\n",
                "You must return only a single, valid Python list of strings. Do not wrap the list in markdown code blocks (e.g., ```python), do not include any preamble, explanation, or conversational text. The output must be ready to be executed as a Python list object.\n",
                "\n",
                "Example output format for a query on 'global warming causes':\n",
                "['causes of global warming and effects', 'recent studies on anthropogenic climate change', 'natural versus human factors in global temperature rise', 'historical data on greenhouse gas emissions']\n",
                "````"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Generating and Parsing Search Queries\n",
                "\n",
                "Excellent work on creating those prompts! Now that you understand how to craft effective instructions for the AI, let's put everything together by implementing the actual search query generation function.\n",
                "\n",
                "In this exercise, you'll build the core function that powers the first step of our research tool: generating search queries from a user's topic.\n",
                "\n",
                "Your task is to complete the generate_initial_search_queries function by:\n",
                "\n",
                "Creating the variables dictionary to pass the user query to the prompts\n",
                "Calling the generate_response function with the correct parameters\n",
                "Convert the response to an array and return it\n",
                "This function is where all the pieces come together — the clean input, the well-designed prompts, and the handling of AI responses. Mastering this workflow will give you the foundation to build more complex AI-powered research tools!\n",
                "\n",
                "```python\n",
                "# main.py\n",
                "from deepresearcher.llm.llm_manager import generate_response\n",
                "from deepresearcher.web.web_searcher import clear_visited_pages\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    # TODO: Define variables dictionary to enrich the prompts\n",
                "    \n",
                "    # TODO: Call the generate_response function\n",
                "    \n",
                "    # TODO: eval() the result of the function and return it\n",
                "    queries = None\n",
                "    return queries\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    pass\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    pass\n",
                "\n",
                "\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    clear_visited_pages()\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        return\n",
                "\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "\n",
                "# search_generator_system prompt.txt\n",
                "You are a helpful and precise research assistant.\n",
                "\n",
                "# search_generator_user prompt.txt\n",
                "User Query: {{user_query}}\n",
                "\n",
                "You are an expert research assistant. Given the user's query, generate up to four distinct, precise search queries that would help gather comprehensive information on the topic. Return only a Python list of strings, for example: ['query1', 'query2', 'query3']. Do not return it in markdown format, just the strings.\n",
                "```\n",
                "\n",
                "This exercise is about implementing the core function to generate search queries using the provided `generate_response` utility and ensuring the output is correctly formatted as a Python list of strings.\n",
                "\n",
                "Here is the completed `generate_initial_search_queries` function:\n",
                "\n",
                "```python\n",
                "# main.py\n",
                "from deepresearcher.llm.llm_manager import generate_response\n",
                "from deepresearcher.web.web_searcher import clear_visited_pages\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    # 1. Define variables dictionary to enrich the prompts\n",
                "    variables = {\n",
                "        \"user_query\": user_query\n",
                "    }\n",
                "    \n",
                "    # 2. Call the generate_response function\n",
                "    # Note: Using the internal prompt file names assumed from the previous exercise\n",
                "    response_text = generate_response(\n",
                "        system_prompt_file=\"search_generator_system_prompt.txt\",\n",
                "        user_prompt_file=\"search_generator_user_prompt.txt\",\n",
                "        variables=variables\n",
                "    )\n",
                "    \n",
                "    # 3. eval() the result of the function and return it\n",
                "    # We use eval() because the prompt explicitly requests a raw, executable Python list.\n",
                "    try:\n",
                "        queries = eval(response_text)\n",
                "        \n",
                "        # Ensure the result is actually a list for robustness\n",
                "        if isinstance(queries, list):\n",
                "            return queries\n",
                "        else:\n",
                "            print(f\"Error: AI response was not a Python list. Received type: {type(queries)}\")\n",
                "            return []\n",
                "\n",
                "    except (SyntaxError, NameError) as e:\n",
                "        print(f\"Error parsing AI response '{response_text}' as a Python list: {e}\")\n",
                "        return []\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    pass\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    pass\n",
                "\n",
                "\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    clear_visited_pages()\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        return\n",
                "\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    # This section is for context and does not need to be executed here.\n",
                "    # The primary task was completing the generate_initial_search_queries function.\n",
                "    pass \n",
                "```\n",
                "\n",
                "### Key Implementation Details\n",
                "\n",
                "1.  **Variables Dictionary:** `variables = {\"user_query\": user_query}` correctly packages the input for template substitution in the user prompt.\n",
                "2.  **`generate_response` Call:** The function is called using assumed file names (`search_generator_system_prompt.txt` and `search_generator_user_prompt.txt`) and the created `variables`.\n",
                "3.  **`eval()` for Parsing:** Since the prompt strictly instructs the AI to return *only* a Python list literal (e.g., `['query1', 'query2']`), the Python built-in function `eval()` is used to safely parse that string output into an actual Python list object. Error handling is included to manage cases where the AI might deviate from the requested format."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Validating AI Responses for Robust Research\n",
                "\n",
                "Fantastic job with those prompts! Now that you've mastered creating clean input and effective prompts, let's focus on an equally important aspect: handling unexpected responses from the language model.\n",
                "\n",
                "In this exercise, you'll enhance the generate_initial_search_queries function by adding robust error handling. When working with AI models, we can't always guarantee they'll return data in the exact format we expect, so we need to validate their responses carefully.\n",
                "\n",
                "Your task is to:\n",
                "\n",
                "Add a try-except block around the eval() call to safely process the model's response\n",
                "Check whether the result is actually a list using isinstance()\n",
                "Print helpful error messages when something goes wrong\n",
                "Return an empty list in case of exceptions\n",
                "This might seem like a small addition, but it's a critical safety feature in any AI application. Without proper validation, unexpected responses could crash your program or even create security vulnerabilities when using functions like eval().\n",
                "\n",
                "By implementing this error handling, you'll make your research tool much more reliable and robust in real-world scenarios!\n",
                "\n",
                "```python\n",
                "# main.py\n",
                "from deepresearcher.llm.llm_manager import generate_response\n",
                "from deepresearcher.web.web_searcher import clear_visited_pages\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    variables = {\"user_query\": user_query}\n",
                "    search_queries_str = generate_response(\"search_generator_system\", \"search_generator_user\", variables)\n",
                "    # TODO: Add a try-except block around eval() to handle invalid responses\n",
                "    # TODO: Check if the result is a list using isinstance()\n",
                "    # TODO: Print an error message and return an empty list if something goes wrong\n",
                "    queries = eval(search_queries_str)\n",
                "    return queries\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    pass\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    pass\n",
                "\n",
                "\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    clear_visited_pages()\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        return\n",
                "\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "\n",
                "# search_generator_system prompt.txt\n",
                "You are a helpful and precise research assistant.\n",
                "\n",
                "# search_generator_user prompt.txt\n",
                "User Query: {{user_query}}\n",
                "\n",
                "You are an expert research assistant. Given the user's query, generate up to four distinct, precise search queries that would help gather comprehensive information on the topic. Return only a Python list of strings, for example: ['query1', 'query2', 'query3']. Do not return it in markdown format, just the strings.\n",
                "\n",
                "```\n",
                "\n",
                "That's a crucial step in building production-ready AI applications\\! Robust error handling ensures that unexpected outputs don't crash the system.\n",
                "\n",
                "Here is the completed `generate_initial_search_queries` function with the required **`try-except` block** and **`isinstance` validation** for a reliable research tool:\n",
                "\n",
                "```python\n",
                "# main.py\n",
                "from deepresearcher.llm.llm_manager import generate_response\n",
                "from deepresearcher.web.web_searcher import clear_visited_pages\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    variables = {\"user_query\": user_query}\n",
                "    # Assuming the prompt file names are 'search_generator_system.txt' and 'search_generator_user.txt'\n",
                "    search_queries_str = generate_response(\"search_generator_system\", \"search_generator_user\", variables)\n",
                "    \n",
                "    queries = []\n",
                "    \n",
                "    # Add a try-except block around eval() to handle invalid responses\n",
                "    try:\n",
                "        # Attempt to evaluate the response string into a Python object\n",
                "        raw_queries = eval(search_queries_str)\n",
                "        \n",
                "        # Check if the result is a list using isinstance()\n",
                "        if isinstance(raw_queries, list):\n",
                "            queries = raw_queries\n",
                "        else:\n",
                "            # Print an error message if the result is not a list\n",
                "            print(f\"⚠️ ERROR: AI returned data of type {type(raw_queries)} instead of a list. Full response: '{search_queries_str}'\")\n",
                "            return [] # Return an empty list on validation failure\n",
                "\n",
                "    # Catch common errors from eval() (e.g., SyntaxError, NameError)\n",
                "    except (SyntaxError, NameError, TypeError) as e:\n",
                "        # Print an error message and return an empty list if something goes wrong\n",
                "        print(f\"❌ ERROR: Failed to parse AI response as a valid Python list. Error details: {e}\")\n",
                "        print(f\"   Raw AI Response: '{search_queries_str}'\")\n",
                "        return [] # Return an empty list on exception\n",
                "\n",
                "    return queries\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    pass\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    pass\n",
                "\n",
                "\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    clear_visited_pages()\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        return\n",
                "\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    # This section is for context and does not need to be executed here.\n",
                "    # The primary task was completing the generate_initial_search_queries function.\n",
                "    pass\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Testing Your Search Query Generator\n",
                "\n",
                "Cosmo\n",
                "Just now\n",
                "Read message aloud\n",
                "Excellent work on implementing error handling! Now that you've built all the essential components, it's time to put your system to the test with real research topics.\n",
                "\n",
                "In this exercise, you'll create a testing script that evaluates your search query generation system with multiple diverse topics. This will help you verify that your implementation works reliably across different types of research questions.\n",
                "\n",
                "Your task is to complete the app.py file by:\n",
                "\n",
                "Adding at least three diverse research topics to test your system\n",
                "Implementing the test function to display the generated queries for each topic\n",
                "Testing your implementation with various topics is a crucial step in developing AI-powered tools. It helps you identify potential issues and understand how your system performs in real-world scenarios. By the end of this exercise, you'll have confidence that your search query generator is ready to power a complete research tool!\n",
                "\n",
                "```python\n",
                "# app.py\n",
                "from deepresearcher.main import generate_initial_search_queries\n",
                "\n",
                "\n",
                "def test_search_queries(topics):\n",
                "    \"\"\"\n",
                "    Test the search query generation with multiple research topics.\n",
                "    \n",
                "    Args:\n",
                "        topics (list): A list of research topics to test\n",
                "    \"\"\"\n",
                "    print(\"===== TESTING SEARCH QUERY GENERATION =====\")\n",
                "    print(f\"Testing {len(topics)} different research topics\\n\")\n",
                "    \n",
                "    for i, topic in enumerate(topics, 1):\n",
                "        print(f\"TOPIC {i}: '{topic}'\")\n",
                "        print(\"-\" * 50)\n",
                "        \n",
                "        # TODO: Generate search queries for this topic using generate_initial_search_queries\n",
                "        \n",
                "        # TODO: Display the results, including the number of queries generated\n",
                "        # If no queries were generated, display an appropriate message\n",
                "        \n",
                "        print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
                "    \n",
                "    # Summary\n",
                "    print(\"Testing complete!\")\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    # TODO: Define at least 3 diverse research topics to test\n",
                "    research_topics = [\n",
                "        # Add your research topics here\n",
                "    ]\n",
                "    \n",
                "    # TODO: Run the test function with your research topics\n",
                "\n",
                "# search_generator_system prompt.txt\n",
                "You are a helpful and precise research assistant.\n",
                "\n",
                "# search_generator_user prompt.txt\n",
                "User Query: {{user_query}}\n",
                "\n",
                "You are an expert research assistant. Given the user's query, generate up to four distinct, precise search queries that would help gather comprehensive information on the topic. Return only a Python list of strings, for example: ['query1', 'query2', 'query3']. Do not return it in markdown format, just the strings.\n",
                "\n",
                "```\n",
                "\n",
                "This final exercise is about creating a robust testing harness for the implemented query generator. It involves defining diverse test cases and implementing the logic to call and display the results of your `generate_initial_search_queries` function.\n",
                "\n",
                "Here is the completed `app.py` file:\n",
                "\n",
                "```python\n",
                "# app.py\n",
                "from deepresearcher.main import generate_initial_search_queries\n",
                "\n",
                "\n",
                "def test_search_queries(topics: list):\n",
                "    \"\"\"\n",
                "    Test the search query generation with multiple research topics.\n",
                "    \n",
                "    Args:\n",
                "        topics (list): A list of research topics to test\n",
                "    \"\"\"\n",
                "    print(\"===== TESTING SEARCH QUERY GENERATION =====\")\n",
                "    print(f\"Testing {len(topics)} different research topics\\n\")\n",
                "    \n",
                "    for i, topic in enumerate(topics, 1):\n",
                "        print(f\"TOPIC {i}: '{topic}'\")\n",
                "        print(\"-\" * 50)\n",
                "        \n",
                "        # Generate search queries for this topic using generate_initial_search_queries\n",
                "        queries = generate_initial_search_queries(topic)\n",
                "        \n",
                "        # Display the results, including the number of queries generated\n",
                "        num_queries = len(queries)\n",
                "        \n",
                "        if num_queries > 0:\n",
                "            print(f\"✅ Generated {num_queries} relevant queries:\")\n",
                "            for j, query in enumerate(queries):\n",
                "                print(f\"   [{j + 1}] {query}\")\n",
                "        else:\n",
                "            print(\"❌ Failed to generate any valid search queries or parsing failed.\")\n",
                "            \n",
                "        print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
                "    \n",
                "    # Summary\n",
                "    print(\"Testing complete! Check the output for query relevance and quantity.\")\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    # Define at least 3 diverse research topics to test\n",
                "    research_topics = [\n",
                "        \"The impact of 5G on supply chain logistics and warehouse automation.\",\n",
                "        \"What are the ethical implications of using deepfake technology in political campaigns?\",\n",
                "        \"Comparative analysis of the two-factor authentication methods used by major social media platforms.\",\n",
                "        # Bonus topic for further testing: a simple, non-technical query\n",
                "        \"Best practices for pruning roses in a temperate climate.\"\n",
                "    ]\n",
                "    \n",
                "    # Run the test function with your research topics\n",
                "    test_search_queries(research_topics)\n",
                "```"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
