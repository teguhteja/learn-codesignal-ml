{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Unit 1"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setting Up the Basic Structure for DeepResearcher\n",
                "\n",
                "## Introduction: Laying the Foundation for DeepResearcher\n",
                "\n",
                "Welcome to the first lesson of the \"**Creating a Researcher in Python with OpenAI**\" course\\! In this course, you'll learn how to build **DeepResearcher**, an AI-powered research tool that can search the web, gather information, and generate a final report â€” all using **Python**.\n",
                "\n",
                "Before we dive into the details of web searching and AI, itâ€™s important to set up a solid foundation. A clear project structure will help you keep your code organized, make it easier to add new features, and help you debug problems as you go. In this lesson, weâ€™ll walk through the basic structure of the **DeepResearcher** project and explain how the main program is set up.\n",
                "\n",
                "By the end of this lesson, youâ€™ll understand how the main parts of the project fit together and be ready to start building out each piece in future lessons.\n",
                "\n",
                "-----\n",
                "\n",
                "## Recall: Project Flowchart\n",
                "\n",
                "Letâ€™s start with a quick reminder about how the DeepResearcher works:\n",
                "\n",
                "| Step | Action | Decision | Next Step (Yes) | Next Step (No) |\n",
                "| :--- | :--- | :--- | :--- | :--- |\n",
                "| 1 | **User Input: Research Query** | | **LLM: Generate Search Queries** | |\n",
                "| 2 | **LLM: Generate Search Queries** | | **Web: Get top Search Results** | |\n",
                "| 3 | **Web: Get top Search Results** | | **Web: Download HTML** | |\n",
                "| 4 | **Web: Download HTML** | | **Web: Convert to Markdown** | |\n",
                "| 5 | **Web: Convert to Markdown** | **Is it Relevant?** | **LLM: Extract Relevant Context** | **Delete entry** |\n",
                "| 6 | **LLM: Extract Relevant Context** | **More Research Needed?** | **LLM: Generate Search Queries** (Go to Step 2) | **LLM: Generate Final Report** |\n",
                "| 7 | **LLM: Generate Final Report** | | **Output: Research Report** | |\n",
                "\n",
                "This flowchart illustrates the step-by-step process, showing how each component fits into the overall workflow. The **LLM** (Language Model) and **Web** components work together to automate the research process.\n",
                "\n",
                "-----\n",
                "\n",
                "## Understanding the Main Program\n",
                "\n",
                "Now, letâ€™s look at the main file of our project: **main.py**. This file is the entry point for DeepResearcher. Itâ€™s where the program starts running.\n",
                "\n",
                "Letâ€™s break down the key parts of this file step by step.\n",
                "\n",
                "### 1\\. Importing Functions\n",
                "\n",
                "At the top of the file, we import a function from another part of our project:\n",
                "\n",
                "```python\n",
                "from deepresearcher.web.web_searcher import clear_visited_pages\n",
                "```\n",
                "\n",
                "This allows us to use the **`clear_visited_pages`** function in our main program.\n",
                "\n",
                "### 2\\. Defining Function Stubs\n",
                "\n",
                "Next, we see several function definitions. Right now, these functions are just \"**stubs**\" â€” they don't do anything yet, but they show what the main steps of our program will be.\n",
                "\n",
                "```python\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    pass\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    pass\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    pass\n",
                "```\n",
                "\n",
                "  * **`generate_initial_search_queries`**: This will take the user's research topic and create a list of search queries.\n",
                "  * **`perform_iterative_research`**: This will handle the main research loop, searching the web and collecting information.\n",
                "  * **`generate_final_report`**: This will take all the information weâ€™ve gathered and create a final report.\n",
                "\n",
                "The **`pass`** statement is a placeholder. It means \"do nothing for now.\" Weâ€™ll fill in these functions in later lessons.\n",
                "\n",
                "### 3\\. The Main Function\n",
                "\n",
                "The main logic of the program is inside the **`research_main()`** function:\n",
                "\n",
                "```python\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    clear_visited_pages()\n",
                "\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        return\n",
                "\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "\n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "```\n",
                "\n",
                "Here's a breakdown of what happens:\n",
                "\n",
                "1.  The program asks the user for a research topic and an iteration limit.\n",
                "2.  It **clears any previously visited web pages**.\n",
                "3.  It generates the **first set of search queries**.\n",
                "4.  If no search queries are generated, it stops.\n",
                "5.  It copies the search queries to keep track of **all queries** used.\n",
                "6.  It performs the **main research loop**.\n",
                "7.  Finally, it **generates a report**.\n",
                "\n",
                "### 4\\. Running the Program\n",
                "\n",
                "At the bottom, we see:\n",
                "\n",
                "```python\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "```\n",
                "\n",
                "This means: \"If this file is run directly, start the program by calling **`research_main()`**.\"\n",
                "\n",
                "-----\n",
                "\n",
                "## Summary and What's Next\n",
                "\n",
                "In this lesson, you learned how to set up the basic structure for the **DeepResearcher** project. You saw how the main program is organized, what each function is responsible for, and how the program flows from user input to generating a final report.\n",
                "\n",
                "This structure will make it much easier to build and test each part of the project as we move forward. In the next practice exercises, you'll get hands-on experience working with this structure and preparing your own project files. After that, we'll start filling in each function to bring DeepResearcher to life, step by step. ðŸš€"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Building the DeepResearcher Framework\n",
                "\n",
                "Now that you understand how the DeepResearcher project is structured, let's put that knowledge into practice! In this exercise, you'll create the skeleton of our main program file with function stubs that will serve as the foundation for our research tool.\n",
                "\n",
                "You'll need to set up:\n",
                "\n",
                "Three function stubs for the core operations (generating queries, performing research, and creating reports)\n",
                "The main research function that coordinates the workflow\n",
                "Code to run the program when the file is executed directly\n",
                "Don't worry about implementing the actual functionality yet â€” we're just creating placeholders with pass statements for now. This structure will serve as the blueprint for all the exciting features we'll add in the upcoming exercises.\n",
                "\n",
                "Building this framework is an important first step â€” it will help you visualize how all the pieces fit together before we dive into the details of each component.\n",
                "\n",
                "```python\n",
                "from deepresearcher.web.web_searcher import clear_visited_pages\n",
                "\n",
                "\n",
                "# TODO: Create a function stub for generate_initial_search_queries that takes a user_query parameter\n",
                "\n",
                "\n",
                "# TODO: Create a function stub for perform_iterative_research that takes user_query, new_search_queries, all_search_queries, and iteration_limit parameters\n",
                "\n",
                "\n",
                "# TODO: Create a function stub for generate_final_report that takes user_query and contexts parameters\n",
                "\n",
                "\n",
                "# TODO: Create the research_main function\n",
                "\n",
                "\n",
                "# TODO: Add code to run the research_main function if this file is executed directly\n",
                "```\n",
                "\n",
                "Here is the completed Python framework for the **DeepResearcher** project, including the required function stubs and the main execution logic.\n",
                "\n",
                "```python\n",
                "from deepresearcher.web.web_searcher import clear_visited_pages\n",
                "\n",
                "\n",
                "# 1. Function stub for generate_initial_search_queries\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    \"\"\"Generates the first set of search queries based on the user's topic.\"\"\"\n",
                "    pass\n",
                "\n",
                "\n",
                "# 2. Function stub for perform_iterative_research\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    \"\"\"Handles the main iterative research loop.\"\"\"\n",
                "    pass\n",
                "\n",
                "\n",
                "# 3. Function stub for generate_final_report\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    \"\"\"Generates the final research report from the gathered contexts.\"\"\"\n",
                "    pass\n",
                "\n",
                "\n",
                "# 4. The main research function\n",
                "def research_main():\n",
                "    # Get user input for query and iteration limit\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    # Clear previously visited pages\n",
                "    clear_visited_pages()\n",
                "\n",
                "    # Generate initial search queries\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    if not new_search_queries:\n",
                "        print(\"No initial queries generated. Exiting.\")\n",
                "        return\n",
                "\n",
                "    # Keep track of all queries used\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "\n",
                "    # Perform the main research loop\n",
                "    aggregated_contexts = perform_iterative_research(\n",
                "        user_query, \n",
                "        new_search_queries, \n",
                "        all_search_queries, \n",
                "        iteration_limit\n",
                "    )\n",
                "\n",
                "    # Generate the final report\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "    \n",
                "    print(\"\\nDeepResearcher process complete.\")\n",
                "\n",
                "\n",
                "# 5. Add code to run the research_main function if this file is executed directly\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "```\n",
                "\n",
                "This file now provides the complete **blueprint** for the DeepResearcher, clearly defining the **flow** from user input to the final report, with placeholders ready to be filled in with the actual logic in later lessons."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Implementing the Main Research Workflow\n",
                "\n",
                "Now that you've created the basic framework for DeepResearcher, let's implement the main workflow function that will coordinate the entire research process. With the function stubs already in place, your job is to build the research_main() function that ties everything together.\n",
                "\n",
                "In this exercise, you'll need to:\n",
                "\n",
                "Collect user input for the research topic and iteration limit\n",
                "Process the iteration limit properly (convert to int or use the default)\n",
                "Call each of our core functions in the correct sequence\n",
                "This exercise helps you understand how the different components of DeepResearcher work together in a coordinated workflow. By implementing the main function, you'll get a clearer picture of how data flows through the system, from user input to the final report.\n",
                "\n",
                "```python\n",
                "from deepresearcher.web.web_searcher import clear_visited_pages\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    pass\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    pass\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    pass\n",
                "\n",
                "\n",
                "# TODO: Create the research_main function that handles user input and coordinates the research process\n",
                "def research_main():\n",
                "    # TODO: Get the user's research query\n",
                "    \n",
                "    # TODO: Get the maximum number of iterations from the user (with a default of 10)\n",
                "    \n",
                "    # TODO: Convert the iteration limit to an integer if it's a valid number, otherwise use 10\n",
                "    \n",
                "    # TODO: Call other functions in correct order\n",
                "\n",
                "```\n",
                "\n",
                "I see you want to implement the `research_main()` function to coordinate the workflow. You already have the function stubs defined. Below is the completed `research_main()` function following the project's required logic.\n",
                "\n",
                "```python\n",
                "from deepresearcher.web.web_searcher import clear_visited_pages\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    pass\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    pass\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    pass\n",
                "\n",
                "\n",
                "# Completed research_main function that handles user input and coordinates the research process\n",
                "def research_main():\n",
                "    # 1. Get the user's research query\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "\n",
                "    # 2. Get the maximum number of iterations from the user (with a default of 10)\n",
                "    iteration_limit_input = input(\"Max number of iterations (default 10): \").strip()\n",
                "\n",
                "    # 3. Convert the iteration limit to an integer if it's a valid number, otherwise use 10\n",
                "    if iteration_limit_input.isdigit():\n",
                "        iteration_limit = int(iteration_limit_input)\n",
                "    else:\n",
                "        iteration_limit = 10\n",
                "    \n",
                "    # Optional: Print initial settings for confirmation\n",
                "    print(f\"\\nStarting DeepResearcher for: '{user_query}' with max iterations: {iteration_limit}\")\n",
                "\n",
                "    # 4. Call other functions in correct order\n",
                "\n",
                "    # Clear visited pages before starting a new run\n",
                "    clear_visited_pages()\n",
                "\n",
                "    # Step A: Generate initial search queries\n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    \n",
                "    if not new_search_queries:\n",
                "        print(\"No initial queries generated. Exiting.\")\n",
                "        return\n",
                "\n",
                "    # Keep a list of ALL queries used throughout the process\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "\n",
                "    # Step B: Perform the main iterative research loop\n",
                "    aggregated_contexts = perform_iterative_research(\n",
                "        user_query, \n",
                "        new_search_queries, \n",
                "        all_search_queries, \n",
                "        iteration_limit\n",
                "    )\n",
                "\n",
                "    # Step C: Generate the final report\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "    \n",
                "    print(\"\\nDeepResearcher process complete.\")\n",
                "\n",
                "# Example of how the program would run if executed directly\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Adding Error Handling to DeepResearcher\n",
                "\n",
                "Excellent work on implementing the main workflow function! Now, let's make our DeepResearcher more robust by adding some essential error handling. With the basic structure in place, we need to ensure our program can handle unexpected situations gracefully.\n",
                "\n",
                "In this exercise, you'll add two important safety features to the research_main() function:\n",
                "\n",
                "Add a call to clear_visited_pages() to reset any previously visited web pages.\n",
                "Implement a check that verifies whether any search queries were generated, and stop the program if none were found.\n",
                "These small but critical additions will help prevent errors and make your research tool more reliable. Good error handling is what separates professional applications from basic scripts â€” it ensures your program can handle real-world scenarios without crashing.\n",
                "\n",
                "```python\n",
                "from deepresearcher.web.web_searcher import clear_visited_pages\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    pass\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    pass\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    pass\n",
                "\n",
                "\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    # TODO: Add a call to clear_visited_pages() to reset previously visited web pages\n",
                "    \n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    # TODO: Add a check to see if new_search_queries is empty, and if so, return from the function\n",
                "\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "\n",
                "```\n",
                "\n",
                "You're absolutely right; adding error handling makes the program much more reliable\\! Here is the updated `research_main()` function with the call to `clear_visited_pages()` and the check for empty search queries implemented.\n",
                "\n",
                "```python\n",
                "from deepresearcher.web.web_searcher import clear_visited_pages\n",
                "\n",
                "\n",
                "def generate_initial_search_queries(user_query: str):\n",
                "    # In a real scenario, this would return a list of strings\n",
                "    # For testing the error check, we'll assume it returns an empty list if the query is blank\n",
                "    if not user_query:\n",
                "        return []\n",
                "    return [\"query 1\", \"query 2\"] # Placeholder\n",
                "\n",
                "\n",
                "def perform_iterative_research(user_query: str, new_search_queries: list, all_search_queries: list, iteration_limit: int):\n",
                "    pass\n",
                "\n",
                "\n",
                "def generate_final_report(user_query: str, contexts: list):\n",
                "    pass\n",
                "\n",
                "\n",
                "def research_main():\n",
                "    user_query = input(\"Enter your research query/topic: \").strip()\n",
                "    iteration_limit = input(\"Max number of iterations (default 10): \").strip()\n",
                "    iteration_limit = int(iteration_limit) if iteration_limit.isdigit() else 10\n",
                "\n",
                "    # 1. Add a call to clear_visited_pages() to reset previously visited web pages\n",
                "    print(\"Clearing visited pages...\")\n",
                "    clear_visited_pages()\n",
                "    \n",
                "    new_search_queries = generate_initial_search_queries(user_query)\n",
                "    \n",
                "    # 2. Add a check to see if new_search_queries is empty, and if so, return from the function\n",
                "    if not new_search_queries:\n",
                "        print(\"Error: No initial search queries were generated. Aborting research process.\")\n",
                "        return # Exit the function gracefully\n",
                "\n",
                "    # If queries were generated, proceed with the workflow\n",
                "    all_search_queries = new_search_queries.copy()\n",
                "    \n",
                "    print(f\"Generated {len(new_search_queries)} initial queries. Starting research loop...\")\n",
                "    \n",
                "    aggregated_contexts = perform_iterative_research(user_query, new_search_queries, all_search_queries, iteration_limit)\n",
                "    generate_final_report(user_query, aggregated_contexts)\n",
                "    \n",
                "    print(\"DeepResearcher workflow finished.\")\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    research_main()\n",
                "```\n",
                "\n",
                "### Explanation of Changes:\n",
                "\n",
                "1.  **`clear_visited_pages()` Call:** It's placed right before the main research steps begin. This ensures that every time a new research job starts, it's not biased by or limited by data from a previous run.\n",
                "2.  **Empty Query Check:** The code uses `if not new_search_queries:` which is the Pythonic way to check if a list is empty. If it is, a message is printed to the user, and the `return` statement immediately **stops the execution** of `research_main()`, preventing the program from crashing on subsequent lines that rely on having valid queries (like `new_search_queries.copy()`)."
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
